
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>2.2: Load Required Functions &#8212; torchIQNx4</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">torchIQNx4</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to the torchIQNx4
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="1_Setup_and_Preprocess.html">
   IQNx4: Chapter 1. Setup and Preprocess
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2_Train_all_IQNs.html">
   IQNx4 Chapter 2: Train All Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3_Autoregressive_Evaluation.html">
   IQNx4: Chapter 3: Autoregressive Evaluation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="4_SupplementaryMaterials_OptunaTuning_Theory_ML_Background.html">
   Chapter 4: Optional Supplementary Material
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="5_Normalizing_Flows.html">
   train
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/AliAlkadhim/torchQN/HEAD?labpath=JupyterBook/v2/gh/AliAlkadhim/torchQN/master?urlpath=tree/JupyterBook/alphaDavidson_IQNx4.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/alphaDavidson_IQNx4.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   2.2: Load Required Functions
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-data-split-scale-and-train-mass">
   2.3 Load Data, split, scale, and Train Mass
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-mass">
     Train Mass
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-model-that-needs-the-longest-time-in-training-is-mass-click-here-to-scroll-down-to-train-p-t">
       The model that needs the longest time in training is mass. Click here to scroll down to train
       <span class="math notranslate nohighlight">
        \(p_T\)
       </span>
       .
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluate-mass">
   Evaluate Mass
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#needed-functions">
     Needed functions
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>2.2: Load Required Functions</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   2.2: Load Required Functions
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-data-split-scale-and-train-mass">
   2.3 Load Data, split, scale, and Train Mass
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-mass">
     Train Mass
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-model-that-needs-the-longest-time-in-training-is-mass-click-here-to-scroll-down-to-train-p-t">
       The model that needs the longest time in training is mass. Click here to scroll down to train
       <span class="math notranslate nohighlight">
        \(p_T\)
       </span>
       .
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluate-mass">
   Evaluate Mass
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#needed-functions">
     Needed functions
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">subprocess</span> <span class="k">as</span> <span class="nn">sb</span>
<span class="n">COLAB</span><span class="o">=</span><span class="kc">True</span>
<span class="k">if</span> <span class="n">COLAB</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
  <span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
  <span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive&#39;</span><span class="p">)</span>
    <span class="c1">#pwd=/content</span>
  <span class="n">sb</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s1">&#39;mkdir -p drive/MyDrive/IQNx4/utils&#39;</span><span class="p">,</span> <span class="n">shell</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;IQN_BASE&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s1">&#39;drive&#39;</span><span class="p">,</span> <span class="s1">&#39;MyDrive&#39;</span><span class="p">,</span> <span class="s1">&#39;IQNx4&#39;</span><span class="p">)</span>
  <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;DATA_DIR&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s1">&#39;drive&#39;</span><span class="p">,</span> <span class="s1">&#39;MyDrive&#39;</span><span class="p">,</span> <span class="s1">&#39;IQNx4&#39;</span><span class="p">)</span>
  <span class="n">sp</span><span class="o">=</span><span class="n">sb</span><span class="o">.</span><span class="n">Popen</span><span class="p">(</span><span class="s1">&#39;tree drive/MyDrive&#39;</span><span class="p">,</span> <span class="n">shell</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stdout</span><span class="o">=</span><span class="n">sb</span><span class="o">.</span><span class="n">PIPE</span><span class="p">,</span> <span class="n">stderr</span><span class="o">=</span><span class="n">sb</span><span class="o">.</span><span class="n">PIPE</span><span class="p">)</span>
  <span class="n">out</span><span class="p">,</span><span class="n">err</span><span class="o">=</span><span class="n">sp</span><span class="o">.</span><span class="n">communicate</span><span class="p">();</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Downloading Environment&#39;</span><span class="p">)</span><span class="c1">#sudo apt update &amp;&amp; sudo apt upgrade &amp;&amp; </span>
  <span class="n">sb</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s1">&#39;sudo apt-get update &amp;&amp; sudo apt install wget pandoc dvipng texlive-xetex texlive-fonts-recommended cm-super&#39;</span><span class="p">,</span> <span class="n">shell</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="c1">#download utils.py from github</span>
  <span class="n">utils_url</span><span class="o">=</span><span class="s1">&#39;https://raw.githubusercontent.com/AliAlkadhim/torchQN/master/utils/utils.py&#39;</span>
  <span class="n">sb</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s1">&#39;wget </span><span class="si">%s</span><span class="s1"> drive/MyDrive/IQNx4/utils&#39;</span> <span class="o">%</span> <span class="n">utils_url</span><span class="p">,</span> <span class="n">shell</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mounted at /content/drive

 b&#39;&#39;
Downloading Environment
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!nvidia-smi
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Thu Jan 19 01:38:05 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |
| N/A   53C    P0    27W /  70W |      0MiB / 15109MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!lscpu
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Architecture:                    x86_64
CPU op-mode(s):                  32-bit, 64-bit
Byte Order:                      Little Endian
Address sizes:                   46 bits physical, 48 bits virtual
CPU(s):                          4
On-line CPU(s) list:             0-3
Thread(s) per core:              2
Core(s) per socket:              2
Socket(s):                       1
NUMA node(s):                    1
Vendor ID:                       GenuineIntel
CPU family:                      6
Model:                           85
Model name:                      Intel(R) Xeon(R) CPU @ 2.00GHz
Stepping:                        3
CPU MHz:                         2000.186
BogoMIPS:                        4000.37
Hypervisor vendor:               KVM
Virtualization type:             full
L1d cache:                       64 KiB
L1i cache:                       64 KiB
L2 cache:                        2 MiB
L3 cache:                        38.5 MiB
NUMA node0 CPU(s):               0-3
Vulnerability Itlb multihit:     Not affected
Vulnerability L1tf:              Mitigation; PTE Inversion
Vulnerability Mds:               Vulnerable; SMT Host state unknown
Vulnerability Meltdown:          Vulnerable
Vulnerability Mmio stale data:   Vulnerable
Vulnerability Retbleed:          Vulnerable
Vulnerability Spec store bypass: Vulnerable
Vulnerability Spectre v1:        Vulnerable: __user pointer sanitization and use
                                 rcopy barriers only; no swapgs barriers
Vulnerability Spectre v2:        Vulnerable, IBPB: disabled, STIBP: disabled, PB
                                 RSB-eIBRS: Not affected
Vulnerability Srbds:             Not affected
Vulnerability Tsx async abort:   Vulnerable
Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtr
                                 r pge mca cmov pat pse36 clflush mmx fxsr sse s
                                 se2 ss ht syscall nx pdpe1gb rdtscp lm constant
                                 _tsc rep_good nopl xtopology nonstop_tsc cpuid 
                                 tsc_known_freq pni pclmulqdq ssse3 fma cx16 pci
                                 d sse4_1 sse4_2 x2apic movbe popcnt aes xsave a
                                 vx f16c rdrand hypervisor lahf_lm abm 3dnowpref
                                 etch invpcid_single ssbd ibrs ibpb stibp fsgsba
                                 se tsc_adjust bmi1 hle avx2 smep bmi2 erms invp
                                 cid rtm mpx avx512f avx512dq rdseed adx smap cl
                                 flushopt clwb avx512cd avx512bw avx512vl xsaveo
                                 pt xsavec xgetbv1 xsaves arat md_clear arch_cap
                                 abilities
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># import scipy as sp; import scipy.stats as st</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;using torch version </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span><span class="c1">#old torch version: 1.9.0</span>
<span class="c1"># use numba&#39;s just-in-time compiler to speed things up</span>
<span class="c1"># from numba import njit</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mp</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;matplotlib version= &quot;</span><span class="p">,</span> <span class="n">mp</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># reset matplotlib stle/parameters</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>

<span class="c1"># reset matplotlib parameters to their defaults</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">mpl</span><span class="o">.</span><span class="n">rcParamsDefault</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;seaborn-deep&quot;</span><span class="p">)</span>
<span class="n">mp</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;agg.path.chunksize&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">font_legend</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">font_axes</span> <span class="o">=</span> <span class="mi">15</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="c1">#or use joblib for caching on disk</span>
<span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span>  <span class="n">Memory</span>
<span class="c1"># from IPython.display import Image, display</span>
<span class="c1"># from importlib import import_module</span>
<span class="c1"># import plotly</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">optuna</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;using (optional) optuna version </span><span class="si">{</span><span class="n">optuna</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;optuna is only used for hyperparameter tuning, not critical!&quot;</span><span class="p">)</span>
    <span class="k">pass</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c1"># import sympy as sy</span>
<span class="c1"># import ipywidgets as wid;</span>


<span class="c1"># try:</span>
<span class="c1">#     IQN_BASE = os.environ[&quot;IQN_BASE&quot;]</span>
<span class="c1">#     print(&quot;BASE directoy properly set = &quot;, IQN_BASE)</span>
<span class="c1">#     utils_dir = os.path.join(IQN_BASE, &quot;utils/&quot;)</span>
<span class="c1">#     sys.path.append(utils_dir)</span>
<span class="c1">#     import utils</span>

<span class="c1">#     # usually its not recommended to import everything from a module, but we know</span>
<span class="c1">#     # whats in it so its fine</span>
<span class="c1">#     from utils import *</span>

<span class="c1">#     print(&quot;DATA directory also properly set, in %s&quot; % os.environ[&quot;DATA_DIR&quot;])</span>
<span class="c1"># except Exception:</span>
<span class="c1">#     # IQN_BASE=os.getcwd()</span>
<span class="c1">#     print(</span>
<span class="c1">#         &quot;&quot;&quot;\nBASE directory not properly set. Read repo README.    If you need a function from utils, use the decorator below, or add utils to sys.path\n</span>
<span class="c1">#     You can also do </span>
<span class="c1">#     os.environ[&#39;IQN_BASE&#39;]=&lt;ABSOLUTE PATH FOR THE IQN REPO&gt;</span>
<span class="c1">#     or</span>
<span class="c1">#     os.environ[&#39;IQN_BASE&#39;]=os.getcwd()&quot;&quot;&quot;</span>
<span class="c1">#     )</span>
<span class="c1">#     pass</span>




<span class="c1"># from IPython.core.magic import register_cell_magic</span>


<span class="c1"># @debug</span>
<span class="c1"># def get_model_params_simple():</span>
<span class="c1">#     dropout=0.2</span>
<span class="c1">#     n_layers = 2</span>
<span class="c1">#     n_hidden=32</span>
<span class="c1">#     starting_learning_rate=1e-3</span>
<span class="c1">#     print(&#39;n_iterations, n_layers, n_hidden, starting_learning_rate, dropout&#39;)</span>
<span class="c1">#     return n_iterations, n_layers, n_hidden, starting_learning_rate, dropout</span>


<span class="c1"># update fonts</span>
<span class="n">FONTSIZE</span> <span class="o">=</span> <span class="mi">14</span>
<span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;family&quot;</span><span class="p">:</span> <span class="s2">&quot;serif&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">:</span> <span class="s2">&quot;normal&quot;</span><span class="p">,</span> <span class="s2">&quot;size&quot;</span><span class="p">:</span> <span class="n">FONTSIZE</span><span class="p">}</span>
<span class="n">mp</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s2">&quot;font&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>

<span class="c1"># set usetex = False if LaTex is not</span>
<span class="c1"># available on your system or if the</span>
<span class="c1"># rendering is too slow</span>
<span class="n">mp</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="n">usetex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># set a seed to ensure reproducibility</span>
<span class="c1"># seed = 128</span>
<span class="c1"># rnd  = np.random.RandomState(seed)</span>
<span class="c1"># sometimes jupyter doesnt initialize MathJax automatically for latex, so do this:</span>
<span class="c1">#######</span>



<span class="n">IQN_BASE</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;IQN_BASE&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">BASE directoy properly set = &quot;</span><span class="p">,</span> <span class="n">IQN_BASE</span><span class="p">)</span>
<span class="n">utils_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">IQN_BASE</span><span class="p">,</span> <span class="s2">&quot;utils/&quot;</span><span class="p">)</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">utils_dir</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">utils</span>

<span class="c1"># usually its not recommended to import everything from a module, but we know</span>
<span class="c1"># whats in it so its fine</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">DATA_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;DATA_DIR&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;using DATA_DIR=</span><span class="si">{</span><span class="n">DATA_DIR</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">memory</span> <span class="o">=</span> <span class="n">Memory</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">)</span>
<span class="c1">################################### SET DATA CONFIGURATIONS ###################################</span>

<span class="n">y_label_dict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;RecoDatapT&quot;</span><span class="p">:</span> <span class="s2">&quot;$p(p_T)$&quot;</span> <span class="o">+</span> <span class="s2">&quot; [ GeV&quot;</span> <span class="o">+</span> <span class="s2">&quot;$^{-1} $&quot;</span> <span class="o">+</span> <span class="s2">&quot;]&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RecoDataeta&quot;</span><span class="p">:</span> <span class="s2">&quot;$p(\eta)$&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RecoDataphi&quot;</span><span class="p">:</span> <span class="s2">&quot;$p(\phi)$&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RecoDatam&quot;</span><span class="p">:</span> <span class="s2">&quot;$p(m)$&quot;</span> <span class="o">+</span> <span class="s2">&quot; [ GeV&quot;</span> <span class="o">+</span> <span class="s2">&quot;$^{-1} $&quot;</span> <span class="o">+</span> <span class="s2">&quot;]&quot;</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">loss_y_label_dict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;RecoDatapT&quot;</span><span class="p">:</span> <span class="s2">&quot;$p_T^</span><span class="si">{reco}</span><span class="s2">$&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RecoDataeta&quot;</span><span class="p">:</span> <span class="s2">&quot;$\eta^</span><span class="si">{reco}</span><span class="s2">$&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RecoDataphi&quot;</span><span class="p">:</span> <span class="s2">&quot;$\phi^</span><span class="si">{reco}</span><span class="s2">$&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RecoDatam&quot;</span><span class="p">:</span> <span class="s2">&quot;$m^</span><span class="si">{reco}</span><span class="s2">$&quot;</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;genDatapT&quot;</span><span class="p">,</span> <span class="s2">&quot;genDataeta&quot;</span><span class="p">,</span> <span class="s2">&quot;genDataphi&quot;</span><span class="p">,</span> <span class="s2">&quot;genDatam&quot;</span><span class="p">,</span> <span class="s2">&quot;tau&quot;</span><span class="p">]</span>

<span class="c1"># set order of training:</span>
<span class="c1"># pT_first: pT-&gt;&gt;m-&gt;eta-&gt;phi</span>
<span class="c1"># m_first: m-&gt;pT-&gt;eta-&gt;phi</span>


<span class="n">ORDER</span> <span class="o">=</span> <span class="s2">&quot;m_First&quot;</span>

<span class="k">if</span> <span class="n">ORDER</span> <span class="o">==</span> <span class="s2">&quot;m_First&quot;</span><span class="p">:</span>
    <span class="n">FIELDS</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;RecoDatam&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span>
            <span class="s2">&quot;xlabel&quot;</span><span class="p">:</span> <span class="sa">r</span><span class="s2">&quot;$m$ (GeV)&quot;</span><span class="p">,</span>
            <span class="s2">&quot;ylabel&quot;</span><span class="p">:</span> <span class="s2">&quot;$m^</span><span class="si">{reco}</span><span class="s2">$&quot;</span><span class="p">,</span>
            <span class="s2">&quot;xmin&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s2">&quot;xmax&quot;</span><span class="p">:</span> <span class="mi">25</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s2">&quot;RecoDatapT&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;RecoDatam&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">,</span>
            <span class="s2">&quot;xlabel&quot;</span><span class="p">:</span> <span class="sa">r</span><span class="s2">&quot;$p_T$ (GeV)&quot;</span><span class="p">,</span>
            <span class="s2">&quot;ylabel&quot;</span><span class="p">:</span> <span class="s2">&quot;$p_T^</span><span class="si">{reco}</span><span class="s2">$&quot;</span><span class="p">,</span>
            <span class="s2">&quot;xmin&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
            <span class="s2">&quot;xmax&quot;</span><span class="p">:</span> <span class="mi">80</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s2">&quot;RecoDataeta&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;RecoDatam&quot;</span><span class="p">,</span> <span class="s2">&quot;RecoDatapT&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">,</span>
            <span class="s2">&quot;xlabel&quot;</span><span class="p">:</span> <span class="sa">r</span><span class="s2">&quot;$\eta$&quot;</span><span class="p">,</span>
            <span class="s2">&quot;ylabel&quot;</span><span class="p">:</span> <span class="s2">&quot;$\eta^</span><span class="si">{reco}</span><span class="s2">$&quot;</span><span class="p">,</span>
            <span class="s2">&quot;xmin&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span>
            <span class="s2">&quot;xmax&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s2">&quot;RecoDataphi&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;RecoDatam&quot;</span><span class="p">,</span> <span class="s2">&quot;RecoDatapT&quot;</span><span class="p">,</span> <span class="s2">&quot;RecoDataeta&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">,</span>
            <span class="s2">&quot;xlabel&quot;</span><span class="p">:</span> <span class="sa">r</span><span class="s2">&quot;$\phi$&quot;</span><span class="p">,</span>
            <span class="s2">&quot;ylabel&quot;</span><span class="p">:</span> <span class="s2">&quot;$\phi^</span><span class="si">{reco}</span><span class="s2">$&quot;</span><span class="p">,</span>
            <span class="s2">&quot;xmin&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mf">3.2</span><span class="p">,</span>
            <span class="s2">&quot;xmax&quot;</span><span class="p">:</span> <span class="mf">3.2</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">}</span>
<span class="k">elif</span> <span class="n">ORDER</span><span class="o">==</span> <span class="s2">&quot;phi_first&quot;</span><span class="p">:</span>
    <span class="n">FIELDS</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;RecoDataphi&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span>
        <span class="s2">&quot;xlabel&quot;</span><span class="p">:</span> <span class="sa">r</span><span class="s2">&quot;$\phi$&quot;</span><span class="p">,</span>
        <span class="s2">&quot;ylabel&quot;</span><span class="p">:</span> <span class="s2">&quot;$\phi^</span><span class="si">{reco}</span><span class="s2">$&quot;</span><span class="p">,</span>
        <span class="s2">&quot;xmin&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mf">3.2</span><span class="p">,</span>
        <span class="s2">&quot;xmax&quot;</span><span class="p">:</span> <span class="mf">3.2</span><span class="p">,</span>
    <span class="p">},</span>

    <span class="s2">&quot;RecoDatam&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;RecoDataphi&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">,</span>
        <span class="s2">&quot;xlabel&quot;</span><span class="p">:</span> <span class="sa">r</span><span class="s2">&quot;$m$ (GeV)&quot;</span><span class="p">,</span>
        <span class="s2">&quot;ylabel&quot;</span><span class="p">:</span> <span class="s2">&quot;$m^</span><span class="si">{reco}</span><span class="s2">$&quot;</span><span class="p">,</span>
        <span class="s2">&quot;xmin&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="s2">&quot;xmax&quot;</span><span class="p">:</span> <span class="mi">25</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s2">&quot;RecoDatapT&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;RecoDataphi&quot;</span><span class="p">,</span> <span class="s2">&quot;RecoDatam&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">,</span>
        <span class="s2">&quot;xlabel&quot;</span><span class="p">:</span> <span class="sa">r</span><span class="s2">&quot;$p_T$ (GeV)&quot;</span><span class="p">,</span>
        <span class="s2">&quot;ylabel&quot;</span><span class="p">:</span> <span class="s2">&quot;$p_T^</span><span class="si">{reco}</span><span class="s2">$&quot;</span><span class="p">,</span>
        <span class="s2">&quot;xmin&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
        <span class="s2">&quot;xmax&quot;</span><span class="p">:</span> <span class="mi">80</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s2">&quot;RecoDataeta&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;RecoDataphi&quot;</span><span class="p">,</span> <span class="s2">&quot;RecoDatam&quot;</span><span class="p">,</span> <span class="s2">&quot;RecoDatapT&quot;</span><span class="p">]</span>  <span class="o">+</span> <span class="n">X</span><span class="p">,</span>
        <span class="s2">&quot;xlabel&quot;</span><span class="p">:</span> <span class="sa">r</span><span class="s2">&quot;$\eta$&quot;</span><span class="p">,</span>
        <span class="s2">&quot;ylabel&quot;</span><span class="p">:</span> <span class="s2">&quot;$\eta^</span><span class="si">{reco}</span><span class="s2">$&quot;</span><span class="p">,</span>
        <span class="s2">&quot;xmin&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span>
        <span class="s2">&quot;xmax&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
    <span class="p">},</span>

    <span class="p">}</span>


<span class="c1"># Load and explore raw (unscaled) dataframes</span>


<span class="n">all_variable_cols</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;genDatapT&quot;</span><span class="p">,</span>
    <span class="s2">&quot;genDataeta&quot;</span><span class="p">,</span>
    <span class="s2">&quot;genDataphi&quot;</span><span class="p">,</span>
    <span class="s2">&quot;genDatam&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RecoDatapT&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RecoDataeta&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RecoDataphi&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RecoDatam&quot;</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">all_cols</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;genDatapT&quot;</span><span class="p">,</span>
    <span class="s2">&quot;genDataeta&quot;</span><span class="p">,</span>
    <span class="s2">&quot;genDataphi&quot;</span><span class="p">,</span>
    <span class="s2">&quot;genDatam&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RecoDatapT&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RecoDataeta&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RecoDataphi&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RecoDatam&quot;</span><span class="p">,</span>
    <span class="s2">&quot;tau&quot;</span><span class="p">,</span>
<span class="p">]</span>


<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="c1"># device=&#39;cpu&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;device is </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s1">&#39;</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>using torch version 1.13.1+cu116
matplotlib version=  3.2.2
optuna is only used for hyperparameter tuning, not critical!

BASE directoy properly set =  /content/drive/MyDrive/IQNx4
using torch version 1.13.1+cu116
matplotlib version=  3.2.2
optuna is only used for hyperparameter tuning, not critical!
BASE directoy properly set =  /content/drive/MyDrive/IQNx4
DATA directory also properly set, in /content/drive/MyDrive/IQNx4
using DATA_DIR=/content/drive/MyDrive/IQNx4
device is cuda
</pre></div>
</div>
</div>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="load-required-functions">
<h1>2.2: Load Required Functions<a class="headerlink" href="#load-required-functions" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">################################### Load unscaled dataframes ###################################</span>
<span class="c1">################################### Load unscaled dataframes ###################################</span>
<span class="nd">@memory</span><span class="o">.</span><span class="n">cache</span>
<span class="k">def</span> <span class="nf">load_raw_data</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Load raw train, test, and validation raw (unscaled) dataframes, in that order.</span>

<span class="sd">    Returns:</span>
<span class="sd">        list(pandas.DataFrame): train, test, valid raw datafranes</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;SUBSAMPLE = </span><span class="si">{</span><span class="n">SUBSAMPLE</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">raw_train_data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span><span class="s1">&#39;train_data_10M_2.csv&#39;</span><span class="p">),</span>
                        <span class="n">usecols</span><span class="o">=</span><span class="n">all_cols</span><span class="p">,</span>
                        <span class="n">nrows</span><span class="o">=</span><span class="n">SUBSAMPLE</span>
                        <span class="p">)</span>

    <span class="n">raw_test_data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span><span class="s1">&#39;test_data_10M_2.csv&#39;</span><span class="p">),</span>
                        <span class="n">usecols</span><span class="o">=</span><span class="n">all_cols</span><span class="p">,</span>
                        <span class="n">nrows</span><span class="o">=</span><span class="n">SUBSAMPLE</span>
                        <span class="p">)</span>

    <span class="n">raw_valid_data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span><span class="s1">&#39;validation_data_10M_2.csv&#39;</span><span class="p">),</span>
                        <span class="n">usecols</span><span class="o">=</span><span class="n">all_cols</span><span class="p">,</span>
                        <span class="n">nrows</span><span class="o">=</span><span class="n">SUBSAMPLE</span>
                        <span class="p">)</span>


    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> RAW TRAIN DATA SHAPE</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">raw_train_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> RAW TRAIN DATA</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">raw_train_data</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="c1">#unscaled</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> RAW TEST DATA\ SHAPEn&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">raw_test_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> RAW TEST DATA</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">raw_test_data</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="c1">#unscaled</span>

    <span class="k">return</span> <span class="n">raw_train_data</span><span class="p">,</span> <span class="n">raw_test_data</span><span class="p">,</span> <span class="n">raw_valid_data</span>


<span class="c1">########## Generate scaled data###############</span>
<span class="c1"># scaled_train_data = L_scale_df(raw_train_data, title=&#39;scaled_train_data_10M_2.csv&#39;,</span>
<span class="c1">#                              save=True)</span>
<span class="c1"># print(&#39;\n\n&#39;)</span>
<span class="c1"># scaled_test_data = L_scale_df(raw_test_data,  title=&#39;scaled_test_data_10M_2.csv&#39;,</span>
<span class="c1">#                             save=True)</span>
<span class="c1"># print(&#39;\n\n&#39;)</span>

<span class="c1"># scaled_valid_data = L_scale_df(raw_valid_data,  title=&#39;scaled_valid_data_10M_2.csv&#39;,</span>
<span class="c1">#                             save=True)</span>

<span class="c1"># explore_data(df=scaled_train_data, title=&#39;Braden Kronheim-L-scaled Dataframe&#39;, scaled=True)</span>

<span class="c1">################ Load scaled data##############</span>
<span class="nd">@utils</span><span class="o">.</span><span class="n">time_type_of_func</span><span class="p">(</span><span class="n">tuning_or_training</span><span class="o">=</span><span class="s1">&#39;loading&#39;</span><span class="p">)</span>
<span class="nd">@memory</span><span class="o">.</span><span class="n">cache</span>
<span class="k">def</span> <span class="nf">load_scaled_dataframes</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Load L-scaled train, test and validation according to Braden scaling, in that order.</span>

<span class="sd">    Returns:</span>
<span class="sd">        list(pandas.DataFarme): L-scaled train, test, validation dataframes, in that order.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># print(&quot;SCALED TRAIN DATA&quot;)</span>
    <span class="n">scaled_train_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="s2">&quot;scaled_train_data_10M_2.csv&quot;</span><span class="p">),</span>
        <span class="n">usecols</span><span class="o">=</span><span class="n">all_cols</span><span class="p">,</span>
        <span class="n">nrows</span><span class="o">=</span><span class="n">SUBSAMPLE</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># print(&quot;TRAINING FEATURES\n&quot;, scaled_train_data.head())</span>

    <span class="n">scaled_test_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="s2">&quot;scaled_test_data_10M_2.csv&quot;</span><span class="p">),</span>
        <span class="n">usecols</span><span class="o">=</span><span class="n">all_cols</span><span class="p">,</span>
        <span class="n">nrows</span><span class="o">=</span><span class="n">SUBSAMPLE</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">scaled_valid_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="s2">&quot;scaled_valid_data_10M_2.csv&quot;</span><span class="p">),</span>
        <span class="n">usecols</span><span class="o">=</span><span class="n">all_cols</span><span class="p">,</span>
        <span class="n">nrows</span><span class="o">=</span><span class="n">SUBSAMPLE</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">scaled_train_data</span><span class="p">,</span> <span class="n">scaled_test_data</span><span class="p">,</span> <span class="n">scaled_valid_data</span>

<span class="c1"># print(&#39;\nTESTING FEATURES\n&#39;, test_data_m.head())</span>

<span class="c1"># print(&#39;\ntrain set shape:&#39;,  train_data_m.shape)</span>
<span class="c1"># print(&#39;\ntest set shape:  &#39;, test_data_m.shape)</span>
<span class="c1"># # print(&#39;validation set shape:&#39;, valid_data.shape)</span>



<span class="k">def</span> <span class="nf">get_train_scale_dict</span><span class="p">(</span><span class="n">USE_BRADEN_SCALING</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get a dictionary containing mean and standard deviation of each gen and reco feature. </span>

<span class="sd">    Args:</span>
<span class="sd">        USE_BRADEN_SCALING (bool): Whether you wish to use the Braden scaling. If True, it uses the L-scaled train dataframe. If False, it uses the unscaled dataframe.</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict: dictionary of floats containing mean and standard deviation of each gen and reco feature. </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">USE_BRADEN_SCALING</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
        <span class="n">TRAIN_SCALE_DICT</span> <span class="o">=</span> <span class="n">get_scaling_info</span><span class="p">(</span><span class="n">scaled_train_data</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;BRADEN SCALING DICTIONARY&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">TRAIN_SCALE_DICT</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># TEST_SCALE_DICT = get_scaling_info(scaled_test_data)</span>
        <span class="c1"># print(TEST_SCALE_DICT)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;NORMAL UNSCALED DICTIONARY&#39;</span><span class="p">)</span>
        <span class="n">TRAIN_SCALE_DICT</span> <span class="o">=</span> <span class="n">get_scaling_info</span><span class="p">(</span><span class="n">raw_train_data</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">TRAIN_SCALE_DICT</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># TEST_SCALE_DICT = get_scaling_info(scaled_test_data)</span>
        <span class="c1"># print(TEST_SCALE_DICT)</span>
    <span class="k">return</span> <span class="n">TRAIN_SCALE_DICT</span>


<span class="k">class</span> <span class="nc">LR_Cooler</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">starting_lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">total_iterations</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">iter_</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">starting_lr</span><span class="o">=</span><span class="n">starting_lr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iter_</span><span class="o">=</span><span class="n">iter_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_iterations</span><span class="o">=</span> <span class="n">total_iterations</span>
    <span class="k">def</span> <span class="nf">exponential_decay</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">starting_lr</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span>  <span class="bp">self</span><span class="o">.</span><span class="n">iter_</span><span class="o">/</span><span class="mf">1e5</span> <span class="p">))</span>
    <span class="k">def</span> <span class="nf">exponential_decay_2</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">decay_rate</span><span class="o">=</span><span class="mf">1e-3</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">starting_lr</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span> <span class="n">decay_rate</span><span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">fractional_decay</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">final_time</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">starting_lr</span><span class="o">/</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iter</span> <span class="o">+</span> <span class="n">final_time</span><span class="p">)</span> 

<span class="c1">################################ SPLIT###########</span>
<span class="c1"># Currently need the split function again here</span>
<span class="c1"># @memory.cache</span>
<span class="k">def</span> <span class="nf">split_t_x</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">input_features</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get the target as the ratio, according to the T equation.</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    list(numpy.array): list of numpy array of target and training features&quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">target</span> <span class="o">==</span> <span class="s2">&quot;RecoDatam&quot;</span><span class="p">:</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">T</span><span class="p">(</span><span class="s2">&quot;m&quot;</span><span class="p">,</span> <span class="n">scaled_df</span><span class="o">=</span><span class="n">scaled_train_data</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">target</span> <span class="o">==</span> <span class="s2">&quot;RecoDatapT&quot;</span><span class="p">:</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">T</span><span class="p">(</span><span class="s2">&quot;pT&quot;</span><span class="p">,</span> <span class="n">scaled_df</span><span class="o">=</span><span class="n">scaled_train_data</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">target</span> <span class="o">==</span> <span class="s2">&quot;RecoDataeta&quot;</span><span class="p">:</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">T</span><span class="p">(</span><span class="s2">&quot;eta&quot;</span><span class="p">,</span> <span class="n">scaled_df</span><span class="o">=</span><span class="n">scaled_train_data</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">target</span> <span class="o">==</span> <span class="s2">&quot;RecoDataphi&quot;</span><span class="p">:</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">T</span><span class="p">(</span><span class="s2">&quot;phi&quot;</span><span class="p">,</span> <span class="n">scaled_df</span><span class="o">=</span><span class="n">scaled_train_data</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">input_features</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">x</span>

<span class="c1"># @memory.cache</span>
<span class="k">def</span> <span class="nf">normal_split_t_x</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">input_features</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;splot dataframe into targets and feature arrays.</span>

<span class="sd">    Args:</span>
<span class="sd">        df (pandas.DataFrame): Dataframe of train, test or validation data.</span>
<span class="sd">        target (str): Choice of &quot;RecoDatapT&quot;, &quot;RecoDataeta&quot;, &quot;RecoDataphi&quot;,&quot;RecoDatam&quot; as target.</span>
<span class="sd">        input_features (list(str)): list of training features labels</span>

<span class="sd">    Returns:</span>
<span class="sd">    list(numpy.array): list of numpy array of target and training features</span>
<span class="sd"> &quot;&quot;&quot;</span>
    <span class="c1"># change from pandas dataframe format to a numpy </span>
    <span class="c1"># array of the specified types</span>
    <span class="c1"># t = np.array(df[target])</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">target</span><span class="p">])</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">input_features</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span>




<span class="c1">################ Apply Z scaling############</span>
<span class="k">def</span> <span class="nf">z</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Simple z-score standardization. Used for targets&quot;&quot;&quot;</span>
    <span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-20</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">z_inverse</span><span class="p">(</span><span class="n">xprime</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">xprime</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># @memory.cache</span>
<span class="k">def</span> <span class="nf">z2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The main z score function. Args:</span>
<span class="sd">        x (numpy.array): feature 1-D array</span>
<span class="sd">        mean (float): mean of the feature (in the training set)</span>
<span class="sd">        std (float): standard deviation of the feature (in the training set)</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.array: z-score-scaled 1-D feature</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-20</span>
    <span class="n">scaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">std</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">scaled</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>




<span class="c1"># @memory.cache</span>
<span class="k">def</span> <span class="nf">z_inverse2</span><span class="p">(</span><span class="n">xprime</span><span class="p">,</span> <span class="n">train_mean</span><span class="p">,</span> <span class="n">train_std</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The main z score de-scaling function. </span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">        xprime (numpy.array): z-score-scaled feature 1-D array</span>
<span class="sd">        train_mean (float): mean of the feature (in the training set)</span>
<span class="sd">        train_std (float): standard deviation of the feature (in the training set)</span>
<span class="sd">        &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">xprime</span> <span class="o">*</span> <span class="n">train_std</span> <span class="o">+</span> <span class="n">train_mean</span>

<span class="c1"># @memory.cache</span>
<span class="k">def</span> <span class="nf">apply_z_to_features</span><span class="p">(</span><span class="n">TRAIN_SCALE_DICT</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">test_x</span><span class="p">,</span> <span class="n">valid_x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;TO ensure this z scaling is only applied once to the training features, we use a generator.</span>
<span class="sd">    This doesn&#39;t change the shapes of anything, just applies z to all the feature columns other than tau.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">    TRAIN_SCALE_DICT (dict(float)): dictionary of train set mean and standard deviation values</span>
<span class="sd">    train_x (numpy.array): 2-D numpy array of training features</span>
<span class="sd">    test_x (numpy.array):  2-D numpy array of test features</span>
<span class="sd">    valid_x (numpy.array):  2-D numpy array of validation features</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NFEATURES</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">variable</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">TRAIN_SCALE_DICT</span><span class="p">)[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">train_mean</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">TRAIN_SCALE_DICT</span><span class="p">[</span><span class="n">variable</span><span class="p">][</span><span class="s2">&quot;mean&quot;</span><span class="p">])</span>
        <span class="n">train_std</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">TRAIN_SCALE_DICT</span><span class="p">[</span><span class="n">variable</span><span class="p">][</span><span class="s2">&quot;std&quot;</span><span class="p">])</span>
        <span class="n">train_x</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">z2</span><span class="p">(</span><span class="n">train_x</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">mean</span><span class="o">=</span><span class="n">train_mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">train_std</span><span class="p">)</span>
        <span class="n">test_x</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">z2</span><span class="p">(</span><span class="n">test_x</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">mean</span><span class="o">=</span><span class="n">train_mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">train_std</span><span class="p">)</span>
        <span class="n">valid_x</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">z2</span><span class="p">(</span><span class="n">valid_x</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">mean</span><span class="o">=</span><span class="n">train_mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">train_std</span><span class="p">)</span>
    <span class="k">yield</span> <span class="n">train_x</span>
    <span class="k">yield</span> <span class="n">test_x</span>
    <span class="k">yield</span> <span class="n">valid_x</span>


<span class="c1"># @memory.cache</span>
<span class="k">def</span> <span class="nf">apply_z_to_targets</span><span class="p">(</span><span class="n">train_t</span><span class="p">,</span> <span class="n">test_t</span><span class="p">,</span> <span class="n">valid_t</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;apply z-score scaling to target columns</span>

<span class="sd">    Args:</span>
<span class="sd">        train_t (numpy.array): target column in the training set</span>
<span class="sd">        test_t (numpy.array): target column in the test set</span>
<span class="sd">        valid_t (numpy.array): target column in the validation set</span>

<span class="sd">    Yields:</span>
<span class="sd">        [type]: [description]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">train_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_t</span><span class="p">)</span>
    <span class="n">train_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">train_t</span><span class="p">)</span>
    <span class="n">train_t_</span> <span class="o">=</span> <span class="n">z2</span><span class="p">(</span><span class="n">train_t</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">train_mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">train_std</span><span class="p">)</span>
    <span class="n">test_t_</span> <span class="o">=</span> <span class="n">z2</span><span class="p">(</span><span class="n">test_t</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">train_mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">train_std</span><span class="p">)</span>
    <span class="n">valid_t_</span> <span class="o">=</span> <span class="n">z2</span><span class="p">(</span><span class="n">valid_t</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">train_mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">train_std</span><span class="p">)</span>

    <span class="k">yield</span> <span class="n">train_t_</span>
    <span class="k">yield</span> <span class="n">test_t_</span>
    <span class="k">yield</span> <span class="n">valid_t_</span>



<span class="c1"># check that it looks correct</span>
<span class="c1"># fig = plt.figure(figsize=(10, 4))</span>
<span class="c1"># ax = fig.add_subplot(autoscale_on=True)</span>
<span class="c1"># ax.grid()</span>
<span class="c1"># for i in range(NFEATURES):</span>
<span class="c1">#     ax.hist(train_x[:,i], alpha=0.35, label=f&#39;feature {i}&#39; )</span>
<span class="c1">#     # set_axes(ax=ax, xlabel=&quot;Transformed features X&#39; &quot;,title=&quot;training features post-z score: X&#39;=z(L(X))&quot;)</span>
<span class="c1"># ax.legend()</span>
<span class="c1"># plt.show()</span>


<span class="c1">######### Get beset hyperparameters</span>
<span class="c1"># tuned_dir = os.path.join(IQN_BASE,&#39;best_params&#39;)</span>
<span class="c1"># tuned_filename=os.path.join(tuned_dir,&#39;best_params_mass_%s_trials.csv&#39; % str(int(n_trials)))</span>
<span class="c1"># BEST_PARAMS = pd.read_csv(os.path.join(IQN_BASE, &#39;best_params&#39;,&#39;best_params_Test_Trials.csv&#39;))</span>
<span class="c1"># BEST_PARAMS=pd.read_csv(tuned_filename)</span>
<span class="c1"># print(BEST_PARAMS)</span>
<span class="k">class</span> <span class="nc">RegularizedRegressionModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Used for hyperparameter tuning&quot;&quot;&quot;</span>

    <span class="c1"># inherit from the super class</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">nfeatures</span><span class="p">,</span>
        <span class="n">ntargets</span><span class="p">,</span>
        <span class="n">nlayers</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="p">,</span>
        <span class="n">dropout_1</span><span class="p">,</span>
        <span class="n">dropout_2</span><span class="p">,</span>
        <span class="n">activation</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nlayers</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># nlayers is number of hidden layers+1, since there is always an input layer and an output layer</span>
                <span class="c1"># INPUT LAYER</span>
                <span class="c1"># inital layer has to have size of (input features, output_nodes),</span>
                <span class="c1"># its output layer can have any size but it must match the size of the input layer of the next linear layer</span>
                <span class="c1"># here we choose its output layer as the hidden size (fully connected)</span>
                <span class="c1"># ALPHA DROPOUT</span>
                <span class="c1"># layers.append(nn.AlphaDropout(dropout_1))</span>

                <span class="n">layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nfeatures</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
                <span class="c1"># batch normalization</span>
                <span class="c1"># layers.append(nn.BatchNorm1d(hidden_size))</span>
                <span class="c1"># dropout should have higher values in deeper layers</span>
                <span class="c1"># layers.append(nn.Dropout(dropout_1))#Use small dropout for 1st layers &amp; larger dropout for later layers. In both cases, the larger he model the larger the dropout.</span>
                <span class="c1"># When model is in training, apply dropout. When using model for inference, dont use dropout</span>

                <span class="c1"># ReLU activation</span>
                <span class="k">if</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;LeakyReLU&quot;</span><span class="p">:</span>
                    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">negative_slope</span><span class="o">=</span><span class="mf">0.3</span><span class="p">))</span>
                <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;PReLU&quot;</span><span class="p">:</span>
                    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">())</span>
                <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;ReLU6&quot;</span><span class="p">:</span>
                    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU6</span><span class="p">())</span>
                <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;ELU&quot;</span><span class="p">:</span>
                    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">())</span>
                <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;SELU&quot;</span><span class="p">:</span>
                    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">SELU</span><span class="p">())</span>
                <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;CELU&quot;</span><span class="p">:</span>
                    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">CELU</span><span class="p">())</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># if this is not the first layer (we dont have layers)</span>
                <span class="n">layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
                <span class="c1"># layers.append(nn.Dropout(dropout_2))</span>
                <span class="c1"># layers.append(nn.BatchNorm1d(hidden_size))</span>

                <span class="k">if</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;LeakyReLU&quot;</span><span class="p">:</span>
                    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">negative_slope</span><span class="o">=</span><span class="mf">0.3</span><span class="p">))</span>
                <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&quot;PReLU&quot;</span><span class="p">:</span>
                    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">())</span>

        <span class="c1"># output layer:</span>
        <span class="n">output_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">ntargets</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">output_layer</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_layer</span><span class="p">)</span>

        <span class="c1"># only for classification add sigmoid</span>
        <span class="c1"># layers.append(nn.Sigmoid()) or softmax</span>
        <span class="c1"># we have defined sequential model using the layers in our list</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1">###################################################################################################</span>


<span class="k">def</span> <span class="nf">load_untrained_model</span><span class="p">(</span><span class="n">PARAMS</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Load an untrained model (with weights initiatted) according to model paramateters in the </span>
<span class="sd">    PARAMS dictionary</span>

<span class="sd">    Args:</span>
<span class="sd">        PARAMS (dict): dictionary of model/training parameters: i.e. hyperparameters and training parameters.</span>

<span class="sd">    Returns:</span>
<span class="sd">        utils.RegularizedRegressionModel object</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
        <span class="n">nfeatures</span><span class="o">=</span><span class="n">NFEATURES</span><span class="p">,</span>
        <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">nlayers</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">],</span>
        <span class="n">hidden_size</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">],</span>
        <span class="n">dropout_1</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s2">&quot;dropout_1&quot;</span><span class="p">],</span>
        <span class="n">dropout_2</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s2">&quot;dropout_2&quot;</span><span class="p">],</span>
        <span class="n">activation</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s2">&quot;activation&quot;</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="c1"># model.apply(initialize_weights)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>




<span class="k">class</span> <span class="nc">SaveModelCheckpoint</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Continuous model-checkpointing class. Updates the latest checkpoint of an object based o validation loss each time its called. </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">best_valid_loss</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initiate an instance of the class based on filename and best_valid_loss/</span>

<span class="sd">        Args:</span>
<span class="sd">            best_valid_loss (float, optional): Best possible validation loss of a checkpoint object. Defaults to np.inf.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_valid_loss</span> <span class="o">=</span> <span class="n">best_valid_loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">filename_model</span><span class="o">=</span><span class="n">filename_model</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">current_valid_loss</span><span class="p">,</span> <span class="n">filename_model</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;When an object of the calss is called, its validation loss gets updated and the model based </span>
<span class="sd">        on the latest validation loss is saved.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: utils.RegularizedRegressionModel object.</span>
<span class="sd">            current_valid_loss (float): current (latest) validation loss of this model during the training process.</span>
<span class="sd">            filename_model (str): filename in which the latest model will be saved. Can be a relative or local path. </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">current_valid_loss</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_valid_loss</span><span class="p">:</span>
            <span class="c1"># update the best loss</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_valid_loss</span> <span class="o">=</span> <span class="n">current_valid_loss</span>
            <span class="c1"># filename_model=&#39;Trained_IQNx4_%s_%sK_iter.dict&#39; % (target, str(int(n_iterations/1000)) )</span>
            <span class="c1"># filename_model = &quot;Trained_IQNx4_%s_TUNED_2lin_with_noise.dict&quot; % target</span>

            <span class="c1"># note that n_iterations is the total n_iterations, we dont want to save a million files for each iteration</span>
            <span class="n">trained_models_dir</span> <span class="o">=</span> <span class="s2">&quot;trained_models&quot;</span>
            <span class="n">mkdir</span><span class="p">(</span><span class="n">trained_models_dir</span><span class="p">)</span>
            <span class="c1"># on cluster, Im using another TRAIN directory</span>
            <span class="n">PATH_model</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                <span class="n">IQN_BASE</span><span class="p">,</span>
                <span class="s2">&quot;JupyterBook&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Cluster&quot;</span><span class="p">,</span>
                <span class="s2">&quot;TRAIN&quot;</span><span class="p">,</span>
                <span class="n">trained_models_dir</span><span class="p">,</span>
                <span class="n">filename_model</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH_model</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Current valid loss: </span><span class="si">{</span><span class="n">current_valid_loss</span><span class="si">}</span><span class="s2">;  saved better model at </span><span class="si">{</span><span class="n">PATH_model</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="c1"># save using .pth object which if a dictionary of dicionaries, so that I can have PARAMS saved in the same file</span>


<span class="k">def</span> <span class="nf">train</span><span class="p">(</span>
    <span class="n">target</span><span class="p">,</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">avloss</span><span class="p">,</span>
    <span class="n">getbatch</span><span class="p">,</span>
    <span class="n">train_x</span><span class="p">,</span>
    <span class="n">train_t</span><span class="p">,</span>
    <span class="n">valid_x</span><span class="p">,</span>
    <span class="n">valid_t</span><span class="p">,</span>
    <span class="n">PARAMS</span><span class="p">,</span>
    <span class="n">traces</span><span class="p">,</span>
    <span class="n">step</span><span class="p">,</span>
    <span class="n">window</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Training Function. </span>

<span class="sd">    Args:</span>
<span class="sd">        target (str): hoice of &quot;RecoDatapT&quot;, &quot;RecoDataeta&quot;, &quot;RecoDataphi&quot;,&quot;RecoDatam&quot; as target.</span>
<span class="sd">        model a torch NN model, e.g utils.RegularizedRegressionModel.</span>
<span class="sd">        avloss (float): average training losss</span>
<span class="sd">        getbatch (function): a get_batch function</span>
<span class="sd">        train_x (numpy.DataFrame): 2-D numpy array of training features</span>
<span class="sd">        train_t (numpy.DataFrame:  1-D numpy array of training targets</span>
<span class="sd">        valid_x (numpy.DataFrame): 2-D numpy array of validation features</span>
<span class="sd">        valid_t (numpy.DataFrame: 1-D numpy array of validation targets</span>
<span class="sd">        PARAMS (dict): dictionary of model/training parameters </span>
<span class="sd">        traces (tuple): tuple of  </span>
<span class="sd">        (iteration, training accuracy, validation accuracy, running average of validation accuracy) </span>
<span class="sd">        = (xx, yy_t, yy_v, yy_v_avg) </span>
<span class="sd">        step (int): number of iterations to take a printout step of the traces</span>
<span class="sd">        window (int): window of running average of validation loss  </span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple: traces</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1"># TODO: obviously, for reference, the &quot;traces&quot; should be saved as a 2D numpy array</span>
    <span class="c1"># with the same naming format as the &quot;model_filename&quot;, so that it can be opened later and </span>
    <span class="c1"># plot loss curves for different models.</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    
    <span class="c1"># TODO: decay the stepsize, such that steps (and hence checkpointing) are large in the beginnig to the learning</span>
    <span class="c1"># process (which corresponds to high learning rates), and decrease as time steps increase.</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">]</span>
    <span class="n">n_iterations</span> <span class="o">=</span> <span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;n_iterations&#39;</span><span class="p">]</span>
    <span class="c1"># to keep track of average losses</span>
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy_t</span><span class="p">,</span> <span class="n">yy_v</span><span class="p">,</span> <span class="n">yy_v_avg</span> <span class="o">=</span> <span class="n">traces</span>
    <span class="n">model_checkpoint</span> <span class="o">=</span> <span class="n">SaveModelCheckpoint</span><span class="p">()</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_x</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Iteration vs average loss&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%10s</span><span class="se">\t</span><span class="si">%10s</span><span class="se">\t</span><span class="si">%10s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="s2">&quot;iteration&quot;</span><span class="p">,</span> <span class="s2">&quot;train-set&quot;</span><span class="p">,</span> <span class="s2">&quot;test-set&quot;</span><span class="p">))</span>
    
    <span class="n">fifth_n_iterations</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">n_iterations</span><span class="o">//</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">starting_learning_rate</span> <span class="o">=</span> <span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;starting_learning_rate&#39;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iterations</span><span class="p">):</span>
        <span class="c1">#experiment with annealing LR from beginning</span>

<span class="c1">#         # starting learning rate (first fifth)</span>
        <span class="n">Cutoff_from_initial_LR</span> <span class="o">=</span> <span class="mi">15000</span>
        <span class="k">if</span> <span class="n">ii</span><span class="o">&lt;</span> <span class="n">Cutoff_from_initial_LR</span><span class="p">:</span>
            <span class="n">learning_rate</span><span class="o">=</span> <span class="n">starting_learning_rate</span>
        
<span class="c1">#         #second fifth</span>

<span class="c1">#         if 2* fifth_n_iterations &lt; ii &lt; 3*fifth_n_iterations:</span>
<span class="c1">#             learning_rate=starting_learning_rate/10 #1e-2</span>
        <span class="k">if</span> <span class="n">ii</span> <span class="o">&gt;</span> <span class="n">Cutoff_from_initial_LR</span><span class="p">:</span>
            <span class="n">LR_sched</span><span class="o">=</span><span class="n">LR_Cooler</span><span class="p">(</span><span class="n">starting_lr</span><span class="o">=</span><span class="n">starting_learning_rate</span><span class="p">,</span> <span class="n">total_iterations</span><span class="o">=</span><span class="n">n_iterations</span><span class="p">,</span> <span class="n">iter_</span><span class="o">=</span><span class="n">ii</span><span class="p">)</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">LR_sched</span><span class="o">.</span><span class="n">exponential_decay</span><span class="p">()</span>
<span class="c1">#         #third fifth</span>
<span class="c1">#         if 3*fifth_n_iterations &lt; ii &lt; 4*fifth_n_iterations:</span>
<span class="c1">#             learning_rate=starting_learning_rate/100 #1e-3</span>
<span class="c1">#         #frouth fifth: stary decay LR</span>
<span class="c1">#         if ii &gt; 4*fifth_n_iterations:</span>
<span class="c1">#             learning_rate = decay_LR(ii)</span>
            
        
        <span class="c1"># add weight decay (important regularization to reduce overfitting)</span>
        <span class="n">L2</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="c1"># optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=L2)</span>
        <span class="c1">#SGD allows for: momentum=0, dampening=0, weight_decay=0, nesterov=boolean, differentiable=boolean</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">optimizer_name</span><span class="p">)(</span>
        <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
        <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
         <span class="c1"># amsgrad=True, </span>

        <span class="c1">#  weight_decay=L2,#</span>
        <span class="c1"># differentiable=True,</span>
        <span class="c1">#For SGD nesterov, it requires momentum and zero dampening</span>
        <span class="c1"># dampening=0,</span>
        <span class="c1"># momentum=momentum,</span>
        <span class="c1"># nesterov=True</span>
        <span class="c1"># BUT no one should ever use SGD in 2022! Adam converges much better and faster.</span>
        <span class="p">)</span>
        
        <span class="c1">#if ii &gt; 1e4: learning_rate=1e-4</span>
        <span class="c1"># set mode to training so that training specific</span>
        <span class="c1"># operations such as dropout are enabled.</span>
        <span class="c1"># time_p_start = time.perf_counter()</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="c1"># get a random sample (a batch) of data (as numpy arrays)</span>
        <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_t</span> <span class="o">=</span> <span class="n">getbatch</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_t</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="c1"># Take df/ dtau</span>
        <span class="c1"># x = torch.from_numpy(batch_x).float()</span>
        <span class="c1"># # print(&#39;x is leaf: &#39;, x.is_leaf)</span>
        <span class="c1"># x.requires_grad_(True)</span>
        <span class="c1"># # x.retain_grad()</span>
        <span class="c1"># # print(&#39;x is leaf after retain: &#39;, x.is_leaf)</span>
        <span class="c1"># # x.requires_grad_(True)</span>
        <span class="c1"># # x.retain_grad()</span>
        <span class="c1"># f = model(x)</span>
        <span class="c1"># f = f.view(-1)</span>
        <span class="c1"># #multiply the model by its ransverse, remember we can only take gradients of scalars</span>
        <span class="c1"># #and f will be a vector before this</span>
        <span class="c1"># f = f @ f.t()</span>
        <span class="c1"># f.retain_grad()</span>
        <span class="c1"># f.backward(gradient=torch.ones_like(f), retain_graph=True)</span>
        <span class="c1"># df_dx = x.grad</span>
        <span class="c1"># df_dtau = df_dx[:,-1]</span>
        <span class="c1"># x.grad.zero_()</span>
        
        <span class="c1">#add noise to training data</span>
        <span class="n">batch_x</span> <span class="o">=</span> <span class="n">add_noise</span><span class="p">(</span><span class="n">batch_x</span><span class="p">)</span>
        <span class="c1"># batch_t = add_noise(batch_t)</span>
        
        <span class="c1"># Try torch scheduler</span>
        <span class="c1"># scheduler=torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)</span>
        <span class="c1"># scheduler.step()</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>  <span class="c1"># no need to compute gradients</span>
            <span class="c1"># wrt. x and t</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">batch_x</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">batch_t</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">empirical_risk</span> <span class="o">=</span> <span class="n">avloss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>  <span class="c1"># clear previous gradients</span>
        <span class="n">empirical_risk</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># compute gradients</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>  <span class="c1"># move one step towards the minimum of the loss function using an SGD-like algorithm.</span>
        
        

        <span class="k">if</span> <span class="n">ii</span> <span class="o">%</span> <span class="n">step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>

            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t\t</span><span class="s2">CURRENT LEARNING RATE: </span><span class="si">{</span><span class="n">learning_rate</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">acc_t</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">avloss</span><span class="p">,</span> <span class="n">train_x</span><span class="p">[:</span><span class="n">n</span><span class="p">],</span> <span class="n">train_t</span><span class="p">[:</span><span class="n">n</span><span class="p">])</span>
            <span class="c1">#acc_t: list of training losses</span>
            <span class="n">acc_v</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">avloss</span><span class="p">,</span> <span class="n">valid_x</span><span class="p">[:</span><span class="n">n</span><span class="p">],</span> <span class="n">valid_t</span><span class="p">[:</span><span class="n">n</span><span class="p">])</span>
            <span class="c1">#acc_v: list of validation losses</span>
            <span class="n">yy_t</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc_t</span><span class="p">)</span>
            <span class="n">yy_v</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc_v</span><span class="p">)</span>
            <span class="n">previous_iter_valid_loss</span> <span class="o">=</span> <span class="n">yy_v</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;previous_iter_valid_loss : </span><span class="si">{</span><span class="n">previous_iter_valid_loss</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="c1"># save better models based on valid loss</span>
            <span class="c1"># filename_model=&quot;Trained_IQNx4_%s_TUNED_0lin_with_high_noise3.dict&quot; % target</span>
            <span class="n">filename_model</span><span class="o">=</span><span class="n">get_model_filename</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">PARAMS</span><span class="p">)</span>
             
            <span class="n">model_checkpoint</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">filename_model</span> <span class="o">=</span><span class="n">filename_model</span> <span class="p">,</span><span class="n">current_valid_loss</span><span class="o">=</span><span class="n">acc_v</span><span class="p">)</span>
            <span class="c1"># compute running average for validation data</span>
            <span class="n">len_yy_v</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">yy_v</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">len_yy_v</span> <span class="o">&lt;</span> <span class="n">window</span><span class="p">:</span>
                <span class="n">yy_v_avg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">yy_v</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">elif</span> <span class="n">len_yy_v</span> <span class="o">==</span> <span class="n">window</span><span class="p">:</span>
                <span class="n">yy_v_avg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">yy_v</span><span class="p">)</span> <span class="o">/</span> <span class="n">window</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">acc_v_avg</span> <span class="o">=</span> <span class="n">yy_v_avg</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">window</span>
                <span class="n">acc_v_avg</span> <span class="o">+=</span> <span class="n">yy_v</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">yy_v</span><span class="p">[</span><span class="o">-</span><span class="n">window</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
                <span class="n">yy_v_avg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc_v_avg</span> <span class="o">/</span> <span class="n">window</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">xx</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">xx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%10d</span><span class="se">\t</span><span class="si">%10.6f</span><span class="se">\t</span><span class="si">%10.6f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">xx</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">yy_t</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">yy_v</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">xx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">xx</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">step</span><span class="p">)</span>

                <span class="nb">print</span><span class="p">(</span>
                    <span class="s2">&quot;</span><span class="se">\r</span><span class="si">%10d</span><span class="se">\t</span><span class="si">%10.6f</span><span class="se">\t</span><span class="si">%10.6f</span><span class="se">\t</span><span class="si">%10.6f</span><span class="s2">&quot;</span>
                    <span class="o">%</span> <span class="p">(</span><span class="n">xx</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">yy_t</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">yy_v</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">yy_v_avg</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
                    <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="c1"># time_p_end = time.perf_counter()</span>
        <span class="c1"># time_for_this_iter = time_p_end-time_p_start</span>
        <span class="c1"># time_per_example = time_for_this_iter/batch_size</span>
        <span class="c1"># print(f&#39;training time for one example: {time_per_example}&#39;)</span>

    <span class="nb">print</span><span class="p">()</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy_t</span><span class="p">,</span> <span class="n">yy_v</span><span class="p">,</span> <span class="n">yy_v_avg</span><span class="p">)</span>


<span class="nd">@utils</span><span class="o">.</span><span class="n">time_type_of_func</span><span class="p">(</span><span class="n">tuning_or_training</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">run</span><span class="p">(</span>
    <span class="n">target</span><span class="p">,</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">train_x</span><span class="p">,</span>
    <span class="n">train_t</span><span class="p">,</span>
    <span class="n">valid_x</span><span class="p">,</span>
    <span class="n">valid_t</span><span class="p">,</span>
    <span class="n">traces</span><span class="p">,</span>
    <span class="n">PARAMS</span><span class="p">,</span>
    <span class="n">traces_step</span><span class="p">,</span>
    <span class="n">traces_window</span><span class="p">,</span>
    <span class="n">save_model</span><span class="p">,</span>
<span class="p">):</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">traces</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span>
        <span class="n">target</span><span class="p">,</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">average_quantile_loss</span><span class="p">,</span>
        <span class="n">get_batch</span><span class="p">,</span>
        <span class="n">train_x</span><span class="p">,</span>
        <span class="n">train_t</span><span class="p">,</span>
        <span class="n">valid_x</span><span class="p">,</span>
        <span class="n">valid_t</span><span class="p">,</span>
        <span class="n">PARAMS</span><span class="p">,</span>
        <span class="n">traces</span><span class="p">,</span>
        <span class="n">step</span><span class="o">=</span><span class="n">traces_step</span><span class="p">,</span>
        <span class="n">window</span><span class="o">=</span><span class="n">traces_window</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">save_model</span><span class="p">:</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="s2">&quot;Trained_IQNx4_</span><span class="si">%s</span><span class="s2">_</span><span class="si">%s</span><span class="s2">K_iter.dict&quot;</span> <span class="o">%</span> <span class="p">(</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_iterations</span> <span class="o">/</span> <span class="mi">1000</span><span class="p">)),</span>
        <span class="p">)</span>
        <span class="n">PATH</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">IQN_BASE</span><span class="p">,</span> <span class="s2">&quot;trained_models&quot;</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">trained model dictionary saved in </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">PATH</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>


<span class="k">def</span> <span class="nf">get_train_scale_dict</span><span class="p">(</span><span class="n">USE_BRADEN_SCALING</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">USE_BRADEN_SCALING</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
        <span class="n">TRAIN_SCALE_DICT</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">get_scaling_info</span><span class="p">(</span><span class="n">scaled_train_data</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;BRADEN SCALING DICTIONARY&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">TRAIN_SCALE_DICT</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># TEST_SCALE_DICT = get_scaling_info(scaled_test_data)</span>
        <span class="c1"># print(TEST_SCALE_DICT)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;NORMAL UNSCALED DICTIONARY&quot;</span><span class="p">)</span>
        <span class="n">TRAIN_SCALE_DICT</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">get_scaling_info</span><span class="p">(</span><span class="n">raw_train_data</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">TRAIN_SCALE_DICT</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># TEST_SCALE_DICT = get_scaling_info(scaled_test_data)</span>
        <span class="c1"># print(TEST_SCALE_DICT)</span>
    <span class="k">return</span> <span class="n">TRAIN_SCALE_DICT</span>


<span class="nd">@utils</span><span class="o">.</span><span class="n">debug</span>
<span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">PATH</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">trained model dictionary saved in </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">PATH</span><span class="p">)</span>


<span class="nd">@utils</span><span class="o">.</span><span class="n">debug</span>
<span class="k">def</span> <span class="nf">save_model_params</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">PATH</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">trained model dictionary saved in </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">PATH</span><span class="p">)</span>


<span class="nd">@utils</span><span class="o">.</span><span class="n">debug</span>
<span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="n">PATH</span><span class="p">):</span>
    <span class="c1"># n_layers = int(BEST_PARAMS[&quot;n_layers&quot;])</span>
    <span class="c1"># hidden_size = int(BEST_PARAMS[&quot;hidden_size&quot;])</span>
    <span class="c1"># dropout = float(BEST_PARAMS[&quot;dropout&quot;])</span>
    <span class="c1"># optimizer_name = BEST_PARAMS[&quot;optimizer_name&quot;].to_string().split()[1]</span>
    <span class="c1"># learning_rate =  float(BEST_PARAMS[&quot;learning_rate&quot;])</span>
    <span class="c1"># batch_size = int(BEST_PARAMS[&quot;batch_size&quot;])</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
        <span class="n">nfeatures</span><span class="o">=</span><span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">nlayers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span>
        <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">))</span>
    <span class="c1"># OR</span>
    <span class="c1"># model=torch.load(PATH)#BUT HERE IT WILL BE A DICT (CANT BE EVALUATED RIGHT AWAY) DISCOURAGED!</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>


<span class="k">def</span> <span class="nf">load_trained_model</span><span class="p">(</span><span class="n">PATH</span><span class="p">,</span> <span class="n">PARAMS</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
        <span class="n">nfeatures</span><span class="o">=</span><span class="n">NFEATURES</span><span class="p">,</span>
        <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">nlayers</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">],</span>
        <span class="n">hidden_size</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">],</span>
        <span class="n">dropout_1</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s2">&quot;dropout_1&quot;</span><span class="p">],</span>
        <span class="n">dropout_2</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s2">&quot;dropout_2&quot;</span><span class="p">],</span>
        <span class="n">activation</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s2">&quot;activation&quot;</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="load-data-split-scale-and-train-mass">
<h1>2.3 Load Data, split, scale, and Train Mass<a class="headerlink" href="#load-data-split-scale-and-train-mass" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">######################################</span>
<span class="n">USE_BRADEN_SCALING</span><span class="o">=</span><span class="kc">False</span>
<span class="c1">#####################################</span>
<span class="c1">################################### CONFIGURATIONS ###################################</span>

<span class="n">JUPYTER</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">use_subsample</span> <span class="o">=</span> <span class="kc">False</span>
<span class="c1"># use_subsample = True</span>
<span class="k">if</span> <span class="n">use_subsample</span><span class="p">:</span>
    <span class="n">SUBSAMPLE</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e5</span><span class="p">)</span>  <span class="c1"># subsample use for development - in production use whole dataset</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">SUBSAMPLE</span> <span class="o">=</span> <span class="kc">None</span>

</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">########################################################################################</span>
<span class="c1"># Load data only once, and with caching!</span>
<span class="n">raw_train_data</span><span class="p">,</span> <span class="n">raw_test_data</span><span class="p">,</span> <span class="n">raw_valid_data</span> <span class="o">=</span><span class="n">load_raw_data</span><span class="p">()</span>
<span class="c1"># Load scaled data</span>
<span class="c1"># scaled_train_data, scaled_test_data, scaled_valid_data = load_scaled_dataframes()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>________________________________________________________________________________
[Memory] Calling __main__--content-&lt;ipython-input-3b01933686c0&gt;.load_raw_data...
load_raw_data()
SUBSAMPLE = None

 RAW TRAIN DATA SHAPE

(8000000, 9)

 RAW TRAIN DATA


 RAW TEST DATA\ SHAPEn
(1000000, 9)

 RAW TEST DATA

___________________________________________________load_raw_data - 17.5s, 0.3min
</pre></div>
</div>
</div>
</div>
<section id="train-mass">
<h2>Train Mass<a class="headerlink" href="#train-mass" title="Permalink to this headline">#</a></h2>
<section id="the-model-that-needs-the-longest-time-in-training-is-mass-click-here-to-scroll-down-to-train-p-t">
<h3>The model that needs the longest time in training is mass. Click here to scroll down to train <span class="math notranslate nohighlight">\(p_T\)</span>.<a class="headerlink" href="#the-model-that-needs-the-longest-time-in-training-is-mass-click-here-to-scroll-down-to-train-p-t" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#######################################</span>
<span class="n">target</span> <span class="o">=</span> <span class="s2">&quot;RecoDatam&quot;</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">FIELDS</span><span class="p">[</span><span class="n">target</span><span class="p">]</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">source</span><span class="p">[</span><span class="s2">&quot;inputs&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training Features:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">features</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Target = &quot;</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;USING NEW DATASET</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>





<span class="c1"># Get targets and features</span>
<span class="k">if</span> <span class="n">USE_BRADEN_SCALING</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;spliting data for </span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">train_t</span><span class="p">,</span> <span class="n">train_x</span> <span class="o">=</span> <span class="n">split_t_x</span><span class="p">(</span>
        <span class="n">df</span><span class="o">=</span><span class="n">scaled_train_data</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">input_features</span><span class="o">=</span><span class="n">features</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train_t shape = &quot;</span><span class="p">,</span> <span class="n">train_t</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;train_x shape = &quot;</span><span class="p">,</span> <span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Training features:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span>
    <span class="n">valid_t</span><span class="p">,</span> <span class="n">valid_x</span> <span class="o">=</span> <span class="n">split_t_x</span><span class="p">(</span>
        <span class="n">df</span><span class="o">=</span><span class="n">scaled_valid_data</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">input_features</span><span class="o">=</span><span class="n">features</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;valid_t shape = &quot;</span><span class="p">,</span> <span class="n">valid_t</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;valid_x shape = &quot;</span><span class="p">,</span> <span class="n">valid_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">test_t</span><span class="p">,</span> <span class="n">test_x</span> <span class="o">=</span> <span class="n">split_t_x</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">scaled_test_data</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">input_features</span><span class="o">=</span><span class="n">features</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;test_t shape = &quot;</span><span class="p">,</span> <span class="n">test_t</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;test_x shape = &quot;</span><span class="p">,</span> <span class="n">test_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;spliting data for </span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">train_t</span><span class="p">,</span> <span class="n">train_x</span> <span class="o">=</span> <span class="n">normal_split_t_x</span><span class="p">(</span>
    <span class="n">df</span><span class="o">=</span><span class="n">raw_train_data</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">input_features</span><span class="o">=</span><span class="n">features</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train_t shape = &quot;</span><span class="p">,</span> <span class="n">train_t</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;train_x shape = &quot;</span><span class="p">,</span> <span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Training features:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span>
    <span class="n">valid_t</span><span class="p">,</span> <span class="n">valid_x</span> <span class="o">=</span> <span class="n">normal_split_t_x</span><span class="p">(</span>
    <span class="n">df</span><span class="o">=</span><span class="n">raw_valid_data</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">input_features</span><span class="o">=</span><span class="n">features</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;valid_t shape = &quot;</span><span class="p">,</span> <span class="n">valid_t</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;valid_x shape = &quot;</span><span class="p">,</span> <span class="n">valid_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">test_t</span><span class="p">,</span> <span class="n">test_x</span> <span class="o">=</span> <span class="n">normal_split_t_x</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">raw_test_data</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">input_features</span><span class="o">=</span><span class="n">features</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;test_t shape = &quot;</span><span class="p">,</span> <span class="n">test_t</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;test_x shape = &quot;</span><span class="p">,</span> <span class="n">test_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>


<span class="c1"># print(f&quot;spliting data for {target}&quot;)</span>
<span class="c1"># train_t, train_x = normal_split_t_x(</span>
<span class="c1"># df=raw_train_data, target=target, input_features=features</span>
<span class="c1"># )</span>
<span class="c1"># print(&quot;train_t shape = &quot;, train_t.shape, &quot;train_x shape = &quot;, train_x.shape)</span>
<span class="c1"># print(&quot;\n Training features:\n&quot;)</span>
<span class="c1"># print(train_x)</span>
<span class="c1"># valid_t, valid_x = normal_split_t_x(</span>
<span class="c1"># df=raw_valid_data, target=target, input_features=features</span>
<span class="c1"># )</span>
<span class="c1"># print(&quot;valid_t shape = &quot;, valid_t.shape, &quot;valid_x shape = &quot;, valid_x.shape)</span>
<span class="c1"># test_t, test_x = normal_split_t_x(df=raw_test_data, target=target, input_features=features)</span>
<span class="c1"># print(&quot;test_t shape = &quot;, test_t.shape, &quot;test_x shape = &quot;, test_x.shape)</span>


<span class="c1"># print(&quot;no need to train_test_split since we already have the split dataframes&quot;)</span>
<span class="c1"># print(valid_x.mean(axis=0), valid_x.std(axis=0))</span>
<span class="c1"># print(train_x.mean(axis=0), train_x.std(axis=0))</span>
<span class="c1"># print(valid_t.mean(), valid_t.std())</span>
<span class="c1"># print(train_t.mean(), train_t.std())</span>
<span class="n">NFEATURES</span> <span class="o">=</span> <span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="c1">######################################################</span>

<span class="c1"># Apply z scaling to features and targets</span>
<span class="c1"># to features</span>
<span class="n">TRAIN_SCALE_DICT</span><span class="o">=</span><span class="n">get_train_scale_dict</span><span class="p">(</span><span class="n">USE_BRADEN_SCALING</span><span class="p">)</span>
<span class="n">apply_z_generator</span> <span class="o">=</span> <span class="n">apply_z_to_features</span><span class="p">(</span><span class="n">TRAIN_SCALE_DICT</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">test_x</span><span class="p">,</span> <span class="n">valid_x</span><span class="p">)</span>
<span class="n">train_x_z_scaled</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">apply_z_generator</span><span class="p">)</span>
<span class="n">test_x_z_scaled</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">apply_z_generator</span><span class="p">)</span>
<span class="n">valid_x_z_scaled</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">apply_z_generator</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">valid_x_z_scaled</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">valid_x_z_scaled</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_x_z_scaled</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">train_x_z_scaled</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

<span class="c1"># to targets</span>
<span class="n">apply_z_to_targets_generator</span> <span class="o">=</span> <span class="n">apply_z_to_targets</span><span class="p">(</span>
    <span class="n">train_t</span><span class="p">,</span> <span class="n">test_t</span><span class="p">,</span> <span class="n">valid_t</span>
<span class="p">)</span>
<span class="n">train_t_z_scaled</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">apply_z_to_targets_generator</span><span class="p">)</span>
<span class="n">test_t_z_scaled</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">apply_z_to_targets_generator</span><span class="p">)</span>
<span class="n">valid_t_z_scaled</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">apply_z_to_targets_generator</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">valid_t_z_scaled</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">valid_t_z_scaled</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_t_z_scaled</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">train_t_z_scaled</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>







<span class="c1">######################################################### Define Mass parameters ###################</span>
<span class="c1">###########################################################</span>
<span class="c1"># Decide on parameters for this model and training</span>
<span class="n">PARAMS_m</span> <span class="o">=</span> <span class="p">{</span>
<span class="s2">&quot;n_layers&quot;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span>
<span class="s2">&quot;hidden_size&quot;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span>
<span class="s2">&quot;dropout_1&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="mf">0.6</span><span class="p">),</span>
<span class="s2">&quot;dropout_2&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
<span class="s2">&quot;activation&quot;</span><span class="p">:</span> <span class="s2">&quot;LeakyReLU&quot;</span><span class="p">,</span>
    <span class="s1">&#39;optimizer_name&#39;</span><span class="p">:</span><span class="s1">&#39;NAdam&#39;</span><span class="p">,</span>
    <span class="s1">&#39;starting_learning_rate&#39;</span><span class="p">:</span><span class="nb">float</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="s1">&#39;momentum&#39;</span><span class="p">:</span><span class="nb">float</span><span class="p">(</span><span class="mf">0.6</span><span class="p">),</span>
    <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span><span class="nb">int</span><span class="p">(</span><span class="mi">512</span><span class="p">),</span>
    <span class="s1">&#39;n_iterations&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e6</span><span class="p">),</span>
<span class="p">}</span>
<span class="c1">###########################################################</span>
<span class="c1">################################################## Train ###########################################################</span>
<span class="n">optimizer_name</span><span class="o">=</span><span class="n">PARAMS_m</span><span class="p">[</span><span class="s1">&#39;optimizer_name&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">optimizer_name</span><span class="p">))</span>
<span class="c1"># optimizer_name = BEST_PARAMS[&quot;optimizer_name&quot;].to_string().split()[1]</span>
<span class="n">NITERATIONS</span><span class="o">=</span><span class="n">PARAMS_m</span><span class="p">[</span><span class="s1">&#39;n_iterations&#39;</span><span class="p">]</span>
<span class="n">BATCHSIZE</span><span class="o">=</span><span class="n">PARAMS_m</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">]</span>
<span class="n">comment</span><span class="o">=</span><span class="s1">&#39;&#39;</span>



<span class="c1"># N_epochs X N_train_examples = N_iterations X batch_size</span>
<span class="n">N_epochs</span> <span class="o">=</span> <span class="p">(</span><span class="n">NITERATIONS</span> <span class="o">*</span> <span class="n">BATCHSIZE</span><span class="p">)</span> <span class="o">/</span> <span class="nb">int</span><span class="p">(</span><span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;training for </span><span class="si">{</span><span class="n">NITERATIONS</span><span class="si">}</span><span class="s2"> iteration, which is  </span><span class="si">{</span><span class="n">N_epochs</span><span class="si">}</span><span class="s2"> epochs&quot;</span><span class="p">)</span>


<span class="n">filename_model</span> <span class="o">=</span> <span class="n">get_model_filename</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">PARAMS_m</span><span class="p">)</span>
<span class="n">trained_models_dir</span> <span class="o">=</span> <span class="s2">&quot;trained_models&quot;</span>
<span class="n">mkdir</span><span class="p">(</span><span class="n">trained_models_dir</span><span class="p">)</span>
<span class="c1"># on cluster, Im using another TRAIN directory</span>
<span class="n">PATH_model</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
    <span class="n">IQN_BASE</span><span class="p">,</span> <span class="c1">#the loaction of the repo</span>
    <span class="s2">&quot;JupyterBook&quot;</span><span class="p">,</span> <span class="c1">#up tp TRAIN could be combined in a srs dicretory</span>
    <span class="s2">&quot;Cluster&quot;</span><span class="p">,</span> 
    <span class="s2">&quot;TRAIN&quot;</span><span class="p">,</span>
    <span class="n">trained_models_dir</span><span class="p">,</span> <span class="c1">#/trained_models </span>
    <span class="n">filename_model</span> <span class="c1"># utils.get_model_filename has the saved file format </span>
<span class="p">)</span>

<span class="c1">#LOAD EITHER TRAINED OR UNTRAINED MODEL</span>
<span class="c1"># to load untrained model (start training from scratch), uncomment the next line</span>
<span class="n">untrained_model</span> <span class="o">=</span> <span class="n">load_untrained_model</span><span class="p">(</span><span class="n">PARAMS_m</span><span class="p">)</span>
<span class="c1"># to continune training of model (pickup where the previous training left off), uncomment below</span>
<span class="c1"># trained_model =load_trained_model(PATH=PATH_model, PARAMS=PARAMS_m)</span>

<span class="n">IQN_trace</span> <span class="o">=</span> <span class="p">([],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[])</span>
<span class="n">traces_step</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">traces_window</span> <span class="o">=</span> <span class="n">traces_step</span>
<span class="n">IQN</span> <span class="o">=</span> <span class="n">run</span><span class="p">(</span>
    <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="n">untrained_model</span><span class="p">,</span>
    <span class="n">train_x</span><span class="o">=</span><span class="n">train_x_z_scaled</span><span class="p">,</span>
    <span class="n">train_t</span><span class="o">=</span><span class="n">train_t_z_scaled</span><span class="p">,</span>
    <span class="n">valid_x</span><span class="o">=</span><span class="n">test_x_z_scaled</span><span class="p">,</span>
    <span class="n">valid_t</span><span class="o">=</span><span class="n">test_t_z_scaled</span><span class="p">,</span>
    <span class="n">traces</span><span class="o">=</span><span class="n">IQN_trace</span><span class="p">,</span>
    <span class="n">PARAMS</span><span class="o">=</span><span class="n">PARAMS_m</span><span class="p">,</span>
    <span class="n">traces_step</span><span class="o">=</span><span class="n">traces_step</span><span class="p">,</span>
    <span class="n">traces_window</span><span class="o">=</span><span class="n">traces_window</span><span class="p">,</span>
    <span class="n">save_model</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>



<span class="n">SAVE_LAST_MODEL</span><span class="o">=</span><span class="kc">False</span>
<span class="k">if</span> <span class="n">SAVE_LAST_MODEL</span><span class="p">:</span>
    <span class="c1"># ## Save last iteration of trained model </span>
    <span class="c1">#dont save the last model, it might be worse than previous iterations, which were automatically savedby model checkpoints</span>

    <span class="n">final_path</span> <span class="o">=</span> <span class="n">get_model_filename</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">PARAMS_m</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.dict&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="s1">&#39;_FINAL.dict&#39;</span>

    <span class="n">trained_models_dir</span> <span class="o">=</span> <span class="s2">&quot;trained_models&quot;</span>
    <span class="n">mkdir</span><span class="p">(</span><span class="n">trained_models_dir</span><span class="p">)</span>
    <span class="c1"># on cluster, Im using another TRAIN directory</span>
    <span class="n">PATH_final_model</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
    <span class="n">IQN_BASE</span><span class="p">,</span> <span class="s2">&quot;JupyterBook&quot;</span><span class="p">,</span> <span class="s2">&quot;Cluster&quot;</span><span class="p">,</span> <span class="s2">&quot;TRAIN&quot;</span><span class="p">,</span> <span class="n">trained_models_dir</span><span class="p">,</span> <span class="n">final_path</span>
    <span class="p">)</span>

    <span class="n">save_model</span><span class="p">(</span><span class="n">IQN</span><span class="p">,</span> <span class="n">PATH_final_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Features:
 [&#39;genDatapT&#39;, &#39;genDataeta&#39;, &#39;genDataphi&#39;, &#39;genDatam&#39;, &#39;tau&#39;]

Target =  RecoDatam
USING NEW DATASET

spliting data for RecoDatam
train_t shape =  (8000000,) train_x shape =  (8000000, 5)

 Training features:

[[29.4452      0.828187    2.90213     2.85348     0.36130954]
 [24.3193     -1.16351     0.636469    5.83685     0.12689925]
 [24.3193     -1.16351     0.636469    5.83685     0.96230681]
 ...
 [41.4192     -2.23358    -2.81921     7.19348     0.08421659]
 [35.4637     -1.12318     0.356494    6.06597     0.05535172]
 [26.5586     -1.09427    -1.49334     4.25409     0.07489863]]
valid_t shape =  (1000000,) valid_x shape =  (1000000, 5)
test_t shape =  (1000000,) test_x shape =  (1000000, 5)
NORMAL UNSCALED DICTIONARY
{&#39;genDatapT&#39;: {&#39;mean&#39;: 32.695234084987476, &#39;std&#39;: 14.937932540562551}, &#39;genDataeta&#39;: {&#39;mean&#39;: -0.0017818817154031672, &#39;std&#39;: 2.204309760627079}, &#39;genDataphi&#39;: {&#39;mean&#39;: -0.0003830903308450233, &#39;std&#39;: 1.8138251604791067}, &#39;genDatam&#39;: {&#39;mean&#39;: 6.962994352358474, &#39;std&#39;: 2.781332025286383}, &#39;RecoDatapT&#39;: {&#39;mean&#39;: 32.86720151648752, &#39;std&#39;: 15.829355769531851}, &#39;RecoDataeta&#39;: {&#39;mean&#39;: -0.0017898858568513964, &#39;std&#39;: 2.197968491495457}, &#39;RecoDataphi&#39;: {&#39;mean&#39;: -0.0004719170328962474, &#39;std&#39;: 1.8144739820043825}, &#39;RecoDatam&#39;: {&#39;mean&#39;: 5.555567451922438, &#39;std&#39;: 2.664339857066051}}



[ 1.81700902e-03  1.12510099e-03 -2.82526482e-04 -6.57626105e-04
  5.00485136e-01] [1.01748627 0.9999745  0.99989115 0.99987283 0.28852734]
[ 1.61650249e-15 -1.10134124e-18 -3.12905257e-17  5.01036723e-15
  4.99915289e-01] [1.         1.         1.         1.         0.28867295]
-0.0015599314696879494 0.9999191874249058
6.996216939114674e-16 1.0000000000000002
&lt;class &#39;str&#39;&gt;
training for 1000000 iteration, which is  64.0 epochs
RegularizedRegressionModel(
  (model): Sequential(
    (0): Linear(in_features=5, out_features=5, bias=True)
    (1): LeakyReLU(negative_slope=0.3)
    (2): Linear(in_features=5, out_features=5, bias=True)
    (3): LeakyReLU(negative_slope=0.3)
    (4): Linear(in_features=5, out_features=5, bias=True)
    (5): LeakyReLU(negative_slope=0.3)
    (6): Linear(in_features=5, out_features=5, bias=True)
    (7): LeakyReLU(negative_slope=0.3)
    (8): Linear(in_features=5, out_features=5, bias=True)
    (9): LeakyReLU(negative_slope=0.3)
    (10): Linear(in_features=5, out_features=1, bias=True)
  )
)
training IQN 
Iteration vs average loss
 iteration	 train-set	  test-set
		CURRENT LEARNING RATE: 0.5
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">328</span><span class="n">a49577cb0</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">    </span><span class="mi">146</span> <span class="n">traces_step</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">147</span> <span class="n">traces_window</span> <span class="o">=</span> <span class="n">traces_step</span>
<span class="ne">--&gt; </span><span class="mi">148</span> <span class="n">IQN</span> <span class="o">=</span> <span class="n">run</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">149</span>     <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">150</span>     <span class="n">model</span><span class="o">=</span><span class="n">untrained_model</span><span class="p">,</span>

<span class="nn">/content/utils.py</span> in <span class="ni">wrapper_timer</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">574</span>                 <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;timing this arbitrary function&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">575</span>             <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
<span class="ne">--&gt; </span><span class="mi">576</span>             <span class="n">value</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">577</span>             <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">578</span>             <span class="n">run_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>

<span class="nn">&lt;ipython-input-10-2d69a21ca30b&gt;</span> in <span class="ni">run</span><span class="nt">(target, model, train_x, train_t, valid_x, valid_t, traces, PARAMS, traces_step, traces_window, save_model)</span>
<span class="g g-Whitespace">    </span><span class="mi">636</span>     <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">637</span> 
<span class="ne">--&gt; </span><span class="mi">638</span>     <span class="n">traces</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">639</span>         <span class="n">target</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">640</span>         <span class="n">model</span><span class="p">,</span>

<span class="nn">&lt;ipython-input-10-2d69a21ca30b&gt;</span> in <span class="ni">train</span><span class="nt">(target, model, avloss, getbatch, train_x, train_t, valid_x, valid_t, PARAMS, traces, step, window)</span>
<span class="g g-Whitespace">    </span><span class="mi">576</span> 
<span class="g g-Whitespace">    </span><span class="mi">577</span>             <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\t\t</span><span class="s2">CURRENT LEARNING RATE: </span><span class="si">{</span><span class="n">learning_rate</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">578</span>             <span class="n">acc_t</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">avloss</span><span class="p">,</span> <span class="n">train_x</span><span class="p">[:</span><span class="n">n</span><span class="p">],</span> <span class="n">train_t</span><span class="p">[:</span><span class="n">n</span><span class="p">])</span>
<span class="g g-Whitespace">    </span><span class="mi">579</span>             <span class="c1">#acc_t: list of training losses</span>
<span class="g g-Whitespace">    </span><span class="mi">580</span>             <span class="n">acc_v</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">avloss</span><span class="p">,</span> <span class="n">valid_x</span><span class="p">[:</span><span class="n">n</span><span class="p">],</span> <span class="n">valid_t</span><span class="p">[:</span><span class="n">n</span><span class="p">])</span>

<span class="nn">/content/utils.py</span> in <span class="ni">validate</span><span class="nt">(model, avloss, inputs, targets)</span>
<span class="g g-Whitespace">   </span><span class="mi">1006</span>         <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="g g-Whitespace">   </span><span class="mi">1007</span>         <span class="c1"># remember to reshape!</span>
<span class="ne">-&gt; </span><span class="mi">1008</span>         <span class="n">o</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1009</span>     <span class="k">return</span> <span class="n">avloss</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1010</span> 

<span class="nn">/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py</span> in <span class="ni">_call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1192</span>         <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1193</span>                 <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1194</span>             <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1195</span>         <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1196</span>         <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">&lt;ipython-input-10-2d69a21ca30b&gt;</span> in <span class="ni">forward</span><span class="nt">(self, x)</span>
<span class="g g-Whitespace">    </span><span class="mi">347</span> 
<span class="g g-Whitespace">    </span><span class="mi">348</span>     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">349</span>         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">350</span> 
<span class="g g-Whitespace">    </span><span class="mi">351</span> <span class="c1">###################################################################################################</span>

<span class="nn">/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py</span> in <span class="ni">_call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1192</span>         <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1193</span>                 <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1194</span>             <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1195</span>         <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1196</span>         <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py</span> in <span class="ni">forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">202</span>     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">203</span>         <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">204</span>             <span class="nb">input</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">205</span>         <span class="k">return</span> <span class="nb">input</span>
<span class="g g-Whitespace">    </span><span class="mi">206</span> 

<span class="nn">/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py</span> in <span class="ni">_call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1192</span>         <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1193</span>                 <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1194</span>             <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1195</span>         <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1196</span>         <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py</span> in <span class="ni">forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">112</span> 
<span class="g g-Whitespace">    </span><span class="mi">113</span>     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">114</span>         <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">115</span> 
<span class="g g-Whitespace">    </span><span class="mi">116</span>     <span class="k">def</span> <span class="nf">extra_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>

<span class="ne">RuntimeError</span>: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="evaluate-mass">
<h1>Evaluate Mass<a class="headerlink" href="#evaluate-mass" title="Permalink to this headline">#</a></h1>
<section id="needed-functions">
<h2>Needed functions<a class="headerlink" href="#needed-functions" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">################################## Load unscaled dataframes ###################################</span>
<span class="nd">@memory</span><span class="o">.</span><span class="n">cache</span>
<span class="k">def</span> <span class="nf">load_raw_data</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Dont use AUTOREGRESSIVE_DIST_NAME for training of any variable. </span>
<span class="sd">    For mass evaluation: dont use AUTOREGRESSIVE_DIST_NAME. For pT evaluation use AUTOREGRESSIVE_DIST_NAME </span>
<span class="sd">    as the distribution predicted by mass, etc.  &quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">SUBSAMPLE = </span><span class="si">{</span><span class="n">SUBSAMPLE</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">raw_train_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="s2">&quot;train_data_10M_2.csv&quot;</span><span class="p">),</span>
        <span class="n">usecols</span><span class="o">=</span><span class="n">all_cols</span><span class="p">,</span>
        <span class="n">nrows</span><span class="o">=</span><span class="n">SUBSAMPLE</span><span class="p">,</span>
    <span class="p">)</span>



    <span class="n">raw_valid_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="s2">&quot;validation_data_10M_2.csv&quot;</span><span class="p">),</span>
        <span class="n">usecols</span><span class="o">=</span><span class="n">all_cols</span><span class="p">,</span>
        <span class="n">nrows</span><span class="o">=</span><span class="n">SUBSAMPLE</span><span class="p">,</span>
    <span class="p">)</span>
    

    
    <span class="n">raw_test_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="s2">&quot;test_data_10M_2.csv&quot;</span><span class="p">),</span> 
    <span class="n">usecols</span><span class="o">=</span><span class="n">all_cols</span><span class="p">,</span> 
    <span class="n">nrows</span><span class="o">=</span><span class="n">SUBSAMPLE</span>
    <span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> RAW TRAIN DATA</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">raw_train_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">raw_train_data</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>  <span class="c1"># unscaled</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> RAW TEST DATA</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">raw_test_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">raw_test_data</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>  <span class="c1"># unscaled</span>

    <span class="k">return</span> <span class="n">raw_train_data</span><span class="p">,</span> <span class="n">raw_test_data</span><span class="p">,</span> <span class="n">raw_valid_data</span>


<span class="c1">########## Generate scaled data###############</span>
<span class="c1"># scaled_train_data = L_scale_df(raw_train_data, title=&#39;scaled_train_data_10M_2.csv&#39;,</span>
<span class="c1">#                              save=True)</span>
<span class="c1"># print(&#39;\n\n&#39;)</span>
<span class="c1"># scaled_test_data = L_scale_df(raw_test_data,  title=&#39;scaled_test_data_10M_2.csv&#39;,</span>
<span class="c1">#                             save=True)</span>
<span class="c1"># print(&#39;\n\n&#39;)</span>

<span class="c1"># scaled_valid_data = L_scale_df(raw_valid_data,  title=&#39;scaled_valid_data_10M_2.csv&#39;,</span>
<span class="c1">#                             save=True)</span>

<span class="c1"># explore_data(df=scaled_train_data, title=&#39;Braden Kronheim-L-scaled Dataframe&#39;, scaled=True)</span>

<span class="c1">################ Load scaled data##############</span>
<span class="nd">@utils</span><span class="o">.</span><span class="n">time_type_of_func</span><span class="p">(</span><span class="n">tuning_or_training</span><span class="o">=</span><span class="s2">&quot;loading&quot;</span><span class="p">)</span>
<span class="c1"># @memory.cache</span>
<span class="k">def</span> <span class="nf">load_scaled_dataframes</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;SCALED TRAIN DATA&quot;</span><span class="p">)</span>
    <span class="n">scaled_train_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="s2">&quot;scaled_train_data_10M_2.csv&quot;</span><span class="p">),</span>
        <span class="n">usecols</span><span class="o">=</span><span class="n">all_cols</span><span class="p">,</span>
        <span class="n">nrows</span><span class="o">=</span><span class="n">SUBSAMPLE</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TRAINING FEATURES</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">scaled_train_data</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

    <span class="n">scaled_test_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="s2">&quot;scaled_test_data_10M_2.csv&quot;</span><span class="p">),</span>
        <span class="n">usecols</span><span class="o">=</span><span class="n">all_cols</span><span class="p">,</span>
        <span class="n">nrows</span><span class="o">=</span><span class="n">SUBSAMPLE</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">scaled_valid_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="s2">&quot;scaled_valid_data_10M_2.csv&quot;</span><span class="p">),</span>
        <span class="n">usecols</span><span class="o">=</span><span class="n">all_cols</span><span class="p">,</span>
        <span class="n">nrows</span><span class="o">=</span><span class="n">SUBSAMPLE</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">scaled_train_data</span><span class="p">,</span> <span class="n">scaled_test_data</span><span class="p">,</span> <span class="n">scaled_valid_data</span>


<span class="c1">#######################################</span>
<span class="c1">#</span>
<span class="c1"># # print(&#39;\nTESTING FEATURES\n&#39;, scaled_test_data.head())</span>

<span class="c1"># print(&#39;\ntrain set shape:&#39;,  scaled_train_data.shape)</span>
<span class="c1"># print(&#39;\ntest set shape:  &#39;, scaled_test_data.shape)</span>
<span class="c1"># # print(&#39;validation set shape:&#39;, valid_data.shape)</span>
<span class="c1"># @memory.cache</span>
<span class="k">def</span> <span class="nf">get_train_scale_dict</span><span class="p">(</span><span class="n">USE_BRADEN_SCALING</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">USE_BRADEN_SCALING</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
        <span class="n">TRAIN_SCALE_DICT</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">get_scaling_info</span><span class="p">(</span><span class="n">scaled_train_data</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;BRADEN SCALING DICTIONARY&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">TRAIN_SCALE_DICT</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># TEST_SCALE_DICT = get_scaling_info(scaled_test_data)</span>
        <span class="c1"># print(TEST_SCALE_DICT)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;NORMAL UNSCALED DICTIONARY&quot;</span><span class="p">)</span>
        <span class="n">TRAIN_SCALE_DICT</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">get_scaling_info</span><span class="p">(</span><span class="n">raw_train_data</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">TRAIN_SCALE_DICT</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># TEST_SCALE_DICT = get_scaling_info(scaled_test_data)</span>
        <span class="c1"># print(TEST_SCALE_DICT)</span>
    <span class="k">return</span> <span class="n">TRAIN_SCALE_DICT</span>


<span class="c1">################################ SPLIT###########</span>
<span class="c1"># @memory.cache</span>
<span class="k">def</span> <span class="nf">T</span><span class="p">(</span><span class="n">variable</span><span class="p">,</span> <span class="n">scaled_df</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">variable</span> <span class="o">==</span> <span class="s2">&quot;pT&quot;</span><span class="p">:</span>
        <span class="n">L_pT_gen</span> <span class="o">=</span> <span class="n">scaled_df</span><span class="p">[</span><span class="s2">&quot;genDatapT&quot;</span><span class="p">]</span>
        <span class="n">L_pT_reco</span> <span class="o">=</span> <span class="n">scaled_df</span><span class="p">[</span><span class="s2">&quot;RecoDatapT&quot;</span><span class="p">]</span>
        <span class="n">target</span> <span class="o">=</span> <span class="p">(</span><span class="n">L_pT_reco</span> <span class="o">+</span> <span class="mi">10</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">L_pT_gen</span> <span class="o">+</span> <span class="mi">10</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">variable</span> <span class="o">==</span> <span class="s2">&quot;eta&quot;</span><span class="p">:</span>
        <span class="n">L_eta_gen</span> <span class="o">=</span> <span class="n">scaled_df</span><span class="p">[</span><span class="s2">&quot;genDataeta&quot;</span><span class="p">]</span>
        <span class="n">L_eta_reco</span> <span class="o">=</span> <span class="n">scaled_df</span><span class="p">[</span><span class="s2">&quot;RecoDataeta&quot;</span><span class="p">]</span>
        <span class="n">target</span> <span class="o">=</span> <span class="p">(</span><span class="n">L_eta_reco</span> <span class="o">+</span> <span class="mi">10</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">L_eta_gen</span> <span class="o">+</span> <span class="mi">10</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">variable</span> <span class="o">==</span> <span class="s2">&quot;phi&quot;</span><span class="p">:</span>
        <span class="n">L_phi_gen</span> <span class="o">=</span> <span class="n">scaled_df</span><span class="p">[</span><span class="s2">&quot;genDataphi&quot;</span><span class="p">]</span>
        <span class="n">L_phi_reco</span> <span class="o">=</span> <span class="n">scaled_df</span><span class="p">[</span><span class="s2">&quot;RecoDataphi&quot;</span><span class="p">]</span>
        <span class="n">target</span> <span class="o">=</span> <span class="p">(</span><span class="n">L_phi_reco</span> <span class="o">+</span> <span class="mi">10</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">L_phi_gen</span> <span class="o">+</span> <span class="mi">10</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">variable</span> <span class="o">==</span> <span class="s2">&quot;m&quot;</span><span class="p">:</span>
        <span class="n">L_m_gen</span> <span class="o">=</span> <span class="n">scaled_df</span><span class="p">[</span><span class="s2">&quot;genDatam&quot;</span><span class="p">]</span>
        <span class="n">L_m_reco</span> <span class="o">=</span> <span class="n">scaled_df</span><span class="p">[</span><span class="s2">&quot;RecoDatam&quot;</span><span class="p">]</span>
        <span class="n">target</span> <span class="o">=</span> <span class="p">(</span><span class="n">L_m_reco</span> <span class="o">+</span> <span class="mi">10</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">L_m_gen</span> <span class="o">+</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">target</span>


<span class="c1"># @memory.cache</span>
<span class="k">def</span> <span class="nf">split_t_x</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">input_features</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get teh target as the ratio, according to the T equation&quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">target</span> <span class="o">==</span> <span class="s2">&quot;RecoDatam&quot;</span><span class="p">:</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">T</span><span class="p">(</span><span class="s2">&quot;m&quot;</span><span class="p">,</span> <span class="n">scaled_df</span><span class="o">=</span><span class="n">scaled_train_data</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">target</span> <span class="o">==</span> <span class="s2">&quot;RecoDatapT&quot;</span><span class="p">:</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">T</span><span class="p">(</span><span class="s2">&quot;pT&quot;</span><span class="p">,</span> <span class="n">scaled_df</span><span class="o">=</span><span class="n">scaled_train_data</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">target</span> <span class="o">==</span> <span class="s2">&quot;RecoDataeta&quot;</span><span class="p">:</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">T</span><span class="p">(</span><span class="s2">&quot;eta&quot;</span><span class="p">,</span> <span class="n">scaled_df</span><span class="o">=</span><span class="n">scaled_train_data</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">target</span> <span class="o">==</span> <span class="s2">&quot;RecoDataphi&quot;</span><span class="p">:</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">T</span><span class="p">(</span><span class="s2">&quot;phi&quot;</span><span class="p">,</span> <span class="n">scaled_df</span><span class="o">=</span><span class="n">scaled_train_data</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">input_features</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">x</span>


<span class="c1"># @memory.cache</span>
<span class="k">def</span> <span class="nf">split_t_x_test</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">input_features</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get teh target as the ratio, according to the T equation&quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">target</span> <span class="o">==</span> <span class="s2">&quot;RecoDatam&quot;</span><span class="p">:</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">T</span><span class="p">(</span><span class="s2">&quot;m&quot;</span><span class="p">,</span> <span class="n">scaled_df</span><span class="o">=</span><span class="n">scaled_test_data</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">target</span> <span class="o">==</span> <span class="s2">&quot;RecoDatapT&quot;</span><span class="p">:</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">T</span><span class="p">(</span><span class="s2">&quot;pT&quot;</span><span class="p">,</span> <span class="n">scaled_df</span><span class="o">=</span><span class="n">scaled_test_data</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">target</span> <span class="o">==</span> <span class="s2">&quot;RecoDataeta&quot;</span><span class="p">:</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">T</span><span class="p">(</span><span class="s2">&quot;eta&quot;</span><span class="p">,</span> <span class="n">scaled_df</span><span class="o">=</span><span class="n">scaled_test_data</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">target</span> <span class="o">==</span> <span class="s2">&quot;RecoDataphi&quot;</span><span class="p">:</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">T</span><span class="p">(</span><span class="s2">&quot;phi&quot;</span><span class="p">,</span> <span class="n">scaled_df</span><span class="o">=</span><span class="n">scaled_test_data</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">input_features</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">x</span>


<span class="c1">#########################################################################</span>
<span class="c1"># @memory.cache</span>
<span class="k">def</span> <span class="nf">normal_split_t_x</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">input_features</span><span class="p">):</span>
    <span class="c1"># change from pandas dataframe format to a numpy</span>
    <span class="c1"># array of the specified types</span>
    <span class="c1"># t = np.array(df[target])</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">target</span><span class="p">])</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">input_features</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span>


<span class="c1">################ Apply Z scaling############</span>
<span class="k">def</span> <span class="nf">z</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-20</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">z_inverse</span><span class="p">(</span><span class="n">xprime</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">xprime</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="c1"># @memory.cache</span>
<span class="k">def</span> <span class="nf">z2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">        x ([type]): [description]</span>
<span class="sd">        mean ([type]): [description]</span>
<span class="sd">        std ([type]): [description]</span>

<span class="sd">    Returns:</span>
<span class="sd">        [type]: [description]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-20</span>
    <span class="n">scaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">std</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">scaled</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">z_inverse</span><span class="p">(</span><span class="n">xprime</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">unscaled</span> <span class="o">=</span> <span class="n">xprime</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">unscaled</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>


<span class="c1"># @memory.cache</span>
<span class="k">def</span> <span class="nf">z_inverse2</span><span class="p">(</span><span class="n">xprime</span><span class="p">,</span> <span class="n">train_mean</span><span class="p">,</span> <span class="n">train_std</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;mean original train mean, std: original. Probably not needed&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">xprime</span> <span class="o">*</span> <span class="n">train_std</span> <span class="o">+</span> <span class="n">train_mean</span>


<span class="c1"># @memory.cache</span>
<span class="k">def</span> <span class="nf">apply_z_to_features</span><span class="p">(</span><span class="n">TRAIN_SCALE_DICT</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">test_x</span><span class="p">,</span> <span class="n">valid_x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;TO ensure this z scaling is only applied once to the training features, we use a generator.</span>
<span class="sd">    This doesn&#39;t change the shapes of anything, just applies z to all the feature columns other than tau&quot;&quot;&quot;</span>
    <span class="n">NFEATURES</span> <span class="o">=</span> <span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NFEATURES</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">variable</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">TRAIN_SCALE_DICT</span><span class="p">)[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">train_mean</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">TRAIN_SCALE_DICT</span><span class="p">[</span><span class="n">variable</span><span class="p">][</span><span class="s2">&quot;mean&quot;</span><span class="p">])</span>
        <span class="n">train_std</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">TRAIN_SCALE_DICT</span><span class="p">[</span><span class="n">variable</span><span class="p">][</span><span class="s2">&quot;std&quot;</span><span class="p">])</span>
        <span class="n">train_x</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">z2</span><span class="p">(</span><span class="n">train_x</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">mean</span><span class="o">=</span><span class="n">train_mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">train_std</span><span class="p">)</span>
        <span class="n">test_x</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">z2</span><span class="p">(</span><span class="n">test_x</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">mean</span><span class="o">=</span><span class="n">train_mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">train_std</span><span class="p">)</span>
        <span class="n">valid_x</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">z2</span><span class="p">(</span><span class="n">valid_x</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">mean</span><span class="o">=</span><span class="n">train_mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">train_std</span><span class="p">)</span>
    <span class="k">yield</span> <span class="n">train_x</span>
    <span class="k">yield</span> <span class="n">test_x</span>
    <span class="k">yield</span> <span class="n">valid_x</span>


<span class="c1"># @memory.cache</span>
<span class="k">def</span> <span class="nf">apply_z_to_targets</span><span class="p">(</span><span class="n">train_t</span><span class="p">,</span> <span class="n">test_t</span><span class="p">,</span> <span class="n">valid_t</span><span class="p">):</span>
    <span class="n">train_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_t</span><span class="p">)</span>
    <span class="n">train_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">train_t</span><span class="p">)</span>
    <span class="n">train_t_</span> <span class="o">=</span> <span class="n">z2</span><span class="p">(</span><span class="n">train_t</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">train_mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">train_std</span><span class="p">)</span>
    <span class="n">test_t_</span> <span class="o">=</span> <span class="n">z2</span><span class="p">(</span><span class="n">test_t</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">train_mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">train_std</span><span class="p">)</span>
    <span class="n">valid_t_</span> <span class="o">=</span> <span class="n">z2</span><span class="p">(</span><span class="n">valid_t</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">train_mean</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">train_std</span><span class="p">)</span>

    <span class="k">yield</span> <span class="n">train_t_</span>
    <span class="k">yield</span> <span class="n">test_t_</span>
    <span class="k">yield</span> <span class="n">valid_t_</span>


<span class="c1"># @utils.debug</span>
<span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">PATH</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">trained model dictionary saved in </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">PATH</span><span class="p">)</span>


<span class="c1"># @utils.debug</span>
<span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="n">PATH</span><span class="p">,</span> <span class="n">PARAMS</span><span class="p">):</span>
    <span class="c1"># n_layers = int(BEST_PARAMS[&quot;n_layers&quot;])</span>
    <span class="c1"># hidden_size = int(BEST_PARAMS[&quot;hidden_size&quot;])</span>
    <span class="c1"># dropout = float(BEST_PARAMS[&quot;dropout&quot;])</span>
    <span class="c1"># optimizer_name = BEST_PARAMS[&quot;optimizer_name&quot;].to_string().split()[1]</span>
    <span class="c1"># learning_rate =  float(BEST_PARAMS[&quot;learning_rate&quot;])</span>
    <span class="c1"># batch_size = int(BEST_PARAMS[&quot;batch_size&quot;])</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
        <span class="n">nfeatures</span><span class="o">=</span><span class="n">NFEATURES</span><span class="p">,</span>
        <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">nlayers</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">],</span>
        <span class="n">hidden_size</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">],</span>
        <span class="n">dropout_1</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s2">&quot;dropout_1&quot;</span><span class="p">],</span>
        <span class="n">dropout_2</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s2">&quot;dropout_2&quot;</span><span class="p">],</span>
        <span class="n">activation</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s2">&quot;activation&quot;</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">))</span>
    <span class="c1"># OR</span>
    <span class="c1"># model=torch.load(PATH)#BUT HERE IT WILL BE A DICT (CANT BE EVALUATED RIGHT AWAY) DISCOURAGED! Also, use dictionary &quot;.pth&quot; which has both the model state dict and the PARAMS dict</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>


<span class="c1"># @memory.cache</span>
<span class="k">def</span> <span class="nf">simple_eval</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_x_z_scaled</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="c1"># evaluate on the scaled features</span>
    <span class="n">valid_x_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">test_x_z_scaled</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="c1"># valid_x_tensor=torch.from_numpy(train_x).float()</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">valid_x_tensor</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="c1"># if USE_BRADEN_SCALING:</span>
    <span class="c1">#     fig, ax = plt.subplots(1,1)</span>
    <span class="c1">#     label=FIELDS[target][&#39;ylabel&#39;]</span>
    <span class="c1">#     ax.hist(p, label=f&#39;Predicted post-z ratio for {label}&#39;, alpha=0.4, density=True)</span>
    <span class="c1">#     # orig_ratio = z(T(&#39;m&#39;, scaled_df=scaled_train_data))</span>
    <span class="c1">#     orig_ratio = z(T(&#39;m&#39;, scaled_df=scaled_test_data))</span>
    <span class="c1">#     print(orig_ratio[:5])</span>
    <span class="c1">#     ax.hist(orig_ratio, label = f&#39;original post-z ratio for {label}&#39;, alpha=0.4,density=True)</span>
    <span class="c1">#     ax.grid()</span>
    <span class="c1">#     set_axes(ax, xlabel=&#39;predicted $T$&#39;)</span>
    <span class="c1"># print(&#39;predicted ratio shape: &#39;, p.shape)</span>
    <span class="k">return</span> <span class="n">p</span>

<span class="k">def</span> <span class="nf">get_previous_autoregressive_dist</span><span class="p">(</span><span class="n">AUTOREGRESSIVE_DIST_NAME</span><span class="p">):</span>
        
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Test (evaluation) Data is Autoregressive, loading </span><span class="si">{</span><span class="n">AUTOREGRESSIVE_DIST_NAME</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">eval_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="n">IQN_BASE</span><span class="p">,</span>
            <span class="s2">&quot;JupyterBook&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Cluster&quot;</span><span class="p">,</span>
            <span class="s2">&quot;EVALUATE&quot;</span><span class="p">,</span>
            <span class="n">AUTOREGRESSIVE_DIST_NAME</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">eval_data</span>


<span class="c1"># @memory.cache</span>
<span class="k">def</span> <span class="nf">get_hist</span><span class="p">(</span><span class="n">label</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;label could be &quot;pT&quot;, &quot;eta&quot;, &quot;phi&quot;, &quot;m&quot; &quot;&quot;&quot;</span>
    <span class="n">predicted_label_counts</span><span class="p">,</span> <span class="n">label_edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span>
        <span class="n">JETS_DICT</span><span class="p">[</span><span class="s2">&quot;Predicted_RecoData&quot;</span> <span class="o">+</span> <span class="n">label</span><span class="p">][</span><span class="s2">&quot;dist&quot;</span><span class="p">],</span>
        <span class="nb">range</span><span class="o">=</span><span class="n">JETS_DICT</span><span class="p">[</span><span class="s2">&quot;Predicted_RecoData&quot;</span> <span class="o">+</span> <span class="n">label</span><span class="p">][</span><span class="s2">&quot;range&quot;</span><span class="p">],</span>
        <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">real_label_counts</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span>
        <span class="n">JETS_DICT</span><span class="p">[</span><span class="s2">&quot;Real_RecoData&quot;</span> <span class="o">+</span> <span class="n">label</span><span class="p">][</span><span class="s2">&quot;dist&quot;</span><span class="p">],</span>
        <span class="nb">range</span><span class="o">=</span><span class="n">JETS_DICT</span><span class="p">[</span><span class="s2">&quot;Real_RecoData&quot;</span> <span class="o">+</span> <span class="n">label</span><span class="p">][</span><span class="s2">&quot;range&quot;</span><span class="p">],</span>
        <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">label_edges</span> <span class="o">=</span> <span class="n">label_edges</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">label_edges</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span>

    <span class="k">return</span> <span class="n">real_label_counts</span><span class="p">,</span> <span class="n">predicted_label_counts</span><span class="p">,</span> <span class="n">label_edges</span>


<span class="c1"># @memory.cache</span>
<span class="k">def</span> <span class="nf">get_hist_simple</span><span class="p">(</span><span class="n">predicted_dist</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
    
    <span class="n">range_</span> <span class="o">=</span> <span class="p">(</span><span class="n">FIELDS</span><span class="p">[</span><span class="n">target</span><span class="p">][</span><span class="s2">&quot;xmin&quot;</span><span class="p">],</span> <span class="n">FIELDS</span><span class="p">[</span><span class="n">target</span><span class="p">][</span><span class="s2">&quot;xmax&quot;</span><span class="p">])</span>
    <span class="n">bins</span><span class="o">=</span><span class="mi">50</span>
    <span class="n">predicted_label_counts</span><span class="p">,</span> <span class="n">label_edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span>
        <span class="n">predicted_dist</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="n">range_</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span>
    <span class="p">)</span>
    
    
    <span class="n">real_label_counts</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">REAL_DIST</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="n">range_</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">)</span>
    <span class="n">label_edges</span> <span class="o">=</span> <span class="n">label_edges</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">label_edges</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="k">return</span> <span class="n">real_label_counts</span><span class="p">,</span> <span class="n">predicted_label_counts</span><span class="p">,</span> <span class="n">label_edges</span>


<span class="c1"># @memory.cache</span>
<span class="k">def</span> <span class="nf">plot_one</span><span class="p">(</span>
    <span class="n">target</span><span class="p">,</span> <span class="n">real_edges</span><span class="p">,</span> <span class="n">real_counts</span><span class="p">,</span> <span class="n">predicted_counts</span><span class="p">,</span> <span class="n">save_plot</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">PARAMS</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">JUPYTER</span><span class="o">=</span><span class="kc">True</span>
<span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span>
        <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">3.5</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">/</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">3.8</span><span class="p">),</span> <span class="n">gridspec_kw</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;height_ratios&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]}</span>
    <span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">step</span><span class="p">(</span>
        <span class="n">real_edges</span><span class="p">,</span> <span class="n">real_counts</span> <span class="o">/</span> <span class="n">norm_data</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="s2">&quot;mid&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span>
    <span class="p">)</span>  <span class="c1"># step real_count_pt</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">step</span><span class="p">(</span>
        <span class="n">real_edges</span><span class="p">,</span>
        <span class="n">predicted_counts</span> <span class="o">/</span> <span class="n">norm_IQN</span><span class="p">,</span>
        <span class="n">where</span><span class="o">=</span><span class="s2">&quot;mid&quot;</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#D7301F&quot;</span><span class="p">,</span>
        <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="p">)</span>  <span class="c1"># step predicted_count_pt</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
        <span class="n">real_edges</span><span class="p">,</span>
        <span class="n">real_counts</span> <span class="o">/</span> <span class="n">norm_data</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s2">&quot;reco&quot;</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span>
        <span class="n">facecolors</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
        <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span>
        <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
        <span class="n">real_edges</span><span class="p">,</span>
        <span class="n">predicted_counts</span> <span class="o">/</span> <span class="n">norm_IQN</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s2">&quot;predicted&quot;</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#D7301F&quot;</span><span class="p">,</span>
        <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span>
        <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">range_</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">predicted_counts</span> <span class="o">/</span> <span class="n">norm_IQN</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.1</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;counts&quot;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([])</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper right&quot;</span><span class="p">)</span>

    <span class="n">ratio</span> <span class="o">=</span> <span class="p">(</span><span class="n">predicted_counts</span> <span class="o">/</span> <span class="n">norm_IQN</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">real_counts</span> <span class="o">/</span> <span class="n">norm_data</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
        <span class="n">real_edges</span><span class="p">,</span> <span class="n">ratio</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span>
    <span class="p">)</span>  <span class="c1"># PREDICTED (IQN)/Reco (Data)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
        <span class="n">real_edges</span><span class="p">,</span>
        <span class="n">ratio</span> <span class="o">/</span> <span class="n">ratio</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span>
        <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span>
        <span class="n">facecolors</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
        <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">range_</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">FIELDS</span><span class="p">[</span><span class="n">target</span><span class="p">][</span><span class="s2">&quot;xlabel&quot;</span><span class="p">])</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span>
        <span class="sa">r</span><span class="s2">&quot;$\frac{\textnormal</span><span class="si">{predicted}</span><span class="s2">}{\textnormal</span><span class="si">{reco}</span><span class="s2">}$&quot;</span>
        <span class="c1">#    , fontsize=10</span>
    <span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">((</span><span class="n">YLIM</span><span class="p">))</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">range_</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">JUPYTER</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

    <span class="c1"># plt.gca().set_position([0, 0, 1, 1])</span>
    <span class="k">if</span> <span class="n">save_plot</span><span class="p">:</span>
        <span class="n">plot_filename</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">get_model_filename</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">PARAMS</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.dict&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;.png&quot;</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span>
            <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">IQN_BASE</span><span class="p">,</span> 
                         <span class="s2">&quot;JupyterBook&quot;</span><span class="p">,</span> 
                         <span class="s2">&quot;Cluster&quot;</span><span class="p">,</span> 
                        <span class="c1">#  &quot;EVALUATE&quot;, </span>
                         <span class="n">plot_filename</span><span class="p">)</span>
        <span class="p">)</span>

    
    <span class="c1"># fig.show()</span>
    <span class="c1"># plt.show();</span>
    <span class="c1"># plt.axis(&quot;off&quot;)</span>
    <span class="c1"># plt.gca().set_position([0, 0, 1, 1])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># TODO: plot the loss curves (train and valid) of all 4 networks on the same plot,</span>
<span class="c1"># and with the learning rate plotted on the same plot but on a different y axis </span>
<span class="c1"># (x axis being iteration, with marks indicating epochs)</span>

<span class="n">target</span> <span class="o">=</span> <span class="s2">&quot;RecoDatam&quot;</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">FIELDS</span><span class="p">[</span><span class="n">target</span><span class="p">]</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">source</span><span class="p">[</span><span class="s2">&quot;inputs&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training Features:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">features</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Target = &quot;</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="n">AUTOREGRESSIVE_DIST_NAME</span> <span class="o">=</span> <span class="s2">&quot;AUTOREGRESSIVE_m_Prime.csv&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;USING NEW DATASET</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1">######################################</span>
<span class="n">USE_BRADEN_SCALING</span> <span class="o">=</span> <span class="kc">True</span>
<span class="c1">#####################################</span>
<span class="c1">################################### CONFIGURATIONS ###################################</span>

<span class="n">JUPYTER</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">use_subsample</span> <span class="o">=</span> <span class="kc">False</span>
<span class="c1"># use_subsample = True</span>
<span class="k">if</span> <span class="n">use_subsample</span><span class="p">:</span>
    <span class="n">SUBSAMPLE</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span>
        <span class="mf">1e5</span>
    <span class="p">)</span>  <span class="c1"># subsample use for development - in production use whole dataset</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">SUBSAMPLE</span> <span class="o">=</span> <span class="kc">None</span>

<span class="c1">########################################################################################</span>
<span class="c1"># Get targets and features</span>
<span class="k">if</span> <span class="n">USE_BRADEN_SCALING</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;spliting data for </span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">train_t</span><span class="p">,</span> <span class="n">train_x</span> <span class="o">=</span> <span class="n">split_t_x</span><span class="p">(</span>
        <span class="n">df</span><span class="o">=</span><span class="n">scaled_train_data</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">input_features</span><span class="o">=</span><span class="n">features</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train_t shape = &quot;</span><span class="p">,</span> <span class="n">train_t</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;train_x shape = &quot;</span><span class="p">,</span> <span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Training features:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span>
    <span class="n">valid_t</span><span class="p">,</span> <span class="n">valid_x</span> <span class="o">=</span> <span class="n">split_t_x</span><span class="p">(</span>
        <span class="n">df</span><span class="o">=</span><span class="n">scaled_valid_data</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">input_features</span><span class="o">=</span><span class="n">features</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;valid_t shape = &quot;</span><span class="p">,</span> <span class="n">valid_t</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;valid_x shape = &quot;</span><span class="p">,</span> <span class="n">valid_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">test_t</span><span class="p">,</span> <span class="n">test_x</span> <span class="o">=</span> <span class="n">split_t_x</span><span class="p">(</span>
        <span class="n">df</span><span class="o">=</span><span class="n">scaled_test_data</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">input_features</span><span class="o">=</span><span class="n">features</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;test_t shape = &quot;</span><span class="p">,</span> <span class="n">test_t</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;test_x shape = &quot;</span><span class="p">,</span> <span class="n">test_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;spliting data for </span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">train_t</span><span class="p">,</span> <span class="n">train_x</span> <span class="o">=</span> <span class="n">normal_split_t_x</span><span class="p">(</span>
        <span class="n">df</span><span class="o">=</span><span class="n">raw_train_data</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">input_features</span><span class="o">=</span><span class="n">features</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train_t shape = &quot;</span><span class="p">,</span> <span class="n">train_t</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;train_x shape = &quot;</span><span class="p">,</span> <span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Training features:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span>
    <span class="n">valid_t</span><span class="p">,</span> <span class="n">valid_x</span> <span class="o">=</span> <span class="n">normal_split_t_x</span><span class="p">(</span>
        <span class="n">df</span><span class="o">=</span><span class="n">raw_valid_data</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">input_features</span><span class="o">=</span><span class="n">features</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;valid_t shape = &quot;</span><span class="p">,</span> <span class="n">valid_t</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;valid_x shape = &quot;</span><span class="p">,</span> <span class="n">valid_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">test_t</span><span class="p">,</span> <span class="n">test_x</span> <span class="o">=</span> <span class="n">normal_split_t_x</span><span class="p">(</span>
        <span class="n">df</span><span class="o">=</span><span class="n">raw_test_data</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">input_features</span><span class="o">=</span><span class="n">features</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;test_t shape = &quot;</span><span class="p">,</span> <span class="n">test_t</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;test_x shape = &quot;</span><span class="p">,</span> <span class="n">test_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;no need to train_test_split since we already have the split dataframes&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">valid_x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">valid_x</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">train_x</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">valid_t</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">valid_t</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_t</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">train_t</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>
<span class="c1">######################################################</span>

<span class="c1"># Apply z scaling to features and targets</span>
<span class="c1"># to features</span>

<span class="n">NFEATURES</span> <span class="o">=</span> <span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">TRAIN_SCALE_DICT</span> <span class="o">=</span> <span class="n">get_train_scale_dict</span><span class="p">(</span><span class="n">USE_BRADEN_SCALING</span><span class="p">)</span>
<span class="c1"># to features</span>
<span class="n">apply_z_generator</span> <span class="o">=</span> <span class="n">apply_z_to_features</span><span class="p">(</span><span class="n">TRAIN_SCALE_DICT</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">test_x</span><span class="p">,</span> <span class="n">valid_x</span><span class="p">)</span>
<span class="n">train_x_z_scaled</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">apply_z_generator</span><span class="p">)</span>
<span class="n">test_x_z_scaled</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">apply_z_generator</span><span class="p">)</span>
<span class="n">valid_x_z_scaled</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">apply_z_generator</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">valid_x_z_scaled</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">valid_x_z_scaled</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_x_z_scaled</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">train_x_z_scaled</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="c1"># to targets</span>
<span class="n">apply_z_to_targets_generator</span> <span class="o">=</span> <span class="n">apply_z_to_targets</span><span class="p">(</span><span class="n">train_t</span><span class="p">,</span> <span class="n">test_t</span><span class="p">,</span> <span class="n">valid_t</span><span class="p">)</span>
<span class="n">train_t_z_scaled</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">apply_z_to_targets_generator</span><span class="p">)</span>
<span class="n">test_t_z_scaled</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">apply_z_to_targets_generator</span><span class="p">)</span>
<span class="n">valid_t_z_scaled</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">apply_z_to_targets_generator</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">valid_t_z_scaled</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">valid_t_z_scaled</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_t_z_scaled</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">train_t_z_scaled</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>

<span class="c1">###########################################################</span>
<span class="c1"># @utils.debug</span>
<span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="n">PATH</span><span class="p">,</span> <span class="n">PARAMS</span><span class="p">):</span>
    <span class="c1"># n_layers = int(BEST_PARAMS[&quot;n_layers&quot;])</span>
    <span class="c1"># hidden_size = int(BEST_PARAMS[&quot;hidden_size&quot;])</span>
    <span class="c1"># dropout = float(BEST_PARAMS[&quot;dropout&quot;])</span>
    <span class="c1"># optimizer_name = BEST_PARAMS[&quot;optimizer_name&quot;].to_string().split()[1]</span>
    <span class="c1"># learning_rate =  float(BEST_PARAMS[&quot;learning_rate&quot;])</span>
    <span class="c1"># batch_size = int(BEST_PARAMS[&quot;batch_size&quot;])</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
        <span class="n">nfeatures</span><span class="o">=</span><span class="n">NFEATURES</span><span class="p">,</span>
        <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">nlayers</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">],</span>
        <span class="n">hidden_size</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">],</span>
        <span class="n">dropout_1</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s2">&quot;dropout_1&quot;</span><span class="p">],</span>
        <span class="n">dropout_2</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s2">&quot;dropout_2&quot;</span><span class="p">],</span>
        <span class="n">activation</span><span class="o">=</span><span class="n">PARAMS</span><span class="p">[</span><span class="s2">&quot;activation&quot;</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">))</span>
    <span class="c1"># OR</span>
    <span class="c1"># model=torch.load(PATH)#BUT HERE IT WILL BE A DICT (CANT BE EVALUATED RIGHT AWAY) DISCOURAGED! Also, use dictionary &quot;.pth&quot; which has both the model state dict and the PARAMS dict</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="c1">############################################################</span>
<span class="c1"># Get the  parameters for this model and training</span>
<span class="n">PARAMS_m</span> <span class="o">=</span> <span class="p">{</span>
<span class="s2">&quot;n_layers&quot;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span>
<span class="s2">&quot;hidden_size&quot;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span>
<span class="s2">&quot;dropout_1&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="mf">0.6</span><span class="p">),</span>
<span class="s2">&quot;dropout_2&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
<span class="s2">&quot;activation&quot;</span><span class="p">:</span> <span class="s2">&quot;LeakyReLU&quot;</span><span class="p">,</span>
    <span class="s1">&#39;optimizer_name&#39;</span><span class="p">:</span><span class="s1">&#39;NAdam&#39;</span><span class="p">,</span>
    <span class="s1">&#39;starting_learning_rate&#39;</span><span class="p">:</span><span class="nb">float</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="s1">&#39;momentum&#39;</span><span class="p">:</span><span class="nb">float</span><span class="p">(</span><span class="mf">0.6</span><span class="p">),</span>
    <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span><span class="nb">int</span><span class="p">(</span><span class="mi">512</span><span class="p">),</span>
    <span class="s1">&#39;n_iterations&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e6</span><span class="p">),</span>
<span class="p">}</span>

<span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">PARAMS_m</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">optimizer_name</span><span class="p">))</span>
<span class="c1"># optimizer_name = BEST_PARAMS[&quot;optimizer_name&quot;].to_string().split()[1]</span>
<span class="n">NITERATIONS</span> <span class="o">=</span> <span class="n">PARAMS_m</span><span class="p">[</span><span class="s2">&quot;n_iterations&quot;</span><span class="p">]</span>
<span class="n">BATCHSIZE</span> <span class="o">=</span> <span class="n">PARAMS_m</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">]</span>
<span class="n">comment</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

<span class="c1"># N_epochs X N_train_examples = N_iterations X batch_size</span>
<span class="n">N_epochs</span> <span class="o">=</span> <span class="p">(</span><span class="n">NITERATIONS</span> <span class="o">*</span> <span class="n">BATCHSIZE</span><span class="p">)</span> <span class="o">/</span> <span class="nb">int</span><span class="p">(</span><span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;This model was trained for </span><span class="si">{</span><span class="n">NITERATIONS</span><span class="si">}</span><span class="s2"> iteration, which is  </span><span class="si">{</span><span class="n">N_epochs</span><span class="si">}</span><span class="s2"> epochs&quot;</span>
<span class="p">)</span>

<span class="c1"># &#39;Trained_IQNx4_%s_TUNED.dict&#39; % target</span>
<span class="n">filename_model</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">get_model_filename</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">PARAMS_m</span><span class="p">)</span>
<span class="c1"># OR, if you know a model filename directly, you can also specify it, </span>
<span class="c1"># BUT, if you pull a trained model explicitly, you have to make sure its parameters in the PARAMS dictionary above match</span>
<span class="c1"># Nominal one is &#39;Trained_IQNx4_RecoDatam_ 8_layer5_hiddenLeakyReLU_activation1024_batchsize300_Kiteration.dict&#39;, also in backup</span>
<span class="c1"># filename_model=&#39;Trained_IQNx4_RecoDatam_ 8_layer5_hiddenLeakyReLU_activation1024_batchsize300_Kiteration.dict&#39;</span>
<span class="c1"># filename_model=&#39;Trained_IQNx4_RecoDatapT_10_layer6_hiddenLeakyReLU_activation512_batchsize300_Kiteration.dict&#39;</span>

<span class="n">trained_models_dir</span> <span class="o">=</span> <span class="s2">&quot;trained_models&quot;</span>
<span class="n">utils</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">trained_models_dir</span><span class="p">)</span>
<span class="c1"># on cluster, Im using another TRAIN directory</span>
<span class="n">PATH_model</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
    <span class="n">IQN_BASE</span><span class="p">,</span>  <span class="c1"># the loaction of the repo</span>
    <span class="s2">&quot;JupyterBook&quot;</span><span class="p">,</span>  <span class="c1"># up tp TRAIN could be combined in a srs dicretory</span>
    <span class="s2">&quot;Cluster&quot;</span><span class="p">,</span>
    <span class="s2">&quot;TRAIN&quot;</span><span class="p">,</span>
    <span class="n">trained_models_dir</span><span class="p">,</span>  <span class="c1"># /trained_models</span>
    <span class="n">filename_model</span><span class="p">,</span>  <span class="c1"># utils.get_model_filename has the saved file format</span>
<span class="p">)</span>

<span class="c1"># Load trained model</span>
<span class="n">IQN_m</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">PATH_model</span><span class="p">,</span> <span class="n">PARAMS_m</span><span class="p">)</span>
<span class="c1"># Get predicted distribution</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">simple_eval</span><span class="p">(</span><span class="n">IQN_m</span><span class="p">,</span> <span class="n">test_x_z_scaled</span><span class="p">)</span>

<span class="n">range_</span> <span class="o">=</span> <span class="p">(</span><span class="n">FIELDS</span><span class="p">[</span><span class="n">target</span><span class="p">][</span><span class="s2">&quot;xmin&quot;</span><span class="p">],</span> <span class="n">FIELDS</span><span class="p">[</span><span class="n">target</span><span class="p">][</span><span class="s2">&quot;xmax&quot;</span><span class="p">])</span>
<span class="n">bins</span> <span class="o">=</span> <span class="mi">50</span>
<span class="k">if</span> <span class="n">USE_BRADEN_SCALING</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
  <span class="n">REAL_RAW_DATA</span> <span class="o">=</span> <span class="n">scaled_test_data</span>
<span class="k">else</span><span class="p">:</span>
  <span class="n">REAL_RAW_DATA</span> <span class="o">=</span> <span class="n">raw_test_data</span>

<span class="n">YLIM</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">)</span>
<span class="c1">###########GET REAL DIST###########</span>
<span class="n">REAL_RAW_DATA</span> <span class="o">=</span> <span class="n">REAL_RAW_DATA</span><span class="p">[</span>
    <span class="p">[</span><span class="s2">&quot;RecoDatapT&quot;</span><span class="p">,</span> <span class="s2">&quot;RecoDataeta&quot;</span><span class="p">,</span> <span class="s2">&quot;RecoDataphi&quot;</span><span class="p">,</span> <span class="s2">&quot;RecoDatam&quot;</span><span class="p">]</span>
<span class="p">]</span>
<span class="n">REAL_RAW_DATA</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;realpT&quot;</span><span class="p">,</span> <span class="s2">&quot;realeta&quot;</span><span class="p">,</span> <span class="s2">&quot;realphi&quot;</span><span class="p">,</span> <span class="s2">&quot;realm&quot;</span><span class="p">]</span>
<span class="n">REAL_DIST</span> <span class="o">=</span> <span class="n">REAL_RAW_DATA</span><span class="p">[</span><span class="s2">&quot;realm&quot;</span><span class="p">]</span>
<span class="n">norm_data</span> <span class="o">=</span> <span class="n">REAL_RAW_DATA</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="c1">#############GET EVALUATION DIST#############</span>
<span class="k">if</span> <span class="n">USE_BRADEN_SCALING</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
  <span class="n">scaled_test_data</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
  <span class="n">m_reco</span> <span class="o">=</span> <span class="n">scaled_test_data</span><span class="p">[</span><span class="s2">&quot;RecoDatam&quot;</span><span class="p">]</span>
  <span class="n">m_gen</span> <span class="o">=</span> <span class="n">scaled_test_data</span><span class="p">[</span><span class="s2">&quot;genDatam&quot;</span><span class="p">]</span>
<span class="k">else</span><span class="p">:</span>  
  <span class="n">raw_test_data</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
  <span class="n">m_reco</span> <span class="o">=</span> <span class="n">raw_test_data</span><span class="p">[</span><span class="s2">&quot;RecoDatam&quot;</span><span class="p">]</span>
  <span class="n">m_gen</span> <span class="o">=</span> <span class="n">raw_test_data</span><span class="p">[</span><span class="s2">&quot;genDatam&quot;</span><span class="p">]</span>
<span class="c1"># plt.hist(m_reco,label=r&#39;$m_{gen}^{test \ data}$&#39;);plt.legend();plt.show()</span>


<span class="k">def</span> <span class="nf">descale_Braden_scaled_prediction</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Label could be m. p is the outcome of the model evaluation, e.g. </span>
<span class="sd">    IQN_m = load_model(PATH_model, PARAMS_m)</span>
<span class="sd">    p = simple_eval(IQN_m, test_x_z_scaled)</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># make sure you&#39;ve set braden scaling global variable to use this function.</span>
    <span class="k">assert</span> <span class="n">USE_BRADEN_SCALING</span><span class="o">==</span><span class="kc">True</span>
    <span class="n">orig_ratio</span> <span class="o">=</span> <span class="n">T</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">scaled_df</span><span class="o">=</span><span class="n">scaled_train_data</span><span class="p">)</span>
    <span class="n">z_inv_f</span> <span class="o">=</span> <span class="n">z_inverse</span><span class="p">(</span><span class="n">xprime</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">orig_ratio</span><span class="p">),</span> <span class="n">std</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">orig_ratio</span><span class="p">))</span>
    <span class="n">L_obs</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">orig_observable</span><span class="o">=</span><span class="n">m_gen</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>
    <span class="n">z_inv_f</span> <span class="o">=</span> <span class="n">z_inv_f</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">z_inv_f</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">factor</span> <span class="o">=</span> <span class="p">(</span><span class="n">z_inv_f</span> <span class="o">*</span> <span class="p">(</span><span class="n">L_obs</span> <span class="o">+</span> <span class="mi">10</span><span class="p">))</span> <span class="o">-</span> <span class="mi">10</span>
    <span class="n">label_pred</span> <span class="o">=</span> <span class="n">L_inverse</span><span class="p">(</span><span class="n">L_observable</span><span class="o">=</span><span class="n">factor</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">label_pred</span>
    
    
<span class="n">m_pred</span> <span class="o">=</span> <span class="n">z_inverse2</span><span class="p">(</span>
    <span class="n">xprime</span><span class="o">=</span><span class="n">p</span><span class="p">,</span>
    <span class="n">train_mean</span><span class="o">=</span><span class="n">TRAIN_SCALE_DICT</span><span class="p">[</span><span class="n">target</span><span class="p">][</span><span class="s2">&quot;mean&quot;</span><span class="p">],</span>
    <span class="n">train_std</span><span class="o">=</span><span class="n">TRAIN_SCALE_DICT</span><span class="p">[</span><span class="n">target</span><span class="p">][</span><span class="s2">&quot;std&quot;</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">m_pred</span> <span class="o">=</span> <span class="n">m_pred</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="c1"># Get histogram of predicted distribution</span>
<span class="n">real_label_counts_m</span><span class="p">,</span> <span class="n">predicted_label_counts_m</span><span class="p">,</span> <span class="n">label_edges_m</span> <span class="o">=</span> <span class="n">get_hist_simple</span><span class="p">(</span>
    <span class="n">predicted_dist</span><span class="o">=</span><span class="n">m_pred</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span>
<span class="p">)</span>
<span class="n">eval_data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="o">+</span><span class="s1">&#39;/test_data_10M_2.csv&#39;</span><span class="p">)</span>
<span class="c1"># Get evaluation data</span>
<span class="c1"># eval_data = pd.read_csv(DATA_DIR + &quot;/test_data_10M_2.csv&quot;)</span>
<span class="n">ev_features</span> <span class="o">=</span> <span class="n">features</span>
<span class="n">eval_data</span> <span class="o">=</span> <span class="n">eval_data</span><span class="p">[</span><span class="n">ev_features</span><span class="p">]</span>
<span class="c1"># save new distribution (m) in the eval data as autoregressive eval for next IQN</span>
<span class="n">eval_data</span><span class="p">[</span><span class="n">target</span><span class="p">]</span> <span class="o">=</span> <span class="n">m_pred</span>

<span class="n">new_cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">target</span><span class="p">]</span> <span class="o">+</span> <span class="n">features</span>
<span class="n">eval_data</span> <span class="o">=</span> <span class="n">eval_data</span><span class="o">.</span><span class="n">reindex</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">new_cols</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;EVALUATION DATA NEW INDEX</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">eval_data</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

<span class="n">eval_data</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">IQN_BASE</span><span class="p">,</span> 
        <span class="s2">&quot;JupyterBook&quot;</span><span class="p">,</span> 
        <span class="s2">&quot;Cluster&quot;</span><span class="p">,</span> 
        <span class="c1"># &quot;EVALUATE&quot;, </span>
        <span class="n">AUTOREGRESSIVE_DIST_NAME</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Load this saved predited autoregressive distribution</span>
<span class="n">AUTOREGRESSIVE_DIST</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">IQN_BASE</span><span class="p">,</span> 
        <span class="s2">&quot;JupyterBook&quot;</span><span class="p">,</span> 
        <span class="s2">&quot;Cluster&quot;</span><span class="p">,</span> 
        <span class="c1"># &quot;EVALUATE&quot;, </span>
        <span class="n">AUTOREGRESSIVE_DIST_NAME</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="c1"># norm_IQN=AUTOREGRESSIVE_DIST.shape[0]</span>
<span class="c1"># get normalization values</span>
<span class="n">norm_autoregressive</span> <span class="o">=</span> <span class="n">AUTOREGRESSIVE_DIST</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">norm_IQN</span> <span class="o">=</span> <span class="n">norm_autoregressive</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;norm_data&quot;</span><span class="p">,</span>
    <span class="n">norm_data</span><span class="p">,</span>
    <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">norm IQN&quot;</span><span class="p">,</span>
    <span class="n">norm_IQN</span><span class="p">,</span>
    <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">norm_autoregressive&quot;</span><span class="p">,</span>
    <span class="n">norm_autoregressive</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Finally, plot predicted distribution</span>

<span class="n">plot_one</span><span class="p">(</span>
    <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span>
    <span class="n">real_edges</span><span class="o">=</span><span class="n">label_edges_m</span><span class="p">,</span>
    <span class="n">real_counts</span><span class="o">=</span><span class="n">real_label_counts_m</span><span class="p">,</span>
    <span class="n">predicted_counts</span><span class="o">=</span><span class="n">predicted_label_counts_m</span><span class="p">,</span>
    <span class="n">save_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">PARAMS</span><span class="o">=</span><span class="n">PARAMS_m</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Features:
 [&#39;genDatapT&#39;, &#39;genDataeta&#39;, &#39;genDataphi&#39;, &#39;genDatam&#39;, &#39;tau&#39;]

Target =  RecoDatam
USING NEW DATASET

spliting data for RecoDatam
train_t shape =  (8000000,) train_x shape =  (8000000, 5)

 Training features:

[[ 3.38253091  0.828187    2.90213     1.57969597  0.36130954]
 [ 3.19127027 -1.16351     0.636469    2.05883697  0.12689925]
 [ 3.19127027 -1.16351     0.636469    2.05883697  0.96230681]
 ...
 [ 3.72374454 -2.23358    -2.81921     2.21849454  0.08421659]
 [ 3.56850964 -1.12318     0.356494    2.08765398  0.05535172]
 [ 3.27935361 -1.09427    -1.49334     1.83323565  0.07489863]]
valid_t shape =  (8000000,) valid_x shape =  (1000000, 5)
test_t shape =  (8000000,) test_x shape =  (1000000, 5)
no need to train_test_split since we already have the split dataframes
[ 3.42122253e+00  6.98189368e-04 -8.95543973e-04  2.15029052e+00
  5.00485136e-01] [0.33618462 2.20425356 1.81362773 0.28827428 0.28852734]
[ 3.42124491e+00 -1.78188172e-03 -3.83090331e-04  2.15056416e+00
  4.99915289e-01] [0.33480629 2.20430976 1.81382516 0.28800584 0.28867295]
0.9850983334720613 0.02124600582704668
0.9850983334720613 0.02124600582704668
BRADEN SCALING DICTIONARY
{&#39;genDatapT&#39;: {&#39;mean&#39;: 3.4212449149089768, &#39;std&#39;: 0.33480629257351374}, &#39;genDataeta&#39;: {&#39;mean&#39;: -0.0017818817154031672, &#39;std&#39;: 2.204309760627079}, &#39;genDataphi&#39;: {&#39;mean&#39;: -0.0003830903308450233, &#39;std&#39;: 1.8138251604791067}, &#39;genDatam&#39;: {&#39;mean&#39;: 2.1505641641311892, &#39;std&#39;: 0.288005836783413}, &#39;RecoDatapT&#39;: {&#39;mean&#39;: 3.4120016292119386, &#39;std&#39;: 0.3804797298312238}, &#39;RecoDataeta&#39;: {&#39;mean&#39;: -0.0017898858568513964, &#39;std&#39;: 2.197968491495457}, &#39;RecoDataphi&#39;: {&#39;mean&#39;: -0.0004719170328962474, &#39;std&#39;: 1.8144739820043825}, &#39;RecoDatam&#39;: {&#39;mean&#39;: 1.967801807330749, &#39;std&#39;: 0.3271234791069229}}



[-6.68528705e-05  1.12510099e-03 -2.82526482e-04 -9.50128735e-04
  5.00485136e-01] [1.0041168  0.9999745  0.99989115 1.00093207 0.28852734]
[ 3.98275191e-15 -1.10134124e-18 -3.12905257e-17 -1.14646888e-14
  4.99915289e-01] [1.         1.         1.         1.         0.28867295]
5.849882889208402e-14 1.0000000000000004
5.849882889208402e-14 1.0000000000000004
&lt;class &#39;str&#39;&gt;
This model was trained for 1000000 iteration, which is  64.0 epochs
RegularizedRegressionModel(
  (model): Sequential(
    (0): Linear(in_features=5, out_features=5, bias=True)
    (1): LeakyReLU(negative_slope=0.3)
    (2): Linear(in_features=5, out_features=5, bias=True)
    (3): LeakyReLU(negative_slope=0.3)
    (4): Linear(in_features=5, out_features=5, bias=True)
    (5): LeakyReLU(negative_slope=0.3)
    (6): Linear(in_features=5, out_features=5, bias=True)
    (7): LeakyReLU(negative_slope=0.3)
    (8): Linear(in_features=5, out_features=5, bias=True)
    (9): LeakyReLU(negative_slope=0.3)
    (10): Linear(in_features=5, out_features=1, bias=True)
  )
)
EVALUATION DATA NEW INDEX
    RecoDatam  genDatapT  genDataeta  genDataphi  genDatam       tau
0   2.097075    43.6113    0.824891    -1.26949   5.93310  0.250046
1   2.538913    43.6113    0.824891    -1.26949   5.93310  0.847493
2   2.165164    26.0153    3.529970     1.55495   7.41270  0.851995
3   1.392167    28.4944   -1.159650     1.82602   7.84157  0.052378
4   2.036560    21.9840    2.747660     2.03085   5.18315  0.542549
norm_data 1000000 
norm IQN 1000000 
norm_autoregressive 1000000
</pre></div>
</div>
<img alt="_images/alphaDavidson_IQNx4_14_2.png" src="_images/alphaDavidson_IQNx4_14_2.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Figure size 432x288 with 0 Axes&gt;
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ali Al Kadhim<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>