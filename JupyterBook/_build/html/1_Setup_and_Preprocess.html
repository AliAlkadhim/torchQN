
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>IQNx4: 1. Setup and Preprocess &#8212; torchIQNx4</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Welcome to the torchIQNx4" href="intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">torchIQNx4</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to the torchIQNx4
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   IQNx4: 1. Setup and Preprocess
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/AliAlkadhim/torchQN/HEAD?labpath=JupyterBook/v2/gh/AliAlkadhim/torchQN/master?urlpath=tree/JupyterBook/1_Setup_and_Preprocess.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/1_Setup_and_Preprocess.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   IQNx4: 1. Setup and Preprocess
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#do-source-setup-sh-before-trying-to-run-this-notebook">
   Do
   <code class="docutils literal notranslate">
    <span class="pre">
     source
    </span>
    <span class="pre">
     setup.sh
    </span>
   </code>
   before trying to run this notebook!
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#external-imports">
     External Imports
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#if-you-want-to-run-this-interactively-on-binder-set-binder-true-this-will-download-our-datasets-using-the-kaggle-api-our-datasets-are-simply-the-following">
       If you want to run this interactively on binder, set
       <code class="docutils literal notranslate">
        <span class="pre">
         BINDER=True
        </span>
       </code>
       . This will download our datasets using the Kaggle API. Our datasets are simply the following:
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#import-utils-and-set-environemnt-variables">
     Import utils, and set environemnt variables
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#a-user-is-competent-enought-to-do-source-setup-sh-on-a-setup-sh-script-that-comes-in-the-repo-such-as-the-next-cell-uncommented">
       A user is competent enought to do
       <code class="docutils literal notranslate">
        <span class="pre">
         source
        </span>
        <span class="pre">
         setup.sh
        </span>
       </code>
       on a
       <code class="docutils literal notranslate">
        <span class="pre">
         setup.sh
        </span>
       </code>
       script that comes in the repo, such as the next cell uncommented
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#utils-py">
   2. utils.py
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#set-arguments-optional-and-configurations">
     Set arguments (optional) and configurations
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#import-the-numpy-data-convert-to-dataframe-and-save-if-you-haven-t-saved-the-dataframes">
       Import the numpy data, convert to dataframe and save (if you haven’t saved the dataframes)
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#explore-the-dataframe-and-preprocess">
   Explore the Dataframe and preprocess
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data">
   Data
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-and-explore-raw-unscaled-dataframes">
   3. Load and explore raw (unscaled) dataframes
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#scaling">
   Scaling
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#basically-a-standard-scaling-procedure-is-the-following-background">
     Basically a “standard scaling procedure” is the following (background):
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#braden-scaling">
   Braden scaling
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optional-scale-the-data-accoding-to-the-braden-kronheim-scaling">
   4. (Optional) Scale the data accoding to the “Braden Kronheim scaling” :
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#if-you-want-to-generate-the-scaled-data-frames-run-the-cell-below">
     If you want to generate the Scaled data frames, run the cell below
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#if-you-want-to-load-the-previously-generated-scaled-dataframe-run-the-cell-below">
     If you want to load the previously generated scaled dataframe, run the cell below
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-mass">
   Train Mass
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#apply-z-to-targets-before-training">
     Apply
     <span class="math notranslate nohighlight">
      \(z\)
     </span>
     to targets before training
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training-and-running-of-training-functions">
     Training and running-of-training functions
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-basic-nn-model">
     Define basic NN model
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hyperparameter-training-workflow">
     Hyperparameter Training Workflow
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#run-training">
       Run training
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#see-if-trainig-works-on-t-ratio">
     See if trainig works on T ratio
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#save-trained-model-if-its-good-and-if-you-haven-t-saved-above-and-load-trained-model-if-you-saved-it">
     Save trained model (if its good, and if you haven’t saved above) and load trained model (if you saved it)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#paper-plotting">
       Paper plotting
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#plot-predicted-vs-real-reco-in-our-paper-s-format">
   Plot predicted vs real reco (in our paper’s format)
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-p-t-using-saved-variables-above">
   Train
   <span class="math notranslate nohighlight">
    \(p_T\)
   </span>
   using saved variables above
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>IQNx4: 1. Setup and Preprocess</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   IQNx4: 1. Setup and Preprocess
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#do-source-setup-sh-before-trying-to-run-this-notebook">
   Do
   <code class="docutils literal notranslate">
    <span class="pre">
     source
    </span>
    <span class="pre">
     setup.sh
    </span>
   </code>
   before trying to run this notebook!
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#external-imports">
     External Imports
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#if-you-want-to-run-this-interactively-on-binder-set-binder-true-this-will-download-our-datasets-using-the-kaggle-api-our-datasets-are-simply-the-following">
       If you want to run this interactively on binder, set
       <code class="docutils literal notranslate">
        <span class="pre">
         BINDER=True
        </span>
       </code>
       . This will download our datasets using the Kaggle API. Our datasets are simply the following:
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#import-utils-and-set-environemnt-variables">
     Import utils, and set environemnt variables
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#a-user-is-competent-enought-to-do-source-setup-sh-on-a-setup-sh-script-that-comes-in-the-repo-such-as-the-next-cell-uncommented">
       A user is competent enought to do
       <code class="docutils literal notranslate">
        <span class="pre">
         source
        </span>
        <span class="pre">
         setup.sh
        </span>
       </code>
       on a
       <code class="docutils literal notranslate">
        <span class="pre">
         setup.sh
        </span>
       </code>
       script that comes in the repo, such as the next cell uncommented
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#utils-py">
   2. utils.py
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#set-arguments-optional-and-configurations">
     Set arguments (optional) and configurations
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#import-the-numpy-data-convert-to-dataframe-and-save-if-you-haven-t-saved-the-dataframes">
       Import the numpy data, convert to dataframe and save (if you haven’t saved the dataframes)
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#explore-the-dataframe-and-preprocess">
   Explore the Dataframe and preprocess
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data">
   Data
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-and-explore-raw-unscaled-dataframes">
   3. Load and explore raw (unscaled) dataframes
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#scaling">
   Scaling
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#basically-a-standard-scaling-procedure-is-the-following-background">
     Basically a “standard scaling procedure” is the following (background):
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#braden-scaling">
   Braden scaling
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optional-scale-the-data-accoding-to-the-braden-kronheim-scaling">
   4. (Optional) Scale the data accoding to the “Braden Kronheim scaling” :
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#if-you-want-to-generate-the-scaled-data-frames-run-the-cell-below">
     If you want to generate the Scaled data frames, run the cell below
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#if-you-want-to-load-the-previously-generated-scaled-dataframe-run-the-cell-below">
     If you want to load the previously generated scaled dataframe, run the cell below
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-mass">
   Train Mass
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#apply-z-to-targets-before-training">
     Apply
     <span class="math notranslate nohighlight">
      \(z\)
     </span>
     to targets before training
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training-and-running-of-training-functions">
     Training and running-of-training functions
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-basic-nn-model">
     Define basic NN model
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hyperparameter-training-workflow">
     Hyperparameter Training Workflow
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#run-training">
       Run training
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#see-if-trainig-works-on-t-ratio">
     See if trainig works on T ratio
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#save-trained-model-if-its-good-and-if-you-haven-t-saved-above-and-load-trained-model-if-you-saved-it">
     Save trained model (if its good, and if you haven’t saved above) and load trained model (if you saved it)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#paper-plotting">
       Paper plotting
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#plot-predicted-vs-real-reco-in-our-paper-s-format">
   Plot predicted vs real reco (in our paper’s format)
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-p-t-using-saved-variables-above">
   Train
   <span class="math notranslate nohighlight">
    \(p_T\)
   </span>
   using saved variables above
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="iqnx4-1-setup-and-preprocess">
<h1>IQNx4: 1. Setup and Preprocess<a class="headerlink" href="#iqnx4-1-setup-and-preprocess" title="Permalink to this headline">#</a></h1>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="do-source-setup-sh-before-trying-to-run-this-notebook">
<h1>Do <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">setup.sh</span></code> before trying to run this notebook!<a class="headerlink" href="#do-source-setup-sh-before-trying-to-run-this-notebook" title="Permalink to this headline">#</a></h1>
<section id="external-imports">
<h2>External Imports<a class="headerlink" href="#external-imports" title="Permalink to this headline">#</a></h2>
<p>If you don’t have some of these packages installed, you can also use the conda environment that has all of the packages by doing <code class="docutils literal notranslate"><span class="pre">conda</span> <span class="pre">env</span> <span class="pre">create</span> <span class="pre">-f</span> <span class="pre">IQN_env.yml</span> <span class="pre">&amp;&amp;</span> <span class="pre">conda</span> <span class="pre">activate</span> <span class="pre">IQN_env</span></code></p>
<p>There is a live executable version of this notebook on binder, just click this link : <a class="reference external" href="https://mybinder.org/v2/gh/AliAlkadhim/torchQN/HEAD?labpath=JupyterBook"><img alt="Binder" src="https://mybinder.org/badge_logo.svg" /></a></p>
<p>Note that the binder will take a while to build, and you’d have to navigate through the files yourself (not as easy or nice as just going to <a class="reference external" href="https://alialkadhim.github.io/torchQN/">https://alialkadhim.github.io/torchQN/</a>)</p>
<section id="if-you-want-to-run-this-interactively-on-binder-set-binder-true-this-will-download-our-datasets-using-the-kaggle-api-our-datasets-are-simply-the-following">
<h3>If you want to run this interactively on binder, set <code class="docutils literal notranslate"><span class="pre">BINDER=True</span></code>. This will download our datasets using the Kaggle API. Our datasets are simply the following:<a class="headerlink" href="#if-you-want-to-run-this-interactively-on-binder-set-binder-true-this-will-download-our-datasets-using-the-kaggle-api-our-datasets-are-simply-the-following" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">BINDER</span><span class="o">=</span><span class="kc">False</span>
<span class="k">if</span> <span class="n">BINDER</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">opendatasets</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span><span class="p">;</span> <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="c1"># import scipy as sp; import scipy.stats as st</span>
<span class="kn">import</span> <span class="nn">torch</span><span class="p">;</span> <span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span><span class="p">;</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;using torch version </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1">#use numba&#39;s just-in-time compiler to speed things up</span>
<span class="c1"># from numba import njit</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">;</span> <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mp</span><span class="p">;</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;matplotlib version= &#39;</span><span class="p">,</span> <span class="n">mp</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span><span class="p">;</span> 
<span class="c1">#reset matplotlib stle/parameters</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="c1">#reset matplotlib parameters to their defaults</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">mpl</span><span class="o">.</span><span class="n">rcParamsDefault</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;seaborn-deep&#39;</span><span class="p">)</span>
<span class="n">mp</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;agg.path.chunksize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">font_legend</span> <span class="o">=</span> <span class="mi">15</span><span class="p">;</span> <span class="n">font_axes</span><span class="o">=</span><span class="mi">15</span>
<span class="c1"># %matplotlib inline</span>
<span class="kn">import</span> <span class="nn">sys</span><span class="p">;</span> <span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span><span class="p">,</span> <span class="n">display</span>
<span class="c1"># from importlib import import_module</span>
<span class="kn">import</span> <span class="nn">plotly</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">optuna</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;using (optional) optuna version </span><span class="si">{</span><span class="n">optuna</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;optuna is only used for hyperparameter tuning, not critical!&#39;</span><span class="p">)</span>
    <span class="k">pass</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="c1"># import sympy as sy</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">wid</span><span class="p">;</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>using torch version 1.9.0
matplotlib version=  3.5.1
using (optional) optuna version 2.8.0
</pre></div>
</div>
</div>
</div>
<p>print the versions of the packages</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> watermark

<span class="o">%</span><span class="k">watermark</span> -v -m -p numpy,pandas,torch,scikit-learn,matplotlib,os,IPython,kaggle,plotly,optuna,argparse,time,ipywidgets

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
<span class="o">%</span><span class="k">watermark</span> -u -n -t -z
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Python implementation: CPython
Python version       : 3.7.10
IPython version      : 7.31.1

numpy       : 1.21.5
pandas      : 1.3.5
torch       : 1.9.0
scikit-learn: 1.0.2
matplotlib  : 3.5.1
os          : unknown
IPython     : None
opendatasets: not installed
plotly      : 5.11.0
optuna      : 2.8.0
argparse    : 1.1
time        : unknown
ipywidgets  : 7.6.5

Compiler    : GCC 9.3.0
OS          : Linux
Release     : 5.4.0-135-generic
Machine     : x86_64
Processor   : x86_64
CPU cores   : 8
Architecture: 64bit

 
Last updated: Fri Dec 30 2022 19:40:01EST
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="import-utils-and-set-environemnt-variables">
<h2>Import utils, and set environemnt variables<a class="headerlink" href="#import-utils-and-set-environemnt-variables" title="Permalink to this headline">#</a></h2>
<p>need to tune latest braden scaling hyperparameters on cluster.</p>
<p>see if i can find/write a decorator to add the current cell to a file which will be run on cluster. I think %writefile <a class="reference external" href="http://file.py">file.py</a> could work, by adding the cell to another file…</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># &#39;IQN&#39; in </span>
<span class="c1"># some_environment={}</span>
<span class="c1"># some_environment.update(os.environ())</span>
<span class="c1"># some_environment</span>
<span class="c1"># &#39;DATA&#39; in list(os.environ)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># os.environ[&#39;IQN_BASE&#39;]=&#39;/home/ali/Desktop/Pulled_Github_Repositories/torchQN&#39;</span>
<span class="c1"># os.environ[&#39;DATA_DIR&#39;]=&#39;/home/DAVIDSON/alalkadhim.visitor/IQN/DAVIDSON_NEW/data&#39;</span>
</pre></div>
</div>
</div>
</div>
<section id="a-user-is-competent-enought-to-do-source-setup-sh-on-a-setup-sh-script-that-comes-in-the-repo-such-as-the-next-cell-uncommented">
<h3>A user is competent enought to do <code class="docutils literal notranslate"><span class="pre">source</span> <span class="pre">setup.sh</span></code> on a <code class="docutils literal notranslate"><span class="pre">setup.sh</span></code> script that comes in the repo, such as the next cell uncommented<a class="headerlink" href="#a-user-is-competent-enought-to-do-source-setup-sh-on-a-setup-sh-script-that-comes-in-the-repo-such-as-the-next-cell-uncommented" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># #!/bin/bash</span>
<span class="c1"># export IQN_BASE= $pwd #/home/ali/Desktop/Pulled_Github_Repositories/torchQN</span>

<span class="c1"># #DAVIDSON</span>
<span class="c1"># export DATA_DIR=&#39;/home/DAVIDSON/alalkadhim.visitor/IQN/DAVIDSON_NEW/data&#39;</span>
<span class="c1"># #LOCAL</span>
<span class="c1"># export DATA_DIR=&#39;/home/ali/Desktop/Pulled_Github_Repositories/IQN_HEP/Davidson/data&#39;</span>
<span class="c1"># echo DATA DIR</span>
<span class="c1"># ls -l $DATA_DIR</span>
<span class="c1"># #ln -s $DATA_DIR $IQN_BASE, if you want</span>
<span class="c1"># #conda create env -n torch_env -f torch_env.yml</span>
<span class="c1"># conda activate torch_env</span>
<span class="c1"># mkdir -p ${IQN_BASE}/images/loss_plots ${IQN_BASE}/trained_models  ${IQN_BASE}/hyperparameters ${IQN_BASE}/predicted_data</span>
<span class="c1"># tree $IQN_BASE</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># env = {}</span>
<span class="c1"># env.update(os.environ)</span>
<span class="c1"># env.update(source(os.environ[&quot;IQN_BASE&quot;])) </span>

<span class="k">try</span><span class="p">:</span>
    <span class="n">IQN_BASE</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;IQN_BASE&#39;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;BASE directoy properly set = &#39;</span><span class="p">,</span> <span class="n">IQN_BASE</span><span class="p">)</span>
    <span class="n">utils_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">IQN_BASE</span><span class="p">,</span> <span class="s1">&#39;utils/&#39;</span><span class="p">)</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">utils_dir</span><span class="p">)</span>
    <span class="kn">import</span> <span class="nn">utils</span>
    <span class="c1">#usually its not recommended to import everything from a module, but we know</span>
    <span class="c1">#whats in it so its fine</span>
    <span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="o">*</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;DATA directory also properly set, in </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;DATA_DIR&#39;</span><span class="p">])</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="c1"># IQN_BASE=os.getcwd()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span><span class="se">\n</span><span class="s2">BASE directory not properly set. Read repo README.</span><span class="se">\</span>
<span class="s2">    If you need a function from utils, use the decorator below, or add utils to sys.path</span><span class="se">\n</span><span class="s2"></span>
<span class="s2">    You can also do </span>
<span class="s2">    os.environ[&#39;IQN_BASE&#39;]=&lt;ABSOLUTE PATH FOR THE IQN REPO&gt;</span>
<span class="s2">    or</span>
<span class="s2">    os.environ[&#39;IQN_BASE&#39;]=os.getcwd()&quot;&quot;&quot;</span><span class="p">)</span>
    <span class="k">pass</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>BASE directoy properly set =  /home/ali/Desktop/Pulled_Github_Repositories/torchQN
using torch version 1.9.0
matplotlib version=  3.5.1
using (optional) optuna version 2.8.0
BASE directoy properly set =  /home/ali/Desktop/Pulled_Github_Repositories/torchQN
DATA directory also properly set, in /home/ali/Desktop/Pulled_Github_Repositories/IQN_HEP/Davidson/data
DATA directory also properly set, in /home/ali/Desktop/Pulled_Github_Repositories/IQN_HEP/Davidson/data
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># update fonts</span>
<span class="n">FONTSIZE</span> <span class="o">=</span> <span class="mi">14</span>
<span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span> <span class="p">:</span> <span class="s1">&#39;serif&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight&#39;</span> <span class="p">:</span> <span class="s1">&#39;normal&#39;</span><span class="p">,</span>
        <span class="s1">&#39;size&#39;</span>   <span class="p">:</span> <span class="n">FONTSIZE</span><span class="p">}</span>
<span class="n">mp</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>

<span class="c1"># set usetex = False if LaTex is not </span>
<span class="c1"># available on your system or if the </span>
<span class="c1"># rendering is too slow</span>
<span class="n">mp</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="n">usetex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># set a seed to ensure reproducibility</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">rnd</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="c1">#sometimes jupyter doesnt initialize MathJax automatically for latex, so do this:</span>
<span class="n">wid</span><span class="o">.</span><span class="n">HTMLMath</span><span class="p">(</span><span class="s1">&#39;$\LaTeX$&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "f36c04486c6249f694fcab2542d2c61f", "version_major": 2, "version_minor": 0}
</script></div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="utils-py">
<h1>2. <a class="reference external" href="http://utils.py">utils.py</a><a class="headerlink" href="#utils-py" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span><span class="p">;</span> <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="c1"># import scipy as sp; import scipy.stats as st</span>
<span class="kn">import</span> <span class="nn">torch</span><span class="p">;</span> <span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span><span class="p">;</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;using torch version </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1">#use numba&#39;s just-in-time compiler to speed things up</span>
<span class="c1"># from numba import njit</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">;</span> <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mp</span><span class="p">;</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;matplotlib version= &#39;</span><span class="p">,</span> <span class="n">mp</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span><span class="p">;</span> 
<span class="c1">#reset matplotlib stle/parameters</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="c1">#reset matplotlib parameters to their defaults</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">mpl</span><span class="o">.</span><span class="n">rcParamsDefault</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;seaborn-deep&#39;</span><span class="p">)</span>
<span class="n">mp</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;agg.path.chunksize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">font_legend</span> <span class="o">=</span> <span class="mi">15</span><span class="p">;</span> <span class="n">font_axes</span><span class="o">=</span><span class="mi">15</span>
<span class="c1"># %matplotlib inline</span>
<span class="kn">import</span> <span class="nn">sys</span><span class="p">;</span> <span class="kn">import</span> <span class="nn">os</span>
<span class="c1"># from IPython.display import Image, display</span>
<span class="c1"># from importlib import import_module</span>
<span class="c1">#import plotly</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">optuna</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;using (optional) optuna version </span><span class="si">{</span><span class="n">optuna</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;optuna is only used for hyperparameter tuning, not critical!&#39;</span><span class="p">)</span>
    <span class="k">pass</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="c1"># import sympy as sy</span>
<span class="c1">#import ipywidgets as wid; </span>


<span class="k">try</span><span class="p">:</span>
    <span class="n">IQN_BASE</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;IQN_BASE&#39;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;BASE directoy properly set = &#39;</span><span class="p">,</span> <span class="n">IQN_BASE</span><span class="p">)</span>
    <span class="n">utils_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">IQN_BASE</span><span class="p">,</span> <span class="s1">&#39;utils&#39;</span><span class="p">)</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">utils_dir</span><span class="p">)</span>
    <span class="kn">import</span> <span class="nn">utils</span>
    <span class="c1">#usually its not recommended to import everything from a module, but we know</span>
    <span class="c1">#whats in it so its fine</span>
    <span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="o">*</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;DATA directory also properly set, in </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;DATA_DIR&#39;</span><span class="p">])</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="c1"># IQN_BASE=os.getcwd()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span><span class="se">\n</span><span class="s2">BASE directory not properly set. Read repo README.    If you need a function from utils, use the decorator below, or add utils to sys.path</span><span class="se">\n</span><span class="s2"></span>
<span class="s2">    You can also do </span>
<span class="s2">    os.environ[&#39;IQN_BASE&#39;]=&lt;ABSOLUTE PATH FOR THE IQN REPO&gt;</span>
<span class="s2">    or</span>
<span class="s2">    os.environ[&#39;IQN_BASE&#39;]=os.getcwd()&quot;&quot;&quot;</span><span class="p">)</span>
    <span class="k">pass</span>


<span class="c1"># device = torch.device(&quot;cuda:0&quot;)</span>

<span class="c1"># update fonts</span>
<span class="n">FONTSIZE</span> <span class="o">=</span> <span class="mi">18</span>
<span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span> <span class="p">:</span> <span class="s1">&#39;serif&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight&#39;</span> <span class="p">:</span> <span class="s1">&#39;normal&#39;</span><span class="p">,</span>
        <span class="s1">&#39;size&#39;</span>   <span class="p">:</span> <span class="n">FONTSIZE</span><span class="p">}</span>
<span class="n">mp</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>

<span class="c1">####################################################################</span>



<span class="c1"># class CustomDataset(Dataset):</span>
<span class="c1">#     &quot;&quot;&quot;This takes the index for the data and target and gives dictionary of tensors of data and targets.</span>
<span class="c1">#     For example we could do train_dataset = CustomDataset(train_data, train_targets); test_dataset = CustomDataset(test_data, test_targets)</span>
<span class="c1">#  where train and test_dataset are np arrays that are reshaped to (-1,1).</span>
<span class="c1">#  Then train_dataset[0] gives a dictionary of samples &quot;X&quot; and targets&quot;&quot;&quot;</span>
<span class="c1">#     def __init__(self, data, targets):</span>
<span class="c1">#         self.data = data</span>
<span class="c1">#         self.targets=targets</span>
<span class="c1">#     def __len__(self):</span>
<span class="c1">#         return self.data.shape[0]</span>
    
<span class="c1">#     def __getitem__(self, idx):</span>
        
<span class="c1">#         current_sample = self.data[idx, :]</span>
<span class="c1">#         current_target = self.targets[idx]</span>
<span class="c1">#         return {&quot;x&quot;: torch.tensor(current_sample, dtype = torch.float),</span>
<span class="c1">#                &quot;y&quot;: torch.tensor(current_target, dtype= torch.float),</span>
<span class="c1">#                }#this already makes the targets made of one tensor (of one value) each</span>


<span class="k">class</span> <span class="nc">RegressionModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="c1">#inherit from the super class</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nfeatures</span><span class="p">,</span> <span class="n">ntargets</span><span class="p">,</span> <span class="n">nlayers</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nlayers</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span> <span class="o">==</span><span class="mi">0</span><span class="p">:</span>
                <span class="c1">#inital layer has to have size of input features as its input layer</span>
                <span class="c1">#its output layer can have any size but it must match the size of the input layer of the next linear layer</span>
                <span class="c1">#here we choose its output layer as the hidden size (fully connected)</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nfeatures</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
                <span class="c1">#batch normalization</span>
                <span class="c1"># layers.append(nn.BatchNorm1d(hidden_size))</span>
                <span class="c1">#Dropout seems to worsen model performance</span>
                <span class="c1"># layers.append(nn.Dropout(dropout))</span>
                <span class="c1">#ReLU activation </span>
                <span class="c1"># layers.append(nn.ReLU())</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1">#if this is not the first layer (we dont have layers)</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
                <span class="c1"># layers.append(nn.BatchNorm1d(hidden_size))</span>
                <span class="c1">#Dropout seems to worsen model performance</span>
                <span class="c1"># layers.append(nn.Dropout(dropout))</span>
                <span class="c1"># layers.append(nn.ReLU())</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">())</span>
                <span class="c1">#output layer:</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">ntargets</span><span class="p">))</span> 
        
        <span class="c1"># ONLY IF ITS A CLASSIFICATION, ADD SIGMOID</span>
        <span class="c1">#layers.append(nn.Sigmoid())</span>
            <span class="c1">#we have defined sequential model using the layers in oulist </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
            
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>




<span class="k">class</span> <span class="nc">RegressionEngine</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;loss, training and evaluation&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
                 <span class="c1">#, device):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="c1">#self.device= device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>
        
    <span class="c1">#the loss function returns the loss function. It is a static method so it doesn&#39;t need self</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">quadratic_loss</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
         <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">average_quadratic_loss</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
    <span class="c1"># f and t must be of the same shape</span>
        <span class="k">return</span>  <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">outputs</span> <span class="o">-</span> <span class="n">targets</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">average_absolute_error</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
    <span class="c1"># f and t must be of the same shape</span>
        <span class="k">return</span>  <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">outputs</span> <span class="o">-</span> <span class="n">targets</span><span class="p">))</span>
    
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">average_cross_entropy_loss</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
        <span class="c1"># f and t must be of the same shape</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">targets</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">outputs</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">outputs</span><span class="p">))</span>
        <span class="c1"># the above means loss = log outputs, if target&gt;0.5, and log(1-output) otherwise</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">average_quantile_loss</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
        <span class="c1"># f and t must be of the same shape</span>
        <span class="n">tau</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="c1">#L= tau * (target - output), if target&gt;output</span>
        <span class="c1">#L= (1-tau)*(output-target), otherwise</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">targets</span> <span class="o">&gt;</span> <span class="n">outputs</span><span class="p">,</span> 
                                      <span class="n">tau</span> <span class="o">*</span> <span class="p">(</span><span class="n">targets</span> <span class="o">-</span> <span class="n">outputs</span><span class="p">),</span> 
                                      <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">tau</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">outputs</span> <span class="o">-</span> <span class="n">targets</span><span class="p">)))</span>


    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;the training function: takes the training dataloader&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">final_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span><span class="c1">#only optimize weights for the current batch, otherwise it&#39;s meaningless!</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">]</span>
            <span class="n">targets</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">average_quantile_loss</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">final_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">final_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span>

    
    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;the training function: takes the training dataloader&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">final_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">]</span><span class="c1">#.to(self.device)</span>
            <span class="n">targets</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]</span><span class="c1">#.to(self.device)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">average_quantile_loss</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
            <span class="n">final_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">final_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span>



<span class="k">class</span> <span class="nc">ModelHandler</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">scalers</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span>  <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scaler_t</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaler_x</span> <span class="o">=</span> <span class="n">scalers</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaler_t</span><span class="o">.</span><span class="n">scale_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># for output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span>   <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaler_t</span><span class="o">.</span><span class="n">mean_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># for output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fields</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaler_x</span><span class="o">.</span><span class="n">feature_names_in_</span>
        
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">):</span>
        
        <span class="c1"># scale input data</span>
        <span class="n">x</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scaler_x</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">fields</span><span class="p">]))</span>
        <span class="n">x</span>  <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># go to evaluation mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    
        <span class="c1"># compute,reshape to a 1d array, and convert to a numpy array</span>
        <span class="n">Y</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        
        <span class="c1"># rescale output</span>
        <span class="n">Y</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">*</span> <span class="n">Y</span>
        
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Y</span>
        
    <span class="k">def</span> <span class="nf">show</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">()</span>


<span class="n">N_CNN_KERNEL</span><span class="o">=</span><span class="mi">2</span>
<span class="n">NFEATURES</span><span class="o">=</span><span class="mi">1</span><span class="c1">#train_x.shape[1]</span>
<span class="n">N_MULT_FACTOR</span><span class="o">=</span><span class="mi">2</span>
<span class="n">N_HIDDEN</span><span class="o">=</span><span class="n">NFEATURES</span> <span class="o">*</span> <span class="n">N_MULT_FACTOR</span>

<span class="k">class</span> <span class="nc">CNN_MODEL</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_feature</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_output</span><span class="p">,</span> <span class="n">n_cnn_kernel</span><span class="p">,</span> <span class="n">n_mult_factor</span><span class="o">=</span><span class="n">N_MULT_FACTOR</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CNN_MODEL</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_feature</span><span class="o">=</span><span class="n">n_feature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="o">=</span><span class="n">n_hidden</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_output</span><span class="o">=</span> <span class="n">n_output</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">n_cnn_kernel</span><span class="o">=</span><span class="n">n_cnn_kernel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_mult_factor</span><span class="o">=</span><span class="n">n_mult_factor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_l2_hidden</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_mult_factor</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_cnn_kernel</span> <span class="o">+</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_out_hidden</span><span class="o">=</span><span class="nb">int</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_l2_hidden</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
                        
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_feature</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span><span class="mf">.85</span><span class="p">),</span>            
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>            
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>            
        <span class="p">)</span>                
        <span class="bp">self</span><span class="o">.</span><span class="n">c1</span><span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>            
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_feature</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">,</span> 
                            <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_cnn_kernel</span><span class="p">,),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span><span class="mf">.75</span><span class="p">),</span>            
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>        
        <span class="p">)</span>                        
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_l2_hidden</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">n_output</span><span class="p">),</span>  
        <span class="p">)</span>                

        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">varSize</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># must be calculated here in forward() since its is a dynamic size        </span>
        <span class="n">x</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>                
        <span class="c1"># for CNN        </span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">varSize</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_feature</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">n_mult_factor</span><span class="p">)</span>
        <span class="n">x</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">c1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># for Linear layer</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">varSize</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_hidden</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_mult_factor</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">n_cnn_kernel</span> <span class="o">+</span> <span class="mi">3</span><span class="p">))</span>
<span class="c1">#         x=self.l2(x)                    </span>
        <span class="n">x</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>   
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># model = CNN_MODEL(n_feature=NFEATURES, n_hidden=N_HIDDEN, n_output=1, n_cnn_kernel=N_CNN_KERNEL)   # define the network    </span>


<span class="c1">#####CONVERT env.yml to requirementes.txt</span>

<span class="c1"># import ruamel.yaml</span>
<span class="c1"># yaml = ruamel.yaml.YAML()</span>
<span class="c1"># data = yaml.load(open(&#39;IQN_env.yml&#39;))</span>
<span class="c1"># requirements = []</span>
<span class="c1"># for dep in data[&#39;dependencies&#39;]:</span>
<span class="c1">#     if isinstance(dep, str):</span>
<span class="c1">#         package, package_version, python_version = dep.split(&#39;=&#39;)</span>
<span class="c1">#         if python_version == &#39;0&#39;:</span>
<span class="c1">#             continue</span>
<span class="c1">#         requirements.append(package + &#39;==&#39; + package_version)</span>
<span class="c1">#     elif isinstance(dep, dict):</span>
<span class="c1">#         for preq in dep.get(&#39;pip&#39;, []):</span>
<span class="c1">#             requirements.append(preq)</span>

<span class="c1"># with open(&#39;requirements.txt&#39;, &#39;w&#39;) as fp:</span>
<span class="c1">#     for requirement in requirements:</span>
<span class="c1">#        print(requirement, file=fp)</span>

<span class="k">def</span> <span class="nf">show_jupyter_image</span><span class="p">(</span><span class="n">image_filename</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="mi">1300</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="mi">300</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Show a saved image directly in jupyter. Make sure image_filename is in your IQN_BASE !&quot;&quot;&quot;</span>
    <span class="n">display</span><span class="p">(</span><span class="n">Image</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">IQN_BASE</span><span class="p">,</span><span class="n">image_filename</span><span class="p">),</span> <span class="n">width</span> <span class="o">=</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="n">height</span>  <span class="p">))</span>
    
    
<span class="k">def</span> <span class="nf">use_svg_display</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Use the svg format to display a plot in Jupyter (better quality)&quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">matplotlib_inline</span> <span class="kn">import</span> <span class="n">backend_inline</span>
    <span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;svg&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">reset_plt_params</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;reset matplotlib parameters - often useful&quot;&quot;&quot;</span>
    <span class="n">use_svg_display</span><span class="p">()</span>
    <span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">mpl</span><span class="o">.</span><span class="n">rcParamsDefault</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">show_plot</span><span class="p">(</span><span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">use_svg_display</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">();</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">legend</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
        
<span class="k">def</span> <span class="nf">set_figsize</span><span class="p">(</span><span class="n">get_axes</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">)):</span>
    <span class="n">use_svg_display</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">figsize</span>
    <span class="k">if</span> <span class="n">get_axes</span><span class="p">:</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span>
    
<span class="k">def</span> <span class="nf">set_axes</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">xlabel</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">xmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">xmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ymin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ymax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;saves a lot of time in explicitly difining each axis, its title and labels: do them all in one go&quot;&quot;&quot;</span>
    <span class="n">use_svg_display</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">font_axes</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ylabel</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">font_axes</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">xmin</span> <span class="ow">and</span> <span class="n">xmax</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_title</span><span class="p">()</span>  <span class="o">!=</span> <span class="s1">&#39;&#39;</span><span class="p">:</span>
        <span class="c1">#if the axes (plot) does have a title (which is non-empty string), display it </span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">():</span>
        <span class="c1">#if an axis has a legned label, display it</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">font_legend</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ymin</span> <span class="ow">and</span> <span class="n">ymax</span><span class="p">:</span>
        <span class="c1">#sometimes we dont have ylimits since we do a lot of histograms, but if an axis has ylimits, set them</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span><span class="p">)</span>
    
    <span class="k">try</span><span class="p">:</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="k">pass</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
<span class="k">def</span> <span class="nf">explore_data</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">scaled</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span> <span class="p">)</span>
    <span class="c1"># df = df[[&#39;genDatapT&#39;, &#39;genDataeta&#39;, &#39;genDataphi&#39;, &#39;genDatam&#39;,&#39;RecoDatapT&#39;, &#39;RecoDataeta&#39;, &#39;RecoDataphi&#39;, &#39;RecoDatam&#39;]]</span>
    <span class="n">levels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;RecoData&#39;</span><span class="p">,</span> <span class="s1">&#39;genData&#39;</span><span class="p">]</span>
    <span class="n">kinematics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;pT&#39;</span><span class="p">,</span><span class="s1">&#39;eta&#39;</span><span class="p">,</span><span class="s1">&#39;phi&#39;</span><span class="p">,</span><span class="s1">&#39;m&#39;</span><span class="p">]</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">level</span><span class="o">+</span><span class="n">k</span> <span class="k">for</span> <span class="n">level</span> <span class="ow">in</span> <span class="n">levels</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">kinematics</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="n">columns</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;tau&#39;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span>
    
    <span class="k">for</span> <span class="n">k_i</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kinematics</span><span class="p">):</span>
        <span class="n">Reco_var</span> <span class="o">=</span> <span class="n">levels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">k</span>
        <span class="n">gen_var</span> <span class="o">=</span> <span class="n">levels</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">k</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Reco_var: &#39;</span><span class="p">,</span> <span class="n">Reco_var</span><span class="p">,</span> <span class="s1">&#39;, </span><span class="se">\t</span><span class="s1"> gen_var: &#39;</span><span class="p">,</span> <span class="n">gen_var</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">k_i</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">Reco_var</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">Reco_var</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.35</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">k_i</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">gen_var</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">gen_var</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.35</span><span class="p">)</span>
        <span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span> <span class="o">=</span> <span class="n">FIELDS</span><span class="p">[</span><span class="n">Reco_var</span><span class="p">][</span><span class="s1">&#39;xmin&#39;</span><span class="p">],</span> <span class="n">FIELDS</span><span class="p">[</span><span class="n">Reco_var</span><span class="p">][</span><span class="s1">&#39;xmax&#39;</span><span class="p">]</span>
        <span class="n">xlabel</span><span class="o">=</span><span class="n">FIELDS</span><span class="p">[</span><span class="n">Reco_var</span><span class="p">][</span><span class="s1">&#39;xlabel&#39;</span><span class="p">]</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">k_i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span> <span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">)</span> <span class="p">)</span>
        <span class="c1"># set_axes(ax[k_i], xlabel=xlabel, ylabel=&#39;&#39;, xmin=xmin, xmax=xmax)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">k_i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">26</span><span class="p">)</span>
        
        
                  
        <span class="k">if</span> <span class="n">scaled</span><span class="p">:</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">k_i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">gen_var</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span><span class="n">df</span><span class="p">[</span><span class="n">gen_var</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="p">)</span>
        
        <span class="n">ax</span><span class="p">[</span><span class="n">k_i</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;tau&#39;</span><span class="p">],</span><span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\tau$&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">show_plot</span><span class="p">()</span>




<span class="k">def</span> <span class="nf">show_jupyter_image</span><span class="p">(</span><span class="n">image_filename</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="mi">1300</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="mi">300</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Show a saved image directly in jupyter. Make sure image_filename is in your IQN_BASE !&quot;&quot;&quot;</span>
    <span class="n">display</span><span class="p">(</span><span class="n">Image</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">IQN_BASE</span><span class="p">,</span><span class="n">image_filename</span><span class="p">),</span> <span class="n">width</span> <span class="o">=</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="n">height</span>  <span class="p">))</span>
    
    
<span class="k">def</span> <span class="nf">use_svg_display</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Use the svg format to display a plot in Jupyter (better quality)&quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">matplotlib_inline</span> <span class="kn">import</span> <span class="n">backend_inline</span>
    <span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;svg&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">reset_plt_params</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;reset matplotlib parameters - often useful&quot;&quot;&quot;</span>
    <span class="n">use_svg_display</span><span class="p">()</span>
    <span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">mpl</span><span class="o">.</span><span class="n">rcParamsDefault</span><span class="p">)</span>
    


<span class="k">def</span> <span class="nf">show_plot</span><span class="p">(</span><span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">use_svg_display</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">();</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">legend</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
        
<span class="k">def</span> <span class="nf">set_figsize</span><span class="p">(</span><span class="n">get_axes</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">)):</span>
    <span class="n">use_svg_display</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">figsize</span>
    <span class="k">if</span> <span class="n">get_axes</span><span class="p">:</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span>
    
<span class="k">def</span> <span class="nf">set_axes</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">xlabel</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">xmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">xmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ymin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ymax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;saves a lot of time in explicitly difining each axis, its title and labels: do them all in one go&quot;&quot;&quot;</span>
    <span class="n">use_svg_display</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">font_axes</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ylabel</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">font_axes</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">xmin</span> <span class="ow">and</span> <span class="n">xmax</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_title</span><span class="p">()</span>  <span class="o">!=</span> <span class="s1">&#39;&#39;</span><span class="p">:</span>
        <span class="c1">#if the axes (plot) does have a title (which is non-empty string), display it </span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">():</span>
        <span class="c1">#if an axis has a legned label, display it</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">font_legend</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ymin</span> <span class="ow">and</span> <span class="n">ymax</span><span class="p">:</span>
        <span class="c1">#sometimes we dont have ylimits since we do a lot of histograms, but if an axis has ylimits, set them</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span><span class="p">)</span>
    
    <span class="k">try</span><span class="p">:</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="k">pass</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="c1"># plt.show()</span>

<span class="k">def</span> <span class="nf">get_finite</span><span class="p">(</span><span class="n">values</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">values</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">values</span><span class="p">)]</span>

<span class="k">def</span> <span class="nf">mkdir</span><span class="p">(</span><span class="n">dir_</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;make a directory without overwriting what&#39;s in it if it exists&quot;&quot;&quot;</span>
    <span class="c1"># assert isinstance(dir_, str)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s1">&#39;mkdir -p </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="n">dir_</span><span class="p">)</span> <span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="k">pass</span>
    
<span class="c1">############################ Some decorators ############################ </span>
<span class="k">def</span> <span class="nf">SourceIQN</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">os</span>
        <span class="kn">from</span> <span class="nn">common.utility.source</span> <span class="kn">import</span> <span class="n">source</span>
        <span class="n">env</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">env</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">)</span>
        <span class="n">env</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">source</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;IQN_BASE&quot;</span><span class="p">]))</span>        
        <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_func</span>


<span class="k">def</span> <span class="nf">time_type_of_func</span><span class="p">(</span><span class="n">tuning_or_training</span><span class="p">,</span> <span class="n">_func</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">timer</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Print the runtime of the decorated function&quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">functools</span>
        <span class="kn">import</span> <span class="nn">time</span>
        <span class="nd">@functools</span><span class="o">.</span><span class="n">wraps</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">wrapper_timer</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">tuning_or_training</span><span class="o">==</span><span class="s1">&#39;training&#39;</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;training IQN &#39;</span><span class="p">)</span><span class="c1">#to estimate {target}</span>
            <span class="k">elif</span> <span class="n">tuning_or_training</span><span class="o">==</span><span class="s1">&#39;tuning&#39;</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;tuning IQN hyperparameters &#39;</span><span class="p">)</span><span class="c1">#to estimate {target}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;timing this arbitrary function&#39;</span><span class="p">)</span>
            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>    
            <span class="n">value</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>      
            <span class="n">run_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>    
            <span class="k">if</span> <span class="n">tuning_or_training</span><span class="o">==</span><span class="s1">&#39;training&#39;</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;training target </span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2"> using </span><span class="si">{</span><span class="n">func</span><span class="o">.</span><span class="vm">__name__</span><span class="si">!r}</span><span class="s2"> in </span><span class="si">{</span><span class="n">run_time</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> secs&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">tuning_or_training</span><span class="o">==</span><span class="s1">&#39;tuning&#39;</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tuning IQN hyperparameters for </span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2"> using </span><span class="si">{</span><span class="n">func</span><span class="o">.</span><span class="vm">__name__</span><span class="si">!r}</span><span class="s2"> in </span><span class="si">{</span><span class="n">run_time</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> secs&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;this arbirary function took </span><span class="si">{</span><span class="n">run_time</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> secs&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">value</span>
        <span class="k">return</span> <span class="n">wrapper_timer</span>
    <span class="k">if</span> <span class="n">_func</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">timer</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">timer</span><span class="p">(</span><span class="n">_func</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">debug</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Print the function signature and return value&quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">functools</span>
    <span class="nd">@functools</span><span class="o">.</span><span class="n">wraps</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">wrapper_debug</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">args_repr</span> <span class="o">=</span> <span class="p">[</span><span class="nb">repr</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">args</span><span class="p">]</span>                      
        <span class="n">kwargs_repr</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">=</span><span class="si">{</span><span class="n">v</span><span class="si">!r}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>  
        <span class="n">signature</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args_repr</span> <span class="o">+</span> <span class="n">kwargs_repr</span><span class="p">)</span>           
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Calling </span><span class="si">{</span><span class="n">func</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(</span><span class="si">{</span><span class="n">signature</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
        <span class="n">values</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">func</span><span class="o">.</span><span class="vm">__name__</span><span class="si">!r}</span><span class="s2"> returned </span><span class="si">{</span><span class="n">values</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>           
        <span class="k">return</span> <span class="n">values</span>
    <span class="k">return</span> <span class="n">wrapper_debug</span>


<span class="k">def</span> <span class="nf">make_interactive</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; make the plot interactive&quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">functools</span>
    <span class="nd">@functools</span><span class="o">.</span><span class="n">wraps</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">wrapper</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>
        <span class="n">output</span><span class="o">=</span><span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ioff</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">output</span>
    <span class="k">return</span> <span class="n">wrapper</span>
        
<span class="c1"># from IPython.core.magic import register_cell_magic</span>

<span class="c1"># @register_cell_magic</span>
<span class="k">def</span> <span class="nf">write_and_run</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="n">cell</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;write the current cell to a file (or append it with -a argument) as well as execute it</span>
<span class="sd">    use with %%write_and_run at the top of a given cell&quot;&quot;&quot;</span>
    <span class="n">argz</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">file</span> <span class="o">=</span> <span class="n">argz</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;w&#39;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">argz</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">argz</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;-a&#39;</span><span class="p">:</span>
        <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;a&#39;</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">cell</span><span class="p">)</span>
    <span class="c1"># get_ipython().run_cell(cell)</span>
    
    
<span class="nd">@debug</span>
<span class="k">def</span> <span class="nf">get_model_params_simple</span><span class="p">():</span>
    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span>
    <span class="n">n_layers</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">n_hidden</span><span class="o">=</span><span class="mi">32</span>
    <span class="n">starting_learning_rate</span><span class="o">=</span><span class="mf">1e-3</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;n_iterations, n_layers, n_hidden, starting_learning_rate, dropout&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">n_iterations</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="n">starting_learning_rate</span><span class="p">,</span> <span class="n">dropout</span>




<span class="c1"># update fonts</span>
<span class="n">FONTSIZE</span> <span class="o">=</span> <span class="mi">14</span>
<span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span> <span class="p">:</span> <span class="s1">&#39;serif&#39;</span><span class="p">,</span>
        <span class="s1">&#39;weight&#39;</span> <span class="p">:</span> <span class="s1">&#39;normal&#39;</span><span class="p">,</span>
        <span class="s1">&#39;size&#39;</span>   <span class="p">:</span> <span class="n">FONTSIZE</span><span class="p">}</span>
<span class="n">mp</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>

<span class="n">DATA_DIR</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;DATA_DIR&#39;</span><span class="p">]</span>
<span class="n">X</span>       <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;genDatapT&#39;</span><span class="p">,</span> <span class="s1">&#39;genDataeta&#39;</span><span class="p">,</span> <span class="s1">&#39;genDataphi&#39;</span><span class="p">,</span> <span class="s1">&#39;genDatam&#39;</span><span class="p">,</span> <span class="s1">&#39;tau&#39;</span><span class="p">]</span>

<span class="n">ORDER</span><span class="o">=</span><span class="s1">&#39;m_First&#39;</span>

<span class="k">if</span> <span class="n">ORDER</span><span class="o">==</span><span class="s1">&#39;m_First&#39;</span><span class="p">:</span>
    <span class="n">FIELDS</span>  <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;RecoDatam&#39;</span> <span class="p">:</span> <span class="p">{</span><span class="s1">&#39;inputs&#39;</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span> 
                               <span class="s1">&#39;xlabel&#39;</span><span class="p">:</span>  <span class="sa">r</span><span class="s1">&#39;$m$ (GeV)&#39;</span><span class="p">,</span> 
                              <span class="s1">&#39;ylabel&#39;</span><span class="p">:</span><span class="s1">&#39;$m^</span><span class="si">{reco}</span><span class="s1">$&#39;</span><span class="p">,</span>
                               <span class="s1">&#39;xmin&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> 
                               <span class="s1">&#39;xmax&#39;</span><span class="p">:</span> <span class="mi">25</span><span class="p">},</span>
                           

               <span class="s1">&#39;RecoDatapT&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;inputs&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;RecoDatam&#39;</span><span class="p">]</span><span class="o">+</span><span class="n">X</span><span class="p">,</span> 
                               <span class="s1">&#39;xlabel&#39;</span><span class="p">:</span>  <span class="sa">r</span><span class="s1">&#39;$p_T$ (GeV)&#39;</span> <span class="p">,</span> 
                              <span class="s1">&#39;ylabel&#39;</span><span class="p">:</span> <span class="s1">&#39;$p_T^</span><span class="si">{reco}</span><span class="s1">$&#39;</span><span class="p">,</span>
                               <span class="s1">&#39;xmin&#39;</span>  <span class="p">:</span> <span class="mi">20</span><span class="p">,</span> 
                               <span class="s1">&#39;xmax&#39;</span>  <span class="p">:</span>  <span class="mi">80</span><span class="p">},</span>

               <span class="s1">&#39;RecoDataeta&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;inputs&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;RecoDatam&#39;</span><span class="p">,</span><span class="s1">&#39;RecoDatapT&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">,</span> 
                               <span class="s1">&#39;xlabel&#39;</span><span class="p">:</span> <span class="sa">r</span><span class="s1">&#39;$\eta$&#39;</span><span class="p">,</span>
                               <span class="s1">&#39;ylabel&#39;</span><span class="p">:</span><span class="s1">&#39;$\eta^</span><span class="si">{reco}</span><span class="s1">$&#39;</span><span class="p">,</span>
                               <span class="s1">&#39;xmin&#39;</span>  <span class="p">:</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span>
                               <span class="s1">&#39;xmax&#39;</span>  <span class="p">:</span>  <span class="mi">5</span><span class="p">},</span>

               <span class="s1">&#39;RecoDataphi&#39;</span>  <span class="p">:</span> <span class="p">{</span><span class="s1">&#39;inputs&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;RecoDatam&#39;</span><span class="p">,</span> <span class="s1">&#39;RecodatapT&#39;</span><span class="p">,</span> <span class="s1">&#39;RecoDataeta&#39;</span><span class="p">]</span><span class="o">+</span><span class="n">X</span><span class="p">,</span>
                               <span class="s1">&#39;xlabel&#39;</span><span class="p">:</span> <span class="sa">r</span><span class="s1">&#39;$\phi$&#39;</span> <span class="p">,</span>
                                <span class="s1">&#39;ylabel&#39;</span> <span class="p">:</span><span class="s1">&#39;$\phi^</span><span class="si">{reco}</span><span class="s1">$&#39;</span><span class="p">,</span>
                               <span class="s1">&#39;xmin&#39;</span>  <span class="p">:</span> <span class="o">-</span><span class="mf">3.2</span><span class="p">,</span> 
                               <span class="s1">&#39;xmax&#39;</span>  <span class="p">:</span><span class="mf">3.2</span><span class="p">}</span>
              <span class="p">}</span>


<span class="c1"># Load and explore raw (unscaled) dataframes</span>

<span class="c1"># In[20]:</span>


<span class="n">all_variable_cols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;genDatapT&#39;</span><span class="p">,</span> <span class="s1">&#39;genDataeta&#39;</span><span class="p">,</span> <span class="s1">&#39;genDataphi&#39;</span><span class="p">,</span> <span class="s1">&#39;genDatam&#39;</span><span class="p">,</span><span class="s1">&#39;RecoDatapT&#39;</span><span class="p">,</span> <span class="s1">&#39;RecoDataeta&#39;</span><span class="p">,</span> <span class="s1">&#39;RecoDataphi&#39;</span><span class="p">,</span> <span class="s1">&#39;RecoDatam&#39;</span><span class="p">]</span>
<span class="n">all_cols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;genDatapT&#39;</span><span class="p">,</span> <span class="s1">&#39;genDataeta&#39;</span><span class="p">,</span> <span class="s1">&#39;genDataphi&#39;</span><span class="p">,</span> <span class="s1">&#39;genDatam&#39;</span><span class="p">,</span><span class="s1">&#39;RecoDatapT&#39;</span><span class="p">,</span> <span class="s1">&#39;RecoDataeta&#39;</span><span class="p">,</span> <span class="s1">&#39;RecoDataphi&#39;</span><span class="p">,</span> <span class="s1">&#39;RecoDatam&#39;</span><span class="p">,</span> <span class="s1">&#39;tau&#39;</span><span class="p">]</span>


    
<span class="k">def</span> <span class="nf">get_model_filename</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">PARAMS</span><span class="p">):</span>
    <span class="n">filename_model</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;&quot;&quot;Trained_IQNx4_</span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2">_</span><span class="se">\</span>
<span class="s2">        </span><span class="si">{</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;n_layers&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">_layer</span><span class="se">\</span>
<span class="s2">        </span><span class="si">{</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;hidden_size&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">_hidden</span><span class="se">\</span>
<span class="s2">            </span><span class="si">{</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;activation&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">_activation</span><span class="se">\</span>
<span class="s2">                </span><span class="si">{</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">_batchsize</span><span class="se">\</span>
<span class="s2">                    </span><span class="si">{</span><span class="n">PARAMS</span><span class="p">[</span><span class="s1">&#39;n_iterations&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">_iteration.dict&quot;&quot;&quot;</span> 
                    
    <span class="k">return</span> <span class="n">filename_model</span>

<span class="k">def</span> <span class="nf">explore_data</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">scaled</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span> <span class="p">)</span>
    <span class="c1"># df = df[[&#39;genDatapT&#39;, &#39;genDataeta&#39;, &#39;genDataphi&#39;, &#39;genDatam&#39;,&#39;RecoDatapT&#39;, &#39;RecoDataeta&#39;, &#39;RecoDataphi&#39;, &#39;RecoDatam&#39;]]</span>
    <span class="n">levels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;RecoData&#39;</span><span class="p">,</span> <span class="s1">&#39;genData&#39;</span><span class="p">]</span>
    <span class="n">kinematics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;pT&#39;</span><span class="p">,</span><span class="s1">&#39;eta&#39;</span><span class="p">,</span><span class="s1">&#39;phi&#39;</span><span class="p">,</span><span class="s1">&#39;m&#39;</span><span class="p">]</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">level</span><span class="o">+</span><span class="n">k</span> <span class="k">for</span> <span class="n">level</span> <span class="ow">in</span> <span class="n">levels</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">kinematics</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="n">columns</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;tau&#39;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span>
    
    <span class="k">for</span> <span class="n">k_i</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kinematics</span><span class="p">):</span>
        <span class="n">Reco_var</span> <span class="o">=</span> <span class="n">levels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">k</span>
        <span class="n">gen_var</span> <span class="o">=</span> <span class="n">levels</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">k</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Reco_var: &#39;</span><span class="p">,</span> <span class="n">Reco_var</span><span class="p">,</span> <span class="s1">&#39;, </span><span class="se">\t</span><span class="s1"> gen_var: &#39;</span><span class="p">,</span> <span class="n">gen_var</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">k_i</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">Reco_var</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">Reco_var</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.35</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">k_i</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">gen_var</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">gen_var</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.35</span><span class="p">)</span>
        <span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span> <span class="o">=</span> <span class="n">FIELDS</span><span class="p">[</span><span class="n">Reco_var</span><span class="p">][</span><span class="s1">&#39;xmin&#39;</span><span class="p">],</span> <span class="n">FIELDS</span><span class="p">[</span><span class="n">Reco_var</span><span class="p">][</span><span class="s1">&#39;xmax&#39;</span><span class="p">]</span>
        <span class="n">xlabel</span><span class="o">=</span><span class="n">FIELDS</span><span class="p">[</span><span class="n">Reco_var</span><span class="p">][</span><span class="s1">&#39;xlabel&#39;</span><span class="p">]</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">k_i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span> <span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">)</span> <span class="p">)</span>
        <span class="c1"># set_axes(ax[k_i], xlabel=xlabel, ylabel=&#39;&#39;, xmin=xmin, xmax=xmax)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">k_i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">26</span><span class="p">)</span>
        
        
                  
        <span class="k">if</span> <span class="n">scaled</span><span class="p">:</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">k_i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">gen_var</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span><span class="n">df</span><span class="p">[</span><span class="n">gen_var</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="p">)</span>
        
        <span class="n">ax</span><span class="p">[</span><span class="n">k_i</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;tau&#39;</span><span class="p">],</span><span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\tau$&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">show_plot</span><span class="p">()</span>
    
<span class="c1"># @memory.cache</span>
<span class="k">def</span> <span class="nf">get_scaling_info</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;args: df is train or eval df.</span>
<span class="sd">    returns: dictionary with mean of std of each feature (column) in the df&quot;&quot;&quot;</span>
    <span class="n">features</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;genDatapT&#39;</span><span class="p">,</span> <span class="s1">&#39;genDataeta&#39;</span><span class="p">,</span> <span class="s1">&#39;genDataphi&#39;</span><span class="p">,</span> <span class="s1">&#39;genDatam&#39;</span><span class="p">,</span>
              <span class="s1">&#39;RecoDatapT&#39;</span><span class="p">,</span> <span class="s1">&#39;RecoDataeta&#39;</span><span class="p">,</span> <span class="s1">&#39;RecoDataphi&#39;</span><span class="p">,</span> <span class="s1">&#39;RecoDatam&#39;</span><span class="p">,</span> 
            <span class="c1">#   &#39;tau&#39;</span>
              <span class="p">]</span>
    
    <span class="n">SCALE_DICT</span> <span class="o">=</span> <span class="nb">dict</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">):</span>
        <span class="n">feature</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">feature_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">feature</span><span class="p">])</span>
        <span class="n">SCALE_DICT</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">=</span><span class="p">{}</span>
        <span class="n">SCALE_DICT</span><span class="p">[</span><span class="n">feature</span><span class="p">][</span><span class="s1">&#39;mean&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">feature_values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">SCALE_DICT</span><span class="p">[</span><span class="n">feature</span><span class="p">][</span><span class="s1">&#39;std&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">feature_values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">SCALE_DICT</span>





<span class="k">def</span> <span class="nf">L</span><span class="p">(</span><span class="n">orig_observable</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
    <span class="n">eps</span><span class="o">=</span><span class="mf">1e-20</span>
    <span class="n">orig_observable</span><span class="o">=</span><span class="n">orig_observable</span><span class="o">+</span><span class="n">eps</span>
    <span class="k">if</span> <span class="n">label</span><span class="o">==</span><span class="s1">&#39;pT&#39;</span><span class="p">:</span>
        <span class="n">const</span><span class="o">=</span><span class="mi">0</span>
        <span class="n">log_pT_</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">orig_observable</span><span class="p">)</span> 
        <span class="n">L_observable</span> <span class="o">=</span> <span class="n">log_pT_</span>
    <span class="k">if</span> <span class="n">label</span><span class="o">==</span><span class="s1">&#39;eta&#39;</span><span class="p">:</span>
        <span class="n">const</span><span class="o">=</span><span class="mi">0</span>
        <span class="n">L_observable</span><span class="o">=</span><span class="n">orig_observable</span>
    <span class="k">if</span> <span class="n">label</span><span class="o">==</span><span class="s1">&#39;m&#39;</span><span class="p">:</span>
        <span class="n">const</span><span class="o">=</span><span class="mi">2</span>
        <span class="n">L_observable</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">orig_observable</span> <span class="o">+</span> <span class="n">const</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">label</span><span class="o">==</span><span class="s1">&#39;phi&#39;</span><span class="p">:</span>
        <span class="n">L_observable</span><span class="o">=</span><span class="n">orig_observable</span>
    <span class="k">if</span> <span class="n">label</span><span class="o">==</span><span class="s1">&#39;tau&#39;</span><span class="p">:</span>
        <span class="n">L_observable</span><span class="o">=</span><span class="n">orig_observable</span>
<span class="c1">#         L_observable = (6*orig_observable) - 3</span>
    
    <span class="k">return</span> <span class="n">L_observable</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>



<span class="k">def</span> <span class="nf">L_inverse</span><span class="p">(</span><span class="n">L_observable</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
    <span class="n">eps</span><span class="o">=</span><span class="mf">1e-20</span>
    <span class="n">L_observable</span><span class="o">=</span><span class="n">L_observable</span><span class="o">+</span><span class="n">eps</span>
    <span class="k">if</span> <span class="n">label</span><span class="o">==</span><span class="s1">&#39;pT&#39;</span><span class="p">:</span>
        <span class="n">const</span><span class="o">=</span><span class="mi">0</span>
        <span class="n">L_inverse_observable</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">L_observable</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">label</span><span class="o">==</span><span class="s1">&#39;eta&#39;</span><span class="p">:</span>
        <span class="n">L_inverse_observable</span> <span class="o">=</span> <span class="n">L_observable</span>
    <span class="k">if</span> <span class="n">label</span><span class="o">==</span><span class="s1">&#39;m&#39;</span><span class="p">:</span>
        <span class="n">const</span><span class="o">=</span><span class="mi">2</span>
        <span class="n">L_inverse_observable</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">L_observable</span><span class="p">)</span> <span class="o">-</span> <span class="n">const</span>
    <span class="k">if</span> <span class="n">label</span><span class="o">==</span><span class="s1">&#39;tau&#39;</span><span class="p">:</span>
        <span class="n">L_inverse_observable</span><span class="o">=</span><span class="n">L_observable</span>
        <span class="c1"># L_inverse_observable = (L_observable+3)/6</span>
        
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">L_inverse_observable</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">L_inverse_observable</span> <span class="o">=</span> <span class="n">L_inverse_observable</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">L_inverse_observable</span>




<span class="k">def</span> <span class="nf">T</span><span class="p">(</span><span class="n">variable</span><span class="p">,</span> <span class="n">scaled_df</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">variable</span><span class="o">==</span><span class="s1">&#39;pT&#39;</span><span class="p">:</span>
        <span class="n">L_pT_gen</span><span class="o">=</span><span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;genDatapT&#39;</span><span class="p">]</span>
        <span class="n">L_pT_reco</span> <span class="o">=</span> <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;RecoDatapT&#39;</span><span class="p">]</span>
        <span class="n">target</span> <span class="o">=</span> <span class="p">(</span><span class="n">L_pT_reco</span><span class="o">+</span><span class="mi">10</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">L_pT_gen</span><span class="o">+</span><span class="mi">10</span><span class="p">)</span> 
    <span class="k">if</span> <span class="n">variable</span><span class="o">==</span><span class="s1">&#39;eta&#39;</span><span class="p">:</span>
        <span class="n">L_eta_gen</span><span class="o">=</span><span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;genDataeta&#39;</span><span class="p">]</span>
        <span class="n">L_eta_reco</span> <span class="o">=</span> <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;RecoDataeta&#39;</span><span class="p">]</span>
        <span class="n">target</span> <span class="o">=</span>  <span class="p">(</span><span class="n">L_eta_reco</span><span class="o">+</span><span class="mi">10</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">L_eta_gen</span><span class="o">+</span><span class="mi">10</span><span class="p">)</span> 
    <span class="k">if</span> <span class="n">variable</span><span class="o">==</span><span class="s1">&#39;phi&#39;</span><span class="p">:</span>
        <span class="n">L_phi_gen</span><span class="o">=</span><span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;genDataphi&#39;</span><span class="p">]</span>
        <span class="n">L_phi_reco</span> <span class="o">=</span> <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;RecoDataphi&#39;</span><span class="p">]</span>
        <span class="n">target</span> <span class="o">=</span>  <span class="p">(</span><span class="n">L_phi_reco</span><span class="o">+</span><span class="mi">10</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">L_phi_gen</span><span class="o">+</span><span class="mi">10</span><span class="p">)</span> 
    <span class="k">if</span> <span class="n">variable</span><span class="o">==</span><span class="s1">&#39;m&#39;</span><span class="p">:</span>
        <span class="n">L_m_gen</span><span class="o">=</span><span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;genDatam&#39;</span><span class="p">]</span>
        <span class="n">L_m_reco</span> <span class="o">=</span> <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;RecoDatam&#39;</span><span class="p">]</span>
        <span class="n">target</span> <span class="o">=</span>  <span class="p">(</span><span class="n">L_m_reco</span><span class="o">+</span><span class="mi">10</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">L_m_gen</span><span class="o">+</span><span class="mi">10</span><span class="p">)</span> 
    
    <span class="k">return</span> <span class="n">target</span>



<span class="k">def</span> <span class="nf">L_scale_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">save</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="c1">#scale</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">all_cols</span><span class="p">]</span>
    <span class="c1"># print(df.head())</span>
    <span class="n">scaled_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="c1">#select the columns by index: </span>
    <span class="c1"># 0:genDatapT, 1:genDataeta, 2:genDataphi, 3:genDatam, </span>
    <span class="c1"># 4:RecoDatapT, 5:RecoDataeta, 6:RecoDataphi, 7: Recodatam</span>
    <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;genDatapT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;pT&#39;</span><span class="p">)</span>
    <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;RecoDatapT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">4</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;pT&#39;</span><span class="p">)</span>
    
    <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;genDataeta&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;eta&#39;</span><span class="p">)</span>
    <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;RecoDataeta&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">5</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;eta&#39;</span><span class="p">)</span>
    
    
    <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;genDataphi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;phi&#39;</span><span class="p">)</span>
    <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;RecoDataphi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">6</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;phi&#39;</span><span class="p">)</span>

    <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;genDatam&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">3</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;m&#39;</span><span class="p">)</span>
    <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;RecoDatam&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">7</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;m&#39;</span><span class="p">)</span>
    <span class="c1">#why scale tau?</span>
    <span class="c1"># scaled_df[&#39;tau&#39;] = 6 * df.iloc[:,8] - 3</span>
    <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;tau&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">8</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;tau&#39;</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="n">scaled_df</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
    
    <span class="k">if</span> <span class="n">save</span><span class="p">:</span>
        <span class="n">scaled_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="n">title</span><span class="p">)</span> <span class="p">)</span>
    <span class="k">return</span> <span class="n">scaled_df</span>


<span class="k">def</span> <span class="nf">decay_LR</span><span class="p">(</span><span class="nb">iter</span><span class="p">):</span>
    <span class="n">starting_LR</span> <span class="o">=</span> <span class="mf">1e-3</span>
    <span class="k">return</span> <span class="n">starting_LR</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span> <span class="nb">iter</span><span class="o">/</span> <span class="p">(</span><span class="mf">1e4</span><span class="p">))</span>

<span class="c1"># @register_cell_magic</span>
<span class="k">def</span> <span class="nf">write_and_run</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="n">cell</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;write the current cell to a file (or append it with -a argument) as well as execute it</span>
<span class="sd">    use with %%write_and_run at the top of a given cell&quot;&quot;&quot;</span>
    <span class="n">argz</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">file</span> <span class="o">=</span> <span class="n">argz</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;w&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">argz</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">argz</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;-a&quot;</span><span class="p">:</span>
        <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;a&quot;</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">cell</span><span class="p">)</span>
    <span class="c1"># get_ipython().run_cell(cell)</span>


<span class="k">def</span> <span class="nf">get_batch</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="c1"># the numpy function choice(length, number)</span>
    <span class="c1"># selects at random &quot;batch_size&quot; integers from </span>
    <span class="c1"># the range [0, length-1] corresponding to the</span>
    <span class="c1"># row indices.</span>
    <span class="n">rows</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">batch_x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">rows</span><span class="p">]</span>
    <span class="n">batch_t</span> <span class="o">=</span> <span class="n">t</span><span class="p">[</span><span class="n">rows</span><span class="p">]</span>
    <span class="c1"># batch_x.T[-1] = np.random.uniform(0, 1, batch_size)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_t</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">add_noise</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">noise</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">shape_x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">x</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">noise</span> 
    <span class="k">return</span> <span class="n">x</span> 
<span class="c1"># Note: there are several average loss functions available </span>
<span class="c1"># in pytorch, but it&#39;s useful to know how to create your own.</span>
<span class="k">def</span> <span class="nf">average_quadratic_loss</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1"># f and t must be of the same shape</span>
    <span class="k">return</span>  <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">f</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">average_cross_entropy_loss</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1"># f and t must be of the same shape</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">t</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">f</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">f</span><span class="p">))</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">average_quantile_loss</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    
    <span class="c1"># f and t must be of the same shape</span>
    <span class="n">tau</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># last column is tau.</span>
    <span class="c1">#L= tau * (target - output), if target&gt;output</span>
    <span class="c1">#L= (1-tau)*(output-target), otherwise</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">t</span> <span class="o">&gt;</span> <span class="n">f</span><span class="p">,</span> 
                                  <span class="n">tau</span> <span class="o">*</span> <span class="p">(</span><span class="n">t</span> <span class="o">-</span> <span class="n">f</span><span class="p">),</span> 
                                  <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">tau</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">f</span> <span class="o">-</span> <span class="n">t</span><span class="p">)))</span>
    
<span class="k">def</span> <span class="nf">average_huber_quantile_loss</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    
    <span class="c1"># f and t must be of the same shape</span>
    <span class="n">tau</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># last column is tau.</span>
    <span class="c1">#u = target-output</span>
    <span class="n">u</span><span class="o">=</span><span class="n">t</span><span class="o">-</span><span class="n">f</span>
    <span class="n">abs_u</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
    <span class="c1">#threshold kappa</span>
    <span class="n">kappa</span><span class="o">=</span><span class="mf">0.5</span>
    <span class="c1">#L = (tau - I[u &lt;=0])/(2*kappa) * u**2 , if |u| &lt;= kappa</span>
    <span class="c1">#L = (1-tau)*kappa* (|u| - kappa/2), otherwise</span>
    <span class="c1">#call I[u &lt;= 0] = z</span>
    <span class="n">z</span><span class="o">=</span> <span class="p">(</span><span class="n">u</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">abs_u</span> <span class="o">&lt;=</span> <span class="n">kappa</span><span class="p">,</span> 
                                  <span class="p">(</span><span class="n">tau</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">kappa</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">u</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span> 
                                 <span class="nb">abs</span><span class="p">(</span><span class="n">tau</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">abs_u</span> <span class="o">-</span> <span class="p">(</span><span class="n">kappa</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span> <span class="p">)</span>                               
                                                                 <span class="p">)</span>  
                                  <span class="p">)</span>
                      
<span class="k">def</span> <span class="nf">RMS</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">v</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">**</span><span class="mf">0.5</span>


<span class="k">def</span> <span class="nf">average_quantile_loss_with_df_dtau</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">df_dtau</span><span class="p">):</span>
    <span class="c1"># f and t must be of the same shape</span>
    <span class="n">tau</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># last column is tau.</span>
    <span class="c1">#Eq (2)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">t</span> <span class="o">&gt;=</span> <span class="n">f</span><span class="p">,</span> 
                                  <span class="n">tau</span> <span class="o">*</span> <span class="p">(</span><span class="n">t</span> <span class="o">-</span> <span class="n">f</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="o">-</span><span class="n">df_dtau</span><span class="p">)</span> <span class="o">*</span> <span class="n">RMS</span><span class="p">(</span><span class="n">df_dtau</span><span class="p">),</span> 
                                  <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">tau</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">f</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">+</span><span class="p">(</span><span class="o">-</span><span class="n">df_dtau</span><span class="p">)</span><span class="o">*</span> <span class="n">RMS</span><span class="p">(</span><span class="n">df_dtau</span><span class="p">)</span>
                                  <span class="p">))</span>
    
<span class="c1"># function to validate model during training.</span>
<span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">avloss</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="c1"># make sure we set evaluation mode so that any training specific</span>
    <span class="c1"># operations are disabled.</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="c1"># evaluation mode</span>
    
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span> <span class="c1"># no need to compute gradients wrt. x and t</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="c1"># remember to reshape!</span>
        <span class="n">o</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">avloss</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">plot_average_loss</span><span class="p">(</span><span class="n">traces</span><span class="p">,</span> <span class="n">n_iterations</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">ftsize</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span><span class="n">save_loss_plots</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show_loss_plots</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy_t</span><span class="p">,</span> <span class="n">yy_v</span><span class="p">,</span> <span class="n">yy_v_avg</span> <span class="o">=</span> <span class="n">traces</span>
    
    <span class="c1"># create an empty figure</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">))</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    
    <span class="c1"># add a subplot to it</span>
    <span class="n">nrows</span><span class="p">,</span> <span class="n">ncols</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span>
    <span class="n">ax</span>  <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">nrows</span><span class="p">,</span><span class="n">ncols</span><span class="p">,</span><span class="n">index</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Average loss&quot;</span><span class="p">)</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy_t</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy_v</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">)</span>
    <span class="c1">#ax.plot(xx, yy_v_avg, &#39;g&#39;, lw=2, label=&#39;Running average&#39;)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Iterations&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">ftsize</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;average loss&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">ftsize</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">save_loss_plots</span><span class="p">:</span>
        <span class="n">filename</span><span class="o">=</span><span class="s1">&#39;IQNx4_Loss_</span><span class="si">%s</span><span class="s1">_</span><span class="si">%s</span><span class="s1">K_iteration.png&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">sr</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_iterations</span><span class="p">))</span> <span class="p">)</span>
        <span class="n">mkdir</span><span class="p">(</span><span class="s1">&#39;images/loss_plots&#39;</span><span class="p">)</span>
        <span class="n">PATH</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">IQN_BASE</span><span class="p">,</span> <span class="s1">&#39;images&#39;</span><span class="p">,</span> <span class="s1">&#39;loss_plots&#39;</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">loss curve saved in </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">PATH</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">show_loss_plots</span><span class="p">:</span>
        <span class="n">show_plot</span><span class="p">()</span>
        
        

<span class="c1"># def split_t_x(df, target, input_features):</span>
<span class="c1">#     &quot;&quot;&quot; Get teh target as the ratio, according to the T equation&quot;&quot;&quot;</span>
    
<span class="c1">#     if target==&#39;RecoDatam&#39;:</span>
<span class="c1">#         t = T(&#39;m&#39;, scaled_df=train_data_m)</span>
<span class="c1">#     if target==&#39;RecoDatapT&#39;:</span>
<span class="c1">#         t = T(&#39;pT&#39;, scaled_df=train_data_m)</span>
<span class="c1">#     if target==&#39;RecoDataeta&#39;:</span>
<span class="c1">#         t = T(&#39;eta&#39;, scaled_df=train_data_m)</span>
<span class="c1">#     if target==&#39;RecoDataphi&#39;:</span>
<span class="c1">#         t = T(&#39;phi&#39;, scaled_df=train_data_m)</span>
<span class="c1">#     x = np.array(df[input_features])</span>
<span class="c1">#     return np.array(t), x</span>



<span class="c1"># def apply_z_to_features():</span>
<span class="c1">#     &quot;&quot;&quot;TO ensure this z scaling is only applied once to the training features, we use a generator &quot;&quot;&quot;</span>
<span class="c1">#     for i in range(NFEATURES-1):</span>
<span class="c1">#         train_x[:,i] = z(train_x[:,i])</span>
<span class="c1">#         test_x[:,i] = z(test_x[:,i])</span>
<span class="c1">#         valid_x[:,i] = z(valid_x[:,i])</span>
<span class="c1">#     yield train_x </span>
<span class="c1">#     yield test_x </span>
<span class="c1">#     yield valid_x</span>





<span class="c1"># ### Apply $z$ to targets before training</span>

<span class="c1"># def apply_z_to_targets():</span>
<span class="c1">#     train_t_ratio_ = z(train_t_ratio) </span>
<span class="c1">#     test_t_ratio_ = z(test_t_ratio) </span>
<span class="c1">#     valid_t_ratio_ = z(valid_t_ratio)</span>
    
<span class="c1">#     yield train_t_ratio_</span>
<span class="c1">#     yield test_t_ratio_</span>
<span class="c1">#     yield valid_t_ratio_</span>
    

<span class="k">class</span> <span class="nc">RegularizedRegressionModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Used for hyperparameter tuning &quot;&quot;&quot;</span>
    <span class="c1">#inherit from the super class</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nfeatures</span><span class="p">,</span> <span class="n">ntargets</span><span class="p">,</span> <span class="n">nlayers</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">dropout_1</span><span class="p">,</span> <span class="n">dropout_2</span><span class="p">,</span><span class="n">activation</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nlayers</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span> <span class="o">==</span><span class="mi">0</span><span class="p">:</span>
                <span class="c1">#nlayers is number of hidden layers+1, since there is always an input layer and an output layer</span>
                <span class="c1">#INPUT LAYER</span>
                <span class="c1">#inital layer has to have size of (input features, output_nodes),</span>
                <span class="c1">#its output layer can have any size but it must match the size of the input layer of the next linear layer</span>
                <span class="c1">#here we choose its output layer as the hidden size (fully connected)</span>
                <span class="c1">#ALPHA DROPOUT</span>
                <span class="c1"># layers.append(nn.AlphaDropout(dropout_1))</span>
                
                <span class="n">layer</span><span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nfeatures</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
                <span class="c1">#batch normalization</span>
                <span class="c1"># layers.append(nn.BatchNorm1d(hidden_size))</span>
                <span class="c1">#dropout should have higher values in deeper layers</span>
                <span class="c1"># layers.append(nn.Dropout(dropout_1))#Use small dropout for 1st layers &amp; larger dropout for later layers. In both cases, the larger he model the larger the dropout.</span>
                <span class="c1">#When model is in training, apply dropout. When using model for inference, dont use dropout</span>

                
                <span class="c1">#ReLU activation </span>
                <span class="k">if</span> <span class="n">activation</span><span class="o">==</span><span class="s1">&#39;LeakyReLU&#39;</span><span class="p">:</span>
                    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">negative_slope</span><span class="o">=</span><span class="mf">0.3</span><span class="p">))</span>
                <span class="k">elif</span> <span class="n">activation</span><span class="o">==</span><span class="s1">&#39;PReLU&#39;</span><span class="p">:</span>
                    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">())</span>
                <span class="k">elif</span> <span class="n">activation</span><span class="o">==</span><span class="s1">&#39;ReLU6&#39;</span><span class="p">:</span>
                    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU6</span><span class="p">())</span>
                <span class="k">elif</span> <span class="n">activation</span><span class="o">==</span><span class="s1">&#39;ELU&#39;</span><span class="p">:</span>
                    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">())</span>
                <span class="k">elif</span> <span class="n">activation</span><span class="o">==</span><span class="s1">&#39;SELU&#39;</span><span class="p">:</span>
                    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">SELU</span><span class="p">())</span>
                <span class="k">elif</span> <span class="n">activation</span><span class="o">==</span><span class="s1">&#39;CELU&#39;</span><span class="p">:</span>
                    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">CELU</span><span class="p">())</span>
                    
                    
            <span class="k">else</span><span class="p">:</span>
                <span class="c1">#if this is not the first layer (we dont have layers)</span>
                <span class="n">layer</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
                <span class="c1"># layers.append(nn.Dropout(dropout_2))</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">))</span>
                
                <span class="k">if</span> <span class="n">activation</span><span class="o">==</span><span class="s1">&#39;LeakyReLU&#39;</span><span class="p">:</span>
                    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">negative_slope</span><span class="o">=</span><span class="mf">0.3</span><span class="p">))</span>
                <span class="k">elif</span> <span class="n">activation</span><span class="o">==</span><span class="s1">&#39;PReLU&#39;</span><span class="p">:</span>
                    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">())</span>
                
        <span class="c1">#output layer:</span>
        <span class="n">output_layer</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">ntargets</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">output_layer</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_layer</span><span class="p">)</span> 

        <span class="c1"># only for classification add sigmoid</span>
        <span class="c1"># layers.append(nn.Sigmoid()) or softmax</span>
            <span class="c1">#we have defined sequential model using the layers in oulist </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
    
    
    
    
    
<span class="k">def</span> <span class="nf">initialize_weights_alone</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;use a different weight initialization &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    
<span class="c1"># class TrainingRegularizedRegressionModel(nn.Module):</span>
<span class="c1">#     &quot;&quot;&quot;Used for training, and adds more regularization to prevent overfitting &quot;&quot;&quot;</span>
<span class="c1">#     #inherit from the super class</span>
<span class="c1">#     def __init__(self, nfeatures, ntargets, nlayers, hidden_size, dropout):</span>
<span class="c1">#         super().__init__()</span>
<span class="c1">#         layers = []</span>
<span class="c1">#         for _ in range(nlayers):</span>
<span class="c1">#             if len(layers) ==0:</span>
<span class="c1">#                 #inital layer has to have size of input features as its input layer</span>
<span class="c1">#                 #its output layer can have any size but it must match the size of the input layer of the next linear layer</span>
<span class="c1">#                 #here we choose its output layer as the hidden size (fully connected)</span>
<span class="c1">#                 layers.append(nn.Linear(nfeatures, hidden_size))</span>
<span class="c1">#                 #batch normalization</span>
<span class="c1">#                 layers.append(nn.BatchNorm1d(hidden_size))</span>
<span class="c1">#                 #dropout only in the first layer</span>
<span class="c1">#                 #Dropout seems to worsen model performance</span>
<span class="c1">#                 layers.append(nn.Dropout(dropout))</span>
<span class="c1">#                 #ReLU activation </span>
<span class="c1">#                 layers.append(nn.LeakyReLU())</span>
<span class="c1">#             else:</span>
<span class="c1">#                 #if this is not the first layer (we dont have layers)</span>
<span class="c1">#                 layers.append(nn.Linear(hidden_size, hidden_size))</span>
<span class="c1">#                 layers.append(nn.BatchNorm1d(hidden_size))</span>
<span class="c1">#                 #Dropout seems to worsen model performance</span>
<span class="c1">#                 layers.append(nn.Dropout(dropout))</span>
<span class="c1">#                 layers.append(nn.LeakyReLU())</span>
<span class="c1">#                 #output layer:</span>
<span class="c1">#         layers.append(nn.Linear(hidden_size, ntargets)) </span>

<span class="c1">#         # only for classification add sigmoid</span>
<span class="c1">#         # layers.append(nn.Sigmoid())</span>
<span class="c1">#             #we have defined sequential model using the layers in oulist </span>
<span class="c1">#         self.model = nn.Sequential(*layers)</span>

    
<span class="c1">#     def forward(self, x):</span>
<span class="c1">#         return self.model(x)</span>




<span class="c1"># ## Hyperparameter Training Workflow</span>


<span class="k">def</span> <span class="nf">get_tuning_sample</span><span class="p">():</span>
    <span class="n">sample</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mi">200000</span><span class="p">)</span>
    <span class="c1"># train_x_sample, train_t_ratio_sample, valid_x_sample, valid_t_ratio_sample</span>
    <span class="n">get_whole</span><span class="o">=</span><span class="kc">True</span>
    <span class="k">if</span> <span class="n">get_whole</span><span class="p">:</span>
        <span class="n">train_x_sample</span><span class="p">,</span> <span class="n">train_t_ratio_sample</span><span class="p">,</span> <span class="n">valid_x_sample</span><span class="p">,</span> <span class="n">valid_t_ratio_sample</span> <span class="o">=</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">train_t_ratio</span><span class="p">,</span> <span class="n">valid_x</span><span class="p">,</span> <span class="n">valid_t_ratio</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">train_x_sample</span><span class="p">,</span> <span class="n">train_t_ratio_sample</span><span class="p">,</span> <span class="n">valid_x_sample</span><span class="p">,</span> <span class="n">valid_t_ratio_sample</span><span class="o">=</span><span class="n">train_x</span><span class="p">[:</span><span class="n">sample</span><span class="p">],</span> <span class="n">train_t_ratio</span><span class="p">[:</span><span class="n">sample</span><span class="p">],</span> <span class="n">valid_x</span><span class="p">[:</span><span class="n">sample</span><span class="p">],</span> <span class="n">valid_t_ratio</span><span class="p">[:</span><span class="n">sample</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">train_x_sample</span><span class="p">,</span> <span class="n">train_t_ratio_sample</span><span class="p">,</span> <span class="n">valid_x_sample</span><span class="p">,</span> <span class="n">valid_t_ratio_sample</span>



<span class="k">class</span> <span class="nc">HyperTrainer</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;loss, training and evaluation&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
                 <span class="c1">#, device):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="c1">#self.device= device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iterations_tune</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>

        <span class="c1">#the loss function returns the loss function. It is a static method so it doesn&#39;t need self</span>
        <span class="c1"># @staticmethod</span>
        <span class="c1"># def loss_fun(targets, outputs):</span>
        <span class="c1">#   tau = torch.rand(outputs.shape)</span>
        <span class="c1">#   return torch.mean(torch.where(targets &gt;= outputs, </span>
        <span class="c1">#                                   tau * (targets - outputs), </span>
        <span class="c1">#                                   (1 - tau)*(outputs - targets)))</span>

        <span class="c1">#     This loss combines a Sigmoid layer and the BCELoss in one single class. This version is more numerically stable than using a plain Sigmoid followed by a BCELoss as, </span>
        <span class="c1">#     by combining the operations into one layer</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">final_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iterations_tune</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_t</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span>  <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="c1">#x and t are train_x and train_t</span>

            <span class="c1"># with torch.no_grad():</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">batch_x</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">targets</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">batch_t</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">average_quantile_loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">final_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">final_loss</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>

    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">final_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iterations_tune</span><span class="p">):</span>
            <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_t</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span>  <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="c1">#x and t are train_x and train_t</span>

            <span class="c1"># with torch.no_grad():            </span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">batch_x</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">targets</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">batch_t</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span><span class="n">average_quantile_loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
            <span class="n">final_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">final_loss</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>

    
<span class="n">EPOCHS</span><span class="o">=</span><span class="mi">1</span>
<span class="k">def</span> <span class="nf">run_train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">save_model</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;For tuning the parameters&quot;&quot;&quot;</span>

    <span class="n">model</span> <span class="o">=</span>  <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
              <span class="n">nfeatures</span><span class="o">=</span><span class="n">train_x_sample</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
                <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">nlayers</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;nlayers&quot;</span><span class="p">],</span> 
                <span class="n">hidden_size</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">],</span>
                <span class="n">dropout</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">]</span>
                <span class="p">)</span>
    <span class="c1"># print(model)</span>
    

    <span class="n">learning_rate</span><span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">]</span>
    <span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">]</span>
    
    <span class="c1"># optimizer = torch.optim.Adam(model.parameters(), lr=params[&quot;learning_rate&quot;]) </span>
    
    <span class="n">optimizer</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">optimizer_name</span><span class="p">)(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> 
                            <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">momentum</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;momentum&quot;</span><span class="p">])</span>
    
    <span class="n">trainer</span><span class="o">=</span><span class="n">HyperTrainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">])</span>
    <span class="n">best_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    <span class="n">early_stopping_iter</span><span class="o">=</span><span class="mi">10</span><span class="c1">#stop after 10 iteractions of not improving loss</span>
    <span class="n">early_stopping_coutner</span><span class="o">=</span><span class="mi">0</span>

    <span class="c1"># for epoch in range(EPOCHS):</span>
    <span class="c1"># train_loss = trainer.train(train_x_sample, train_t_ratio_sample)</span>
        <span class="c1">#test loss</span>
    <span class="n">valid_loss</span><span class="o">=</span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">valid_x_sample</span><span class="p">,</span> <span class="n">valid_t_ratio_sample</span><span class="p">)</span>

        <span class="c1"># print(f&quot;{epoch} \t {train_loss} \t {valid_loss}&quot;)</span>
        
        <span class="c1"># if valid_loss&lt;best_loss:</span>
        <span class="c1">#     best_loss=valid_loss</span>
        <span class="c1"># else:</span>
        <span class="c1">#     early_stopping_coutner+=1</span>
        <span class="c1"># if early_stopping_coutner &gt; early_stopping_iter:</span>
            <span class="c1"># break</span>
            
    <span class="c1"># return best_loss</span>
    <span class="k">return</span> <span class="n">valid_loss</span>




<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    <span class="n">CLUSTER</span><span class="o">=</span><span class="kc">False</span>
    <span class="c1">#cluster has greater memory than my laptop, which allows higher max values in hyperparam. search space</span>
    <span class="k">if</span> <span class="n">CLUSTER</span><span class="p">:</span>
        <span class="n">nlayers_max</span><span class="p">,</span><span class="n">n_hidden_max</span><span class="p">,</span> <span class="n">batch_size_max</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mi">24</span><span class="p">),</span><span class="nb">int</span><span class="p">(</span><span class="mi">350</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e5</span><span class="p">)</span>
        <span class="n">n_trials</span><span class="o">=</span><span class="mi">1000</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">nlayers_max</span><span class="p">,</span><span class="n">n_hidden_max</span><span class="p">,</span> <span class="n">batch_size_max</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mi">6</span><span class="p">),</span><span class="nb">int</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="mf">3e4</span><span class="p">)</span>
        <span class="n">n_trials</span><span class="o">=</span><span class="mi">2</span>
    <span class="c1">#hyperparameter search space:</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
          <span class="s2">&quot;nlayers&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">&quot;nlayers&quot;</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">nlayers_max</span><span class="p">),</span>      
          <span class="s2">&quot;hidden_size&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_hidden_max</span><span class="p">),</span>
          <span class="s2">&quot;dropout&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s2">&quot;dropout&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span><span class="mf">0.5</span><span class="p">),</span>
          <span class="s2">&quot;optimizer_name&quot;</span> <span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_categorical</span><span class="p">(</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;RMSprop&quot;</span><span class="p">,</span> <span class="s2">&quot;SGD&quot;</span><span class="p">]),</span>
          <span class="s2">&quot;momentum&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s2">&quot;momentum&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span><span class="mf">0.99</span><span class="p">),</span>
          <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">),</span>
          <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">&quot;batch_size&quot;</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="n">batch_size_max</span><span class="p">)</span>

        <span class="p">}</span>
    
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>

        <span class="n">temp_loss</span> <span class="o">=</span> <span class="n">run_train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span><span class="n">save_model</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">trial</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">temp_loss</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
        <span class="c1">#activate pruning (early stopping if the current step in the trial has unpromising results)</span>
        <span class="c1">#instead of doing lots of iterations, do less iterations and more steps in each trial,  </span>
        <span class="c1">#such that a trial is terminated if a step yields an unpromising loss.</span>
        
        <span class="k">if</span> <span class="n">trial</span><span class="o">.</span><span class="n">should_prune</span><span class="p">():</span>
            <span class="k">raise</span> <span class="n">optuna</span><span class="o">.</span><span class="n">TrialPruned</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">temp_loss</span>

<span class="nd">@time_type_of_func</span><span class="p">(</span><span class="n">tuning_or_training</span><span class="o">=</span><span class="s1">&#39;tuning&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">tune_hyperparameters</span><span class="p">(</span><span class="n">save_best_params</span><span class="p">):</span>
    

    <span class="n">sampler</span><span class="o">=</span><span class="kc">False</span><span class="c1">#use different sampling technique than the defualt one if sampler=True.</span>
    <span class="k">if</span> <span class="n">sampler</span><span class="p">:</span>
        <span class="c1">#choose a different sampling strategy (https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.CmaEsSampler.html#optuna.samplers.CmaEsSampler)</span>
        <span class="c1"># sampler=optuna.samplers.RandomSampler()</span>
        <span class="n">study</span><span class="o">=</span><span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="s1">&#39;minimize&#39;</span><span class="p">,</span>
                                  <span class="n">pruner</span><span class="o">=</span><span class="n">optuna</span><span class="o">.</span><span class="n">pruners</span><span class="o">.</span><span class="n">MedianPruner</span><span class="p">(),</span> <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1">#but the default sampler is usually better - no need to change it!</span>
        <span class="n">study</span><span class="o">=</span><span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="s1">&#39;minimize&#39;</span><span class="p">,</span>
                                  <span class="n">pruner</span><span class="o">=</span><span class="n">optuna</span><span class="o">.</span><span class="n">pruners</span><span class="o">.</span><span class="n">HyperbandPruner</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;using </span><span class="si">{</span><span class="n">n_trials</span><span class="si">}</span><span class="s1"> trials for tuning&#39;</span><span class="p">)</span>
    <span class="n">study</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="n">n_trials</span><span class="p">)</span>
    <span class="n">best_trial</span> <span class="o">=</span> <span class="n">study</span><span class="o">.</span><span class="n">best_trial</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;best model parameters&#39;</span><span class="p">,</span> <span class="n">best_trial</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>

    <span class="n">best_params</span><span class="o">=</span><span class="n">best_trial</span><span class="o">.</span><span class="n">params</span><span class="c1">#this is a dictionary</span>
    <span class="c1">#save best hyperapameters in a pandas dataframe as a .csv</span>
    <span class="k">if</span> <span class="n">save_best_params</span><span class="p">:</span>
        <span class="n">tuned_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">IQN_BASE</span><span class="p">,</span><span class="s1">&#39;best_params&#39;</span><span class="p">)</span>
        <span class="n">mkdir</span><span class="p">(</span><span class="s1">&#39;tuned_dir&#39;</span><span class="p">)</span>
        <span class="n">filename</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tuned_dir</span><span class="p">,</span><span class="s1">&#39;best_params_mass_</span><span class="si">%s</span><span class="s1">_trials.csv&#39;</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_trials</span><span class="p">)))</span>
        <span class="n">param_df</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
                                <span class="s1">&#39;n_layers&#39;</span><span class="p">:</span><span class="n">best_params</span><span class="p">[</span><span class="s2">&quot;nlayers&quot;</span><span class="p">],</span> 
                                <span class="s1">&#39;hidden_size&#39;</span><span class="p">:</span><span class="n">best_params</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">],</span> 
                                <span class="s1">&#39;dropout&#39;</span><span class="p">:</span><span class="n">best_params</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">],</span>
                                <span class="s1">&#39;optimizer_name&#39;</span><span class="p">:</span><span class="n">best_params</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">],</span>
                                <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">best_params</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">],</span> 
                                <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span><span class="n">best_params</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">],</span>
                                <span class="s1">&#39;momentum&#39;</span><span class="p">:</span><span class="n">best_params</span><span class="p">[</span><span class="s2">&quot;momentum&quot;</span><span class="p">]},</span>
                                        <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="n">param_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>   
    <span class="k">return</span> <span class="n">study</span>



<span class="c1"># def load_untrained_model():</span>
<span class="c1">#     model=TrainingRegularizedRegressionModel(nfeatures=NFEATURES, ntargets=1,</span>
<span class="c1">#                                nlayers=n_layers, hidden_size=hidden_size, dropout=dropout)</span>
    
    
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>using torch version 1.9.0
matplotlib version=  3.5.1
using (optional) optuna version 2.8.0
BASE directoy properly set =  /home/ali/Desktop/Pulled_Github_Repositories/torchQN
DATA directory also properly set, in /home/ali/Desktop/Pulled_Github_Repositories/IQN_HEP/Davidson/data
</pre></div>
</div>
</div>
</div>
<section id="set-arguments-optional-and-configurations">
<h2>Set arguments (optional) and configurations<a class="headerlink" href="#set-arguments-optional-and-configurations" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># add_to_cluster()</span>
<span class="c1">################################### ARGUMENTS ###################################</span>
<span class="n">parser</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s1">&#39;train for different targets&#39;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--N&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;&#39;&#39;size of the dataset you want to use. </span>
<span class="s1">                    Options are 10M and 100K and 10M_2, the default is 10M_2&#39;&#39;&#39;</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">default</span><span class="o">=</span><span class="s1">&#39;10M_2&#39;</span><span class="p">)</span>
<span class="c1">#N_epochs X N_train_examples = N_iterations X batch_size</span>
<span class="c1"># N_iterations = (N_epochs * train_data.shape[0])/batch_size</span>
<span class="c1">#N_iterations = (N_epochs * train_data.shape[0])/64 = 125000 for 1 epoch</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--n_iterations&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;&#39;&#39;The number of iterations for training, </span>
<span class="s1">                    the default is&#39;&#39;&#39;</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">default</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="c1">#default=5000000 )</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--n_layers&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;&#39;&#39;The number of layers in your NN, </span>
<span class="s1">                    the default is 5&#39;&#39;&#39;</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">default</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--n_hidden&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;&#39;&#39;The number of hidden layers in your NN, </span>
<span class="s1">                    the default is 5&#39;&#39;&#39;</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">default</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--starting_learning_rate&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;&#39;&#39;Starting learning rate, </span>
<span class="s1">                    the defulat is 10^-3&#39;&#39;&#39;</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">default</span><span class="o">=</span><span class="mf">1.e-2</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--show_loss_plots&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">bool</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;&#39;&#39;Boolean to show the loss plots, </span>
<span class="s1">                    default is False&#39;&#39;&#39;</span><span class="p">,</span> <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--save_model&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">bool</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;&#39;&#39;Boolean to save the trained model dictionary&#39;&#39;&#39;</span><span class="p">,</span> 
                    <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--save_loss_plots&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">bool</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;&#39;&#39;Boolean to save the loss plots&#39;&#39;&#39;</span><span class="p">,</span> 
                    <span class="n">required</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>


<span class="c1">################################### CONFIGURATIONS ###################################</span>
<span class="n">DATA_DIR</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;DATA_DIR&#39;</span><span class="p">]</span>
<span class="n">JUPYTER</span><span class="o">=</span><span class="kc">True</span>
<span class="n">use_subsample</span><span class="o">=</span><span class="kc">False</span>
<span class="k">if</span> <span class="n">use_subsample</span><span class="p">:</span>
    <span class="n">SUBSAMPLE</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e5</span><span class="p">)</span><span class="c1">#subsample use for development - in production use whole dataset</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">SUBSAMPLE</span><span class="o">=</span><span class="kc">None</span>
    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">JUPYTER</span><span class="p">:</span>
    <span class="c1"># print(plt.rcsetup.interactive_bk )</span>
    <span class="c1"># matplotlib interactive mode: ion or ioff</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ioff</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;interactive? &#39;</span><span class="p">,</span> <span class="n">mpl</span><span class="o">.</span><span class="n">is_interactive</span><span class="p">())</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">(</span><span class="n">args</span><span class="o">=</span><span class="p">[])</span>
    <span class="n">N</span> <span class="o">=</span> <span class="s1">&#39;10M_2&#39;</span>
    <span class="n">n_iterations</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e4</span><span class="p">)</span>
    <span class="n">n_layers</span><span class="p">,</span> <span class="n">n_hidden</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">starting_learning_rate</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="mf">1.e-2</span><span class="p">)</span>
    <span class="n">show_loss_plots</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">save_model</span><span class="o">=</span><span class="kc">False</span>
    <span class="n">save_loss_plots</span> <span class="o">=</span> <span class="kc">False</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">N</span>
    <span class="n">n_iterations</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">n_iterations</span>
    <span class="n">n_layers</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">n_layers</span>
    <span class="n">n_hidden</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">n_hidden</span>
    <span class="n">starting_learning_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">starting_learning_rate</span>
    <span class="n">show_loss_plots</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">show_loss_plots</span>
    <span class="n">save_model</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">save_model</span>
    <span class="n">save_loss_plots</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">save_loss_plots</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>interactive?  False
</pre></div>
</div>
</div>
</div>
<section id="import-the-numpy-data-convert-to-dataframe-and-save-if-you-haven-t-saved-the-dataframes">
<h3>Import the numpy data, convert to dataframe and save (if you haven’t saved the dataframes)<a class="headerlink" href="#import-the-numpy-data-convert-to-dataframe-and-save-if-you-haven-t-saved-the-dataframes" title="Permalink to this headline">#</a></h3>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="explore-the-dataframe-and-preprocess">
<h1>Explore the Dataframe and preprocess<a class="headerlink" href="#explore-the-dataframe-and-preprocess" title="Permalink to this headline">#</a></h1>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="data">
<h1>Data<a class="headerlink" href="#data" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">use_svg_display</span><span class="p">()</span>
<span class="n">show_jupyter_image</span><span class="p">(</span><span class="s1">&#39;images/pythia_ppt_diagram.png&#39;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span><span class="n">height</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1_Setup_and_Preprocess_24_0.png" src="_images/1_Setup_and_Preprocess_24_0.png" />
</div>
</div>
<p>Decide on an evaluation order</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">################################### SET DATA CONFIGURATIONS ###################################</span>
<span class="n">X</span>       <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;genDatapT&#39;</span><span class="p">,</span> <span class="s1">&#39;genDataeta&#39;</span><span class="p">,</span> <span class="s1">&#39;genDataphi&#39;</span><span class="p">,</span> <span class="s1">&#39;genDatam&#39;</span><span class="p">,</span> <span class="s1">&#39;tau&#39;</span><span class="p">]</span>

<span class="c1">#set order of training:</span>
<span class="c1">#pT_first: pT-&gt;&gt;m-&gt;eta-&gt;phi</span>
<span class="c1">#m_first: m-&gt;pT-&gt;eta-&gt;phi</span>



<span class="c1">#we&#39;ll just go with m first since that&#39;s the order we discuss in the paper.</span>
<span class="n">ORDER</span><span class="o">=</span><span class="s1">&#39;m_First&#39;</span>

<span class="k">if</span> <span class="n">ORDER</span><span class="o">==</span><span class="s1">&#39;m_First&#39;</span><span class="p">:</span>
    <span class="n">FIELDS</span>  <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;RecoDatam&#39;</span> <span class="p">:</span> <span class="p">{</span><span class="s1">&#39;inputs&#39;</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span> 
                               <span class="s1">&#39;xlabel&#39;</span><span class="p">:</span>  <span class="sa">r</span><span class="s1">&#39;$m$ (GeV)&#39;</span><span class="p">,</span> 
                              <span class="s1">&#39;ylabel&#39;</span><span class="p">:</span><span class="s1">&#39;$m^</span><span class="si">{reco}</span><span class="s1">$&#39;</span><span class="p">,</span>
                               <span class="s1">&#39;xmin&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> 
                               <span class="s1">&#39;xmax&#39;</span><span class="p">:</span> <span class="mi">25</span><span class="p">},</span>
                           

               <span class="s1">&#39;RecoDatapT&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;inputs&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;RecoDatam&#39;</span><span class="p">]</span><span class="o">+</span><span class="n">X</span><span class="p">,</span> 
                               <span class="s1">&#39;xlabel&#39;</span><span class="p">:</span>  <span class="sa">r</span><span class="s1">&#39;$p_T$ (GeV)&#39;</span> <span class="p">,</span> 
                              <span class="s1">&#39;ylabel&#39;</span><span class="p">:</span> <span class="s1">&#39;$p_T^</span><span class="si">{reco}</span><span class="s1">$&#39;</span><span class="p">,</span>
                               <span class="s1">&#39;xmin&#39;</span>  <span class="p">:</span> <span class="mi">20</span><span class="p">,</span> 
                               <span class="s1">&#39;xmax&#39;</span>  <span class="p">:</span>  <span class="mi">80</span><span class="p">},</span>

               <span class="s1">&#39;RecoDataeta&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;inputs&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;RecoDatam&#39;</span><span class="p">,</span><span class="s1">&#39;RecoDatapT&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">,</span> 
                               <span class="s1">&#39;xlabel&#39;</span><span class="p">:</span> <span class="sa">r</span><span class="s1">&#39;$\eta$&#39;</span><span class="p">,</span>
                               <span class="s1">&#39;ylabel&#39;</span><span class="p">:</span><span class="s1">&#39;$\eta^</span><span class="si">{reco}</span><span class="s1">$&#39;</span><span class="p">,</span>
                               <span class="s1">&#39;xmin&#39;</span>  <span class="p">:</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span>
                               <span class="s1">&#39;xmax&#39;</span>  <span class="p">:</span>  <span class="mi">5</span><span class="p">},</span>

               <span class="s1">&#39;RecoDataphi&#39;</span>  <span class="p">:</span> <span class="p">{</span><span class="s1">&#39;inputs&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;RecoDatam&#39;</span><span class="p">,</span> <span class="s1">&#39;RecodatapT&#39;</span><span class="p">,</span> <span class="s1">&#39;RecoDataeta&#39;</span><span class="p">]</span><span class="o">+</span><span class="n">X</span><span class="p">,</span>
                               <span class="s1">&#39;xlabel&#39;</span><span class="p">:</span> <span class="sa">r</span><span class="s1">&#39;$\phi$&#39;</span> <span class="p">,</span>
                                <span class="s1">&#39;ylabel&#39;</span> <span class="p">:</span><span class="s1">&#39;$\phi^</span><span class="si">{reco}</span><span class="s1">$&#39;</span><span class="p">,</span>
                               <span class="s1">&#39;xmin&#39;</span>  <span class="p">:</span> <span class="o">-</span><span class="mf">3.2</span><span class="p">,</span> 
                               <span class="s1">&#39;xmax&#39;</span>  <span class="p">:</span><span class="mf">3.2</span><span class="p">}</span>
              <span class="p">}</span>
    

<span class="n">all_variable_cols</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;genDatapT&quot;</span><span class="p">,</span>
    <span class="s2">&quot;genDataeta&quot;</span><span class="p">,</span>
    <span class="s2">&quot;genDataphi&quot;</span><span class="p">,</span>
    <span class="s2">&quot;genDatam&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RecoDatapT&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RecoDataeta&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RecoDataphi&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RecoDatam&quot;</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">all_cols</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;genDatapT&quot;</span><span class="p">,</span>
    <span class="s2">&quot;genDataeta&quot;</span><span class="p">,</span>
    <span class="s2">&quot;genDataphi&quot;</span><span class="p">,</span>
    <span class="s2">&quot;genDatam&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RecoDatapT&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RecoDataeta&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RecoDataphi&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RecoDatam&quot;</span><span class="p">,</span>
    <span class="s2">&quot;tau&quot;</span><span class="p">,</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="load-and-explore-raw-unscaled-dataframes">
<h1>3. Load and explore raw (unscaled) dataframes<a class="headerlink" href="#load-and-explore-raw-unscaled-dataframes" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span>  <span class="n">Memory</span>
<span class="n">DATA_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;DATA_DIR&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;using DATA_DIR=</span><span class="si">{</span><span class="n">DATA_DIR</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">memory</span> <span class="o">=</span> <span class="n">Memory</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;USING NEW DATASET</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1">######################################</span>
<span class="n">USE_BRADEN_SCALING</span><span class="o">=</span><span class="kc">False</span>
<span class="c1">#####################################</span>
<span class="c1">################################### CONFIGURATIONS ###################################</span>
<span class="nd">@memory</span><span class="o">.</span><span class="n">cache</span>
<span class="k">def</span> <span class="nf">load_raw_data</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;SUBSAMPLE = </span><span class="si">{</span><span class="n">SUBSAMPLE</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">raw_train_data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span><span class="s1">&#39;train_data_10M_2.csv&#39;</span><span class="p">),</span>
                        <span class="n">usecols</span><span class="o">=</span><span class="n">all_cols</span><span class="p">,</span>
                        <span class="n">nrows</span><span class="o">=</span><span class="n">SUBSAMPLE</span>
                        <span class="p">)</span>

    <span class="n">raw_test_data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span><span class="s1">&#39;test_data_10M_2.csv&#39;</span><span class="p">),</span>
                        <span class="n">usecols</span><span class="o">=</span><span class="n">all_cols</span><span class="p">,</span>
                        <span class="n">nrows</span><span class="o">=</span><span class="n">SUBSAMPLE</span>
                        <span class="p">)</span>

    <span class="n">raw_valid_data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span><span class="s1">&#39;validation_data_10M_2.csv&#39;</span><span class="p">),</span>
                        <span class="n">usecols</span><span class="o">=</span><span class="n">all_cols</span><span class="p">,</span>
                        <span class="n">nrows</span><span class="o">=</span><span class="n">SUBSAMPLE</span>
                        <span class="p">)</span>


    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> RAW TRAIN DATA SHAPE</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">raw_train_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> RAW TRAIN DATA</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">raw_train_data</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="c1">#unscaled</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> RAW TEST DATA\ SHAPEn&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">raw_test_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> RAW TEST DATA</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">raw_test_data</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="c1">#unscaled</span>

    <span class="k">return</span> <span class="n">raw_train_data</span><span class="p">,</span> <span class="n">raw_test_data</span><span class="p">,</span> <span class="n">raw_valid_data</span>

    
<span class="n">JUPYTER</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">use_subsample</span> <span class="o">=</span> <span class="kc">False</span>
<span class="c1"># use_subsample = True</span>
<span class="k">if</span> <span class="n">use_subsample</span><span class="p">:</span>
    <span class="n">SUBSAMPLE</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span>
        <span class="mf">1e5</span>
    <span class="p">)</span>  <span class="c1"># subsample use for development - in production use whole dataset</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">SUBSAMPLE</span> <span class="o">=</span> <span class="kc">None</span>




<span class="c1">########################################################################################</span>
<span class="n">raw_train_data</span><span class="p">,</span> <span class="n">raw_test_data</span><span class="p">,</span> <span class="n">raw_valid_data</span> <span class="o">=</span><span class="n">load_raw_data</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>using DATA_DIR=/home/ali/Desktop/Pulled_Github_Repositories/IQN_HEP/Davidson/data
USING NEW DATASET

________________________________________________________________________________
[Memory] Calling __main__--tmp-ipykernel-3950853832.load_raw_data...
load_raw_data()
SUBSAMPLE = None

 RAW TRAIN DATA SHAPE

(8000000, 9)

 RAW TRAIN DATA


 RAW TEST DATA\ SHAPEn
(1000000, 9)

 RAW TEST DATA

___________________________________________________load_raw_data - 13.3s, 0.2min
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">explore_data</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">scaled</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span> <span class="p">)</span>
    <span class="c1"># df = df[[&#39;genDatapT&#39;, &#39;genDataeta&#39;, &#39;genDataphi&#39;, &#39;genDatam&#39;,&#39;RecoDatapT&#39;, &#39;RecoDataeta&#39;, &#39;RecoDataphi&#39;, &#39;RecoDatam&#39;]]</span>
    <span class="n">levels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;RecoData&#39;</span><span class="p">,</span> <span class="s1">&#39;genData&#39;</span><span class="p">]</span>
    <span class="n">kinematics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;pT&#39;</span><span class="p">,</span><span class="s1">&#39;eta&#39;</span><span class="p">,</span><span class="s1">&#39;phi&#39;</span><span class="p">,</span><span class="s1">&#39;m&#39;</span><span class="p">]</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">level</span><span class="o">+</span><span class="n">k</span> <span class="k">for</span> <span class="n">level</span> <span class="ow">in</span> <span class="n">levels</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">kinematics</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="n">columns</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;tau&#39;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span>
    
    <span class="k">for</span> <span class="n">k_i</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kinematics</span><span class="p">):</span>
        <span class="n">Reco_var</span> <span class="o">=</span> <span class="n">levels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">k</span>
        <span class="n">gen_var</span> <span class="o">=</span> <span class="n">levels</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">k</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Reco_var: &#39;</span><span class="p">,</span> <span class="n">Reco_var</span><span class="p">,</span> <span class="s1">&#39;, </span><span class="se">\t</span><span class="s1"> gen_var: &#39;</span><span class="p">,</span> <span class="n">gen_var</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">k_i</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">Reco_var</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">Reco_var</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.35</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">k_i</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">gen_var</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">gen_var</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.35</span><span class="p">)</span>
        <span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span> <span class="o">=</span> <span class="n">FIELDS</span><span class="p">[</span><span class="n">Reco_var</span><span class="p">][</span><span class="s1">&#39;xmin&#39;</span><span class="p">],</span> <span class="n">FIELDS</span><span class="p">[</span><span class="n">Reco_var</span><span class="p">][</span><span class="s1">&#39;xmax&#39;</span><span class="p">]</span>
        <span class="n">xlabel</span><span class="o">=</span><span class="n">FIELDS</span><span class="p">[</span><span class="n">Reco_var</span><span class="p">][</span><span class="s1">&#39;xlabel&#39;</span><span class="p">]</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">k_i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span> <span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">)</span> <span class="p">)</span>
        <span class="c1"># set_axes(ax[k_i], xlabel=xlabel, ylabel=&#39;&#39;, xmin=xmin, xmax=xmax)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">k_i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">26</span><span class="p">)</span>
        
        
                  
        <span class="k">if</span> <span class="n">scaled</span><span class="p">:</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">k_i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">gen_var</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span><span class="n">df</span><span class="p">[</span><span class="n">gen_var</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="p">)</span>
        
        <span class="n">ax</span><span class="p">[</span><span class="n">k_i</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;tau&#39;</span><span class="p">],</span><span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\tau$&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">show_plot</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">explore_data</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">raw_train_data</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Unscaled Dataframe&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;RecoDatapT&#39;, &#39;RecoDataeta&#39;, &#39;RecoDataphi&#39;, &#39;RecoDatam&#39;, &#39;genDatapT&#39;, &#39;genDataeta&#39;, &#39;genDataphi&#39;, &#39;genDatam&#39;]
[&#39;RecoDatapT&#39;, &#39;RecoDataeta&#39;, &#39;RecoDataphi&#39;, &#39;RecoDatam&#39;, &#39;genDatapT&#39;, &#39;genDataeta&#39;, &#39;genDataphi&#39;, &#39;genDatam&#39;, &#39;tau&#39;]
Reco_var:  RecoDatapT , 	 gen_var:  genDatapT
Reco_var:  RecoDataeta , 	 gen_var:  genDataeta
Reco_var:  RecoDataphi , 	 gen_var:  genDataphi
Reco_var:  RecoDatam , 	 gen_var:  genDatam
</pre></div>
</div>
<img alt="_images/1_Setup_and_Preprocess_30_1.svg" src="_images/1_Setup_and_Preprocess_30_1.svg" /></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">raw_train_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">raw_train_data</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="c1">#unscaled</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(8000000, 9)
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>genDatapT</th>
      <th>genDataeta</th>
      <th>genDataphi</th>
      <th>genDatam</th>
      <th>RecoDatapT</th>
      <th>RecoDataeta</th>
      <th>RecoDataphi</th>
      <th>RecoDatam</th>
      <th>tau</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>8.000000e+06</td>
      <td>8.000000e+06</td>
      <td>8.000000e+06</td>
      <td>8.000000e+06</td>
      <td>8.000000e+06</td>
      <td>8.000000e+06</td>
      <td>8.000000e+06</td>
      <td>8.000000e+06</td>
      <td>8.000000e+06</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>3.269523e+01</td>
      <td>-1.781882e-03</td>
      <td>-3.830903e-04</td>
      <td>6.962994e+00</td>
      <td>3.286720e+01</td>
      <td>-1.789886e-03</td>
      <td>-4.719170e-04</td>
      <td>5.555567e+00</td>
      <td>4.999153e-01</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.493793e+01</td>
      <td>2.204310e+00</td>
      <td>1.813825e+00</td>
      <td>2.781332e+00</td>
      <td>1.582936e+01</td>
      <td>2.197969e+00</td>
      <td>1.814474e+00</td>
      <td>2.664340e+00</td>
      <td>2.886730e-01</td>
    </tr>
    <tr>
      <th>min</th>
      <td>2.000000e+01</td>
      <td>-5.227320e+00</td>
      <td>-3.141590e+00</td>
      <td>-7.042220e-04</td>
      <td>1.144390e+01</td>
      <td>-5.006930e+00</td>
      <td>-3.480195e+00</td>
      <td>-8.631670e-05</td>
      <td>5.075658e-08</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>2.376670e+01</td>
      <td>-1.654600e+00</td>
      <td>-1.571320e+00</td>
      <td>5.116180e+00</td>
      <td>2.348440e+01</td>
      <td>-1.651130e+00</td>
      <td>-1.571500e+00</td>
      <td>3.805560e+00</td>
      <td>2.498142e-01</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>2.840240e+01</td>
      <td>-2.726765e-03</td>
      <td>6.159285e-05</td>
      <td>6.537620e+00</td>
      <td>2.898930e+01</td>
      <td>-3.001240e-03</td>
      <td>-4.192835e-05</td>
      <td>5.120820e+00</td>
      <td>4.999874e-01</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>3.627690e+01</td>
      <td>1.651250e+00</td>
      <td>1.570300e+00</td>
      <td>8.282190e+00</td>
      <td>3.749822e+01</td>
      <td>1.647990e+00</td>
      <td>1.570142e+00</td>
      <td>6.774150e+00</td>
      <td>7.500011e-01</td>
    </tr>
    <tr>
      <th>max</th>
      <td>8.397820e+02</td>
      <td>5.188200e+00</td>
      <td>3.141590e+00</td>
      <td>1.112440e+02</td>
      <td>8.148800e+02</td>
      <td>5.005230e+00</td>
      <td>3.482885e+00</td>
      <td>1.139730e+02</td>
      <td>9.999999e-01</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">raw_test_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">raw_test_data</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="c1">#unscaled</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1000000, 9)
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>genDatapT</th>
      <th>genDataeta</th>
      <th>genDataphi</th>
      <th>genDatam</th>
      <th>RecoDatapT</th>
      <th>RecoDataeta</th>
      <th>RecoDataphi</th>
      <th>RecoDatam</th>
      <th>tau</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
      <td>1.000000e+06</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>32.665481</td>
      <td>0.002822</td>
      <td>-0.000512</td>
      <td>6.957271</td>
      <td>32.849094</td>
      <td>0.002815</td>
      <td>-0.000550</td>
      <td>5.554067</td>
      <td>4.997935e-01</td>
    </tr>
    <tr>
      <th>std</th>
      <td>14.746671</td>
      <td>2.202514</td>
      <td>1.814159</td>
      <td>2.765754</td>
      <td>15.617181</td>
      <td>2.196167</td>
      <td>1.814699</td>
      <td>2.644894</td>
      <td>2.888304e-01</td>
    </tr>
    <tr>
      <th>min</th>
      <td>20.000000</td>
      <td>-5.159990</td>
      <td>-3.141590</td>
      <td>-0.000566</td>
      <td>11.475300</td>
      <td>-4.999270</td>
      <td>-3.477685</td>
      <td>-0.000061</td>
      <td>2.595965e-07</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>23.759175</td>
      <td>-1.648685</td>
      <td>-1.571470</td>
      <td>5.111978</td>
      <td>23.489400</td>
      <td>-1.644865</td>
      <td>-1.571400</td>
      <td>3.806208</td>
      <td>2.496069e-01</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>28.395500</td>
      <td>0.000701</td>
      <td>-0.001251</td>
      <td>6.532905</td>
      <td>28.992800</td>
      <td>0.001701</td>
      <td>-0.000872</td>
      <td>5.119875</td>
      <td>4.996784e-01</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>36.294825</td>
      <td>1.654850</td>
      <td>1.571060</td>
      <td>8.277790</td>
      <td>37.563675</td>
      <td>1.651652</td>
      <td>1.570125</td>
      <td>6.775580</td>
      <td>7.503565e-01</td>
    </tr>
    <tr>
      <th>max</th>
      <td>553.745000</td>
      <td>5.143080</td>
      <td>3.141590</td>
      <td>77.079700</td>
      <td>516.104000</td>
      <td>5.005660</td>
      <td>3.478095</td>
      <td>75.951300</td>
      <td>9.999998e-01</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># np.array(train_data[&#39;genDatapT&#39;])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="scaling">
<h1>Scaling<a class="headerlink" href="#scaling" title="Permalink to this headline">#</a></h1>
<p>scaling (or standarization, normalization) is someimes done in the following way:
$<span class="math notranslate nohighlight">\( X' = \frac{X-X_{min}}{X_{max}-X_{min}} \qquad \rightarrow \qquad X= X' (X_{max}-X_{min}) + X_{min}\)</span>$</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># def standarize(values):</span>
<span class="c1">#     expected_min, expected_max = values.min(), values.max()</span>
<span class="c1">#     scale_factor = expected_max - expected_min</span>
<span class="c1">#     offset = expected_min</span>
<span class="c1">#     standarized_values = (values - offset)/scale_factor </span>
<span class="c1">#     return standarized_values</span>
</pre></div>
</div>
</div>
</div>
<p>Or by taking z-score:</p>
<div class="math notranslate nohighlight">
\[ X'=z(X)=\frac{X-E[X]}{\sigma_{X}}  \qquad \rightarrow \qquad X = z^{-1}(X')= X' \sigma_{X} + E[X].\]</div>
<hr class="docutils" />
<section id="basically-a-standard-scaling-procedure-is-the-following-background">
<h2>Basically a “standard scaling procedure” is the following (background):<a class="headerlink" href="#basically-a-standard-scaling-procedure-is-the-following-background" title="Permalink to this headline">#</a></h2>
<ol class="simple">
<li><p>Split the data into train and test dataframes</p></li>
<li><p>Fit on the train set, and transform everything according to the train set, that is, get the mean and std, ( optionally and min and max or other quantities) of each feature (column) of each of the train set, and standarize everything according to that.</p></li>
<li><p>transform each of the train and test sets independently. That is, use the means and stds of each column to transform a column <span class="math notranslate nohighlight">\(X\)</span> into a column <span class="math notranslate nohighlight">\(X'\)</span> e.g. according to
$<span class="math notranslate nohighlight">\( X'=z(X)= \frac{X-E[X]}{\sigma_{X}}\)</span>$</p></li>
<li><p>Train NN on transformed features <span class="math notranslate nohighlight">\(X_{train}'\)</span> (and target <span class="math notranslate nohighlight">\(y_{train}'\)</span>) (in train df, but validate on test set, which will not influence the weights of NN ( just used for observation that it doesnt overfit) )</p></li>
<li><p>Once the training is done, <em>evaluate the NN on transformed features of the test set</em> <span class="math notranslate nohighlight">\(X_{test}'\)</span>, i.e. do <span class="math notranslate nohighlight">\(NN(X_{test}')\)</span>, which will result in a scaled prediction of the target <span class="math notranslate nohighlight">\(y_{pred}'\)</span></p></li>
<li><p>Unscale the <span class="math notranslate nohighlight">\(y_{pred}'\)</span>, i.e. apply the inverse of the scaling operation, e.g.
$<span class="math notranslate nohighlight">\( y_{pred}=z^{-1}(y_{pred}')= y_{pred}' \sigma_{y} + E[y]\)</span>$,
where</p></li>
</ol>
<div class="math notranslate nohighlight">
\[\sigma_y\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[E[y]\]</div>
<p>are attained from the test set <em>prior to training and scaling</em>.</p>
<ol class="simple">
<li><p>Compare to <span class="math notranslate nohighlight">\(y\)</span> (the actual distribution you’re trying to estimate) one-to-one</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">use_svg_display</span><span class="p">()</span>
<span class="n">show_jupyter_image</span><span class="p">(</span><span class="s1">&#39;images/scaling_forNN.jpg&#39;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span><span class="n">height</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1_Setup_and_Preprocess_38_0.jpg" src="_images/1_Setup_and_Preprocess_38_0.jpg" />
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="braden-scaling">
<h1>Braden scaling<a class="headerlink" href="#braden-scaling" title="Permalink to this headline">#</a></h1>
<p>In the IQN-scipost overleaf, we say the scaling is the following:</p>
<div class="math notranslate nohighlight">
\[\mathbb{T}(p_T) = z(\log p_T), \qquad \mathbb{T}(\eta) = z(\eta), \qquad \mathbb{T}(\phi) = z(\phi), \qquad \mathbb{T}(m) = z(\log (m + 2))\]</div>
<div class="math notranslate nohighlight">
\[ \mathbb{T}(\tau) = 6\tau - 3 \]</div>
<p>Which means, for a jet observable <span class="math notranslate nohighlight">\(\mathcal{O}\)</span> (or quantile <span class="math notranslate nohighlight">\(\tau\)</span>), the Braden-scaling perscribes that the data is first scaled according to:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
    \mathbb{L} (\mathcal{O} \mid \mathcal{O} \in X ) &amp;=
    \begin{cases}
        z \left( \log{\mathcal{O}} \right), \qquad &amp; \text{if } \mathcal{O}= p_T \\
        z \left(\mathcal{O} \right), \qquad &amp; \text{if } \mathcal{O}=\eta \\
        z \left( \log (\mathcal{O} + 2) \right), \qquad &amp; \text{if } \mathcal{O}=m \\
        z \left( \mathcal{O} \right), \qquad &amp; \text{if } \mathcal{O}=\phi \\
        z \left( 6 \mathcal{O} -3 \right), \qquad &amp; \text{if } \mathcal{O}=\tau
    \end{cases}
\end{align}
\end{split}\]</div>
<p>Note that the equation above describes the scaling for the training features <span class="math notranslate nohighlight">\(X\)</span>. The point of taking the log is</p>
<p>The targets, as we say in the paper, are chosen to be the following:</p>
<div class="math notranslate nohighlight">
\[
z\left(\frac{y_n + 10}{x_n + 10}\right), \qquad n = 1,\cdots,4,
\label{eq:normalization}
\]</div>
<p>We mean that the predicted target for a desired reco observable <span class="math notranslate nohighlight">\(\mathcal{O}\)</span> is chosen to be the following function</p>
<div class="math notranslate nohighlight">
\[
    \mathbb{T}(\mathcal{O} \mid \mathcal{O} \in y) = z \left( \frac{\mathbb{L} (\mathcal{O}^{\text{reco}}) +10 }{\mathbb{L}(\mathcal{O}^{\text{gen}}) +10} \right),
\]</div>
<p>where for a random variable <span class="math notranslate nohighlight">\(x\)</span>, <span class="math notranslate nohighlight">\(z\)</span> is the standardization function (z-score):</p>
<div class="math notranslate nohighlight">
\[
   x'= z (x) \equiv \frac{x-\bar{x}}{\sigma_{x}} \ .
\]</div>
<p>Such that its inverse is</p>
<div class="math notranslate nohighlight">
\[ z^{-1}(x') = x' \ \sigma_x + \bar{x} \]</div>
<p>If we do this on the data, after training, the NN <span class="math notranslate nohighlight">\(f_{\text{IQN}}\)</span> will not estimate the observable,</p>
<div class="math notranslate nohighlight">
\[\mathcal{O}^{\text{predicted}} \ne \mathcal{O}^{\text{reco}}\]</div>
<p>but will instead estimate</p>
<div class="math notranslate nohighlight">
\[
        f_{\text{IQN}} (\mathcal{O}) \approx  z \left( \frac{\mathbb{L} (\mathcal{O}^{\text{reco}}) +10 }{\mathbb{L}(\mathcal{O}^{\text{gen}}) +10} \right),
\]</div>
<p>which needs to be de-scaled (when evaluated on the data that which has been scaled according to</p>
<div class="math notranslate nohighlight">
\[\mathbb{T}(\text{evaluation data}) = z \left( \frac{\mathbb{L} (\text{data}^{\text{reco}}) +10 }{\mathbb{L}(\text{data}^{\text{gen}}) +10} \right) \]</div>
<p>in order to copare with <span class="math notranslate nohighlight">\(\mathcal{O}\)</span> directly.) The descaling for <span class="math notranslate nohighlight">\(\mathcal{O}=p_T\)</span> (as an example) would be:</p>
<div class="math notranslate nohighlight">
\[
    p_T^{\text{predicted}} = \mathbb{L}^{-1} \left[ z^{-1} (f_{\text{IQN}} ) \left[ \mathbb{L} (p_T^\text{gen})+10 \right] -10 \right]
\]</div>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="optional-scale-the-data-accoding-to-the-braden-kronheim-scaling">
<h1>4. (Optional) Scale the data accoding to the “Braden Kronheim scaling” :<a class="headerlink" href="#optional-scale-the-data-accoding-to-the-braden-kronheim-scaling" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">TRAIN_SCALE_DICT</span> <span class="o">=</span> <span class="n">get_scaling_info</span><span class="p">(</span><span class="n">raw_train_data</span><span class="p">);</span><span class="nb">print</span><span class="p">(</span><span class="n">TRAIN_SCALE_DICT</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">TEST_SCALE_DICT</span> <span class="o">=</span> <span class="n">get_scaling_info</span><span class="p">(</span><span class="n">raw_test_data</span><span class="p">);</span><span class="nb">print</span><span class="p">(</span><span class="n">TEST_SCALE_DICT</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;genDatapT&#39;: {&#39;mean&#39;: 32.695234084987476, &#39;std&#39;: 14.937932540562551}, &#39;genDataeta&#39;: {&#39;mean&#39;: -0.0017818817154031672, &#39;std&#39;: 2.204309760627079}, &#39;genDataphi&#39;: {&#39;mean&#39;: -0.0003830903308450233, &#39;std&#39;: 1.8138251604791067}, &#39;genDatam&#39;: {&#39;mean&#39;: 6.962994352358474, &#39;std&#39;: 2.781332025286383}, &#39;RecoDatapT&#39;: {&#39;mean&#39;: 32.86720151648752, &#39;std&#39;: 15.829355769531851}, &#39;RecoDataeta&#39;: {&#39;mean&#39;: -0.0017898858568513964, &#39;std&#39;: 2.197968491495457}, &#39;RecoDataphi&#39;: {&#39;mean&#39;: -0.0004719170328962474, &#39;std&#39;: 1.8144739820043825}, &#39;RecoDatam&#39;: {&#39;mean&#39;: 5.555567451922438, &#39;std&#39;: 2.664339857066051}}



{&#39;genDatapT&#39;: {&#39;mean&#39;: 32.6654809616, &#39;std&#39;: 14.746663776411731}, &#39;genDataeta&#39;: {&#39;mean&#39;: 0.002821766734118711, &#39;std&#39;: 2.2025132218012735}, &#39;genDataphi&#39;: {&#39;mean&#39;: -0.0005116820324618385, &#39;std&#39;: 1.8141583811877282}, &#39;genDatam&#39;: {&#39;mean&#39;: 6.957271011526192, &#39;std&#39;: 2.765752894623606}, &#39;RecoDatapT&#39;: {&#39;mean&#39;: 32.8490938466, &#39;std&#39;: 15.617172793936655}, &#39;RecoDataeta&#39;: {&#39;mean&#39;: 0.0028149588128446, &#39;std&#39;: 2.196165457846061}, &#39;RecoDataphi&#39;: {&#39;mean&#39;: -0.0005495613684869987, &#39;std&#39;: 1.8146982567744574}, &#39;RecoDatam&#39;: {&#39;mean&#39;: 5.554066938043617, &#39;std&#39;: 2.644892802850232}}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">L</span><span class="p">(</span><span class="n">orig_observable</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
    <span class="n">eps</span><span class="o">=</span><span class="mf">1e-20</span>
    <span class="n">orig_observable</span><span class="o">=</span><span class="n">orig_observable</span><span class="o">+</span><span class="n">eps</span>
    <span class="k">if</span> <span class="n">label</span><span class="o">==</span><span class="s1">&#39;pT&#39;</span><span class="p">:</span>
        <span class="n">const</span><span class="o">=</span><span class="mi">0</span>
        <span class="n">log_pT_</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">orig_observable</span><span class="p">)</span> 
        <span class="n">L_observable</span> <span class="o">=</span> <span class="n">log_pT_</span>
    <span class="k">if</span> <span class="n">label</span><span class="o">==</span><span class="s1">&#39;eta&#39;</span><span class="p">:</span>
        <span class="n">const</span><span class="o">=</span><span class="mi">0</span>
        <span class="n">L_observable</span><span class="o">=</span><span class="n">orig_observable</span>
    <span class="k">if</span> <span class="n">label</span><span class="o">==</span><span class="s1">&#39;m&#39;</span><span class="p">:</span>
        <span class="n">const</span><span class="o">=</span><span class="mi">2</span>
        <span class="n">L_observable</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">orig_observable</span> <span class="o">+</span> <span class="n">const</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">label</span><span class="o">==</span><span class="s1">&#39;phi&#39;</span><span class="p">:</span>
        <span class="n">L_observable</span><span class="o">=</span><span class="n">orig_observable</span>
    <span class="k">if</span> <span class="n">label</span><span class="o">==</span><span class="s1">&#39;tau&#39;</span><span class="p">:</span>
        <span class="n">L_observable</span><span class="o">=</span><span class="n">orig_observable</span>
<span class="c1">#         L_observable = (6*orig_observable) - 3</span>
    
    <span class="k">return</span> <span class="n">L_observable</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">L_inverse</span><span class="p">(</span><span class="n">L_observable</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
    <span class="n">eps</span><span class="o">=</span><span class="mf">1e-20</span>
    <span class="n">L_observable</span><span class="o">=</span><span class="n">L_observable</span><span class="o">+</span><span class="n">eps</span>
    <span class="k">if</span> <span class="n">label</span><span class="o">==</span><span class="s1">&#39;pT&#39;</span><span class="p">:</span>
        <span class="n">const</span><span class="o">=</span><span class="mi">0</span>
        <span class="n">L_inverse_observable</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">L_observable</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">label</span><span class="o">==</span><span class="s1">&#39;eta&#39;</span><span class="p">:</span>
        <span class="n">L_inverse_observable</span> <span class="o">=</span> <span class="n">L_observable</span>
    <span class="k">if</span> <span class="n">label</span><span class="o">==</span><span class="s1">&#39;m&#39;</span><span class="p">:</span>
        <span class="n">const</span><span class="o">=</span><span class="mi">2</span>
        <span class="n">L_inverse_observable</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">L_observable</span><span class="p">)</span> <span class="o">-</span> <span class="n">const</span>
    <span class="k">if</span> <span class="n">label</span><span class="o">==</span><span class="s1">&#39;tau&#39;</span><span class="p">:</span>
        <span class="n">L_inverse_observable</span><span class="o">=</span><span class="n">L_observable</span>
        <span class="c1"># L_inverse_observable = (L_observable+3)/6</span>
        
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">L_inverse_observable</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">L_inverse_observable</span> <span class="o">=</span> <span class="n">L_inverse_observable</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">L_inverse_observable</span>
</pre></div>
</div>
</div>
</div>
<div class="math notranslate nohighlight">
\[
    \mathbb{T}(\mathcal{O}) = z \left( \frac{\mathbb{L} (\mathcal{O}^{\text{reco}}) +10 }{\mathbb{L}(\mathcal{O}^{\text{gen}}) +10} \right),
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">T</span><span class="p">(</span><span class="n">variable</span><span class="p">,</span> <span class="n">scaled_df</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">variable</span><span class="o">==</span><span class="s1">&#39;pT&#39;</span><span class="p">:</span>
        <span class="n">L_pT_gen</span><span class="o">=</span><span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;genDatapT&#39;</span><span class="p">]</span>
        <span class="n">L_pT_reco</span> <span class="o">=</span> <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;RecoDatapT&#39;</span><span class="p">]</span>
        <span class="n">target</span> <span class="o">=</span> <span class="p">(</span><span class="n">L_pT_reco</span><span class="o">+</span><span class="mi">10</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">L_pT_gen</span><span class="o">+</span><span class="mi">10</span><span class="p">)</span> 
    <span class="k">if</span> <span class="n">variable</span><span class="o">==</span><span class="s1">&#39;eta&#39;</span><span class="p">:</span>
        <span class="n">L_eta_gen</span><span class="o">=</span><span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;genDataeta&#39;</span><span class="p">]</span>
        <span class="n">L_eta_reco</span> <span class="o">=</span> <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;RecoDataeta&#39;</span><span class="p">]</span>
        <span class="n">target</span> <span class="o">=</span>  <span class="p">(</span><span class="n">L_eta_reco</span><span class="o">+</span><span class="mi">10</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">L_eta_gen</span><span class="o">+</span><span class="mi">10</span><span class="p">)</span> 
    <span class="k">if</span> <span class="n">variable</span><span class="o">==</span><span class="s1">&#39;phi&#39;</span><span class="p">:</span>
        <span class="n">L_phi_gen</span><span class="o">=</span><span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;genDataphi&#39;</span><span class="p">]</span>
        <span class="n">L_phi_reco</span> <span class="o">=</span> <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;RecoDataphi&#39;</span><span class="p">]</span>
        <span class="n">target</span> <span class="o">=</span>  <span class="p">(</span><span class="n">L_phi_reco</span><span class="o">+</span><span class="mi">10</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">L_phi_gen</span><span class="o">+</span><span class="mi">10</span><span class="p">)</span> 
    <span class="k">if</span> <span class="n">variable</span><span class="o">==</span><span class="s1">&#39;m&#39;</span><span class="p">:</span>
        <span class="n">L_m_gen</span><span class="o">=</span><span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;genDatam&#39;</span><span class="p">]</span>
        <span class="n">L_m_reco</span> <span class="o">=</span> <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;RecoDatam&#39;</span><span class="p">]</span>
        <span class="n">target</span> <span class="o">=</span>  <span class="p">(</span><span class="n">L_m_reco</span><span class="o">+</span><span class="mi">10</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">L_m_gen</span><span class="o">+</span><span class="mi">10</span><span class="p">)</span> 
    
    <span class="k">return</span> <span class="n">target</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">L_scale_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">save</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="c1">#scale</span>
    <span class="c1"># SUBSAMPLE=int(1e6)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">all_cols</span><span class="p">]</span><span class="c1">#[:SUBSAMPLE]</span>
    <span class="c1"># print(df.head())</span>
    <span class="n">scaled_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="c1">#select the columns by index: </span>
    <span class="c1"># 0:genDatapT, 1:genDataeta, 2:genDataphi, 3:genDatam, </span>
    <span class="c1"># 4:RecoDatapT, 5:RecoDataeta, 6:RecoDataphi, 7: Recodatam</span>
    <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;genDatapT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;pT&#39;</span><span class="p">)</span>
    <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;RecoDatapT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">4</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;pT&#39;</span><span class="p">)</span>
    
    <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;genDataeta&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;eta&#39;</span><span class="p">)</span>
    <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;RecoDataeta&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">5</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;eta&#39;</span><span class="p">)</span>
    
    
    <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;genDataphi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;phi&#39;</span><span class="p">)</span>
    <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;RecoDataphi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">6</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;phi&#39;</span><span class="p">)</span>

    <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;genDatam&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">3</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;m&#39;</span><span class="p">)</span>
    <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;RecoDatam&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">7</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;m&#39;</span><span class="p">)</span>
    <span class="c1">#why scale tau?</span>
    <span class="c1"># scaled_df[&#39;tau&#39;] = 6 * df.iloc[:,8] - 3</span>
    <span class="n">scaled_df</span><span class="p">[</span><span class="s1">&#39;tau&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">8</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;tau&#39;</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="n">scaled_df</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
    
    <span class="k">if</span> <span class="n">save</span><span class="p">:</span>
        <span class="n">scaled_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="n">title</span><span class="p">)</span> <span class="p">)</span>
    <span class="k">return</span> <span class="n">scaled_df</span>
</pre></div>
</div>
</div>
</div>
<section id="if-you-want-to-generate-the-scaled-data-frames-run-the-cell-below">
<h2>If you want to generate the Scaled data frames, run the cell below<a class="headerlink" href="#if-you-want-to-generate-the-scaled-data-frames-run-the-cell-below" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaled_train_data</span> <span class="o">=</span> <span class="n">L_scale_df</span><span class="p">(</span><span class="n">raw_train_data</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;scaled_train_data_10M_2.csv&#39;</span><span class="p">,</span>
                             <span class="n">save</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">scaled_test_data</span> <span class="o">=</span> <span class="n">L_scale_df</span><span class="p">(</span><span class="n">raw_test_data</span><span class="p">,</span>  <span class="n">title</span><span class="o">=</span><span class="s1">&#39;scaled_test_data_10M_2.csv&#39;</span><span class="p">,</span>
                            <span class="n">save</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">scaled_valid_data</span> <span class="o">=</span> <span class="n">L_scale_df</span><span class="p">(</span><span class="n">raw_valid_data</span><span class="p">,</span>  <span class="n">title</span><span class="o">=</span><span class="s1">&#39;scaled_valid_data_10M_2.csv&#39;</span><span class="p">,</span>
                            <span class="n">save</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">explore_data</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">scaled_train_data</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Braden Kronheim-L-scaled Dataframe&#39;</span><span class="p">,</span> <span class="n">scaled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>          genDatapT    RecoDatapT    genDataeta   RecoDataeta    genDataphi  \
count  8.000000e+06  8.000000e+06  8.000000e+06  8.000000e+06  8.000000e+06   
mean   3.421245e+00  3.412002e+00 -1.781882e-03 -1.789886e-03 -3.830903e-04   
std    3.348063e-01  3.804798e-01  2.204310e+00  2.197969e+00  1.813825e+00   
min    2.995732e+00  2.437457e+00 -5.227320e+00 -5.006930e+00 -3.141590e+00   
25%    3.168285e+00  3.156336e+00 -1.654600e+00 -1.651130e+00 -1.571320e+00   
50%    3.346474e+00  3.366927e+00 -2.726765e-03 -3.001240e-03  6.159285e-05   
75%    3.591181e+00  3.624294e+00  1.651250e+00  1.647990e+00  1.570300e+00   
max    6.733142e+00  6.703041e+00  5.188200e+00  5.005230e+00  3.141590e+00   

        RecoDataphi      genDatam     RecoDatam           tau  
count  8.000000e+06  8.000000e+06  8.000000e+06  8.000000e+06  
mean  -4.719170e-04  2.150564e+00  1.967802e+00  4.999153e-01  
std    1.814474e+00  2.880059e-01  3.271235e-01  2.886730e-01  
min   -3.480195e+00  6.927950e-01  6.931040e-01  5.075658e-08  
25%   -1.571500e+00  1.962371e+00  1.758816e+00  2.498142e-01  
50%   -4.192835e-05  2.144482e+00  1.963023e+00  4.999874e-01  
75%    1.570142e+00  2.330413e+00  2.171810e+00  7.500011e-01  
max    3.482885e+00  4.729545e+00  4.753357e+00  9.999999e-01  



            genDatapT      RecoDatapT      genDataeta     RecoDataeta  \
count  1000000.000000  1000000.000000  1000000.000000  1000000.000000   
mean         3.420882        3.412147        0.002822        0.002815   
std          0.334051        0.379574        2.202514        2.196167   
min          2.995732        2.440197       -5.159990       -4.999270   
25%          3.167969        3.156549       -1.648685       -1.644865   
50%          3.346231        3.367048        0.000701        0.001701   
75%          3.591675        3.626037        1.654850        1.651652   
max          6.316704        6.246308        5.143080        5.005660   

           genDataphi     RecoDataphi        genDatam       RecoDatam  \
count  1000000.000000  1000000.000000  1000000.000000  1000000.000000   
mean        -0.000512       -0.000550        2.150071        1.967908   
std          1.814159        1.814699        0.287706        0.326501   
min         -3.141590       -3.477685        0.692864        0.693117   
25%         -1.571470       -1.571400        1.961780        1.758928   
50%         -0.001251       -0.000872        2.143930        1.962890   
75%          1.571060        1.570125        2.329985        2.171973   
max          3.141590        3.478095        4.370456        4.356084   

                tau  
count  1.000000e+06  
mean   4.997935e-01  
std    2.888304e-01  
min    2.595965e-07  
25%    2.496069e-01  
50%    4.996784e-01  
75%    7.503565e-01  
max    9.999998e-01  



            genDatapT      RecoDatapT      genDataeta     RecoDataeta  \
count  1000000.000000  1000000.000000  1000000.000000  1000000.000000   
mean         3.421223        3.411684        0.000698        0.000735   
std          0.336185        0.381671        2.204255        2.197915   
min          2.995732        2.438330       -5.184830       -5.000600   
25%          3.167410        3.155224       -1.652290       -1.647702   
50%          3.345898        3.366547        0.001781        0.000949   
75%          3.591019        3.623741        1.652180        1.648922   
max          6.518423        6.374464        5.139480        4.999840   

           genDataphi     RecoDataphi        genDatam       RecoDatam  \
count  1000000.000000  1000000.000000  1000000.000000  1000000.000000   
mean        -0.000896       -0.000819        2.150291        1.967158   
std          1.813629        1.814279        0.288274        0.327415   
min         -3.141580       -3.480465        0.693135        0.693121   
25%         -1.569685       -1.570240        1.962370        1.758022   
50%         -0.000836       -0.001184        2.144196        1.961933   
75%          1.568172        1.568535        2.329907        2.171459   
max          3.141590        3.483175        4.110044        4.258457   

                tau  
count  1.000000e+06  
mean   5.004851e-01  
std    2.885275e-01  
min    5.130061e-07  
25%    2.507914e-01  
50%    5.007886e-01  
75%    7.504558e-01  
max    9.999994e-01  
[&#39;RecoDatapT&#39;, &#39;RecoDataeta&#39;, &#39;RecoDataphi&#39;, &#39;RecoDatam&#39;, &#39;genDatapT&#39;, &#39;genDataeta&#39;, &#39;genDataphi&#39;, &#39;genDatam&#39;]
[&#39;RecoDatapT&#39;, &#39;RecoDataeta&#39;, &#39;RecoDataphi&#39;, &#39;RecoDatam&#39;, &#39;genDatapT&#39;, &#39;genDataeta&#39;, &#39;genDataphi&#39;, &#39;genDatam&#39;, &#39;tau&#39;]
Reco_var:  RecoDatapT , 	 gen_var:  genDatapT
Reco_var:  RecoDataeta , 	 gen_var:  genDataeta
Reco_var:  RecoDataphi , 	 gen_var:  genDataphi
Reco_var:  RecoDatam , 	 gen_var:  genDatam
</pre></div>
</div>
<img alt="_images/1_Setup_and_Preprocess_48_1.svg" src="_images/1_Setup_and_Preprocess_48_1.svg" /><img alt="_images/1_Setup_and_Preprocess_48_2.svg" src="_images/1_Setup_and_Preprocess_48_2.svg" /></div>
</div>
</section>
<section id="if-you-want-to-load-the-previously-generated-scaled-dataframe-run-the-cell-below">
<h2>If you want to load the previously generated scaled dataframe, run the cell below<a class="headerlink" href="#if-you-want-to-load-the-previously-generated-scaled-dataframe-run-the-cell-below" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;RecoDatam&#39;</span>
<span class="n">source</span>  <span class="o">=</span> <span class="n">FIELDS</span><span class="p">[</span><span class="n">target</span><span class="p">]</span>
<span class="n">features</span><span class="o">=</span> <span class="n">source</span><span class="p">[</span><span class="s1">&#39;inputs&#39;</span><span class="p">]</span>
<span class="c1">########</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;USING NEW DATASET</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="c1">#UNSCALED</span>
<span class="c1"># train_data_m=pd.read_csv(os.path.join(DATA_DIR,&#39;train_data_10M_2.csv&#39;),</span>
<span class="c1">#                        usecols=features,</span>
<span class="c1">#                        nrows=SUBSAMPLE)</span>

<span class="c1"># print(&#39;TRAINING FEATURES\n&#39;, train_data.head())</span>

<span class="c1"># test_data_m= pd.read_csv(os.path.join(DATA_DIR,&#39;test_data_10M_2.csv&#39;),</span>
<span class="c1">#                        usecols=features,</span>
<span class="c1">#                        nrows=SUBSAMPLE)</span>
<span class="c1"># print(&#39;\nTESTING FEATURES\n&#39;, test_data.head())</span>
<span class="c1"># valid_data= pd.read_csv(os.path.join(DATA_DIR,&#39;valid_data_10M_2.csv&#39;),</span>
<span class="c1">#                        usecols=features,</span>
<span class="c1">#                        nrows=SUBSAMPLE)</span>


<span class="c1"># SCALED</span>
<span class="n">train_data_m</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span><span class="s1">&#39;scaled_train_data_10M_2.csv&#39;</span><span class="p">),</span>
                       <span class="n">usecols</span><span class="o">=</span><span class="n">all_cols</span><span class="p">,</span>
                       <span class="n">nrows</span><span class="o">=</span><span class="n">SUBSAMPLE</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TRAINING FEATURES</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">train_data_m</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

<span class="n">test_data_m</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span><span class="s1">&#39;scaled_test_data_10M_2.csv&#39;</span><span class="p">),</span>
                       <span class="n">usecols</span><span class="o">=</span><span class="n">all_cols</span><span class="p">,</span>
                       <span class="n">nrows</span><span class="o">=</span><span class="n">SUBSAMPLE</span><span class="p">)</span>

<span class="n">valid_data_m</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span><span class="s1">&#39;scaled_valid_data_10M_2.csv&#39;</span><span class="p">),</span>
                       <span class="n">usecols</span><span class="o">=</span><span class="n">all_cols</span><span class="p">,</span>
                       <span class="n">nrows</span><span class="o">=</span><span class="n">SUBSAMPLE</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">TESTING FEATURES</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">test_data_m</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">train set shape:&#39;</span><span class="p">,</span>  <span class="n">train_data_m</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">test set shape:  &#39;</span><span class="p">,</span> <span class="n">test_data_m</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># print(&#39;validation set shape:&#39;, valid_data.shape)</span>

<span class="n">scaled_train_data</span> <span class="o">=</span> <span class="n">train_data_m</span>
<span class="n">scaled_test_data</span> <span class="o">=</span> <span class="n">test_data_m</span>
<span class="n">scaled_valid_data</span> <span class="o">=</span> <span class="n">valid_data_m</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>USING NEW DATASET

TRAINING FEATURES
    genDatapT  RecoDatapT  genDataeta  RecoDataeta  genDataphi  RecoDataphi  \
0   3.382531    3.463020    0.828187     0.817082    2.902130     2.919510   
1   3.191270    3.308764   -1.163510    -1.151020    0.636469     0.652153   
2   3.191270    3.308764   -1.163510    -1.151020    0.636469     0.652153   
3   3.191270    3.308764   -1.163510    -1.151020    0.636469     0.652153   
4   3.004211    3.187005    1.844410     1.837910   -0.186685    -0.160621   

   genDatam  RecoDatam       tau  
0  1.579696   1.525158  0.361310  
1  2.058837   1.995432  0.126899  
2  2.058837   1.995432  0.962307  
3  2.058837   1.995432  0.457282  
4  2.040038   1.886115  0.840862  

TESTING FEATURES
    genDatapT  RecoDatapT  genDataeta  RecoDataeta  genDataphi  RecoDataphi  \
0   3.775316    3.791603    0.824891     0.824645    -1.26949     -1.26117   
1   3.775316    3.791603    0.824891     0.824645    -1.26949     -1.26117   
2   3.258685    3.313277    3.529970     3.590390     1.55495      1.52062   
3   3.349708    3.522816   -1.159650    -1.139940     1.82602      1.76254   
4   3.090315    3.149058    2.747660     2.775790     2.03085      2.10209   

   genDatam  RecoDatam       tau  
0  2.071044   2.054470  0.250046  
1  2.071044   2.054470  0.847493  
2  2.242060   1.918984  0.851995  
3  2.286615   2.204338  0.052378  
4  1.971738   1.805105  0.542549  

train set shape: (8000000, 9)

test set shape:   (1000000, 9)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;pT&#39;</span><span class="p">,</span> <span class="s1">&#39;eta&#39;</span><span class="p">,</span><span class="s1">&#39;phi&#39;</span><span class="p">,</span><span class="s1">&#39;m&#39;</span><span class="p">]</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">:</span>
    <span class="n">target_</span> <span class="o">=</span> <span class="n">T</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">scaled_df</span><span class="o">=</span><span class="n">scaled_train_data</span><span class="p">)</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">target_</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;$T($&#39;</span> <span class="o">+</span><span class="n">label</span><span class="o">+</span> <span class="s1">&#39;$)$&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span> <span class="p">)</span>
<span class="n">set_axes</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;pre-z ratio targets T&#39;</span><span class="p">,</span> <span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1_Setup_and_Preprocess_51_1.svg" src="_images/1_Setup_and_Preprocess_51_1.svg" /></div>
</div>
<p>Our risk functional is minimized for</p>
<div class="math notranslate nohighlight">
\[\frac{\delta R_{\text{IQN}x4} }{\delta f_m}=0\tag{5}\]</div>
<p>(which is basically what’s done in the training process to get <span class="math notranslate nohighlight">\(f_m^{*}\)</span> whose weights/parameters minimize the loss). Suppose we factorize the risk as</p>
<div class="math notranslate nohighlight">
\[ R_{\text{IQN}x4}  = R_{\text{IQN}}^m \ R_{\text{IQN}}^{p_T}  \ R_{\text{IQN}}^\eta \ R_{\text{IQN}}^\phi \tag{6},\]</div>
<p>then, by Eq (4),</p>
<div class="math notranslate nohighlight">
\[R_{\text{IQN}}^m \equiv \int L_\text{IQN} \left( f_m (\mathbf{x_m},\tau), \mathbf{y_m} \right) p(\mathbf{x_m, y_m,\tau})  d \mathbf{x_m} d \mathbf{y_m} d \mathbf{\tau},
\]</div>
<p>and by Eq (5)</p>
<div class="math notranslate nohighlight">
\[\int d \mathbf{x_m} d \mathbf{y_m} d \mathbf{\tau} \ p(\mathbf{x_m, y_m,\tau})   \ \frac{ \delta L_\text{IQN} \left( f_m (\mathbf{x_m},\tau), \mathbf{y_m} \right) }{\delta f_m} = 0\]</div>
<p>and by Eq (2)</p>
<div class="math notranslate nohighlight">
\[
\int d \mathbf{x_m} d \mathbf{y_m} d \mathbf{\tau} \ p(\mathbf{x_m, y_m,\tau})   \ \frac{ \delta L_\text{IQN} \left( f_m (\mathbf{x_m},\tau), \mathbf{y_m} \right) }{\delta f_m} = 0 \tag{7}
\]</div>
<blockquote>
<div><blockquote>
<div><p>…
<br></p>
</div></blockquote>
</div></blockquote>
<p>Expand Eq (2) in Eq (7) and integrate wrt y over the appropriate limits to see that  <span class="math notranslate nohighlight">\(f(\mathbf{x},\mathbf{\tau})\)</span> is the quantile function for <span class="math notranslate nohighlight">\(p(\mathbf{y}|\mathbf{x})\)</span>, i.e. (I believe) that IQNx4 should work basically exactly.</p>
<div class="math notranslate nohighlight">
\[R_{\text{IQN}x4} = [ L \left( f_m( \{ p_T^{\text{gen}}, \eta^{\text{gen}}, \phi^{\text{gen}}, m^{\text{gen}} , \tau \}, m^\text{reco} ) \]</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="train-mass">
<h1>Train Mass<a class="headerlink" href="#train-mass" title="Permalink to this headline">#</a></h1>
<p>for mass,</p>
<div class="math notranslate nohighlight">
\[\mathbf{y_m}=m_{\text{reco}}\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\mathbf{x_m}=\{p_T^{\text{gen}}, \eta^{\text{gen}}, \phi^{\text{gen}}, m^{\text{gen}} , \tau \}.\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">show_jupyter_image</span><span class="p">(</span><span class="s1">&#39;images/IQN_training_flowchart.png&#39;</span><span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span><span class="n">height</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1_Setup_and_Preprocess_54_0.png" src="_images/1_Setup_and_Preprocess_54_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">apply_z_generator</span> <span class="o">=</span> <span class="n">apply_z_to_features</span><span class="p">()</span>

<span class="n">train_x</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">apply_z_generator</span><span class="p">)</span>
<span class="n">test_x</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">apply_z_generator</span><span class="p">)</span>
<span class="n">valid_x</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">apply_z_generator</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">valid_x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">valid_x</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">train_x</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">train_x</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[-2.55532484e-16  2.34408049e-17 -2.47215581e-17 -2.22109975e-15
  5.00485136e-01] [1.         1.         1.         1.         0.28852734]
[ 3.98275191e-15 -1.10134124e-18 -3.12905257e-17 -1.14646888e-14
  4.99915289e-01] [1.         1.         1.         1.         0.28867295]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_x</span><span class="p">[:</span><span class="mi">3</span><span class="p">,:],</span> <span class="n">test_x</span><span class="p">[:</span><span class="mi">3</span><span class="p">,:],</span> <span class="n">valid_x</span><span class="p">[:</span><span class="mi">3</span><span class="p">,:]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([[-0.11563106,  0.37652098,  1.60021658, -1.98214105,  0.36130954],
        [-0.68688865, -0.5270258 ,  0.35110997, -0.31849075,  0.12689925],
        [-0.68688865, -0.5270258 ,  0.35110997, -0.31849075,  0.96230681]]),
 array([[ 1.06101772,  0.37324145, -0.69948596, -0.27467897,  0.25004557],
        [ 1.06101772,  0.37324145, -0.69948596, -0.27467897,  0.84749256],
        [-0.48554751,  1.60141978,  0.85740126,  0.31973299,  0.85199529]]),
 array([[-0.68215953,  0.56054886, -0.34477387, -1.23054084,  0.93582274],
        [-0.2284882 ,  1.43668218, -0.12155883, -0.6725882 ,  0.9272482 ],
        [-0.2284882 ,  1.43668218, -0.12155883, -0.6725882 ,  0.37568739]]))
</pre></div>
</div>
</div>
</div>
<section id="apply-z-to-targets-before-training">
<h2>Apply <span class="math notranslate nohighlight">\(z\)</span> to targets before training<a class="headerlink" href="#apply-z-to-targets-before-training" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">apply_z_to_targets</span><span class="p">():</span>
    <span class="n">train_t_ratio_</span> <span class="o">=</span> <span class="n">z</span><span class="p">(</span><span class="n">train_t_ratio</span><span class="p">)</span> 
    <span class="n">test_t_ratio_</span> <span class="o">=</span> <span class="n">z</span><span class="p">(</span><span class="n">test_t_ratio</span><span class="p">)</span> 
    <span class="n">valid_t_ratio_</span> <span class="o">=</span> <span class="n">z</span><span class="p">(</span><span class="n">valid_t_ratio</span><span class="p">)</span>
    
    <span class="k">yield</span> <span class="n">train_t_ratio_</span>
    <span class="k">yield</span> <span class="n">test_t_ratio_</span>
    <span class="k">yield</span> <span class="n">valid_t_ratio_</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">apply_z_to_targets_generator</span> <span class="o">=</span> <span class="n">apply_z_to_targets</span><span class="p">()</span>
<span class="n">train_t_ratio</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">apply_z_to_targets_generator</span><span class="p">)</span>
<span class="n">test_t_ratio</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">apply_z_to_targets_generator</span><span class="p">)</span>
<span class="n">valid_t_ratio</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">apply_z_to_targets_generator</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">valid_t_ratio</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">valid_t_ratio</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_t_ratio</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">train_t_ratio</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5.849882889208402e-14 1.0000000000000004
5.849882889208402e-14 1.0000000000000004
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#check that it looks correct</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">autoscale_on</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NFEATURES</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">train_x</span><span class="p">[:,</span><span class="n">i</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.35</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;feature </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span> <span class="p">)</span>
    <span class="c1"># set_axes(ax=ax, xlabel=&quot;Transformed features X&#39; &quot;,title=&quot;training features post-z score: X&#39;=z(L(X))&quot;)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_45271</span><span class="o">/</span><span class="mf">3949263507.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1">#check that it looks correct</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">autoscale_on</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NFEATURES</span><span class="p">):</span>

<span class="ne">NameError</span>: name &#39;plt&#39; is not defined
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The history saving thread hit an unexpected error (OperationalError(&#39;database is locked&#39;)).History will not be written to the database.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_x</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9999999358588744
</pre></div>
</div>
</div>
</div>
</section>
<section id="training-and-running-of-training-functions">
<h2>Training and running-of-training functions<a class="headerlink" href="#training-and-running-of-training-functions" title="Permalink to this headline">#</a></h2>
</section>
<section id="define-basic-nn-model">
<h2>Define basic NN model<a class="headerlink" href="#define-basic-nn-model" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">RegularizedRegressionModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Used for hyperparameter tuning &quot;&quot;&quot;</span>
    <span class="c1">#inherit from the super class</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nfeatures</span><span class="p">,</span> <span class="n">ntargets</span><span class="p">,</span> <span class="n">nlayers</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nlayers</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span> <span class="o">==</span><span class="mi">0</span><span class="p">:</span>
                <span class="c1">#inital layer has to have size of input features as its input layer</span>
                <span class="c1">#its output layer can have any size but it must match the size of the input layer of the next linear layer</span>
                <span class="c1">#here we choose its output layer as the hidden size (fully connected)</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nfeatures</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
                <span class="c1">#batch normalization</span>
                <span class="c1"># layers.append(nn.BatchNorm1d(hidden_size))</span>
                <span class="c1">#dropout only in the first layer</span>
                <span class="c1">#Dropout seems to worsen model performance</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">))</span>
                <span class="c1">#ReLU activation </span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1">#if this is not the first layer (we dont have layers)</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
                <span class="c1"># layers.append(nn.BatchNorm1d(hidden_size))</span>
                <span class="c1">#Dropout seems to worsen model performance</span>
                <span class="c1"># layers.append(nn.Dropout(dropout))</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">())</span>
                <span class="c1">#output layer:</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">ntargets</span><span class="p">))</span> 

        <span class="c1"># only for classification add sigmoid</span>
        <span class="c1"># layers.append(nn.Sigmoid())</span>
            <span class="c1">#we have defined sequential model using the layers in oulist </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
    
<span class="k">class</span> <span class="nc">TrainingRegularizedRegressionModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Used for training, and adds more regularization to prevent overfitting &quot;&quot;&quot;</span>
    <span class="c1">#inherit from the super class</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nfeatures</span><span class="p">,</span> <span class="n">ntargets</span><span class="p">,</span> <span class="n">nlayers</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nlayers</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span> <span class="o">==</span><span class="mi">0</span><span class="p">:</span>
                <span class="c1">#inital layer has to have size of input features as its input layer</span>
                <span class="c1">#its output layer can have any size but it must match the size of the input layer of the next linear layer</span>
                <span class="c1">#here we choose its output layer as the hidden size (fully connected)</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nfeatures</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
                <span class="c1">#batch normalization</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">))</span>
                <span class="c1">#dropout only in the first layer</span>
                <span class="c1">#Dropout seems to worsen model performance</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">))</span>
                <span class="c1">#ReLU activation </span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1">#if this is not the first layer (we dont have layers)</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">))</span>
                <span class="c1">#Dropout seems to worsen model performance</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">))</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">())</span>
                <span class="c1">#output layer:</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">ntargets</span><span class="p">))</span> 

        <span class="c1"># only for classification add sigmoid</span>
        <span class="c1"># layers.append(nn.Sigmoid())</span>
            <span class="c1">#we have defined sequential model using the layers in oulist </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
</section>
<hr class="docutils" />
<section id="hyperparameter-training-workflow">
<h2>Hyperparameter Training Workflow<a class="headerlink" href="#hyperparameter-training-workflow" title="Permalink to this headline">#</a></h2>
<p>We should not touch our test set until we have chosen our hyperparameters (have done model selection) using the valid set (also, we can’t tune the model using the train set since it obviously will just overfit the train set). Then in the training process we evaluate on test set to keep ourselves honest and to see if we are overfitting the train set.</p>
<p>It seems that one of the big challenges in this project is generalization (or overfitting). ways to reduce overfitting and improve generalization (that is, make the generalization error <span class="math notranslate nohighlight">\(R[f]\)</span> closer to the training error <span class="math notranslate nohighlight">\(R_{\text{emp}}\)</span> is:</p>
<ol class="simple">
<li><p>Reducing model complexity (e.g. using a linear model instead of a non-linear model, and user fewer model parameters). 2. using more training data. 3. feature selecting (i.e. using fewer features, since some of the features might be irrelevant or redundant). 4. Data augmentation, i.e. generating additional training examples through e.g. horizontal flipping/random cropping for images, or adding noise to training examples, all of which increase the size and diversity of the training set. 5. Regularization techniques, such as adding a penalty to the weights of the model during training (weight decay). This penalty could be e.g. L1 or L2 norm of the weights. 5. Cross valudation: dividing the training set into several smaller sets, training the model on one set, and evaluating it on the others. (can use e.g. <code class="docutils literal notranslate"><span class="pre">sklearn.model_selection.KFold</span></code> instead of doing it from scratch).</p></li>
</ol>
<p>Other than overfitting, the name of the game for training of course is to minimize the loss with respect to the weights. INPUT (features) is forward propagated (meaning each layer is basically a matrix of the size of the weights is a matrix of <span class="math notranslate nohighlight">\(( N_inputs + 1) X (N_outputs)\)</span> (and the inputs) is <span class="math notranslate nohighlight">\(w[N_inputs]+b\)</span> which is the rows, and the outputs (<span class="math notranslate nohighlight">\(y=\mathbf{w}+b\)</span>) will have shape <span class="math notranslate nohighlight">\([N_outputs]\)</span>  through each layer into the OUTPUT (target). More explicitly the shape of output <span class="math notranslate nohighlight">\(y\)</span> of each layer will be</p>
<div class="math notranslate nohighlight">
\[[y] = [1 \times (N_{input}+1) ] \cdot [(N_{input} +1) \times N_{output}] = [1\times N_{output}]  \]</div>
<p>Where <span class="math notranslate nohighlight">\(N_{input}\)</span> and <span class="math notranslate nohighlight">\(N_{output}\)</span> are the numbers of input and output features, taken to be rows and columns of the matrices, respectively. The <span class="math notranslate nohighlight">\(+1\)</span> in <span class="math notranslate nohighlight">\( (N_{input}+1) \)</span> is for the bias column.</p>
<p>Forward Prop: pass.
INPUT <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> -&gt; … -&gt; a bunch of layers … -&gt; OUTPUT <span class="math notranslate nohighlight">\(y\)</span></p>
<p>Backprop.: Going backward from the output layer to the input layer. Basically, for one layer, <span class="math notranslate nohighlight">\(Backprop(dLoss/dy) = dLoss/dx\)</span>, where <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> are the inputs and outputs for one layer. This will use, in the simplest case, <span class="math notranslate nohighlight">\(dLoss/dx = dLoss/dy \ dy/dx\)</span> where <span class="math notranslate nohighlight">\( dy/dx\)</span> will be in terms of the weights of the current layer. <span class="math notranslate nohighlight">\(dLoss/dw = dLoss/dy \ dy/dw\)</span>, and then the weights are updated as to minimize the loss, e.g. for SGD: <span class="math notranslate nohighlight">\(w \leftarrow w - (dLoss/dw \ \eta\)</span> where <span class="math notranslate nohighlight">\(\eta\)</span> is the learning rate.</p>
<p>the dLoss/dx becomes the dLoss/dy of the next layer:</p>
<p>X layer1 - &gt; layer_2 … -&gt; layer_n -&gt; y
&lt;-…  dL/dx  &lt;- BP dL/dy  &lt;- dL/dx   &lt;-BP  dL/dy</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_tuning_sample</span><span class="p">():</span>
    <span class="n">sample</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mi">200000</span><span class="p">)</span>
    <span class="c1"># train_x_sample, train_t_ratio_sample, valid_x_sample, valid_t_ratio_sample</span>
    <span class="n">get_whole</span><span class="o">=</span><span class="kc">True</span>
    <span class="k">if</span> <span class="n">get_whole</span><span class="p">:</span>
        <span class="n">train_x_sample</span><span class="p">,</span> <span class="n">train_t_ratio_sample</span><span class="p">,</span> <span class="n">valid_x_sample</span><span class="p">,</span> <span class="n">valid_t_ratio_sample</span> <span class="o">=</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">train_t_ratio</span><span class="p">,</span> <span class="n">valid_x</span><span class="p">,</span> <span class="n">valid_t_ratio</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">train_x_sample</span><span class="p">,</span> <span class="n">train_t_ratio_sample</span><span class="p">,</span> <span class="n">valid_x_sample</span><span class="p">,</span> <span class="n">valid_t_ratio_sample</span><span class="o">=</span><span class="n">train_x</span><span class="p">[:</span><span class="n">sample</span><span class="p">],</span> <span class="n">train_t_ratio</span><span class="p">[:</span><span class="n">sample</span><span class="p">],</span> <span class="n">valid_x</span><span class="p">[:</span><span class="n">sample</span><span class="p">],</span> <span class="n">valid_t_ratio</span><span class="p">[:</span><span class="n">sample</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">train_x_sample</span><span class="p">,</span> <span class="n">train_t_ratio_sample</span><span class="p">,</span> <span class="n">valid_x_sample</span><span class="p">,</span> <span class="n">valid_t_ratio_sample</span>

<span class="n">train_x_sample</span><span class="p">,</span> <span class="n">train_t_ratio_sample</span><span class="p">,</span> <span class="n">valid_x_sample</span><span class="p">,</span> <span class="n">valid_t_ratio_sample</span> <span class="o">=</span> <span class="n">get_tuning_sample</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_x_sample</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(8000000, 5)
</pre></div>
</div>
</div>
</div>
<p>Need to use test set <em>and</em> validation set for tuning.</p>
<p>Note that hyperparameters are usually not directly transferrable across architectures and datasets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">HyperTrainer</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;loss, training and evaluation&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
                 <span class="c1">#, device):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="c1">#self.device= device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iterations_tune</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>

        <span class="c1">#the loss function returns the loss function. It is a static method so it doesn&#39;t need self</span>
        <span class="c1"># @staticmethod</span>
        <span class="c1"># def loss_fun(targets, outputs):</span>
        <span class="c1">#   tau = torch.rand(outputs.shape)</span>
        <span class="c1">#   return torch.mean(torch.where(targets &gt;= outputs, </span>
        <span class="c1">#                                   tau * (targets - outputs), </span>
        <span class="c1">#                                   (1 - tau)*(outputs - targets)))</span>

        <span class="c1">#     This loss combines a Sigmoid layer and the BCELoss in one single class. This version is more numerically stable than using a plain Sigmoid followed by a BCELoss as, </span>
        <span class="c1">#     by combining the operations into one layer</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">final_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iterations_tune</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_t</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span>  <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="c1">#x and t are train_x and train_t</span>

            <span class="c1"># with torch.no_grad():</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">batch_x</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">targets</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">batch_t</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">average_quantile_loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">final_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">final_loss</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>

    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">final_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_iterations_tune</span><span class="p">):</span>
            <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_t</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span>  <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="c1">#x and t are train_x and train_t</span>

            <span class="c1"># with torch.no_grad():            </span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">batch_x</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">targets</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">batch_t</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span><span class="n">average_quantile_loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
            <span class="n">final_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">final_loss</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>

    
<span class="n">EPOCHS</span><span class="o">=</span><span class="mi">1</span>
<span class="k">def</span> <span class="nf">run_train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">save_model</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;For tuning the parameters&quot;&quot;&quot;</span>

    <span class="n">model</span> <span class="o">=</span>  <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
              <span class="n">nfeatures</span><span class="o">=</span><span class="n">train_x_sample</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
                <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">nlayers</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;nlayers&quot;</span><span class="p">],</span> 
                <span class="n">hidden_size</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">],</span>
                <span class="n">dropout</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">]</span>
                <span class="p">)</span>
    <span class="c1"># print(model)</span>
    

    <span class="n">learning_rate</span><span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">]</span>
    <span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">]</span>
    
    <span class="c1"># optimizer = torch.optim.Adam(model.parameters(), lr=params[&quot;learning_rate&quot;]) </span>
    
    <span class="n">optimizer</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">optimizer_name</span><span class="p">)(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> 
                            <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">momentum</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;momentum&quot;</span><span class="p">])</span>
    
    <span class="n">trainer</span><span class="o">=</span><span class="n">HyperTrainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">])</span>
    <span class="n">best_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    <span class="n">early_stopping_iter</span><span class="o">=</span><span class="mi">10</span><span class="c1">#stop after 10 iteractions of not improving loss</span>
    <span class="n">early_stopping_coutner</span><span class="o">=</span><span class="mi">0</span>

    <span class="c1"># for epoch in range(EPOCHS):</span>
    <span class="c1"># train_loss = trainer.train(train_x_sample, train_t_ratio_sample)</span>
        <span class="c1">#test loss</span>
    <span class="n">valid_loss</span><span class="o">=</span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">valid_x_sample</span><span class="p">,</span> <span class="n">valid_t_ratio_sample</span><span class="p">)</span>

        <span class="c1"># print(f&quot;{epoch} \t {train_loss} \t {valid_loss}&quot;)</span>
        
        <span class="c1"># if valid_loss&lt;best_loss:</span>
        <span class="c1">#     best_loss=valid_loss</span>
        <span class="c1"># else:</span>
        <span class="c1">#     early_stopping_coutner+=1</span>
        <span class="c1"># if early_stopping_coutner &gt; early_stopping_iter:</span>
            <span class="c1"># break</span>
            
    <span class="c1"># return best_loss</span>
    <span class="k">return</span> <span class="n">valid_loss</span>


<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    <span class="n">CLUSTER</span><span class="o">=</span><span class="kc">False</span>
    <span class="c1">#cluster has greater memory than my laptop, which allows higher max values in hyperparam. search space</span>
    <span class="k">if</span> <span class="n">CLUSTER</span><span class="p">:</span>
        <span class="n">nlayers_max</span><span class="p">,</span><span class="n">n_hidden_max</span><span class="p">,</span> <span class="n">batch_size_max</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mi">24</span><span class="p">),</span><span class="nb">int</span><span class="p">(</span><span class="mi">350</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="mf">2e5</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">nlayers_max</span><span class="p">,</span><span class="n">n_hidden_max</span><span class="p">,</span> <span class="n">batch_size_max</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mi">6</span><span class="p">),</span><span class="nb">int</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="mf">3e4</span><span class="p">)</span>

    <span class="c1">#hyperparameter search space:</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
          <span class="s2">&quot;nlayers&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">&quot;nlayers&quot;</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">nlayers_max</span><span class="p">),</span>      
          <span class="s2">&quot;hidden_size&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_hidden_max</span><span class="p">),</span>
          <span class="s2">&quot;dropout&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s2">&quot;dropout&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span><span class="mf">0.5</span><span class="p">),</span>
          <span class="s2">&quot;optimizer_name&quot;</span> <span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_categorical</span><span class="p">(</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;RMSprop&quot;</span><span class="p">,</span> <span class="s2">&quot;SGD&quot;</span><span class="p">]),</span>
          <span class="s2">&quot;momentum&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s2">&quot;momentum&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span><span class="mf">0.99</span><span class="p">),</span>
          <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">),</span>
          <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">&quot;batch_size&quot;</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="n">batch_size_max</span><span class="p">)</span>

        <span class="p">}</span>
    
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>

        <span class="n">temp_loss</span> <span class="o">=</span> <span class="n">run_train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span><span class="n">save_model</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">trial</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">temp_loss</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
        <span class="c1">#activate pruning (early stopping if the current step in the trial has unpromising results)</span>
        <span class="c1">#instead of doing lots of iterations, do less iterations and more steps in each trial,  </span>
        <span class="c1">#such that a trial is terminated if a step yields an unpromising loss.</span>
        
        <span class="k">if</span> <span class="n">trial</span><span class="o">.</span><span class="n">should_prune</span><span class="p">():</span>
            <span class="k">raise</span> <span class="n">optuna</span><span class="o">.</span><span class="n">TrialPruned</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">temp_loss</span>

<span class="nd">@time_type_of_func</span><span class="p">(</span><span class="n">tuning_or_training</span><span class="o">=</span><span class="s1">&#39;tuning&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">tune_hyperparameters</span><span class="p">(</span><span class="n">save_best_params</span><span class="p">):</span>
    

    <span class="n">sampler</span><span class="o">=</span><span class="kc">False</span><span class="c1">#use different sampling technique than the defualt one if sampler=True.</span>
    <span class="k">if</span> <span class="n">sampler</span><span class="p">:</span>
        <span class="c1">#choose a different sampling strategy (https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.CmaEsSampler.html#optuna.samplers.CmaEsSampler)</span>
        <span class="c1"># sampler=optuna.samplers.RandomSampler()</span>
        <span class="n">study</span><span class="o">=</span><span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="s1">&#39;minimize&#39;</span><span class="p">,</span>
                                  <span class="n">pruner</span><span class="o">=</span><span class="n">optuna</span><span class="o">.</span><span class="n">pruners</span><span class="o">.</span><span class="n">MedianPruner</span><span class="p">(),</span> <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1">#but the default sampler is usually better - no need to change it!</span>
        <span class="n">study</span><span class="o">=</span><span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="s1">&#39;minimize&#39;</span><span class="p">,</span>
                                  <span class="n">pruner</span><span class="o">=</span><span class="n">optuna</span><span class="o">.</span><span class="n">pruners</span><span class="o">.</span><span class="n">HyperbandPruner</span><span class="p">())</span>
    <span class="n">n_trials</span><span class="o">=</span><span class="mi">100</span>
    <span class="n">study</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="n">n_trials</span><span class="p">)</span>
    <span class="n">best_trial</span> <span class="o">=</span> <span class="n">study</span><span class="o">.</span><span class="n">best_trial</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;best model parameters&#39;</span><span class="p">,</span> <span class="n">best_trial</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>

    <span class="n">best_params</span><span class="o">=</span><span class="n">best_trial</span><span class="o">.</span><span class="n">params</span><span class="c1">#this is a dictionary</span>
    <span class="c1">#save best hyperapameters in a pandas dataframe as a .csv</span>
    <span class="k">if</span> <span class="n">save_best_params</span><span class="p">:</span>
        <span class="n">tuned_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">IQN_BASE</span><span class="p">,</span><span class="s1">&#39;best_params&#39;</span><span class="p">)</span>
        <span class="n">mkdir</span><span class="p">(</span><span class="n">tuned_dir</span><span class="p">)</span>
        <span class="n">filename</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tuned_dir</span><span class="p">,</span><span class="s1">&#39;best_params_mass_</span><span class="si">%s</span><span class="s1">_trials.csv&#39;</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_trials</span><span class="p">)))</span>
        <span class="n">param_df</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
                                <span class="s1">&#39;n_layers&#39;</span><span class="p">:</span><span class="n">best_params</span><span class="p">[</span><span class="s2">&quot;nlayers&quot;</span><span class="p">],</span> 
                                <span class="s1">&#39;hidden_size&#39;</span><span class="p">:</span><span class="n">best_params</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">],</span> 
                                <span class="s1">&#39;dropout&#39;</span><span class="p">:</span><span class="n">best_params</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">],</span>
                                <span class="s1">&#39;optimizer_name&#39;</span><span class="p">:</span><span class="n">best_params</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">],</span>
                                <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">best_params</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">],</span> 
                                <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span><span class="n">best_params</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">],</span>
                                <span class="s1">&#39;momentum&#39;</span><span class="p">:</span><span class="n">best_params</span><span class="p">[</span><span class="s2">&quot;momentum&quot;</span><span class="p">]},</span>
                                        <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="n">param_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>   
    <span class="k">return</span> <span class="n">study</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">study</span><span class="o">=</span> <span class="n">tune_hyperparameters</span><span class="p">(</span><span class="n">save_best_params</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tuning IQN hyperparameters to estimate RecoDatam
Getting best hyperparameters for target RecoDatam
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span> <span class="p">[</span><span class="mi">56</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">study</span><span class="o">=</span> <span class="n">tune_hyperparameters</span><span class="p">(</span><span class="n">save_best_params</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nn">Cell In [6], line 93,</span> in <span class="ni">time_type_of_func.&lt;locals&gt;.timer.&lt;locals&gt;.wrapper_timer</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">91</span>     <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;tuning IQN hyperparameters to estimate </span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">92</span> <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>    
<span class="ne">---&gt; </span><span class="mi">93</span> <span class="n">value</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">94</span> <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>      
<span class="g g-Whitespace">     </span><span class="mi">95</span> <span class="n">run_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>    

<span class="nn">Cell In [55], line 138,</span> in <span class="ni">tune_hyperparameters</span><span class="nt">(save_best_params)</span>
<span class="g g-Whitespace">    </span><span class="mi">135</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">136</span>     <span class="n">study</span><span class="o">=</span><span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="s1">&#39;minimize&#39;</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">137</span>                               <span class="n">pruner</span><span class="o">=</span><span class="n">optuna</span><span class="o">.</span><span class="n">pruners</span><span class="o">.</span><span class="n">HyperbandPruner</span><span class="p">())</span>
<span class="ne">--&gt; </span><span class="mi">138</span> <span class="n">study</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">139</span> <span class="n">best_trial</span> <span class="o">=</span> <span class="n">study</span><span class="o">.</span><span class="n">best_trial</span>
<span class="g g-Whitespace">    </span><span class="mi">140</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;best model parameters&#39;</span><span class="p">,</span> <span class="n">best_trial</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/new_torch/lib/python3.9/site-packages/optuna/study/study.py:419,</span> in <span class="ni">Study.optimize</span><span class="nt">(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)</span>
<span class="g g-Whitespace">    </span><span class="mi">315</span> <span class="k">def</span> <span class="nf">optimize</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">316</span>     <span class="bp">self</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">317</span>     <span class="n">func</span><span class="p">:</span> <span class="n">ObjectiveFuncType</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">324</span>     <span class="n">show_progress_bar</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">325</span> <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">326</span>     <span class="sd">&quot;&quot;&quot;Optimize an objective function.</span>
<span class="g g-Whitespace">    </span><span class="mi">327</span><span class="sd"> </span>
<span class="g g-Whitespace">    </span><span class="mi">328</span><span class="sd">     Optimization is done by choosing a suitable set of hyperparameter values from a given</span>
<span class="sd">   (...)</span>
<span class="g g-Whitespace">    </span><span class="mi">416</span><span class="sd">             If nested invocation of this method occurs.</span>
<span class="g g-Whitespace">    </span><span class="mi">417</span><span class="sd">     &quot;&quot;&quot;</span>
<span class="ne">--&gt; </span><span class="mi">419</span>     <span class="n">_optimize</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">420</span>         <span class="n">study</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">421</span>         <span class="n">func</span><span class="o">=</span><span class="n">func</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">422</span>         <span class="n">n_trials</span><span class="o">=</span><span class="n">n_trials</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">423</span>         <span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">424</span>         <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">425</span>         <span class="n">catch</span><span class="o">=</span><span class="n">catch</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">426</span>         <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">427</span>         <span class="n">gc_after_trial</span><span class="o">=</span><span class="n">gc_after_trial</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">428</span>         <span class="n">show_progress_bar</span><span class="o">=</span><span class="n">show_progress_bar</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">429</span>     <span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/new_torch/lib/python3.9/site-packages/optuna/study/_optimize.py:66,</span> in <span class="ni">_optimize</span><span class="nt">(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)</span>
<span class="g g-Whitespace">     </span><span class="mi">64</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">65</span>     <span class="k">if</span> <span class="n">n_jobs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">66</span>         <span class="n">_optimize_sequential</span><span class="p">(</span>
<span class="g g-Whitespace">     </span><span class="mi">67</span>             <span class="n">study</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">68</span>             <span class="n">func</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">69</span>             <span class="n">n_trials</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">70</span>             <span class="n">timeout</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">71</span>             <span class="n">catch</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">72</span>             <span class="n">callbacks</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">73</span>             <span class="n">gc_after_trial</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">74</span>             <span class="n">reseed_sampler_rng</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">75</span>             <span class="n">time_start</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">76</span>             <span class="n">progress_bar</span><span class="o">=</span><span class="n">progress_bar</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">77</span>         <span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">78</span>     <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">79</span>         <span class="k">if</span> <span class="n">n_jobs</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>

<span class="nn">File ~/anaconda3/envs/new_torch/lib/python3.9/site-packages/optuna/study/_optimize.py:160,</span> in <span class="ni">_optimize_sequential</span><span class="nt">(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)</span>
<span class="g g-Whitespace">    </span><span class="mi">157</span>         <span class="k">break</span>
<span class="g g-Whitespace">    </span><span class="mi">159</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">160</span>     <span class="n">frozen_trial</span> <span class="o">=</span> <span class="n">_run_trial</span><span class="p">(</span><span class="n">study</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">catch</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">161</span> <span class="k">finally</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">162</span>     <span class="c1"># The following line mitigates memory problems that can be occurred in some</span>
<span class="g g-Whitespace">    </span><span class="mi">163</span>     <span class="c1"># environments (e.g., services that use computing containers such as CircleCI).</span>
<span class="g g-Whitespace">    </span><span class="mi">164</span>     <span class="c1"># Please refer to the following PR for further details:</span>
<span class="g g-Whitespace">    </span><span class="mi">165</span>     <span class="c1"># https://github.com/optuna/optuna/pull/325.</span>
<span class="g g-Whitespace">    </span><span class="mi">166</span>     <span class="k">if</span> <span class="n">gc_after_trial</span><span class="p">:</span>

<span class="nn">File ~/anaconda3/envs/new_torch/lib/python3.9/site-packages/optuna/study/_optimize.py:234,</span> in <span class="ni">_run_trial</span><span class="nt">(study, func, catch)</span>
<span class="g g-Whitespace">    </span><span class="mi">227</span>         <span class="k">assert</span> <span class="kc">False</span><span class="p">,</span> <span class="s2">&quot;Should not reach.&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">229</span> <span class="k">if</span> <span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">230</span>     <span class="n">frozen_trial</span><span class="o">.</span><span class="n">state</span> <span class="o">==</span> <span class="n">TrialState</span><span class="o">.</span><span class="n">FAIL</span>
<span class="g g-Whitespace">    </span><span class="mi">231</span>     <span class="ow">and</span> <span class="n">func_err</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span class="g g-Whitespace">    </span><span class="mi">232</span>     <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">func_err</span><span class="p">,</span> <span class="n">catch</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">233</span> <span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">234</span>     <span class="k">raise</span> <span class="n">func_err</span>
<span class="g g-Whitespace">    </span><span class="mi">235</span> <span class="k">return</span> <span class="n">frozen_trial</span>

<span class="nn">File ~/anaconda3/envs/new_torch/lib/python3.9/site-packages/optuna/study/_optimize.py:196,</span> in <span class="ni">_run_trial</span><span class="nt">(study, func, catch)</span>
<span class="g g-Whitespace">    </span><span class="mi">194</span> <span class="k">with</span> <span class="n">get_heartbeat_thread</span><span class="p">(</span><span class="n">trial</span><span class="o">.</span><span class="n">_trial_id</span><span class="p">,</span> <span class="n">study</span><span class="o">.</span><span class="n">_storage</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">195</span>     <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">196</span>         <span class="n">value_or_values</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">trial</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">197</span>     <span class="k">except</span> <span class="n">exceptions</span><span class="o">.</span><span class="n">TrialPruned</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">198</span>         <span class="c1"># TODO(mamu): Handle multi-objective cases.</span>
<span class="g g-Whitespace">    </span><span class="mi">199</span>         <span class="n">state</span> <span class="o">=</span> <span class="n">TrialState</span><span class="o">.</span><span class="n">PRUNED</span>

<span class="nn">Cell In [55], line 117,</span> in <span class="ni">objective</span><span class="nt">(trial)</span>
<span class="g g-Whitespace">    </span><span class="mi">104</span> <span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
<span class="g g-Whitespace">    </span><span class="mi">105</span>       <span class="s2">&quot;nlayers&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">&quot;nlayers&quot;</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span>      
<span class="g g-Whitespace">    </span><span class="mi">106</span>       <span class="s2">&quot;hidden_size&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">112</span> 
<span class="g g-Whitespace">    </span><span class="mi">113</span>     <span class="p">}</span>
<span class="g g-Whitespace">    </span><span class="mi">115</span> <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">117</span>     <span class="n">temp_loss</span> <span class="o">=</span> <span class="n">run_train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span><span class="n">save_model</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">118</span>     <span class="n">trial</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">temp_loss</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">119</span>     <span class="c1">#activate pruning (early stopping)</span>

<span class="nn">Cell In [55], line 87,</span> in <span class="ni">run_train</span><span class="nt">(params, save_model)</span>
<span class="g g-Whitespace">     </span><span class="mi">82</span> <span class="n">early_stopping_coutner</span><span class="o">=</span><span class="mi">0</span>
<span class="g g-Whitespace">     </span><span class="mi">84</span> <span class="c1"># for epoch in range(EPOCHS):</span>
<span class="g g-Whitespace">     </span><span class="mi">85</span> <span class="c1"># train_loss = trainer.train(train_x_sample, train_t_ratio_sample)</span>
<span class="g g-Whitespace">     </span><span class="mi">86</span>     <span class="c1">#test loss</span>
<span class="ne">---&gt; </span><span class="mi">87</span> <span class="n">valid_loss</span><span class="o">=</span><span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">valid_x_sample</span><span class="p">,</span> <span class="n">valid_t_ratio_sample</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">89</span>     <span class="c1"># print(f&quot;{epoch} \t {train_loss} \t {valid_loss}&quot;)</span>
<span class="g g-Whitespace">     </span><span class="mi">90</span>     
<span class="g g-Whitespace">     </span><span class="mi">91</span>     <span class="c1"># if valid_loss&lt;best_loss:</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">97</span>         
<span class="g g-Whitespace">     </span><span class="mi">98</span> <span class="c1"># return best_loss</span>
<span class="g g-Whitespace">     </span><span class="mi">99</span> <span class="k">return</span> <span class="n">valid_loss</span>

<span class="nn">Cell In [55], line 52,</span> in <span class="ni">HyperTrainer.evaluate</span><span class="nt">(self, x, t)</span>
<span class="g g-Whitespace">     </span><span class="mi">50</span>     <span class="n">targets</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">batch_t</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">51</span>     <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">52</span>     <span class="n">loss</span> <span class="o">=</span><span class="n">average_quantile_loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">53</span>     <span class="n">final_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">54</span> <span class="k">return</span> <span class="n">final_loss</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>

<span class="nn">Cell In [38], line 28,</span> in <span class="ni">average_quantile_loss</span><span class="nt">(f, t, x)</span>
<span class="g g-Whitespace">     </span><span class="mi">25</span> <span class="n">tau</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># last column is tau.</span>
<span class="g g-Whitespace">     </span><span class="mi">26</span> <span class="c1">#Eq (2)</span>
<span class="g g-Whitespace">     </span><span class="mi">27</span> <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">t</span> <span class="o">&gt;=</span> <span class="n">f</span><span class="p">,</span> 
<span class="ne">---&gt; </span><span class="mi">28</span>                               <span class="n">tau</span> <span class="o">*</span> <span class="p">(</span><span class="n">t</span> <span class="o">-</span> <span class="n">f</span><span class="p">),</span> 
<span class="g g-Whitespace">     </span><span class="mi">29</span>                               <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">tau</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">f</span> <span class="o">-</span> <span class="n">t</span><span class="p">)))</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#make sure you have plotly installed with jupyterlab support. For jupyterlab3.x:</span>
<span class="c1"># conda install &quot;jupyterlab&gt;=3&quot; &quot;ipywidgets&gt;=7.6&quot;</span>

<span class="c1"># for JupyterLab 2.x renderer support:</span>
<span class="c1"># jupyter labextension install jupyterlab-plotly@5.11.0 @jupyter-widgets/jupyterlab-manager</span>
<span class="c1">#conda install -c plotly plotly=5.11.0</span>
<span class="kn">from</span> <span class="nn">optuna</span> <span class="kn">import</span> <span class="n">visualization</span>

<span class="n">visualization</span><span class="o">.</span><span class="n">plot_param_importances</span><span class="p">(</span><span class="n">study</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="o">~/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.7</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">optuna</span><span class="o">/</span><span class="n">visualization</span><span class="o">/</span><span class="n">_plotly_imports</span><span class="o">.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="k">with</span> <span class="n">try_import</span><span class="p">()</span> <span class="k">as</span> <span class="n">_imports</span><span class="p">:</span>  <span class="c1"># NOQA</span>
<span class="ne">----&gt; </span><span class="mi">7</span>     <span class="kn">import</span> <span class="nn">plotly</span>  <span class="c1"># NOQA</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span>     <span class="kn">from</span> <span class="nn">plotly</span> <span class="kn">import</span> <span class="n">__version__</span> <span class="k">as</span> <span class="n">plotly_version</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;plotly&#39;

<span class="n">The</span> <span class="n">above</span> <span class="n">exception</span> <span class="n">was</span> <span class="n">the</span> <span class="n">direct</span> <span class="n">cause</span> <span class="n">of</span> <span class="n">the</span> <span class="n">following</span> <span class="n">exception</span><span class="p">:</span>

<span class="ne">ImportError</span><span class="g g-Whitespace">                               </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_797645</span><span class="o">/</span><span class="mf">859914537.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="kn">from</span> <span class="nn">optuna</span> <span class="kn">import</span> <span class="n">visualization</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span> 
<span class="ne">----&gt; </span><span class="mi">9</span> <span class="n">visualization</span><span class="o">.</span><span class="n">plot_param_importances</span><span class="p">(</span><span class="n">study</span><span class="p">)</span>

<span class="nn">~/anaconda3/lib/python3.7/site-packages/optuna/visualization/_param_importances.py</span> in <span class="ni">plot_param_importances</span><span class="nt">(study, evaluator, params, target, target_name)</span>
<span class="g g-Whitespace">     </span><span class="mi">93</span>     <span class="s2">&quot;&quot;&quot;</span>
<span class="g g-Whitespace">     </span><span class="mi">94</span><span class="s2"> </span>
<span class="ne">---&gt; </span><span class="mi">95</span><span class="s2">     _imports.check()</span>
<span class="g g-Whitespace">     </span><span class="mi">96</span><span class="s2">     _check_plot_args(study, target, target_name)</span>
<span class="g g-Whitespace">     </span><span class="mi">97</span><span class="s2"> </span>

<span class="nn">~/anaconda3/lib/python3.7/site-packages/optuna/_imports.py</span> in <span class="ni">check</span><span class="nt">(self)</span>
<span class="g g-Whitespace">     </span><span class="mi">84</span><span class="s2">         if self._deferred is not None:</span>
<span class="g g-Whitespace">     </span><span class="mi">85</span><span class="s2">             exc_value, message = self._deferred</span>
<span class="ne">---&gt; </span><span class="mi">86</span><span class="s2">             raise ImportError(message) from exc_value</span>
<span class="g g-Whitespace">     </span><span class="mi">87</span><span class="s2"> </span>
<span class="g g-Whitespace">     </span><span class="mi">88</span><span class="s2"> </span>

<span class="ne">ImportError</span>: Tried to import &#39;plotly&#39; but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named &#39;plotly&#39;.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">optuna</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">plot_parallel_coordinate</span><span class="p">(</span><span class="n">study</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<hr class="docutils" />
<hr class="docutils" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># BEST_PARAMS = {&#39;nlayers&#39;: 6, &#39;hidden_size&#39;: 2, &#39;dropout&#39;: 0.40716885971031636, &#39;optimizer_name&#39;: &#39;Adam&#39;, &#39;learning_rate&#39;: 0.005215585403055171, &#39;batch_size&#39;: 1983}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># def get_model_params_tuned()</span>

<span class="n">tuned_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">IQN_BASE</span><span class="p">,</span><span class="s1">&#39;best_params&#39;</span><span class="p">)</span>
<span class="n">tuned_filename</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tuned_dir</span><span class="p">,</span><span class="s1">&#39;best_params_mass.csv&#39;</span><span class="p">)</span>
<span class="c1"># BEST_PARAMS = pd.read_csv(os.path.join(IQN_BASE, &#39;best_params&#39;,&#39;best_params_Test_Trials.csv&#39;))</span>
<span class="n">BEST_PARAMS</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">tuned_filename</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">)</span>

<span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">])</span> 
<span class="n">hidden_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">])</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">])</span>

<span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">optimizer_name</span><span class="p">))</span>
<span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_string</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>   Unnamed: 0  n_layers  hidden_size   dropout optimizer_name  learning_rate  \
0           0         1            5  0.141347            SGD       0.003165   

   batch_size  momentum  
0        2948  0.369386  
&lt;class &#39;pandas.core.series.Series&#39;&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">NFEATURES</span><span class="o">=</span><span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">load_untrained_model</span><span class="p">():</span>
    <span class="n">model</span><span class="o">=</span><span class="n">TrainingRegularizedRegressionModel</span><span class="p">(</span><span class="n">nfeatures</span><span class="o">=</span><span class="n">NFEATURES</span><span class="p">,</span> <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                               <span class="n">nlayers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="n">model</span><span class="o">=</span><span class="n">load_untrained_model</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RegularizedRegressionModel(
  (model): Sequential(
    (0): Linear(in_features=5, out_features=20, bias=True)
    (1): Dropout(p=0.141346858975224, inplace=False)
    (2): LeakyReLU(negative_slope=0.01)
    (3): Linear(in_features=20, out_features=20, bias=True)
    (4): LeakyReLU(negative_slope=0.01)
    (5): Linear(in_features=20, out_features=20, bias=True)
    (6): LeakyReLU(negative_slope=0.01)
    (7): Linear(in_features=20, out_features=1, bias=True)
  )
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># optimizer_name =  &#39;Adam&#39;</span>
<span class="n">best_learning_rate</span> <span class="o">=</span>  <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">])</span>
<span class="n">momentum</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;momentum&quot;</span><span class="p">])</span> 
<span class="n">best_optimizer_temp</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">optimizer_name</span><span class="p">)(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">best_learning_rate</span><span class="p">,</span><span class="n">momentum</span><span class="o">=</span><span class="n">momentum</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_optimizer_temp</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>SGD (
Parameter Group 0
    dampening: 0
    lr: 0.0031645926758082
    momentum: 0.7387727733031814
    nesterov: False
    weight_decay: 0
)
</pre></div>
</div>
</div>
</div>
<section id="run-training">
<h3>Run training<a class="headerlink" href="#run-training" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># BATCHSIZE=10000</span>
<span class="n">BATCHSIZE</span><span class="o">=</span><span class="n">batch_size</span> <span class="o">*</span> <span class="mi">2</span>
<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">avloss</span><span class="p">,</span> <span class="n">getbatch</span><span class="p">,</span>
          <span class="n">train_x</span><span class="p">,</span> <span class="n">train_t</span><span class="p">,</span> 
          <span class="n">valid_x</span><span class="p">,</span> <span class="n">valid_t</span><span class="p">,</span>
          <span class="n">batch_size</span><span class="p">,</span> 
          <span class="n">n_iterations</span><span class="p">,</span> <span class="n">traces</span><span class="p">,</span> 
          <span class="n">step</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    
    <span class="c1"># to keep track of average losses</span>
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy_t</span><span class="p">,</span> <span class="n">yy_v</span><span class="p">,</span> <span class="n">yy_v_avg</span> <span class="o">=</span> <span class="n">traces</span>
    
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_x</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration vs average loss&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%10s</span><span class="se">\t</span><span class="si">%10s</span><span class="se">\t</span><span class="si">%10s</span><span class="s2">&quot;</span> <span class="o">%</span> \
          <span class="p">(</span><span class="s1">&#39;iteration&#39;</span><span class="p">,</span> <span class="s1">&#39;train-set&#39;</span><span class="p">,</span> <span class="s1">&#39;test-set&#39;</span><span class="p">))</span>
    
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iterations</span><span class="p">):</span>

        <span class="c1"># set mode to training so that training specific </span>
        <span class="c1"># operations such as dropout are enabled.</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        
        <span class="c1"># get a random sample (a batch) of data (as numpy arrays)</span>
        <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_t</span> <span class="o">=</span> <span class="n">getbatch</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_t</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="c1"># batch_x[:,-1]=batch_x[:,-1] </span>
        <span class="c1"># convert the numpy arrays batch_x and batch_t to tensor </span>
        <span class="c1"># types. The PyTorch tensor type is the magic that permits </span>
        <span class="c1"># automatic differentiation with respect to parameters. </span>
        <span class="c1"># However, since we do not need to take the derivatives</span>
        <span class="c1"># with respect to x and t, we disable this feature</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span> <span class="c1"># no need to compute gradients </span>
            <span class="c1"># wrt. x and t</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">batch_x</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">batch_t</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>      

        <span class="c1"># compute the output of the model for the batch of data x</span>
        <span class="c1"># Note: outputs is </span>
        <span class="c1">#   of shape (-1, 1), but the tensor targets, t, is</span>
        <span class="c1">#   of shape (-1,)</span>
        <span class="c1"># In order for the tensor operations with outputs and t</span>
        <span class="c1"># to work correctly, it is necessary that they have the</span>
        <span class="c1"># same shape. We can do this with the reshape method.</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
   
        <span class="c1"># compute a noisy approximation to the average loss</span>
        <span class="n">empirical_risk</span> <span class="o">=</span> <span class="n">avloss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># use automatic differentiation to compute a </span>
        <span class="c1"># noisy approximation of the local gradient</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>       <span class="c1"># clear previous gradients</span>
        <span class="n">empirical_risk</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>   <span class="c1"># compute gradients</span>
        
        <span class="c1"># finally, advance one step in the direction of steepest </span>
        <span class="c1"># descent, using the noisy local gradient. </span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>            <span class="c1"># move one step</span>
        
        <span class="c1">#add early stopping when the model starts to overfit, as determined by performance on</span>
        <span class="c1">#valid set (when valid loss plateaus or starts increasing when train loss keeps decreasing)</span>
        <span class="k">if</span> <span class="n">ii</span> <span class="o">%</span> <span class="n">step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            
            <span class="n">acc_t</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">avloss</span><span class="p">,</span> <span class="n">train_x</span><span class="p">[:</span><span class="n">n</span><span class="p">],</span> <span class="n">train_t</span><span class="p">[:</span><span class="n">n</span><span class="p">])</span> 
            <span class="n">acc_v</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">avloss</span><span class="p">,</span> <span class="n">valid_x</span><span class="p">[:</span><span class="n">n</span><span class="p">],</span> <span class="n">valid_t</span><span class="p">[:</span><span class="n">n</span><span class="p">])</span>
            <span class="n">yy_t</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc_t</span><span class="p">)</span>
            <span class="n">yy_v</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc_v</span><span class="p">)</span>
            
            <span class="c1"># compute running average for validation data</span>
            <span class="n">len_yy_v</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">yy_v</span><span class="p">)</span>
            <span class="k">if</span>   <span class="n">len_yy_v</span> <span class="o">&lt;</span> <span class="n">window</span><span class="p">:</span>
                <span class="n">yy_v_avg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">yy_v</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">)</span>
            <span class="k">elif</span> <span class="n">len_yy_v</span> <span class="o">==</span> <span class="n">window</span><span class="p">:</span>
                <span class="n">yy_v_avg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="nb">sum</span><span class="p">(</span><span class="n">yy_v</span><span class="p">)</span> <span class="o">/</span> <span class="n">window</span> <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">acc_v_avg</span>  <span class="o">=</span> <span class="n">yy_v_avg</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">window</span>
                <span class="n">acc_v_avg</span> <span class="o">+=</span> <span class="n">yy_v</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">yy_v</span><span class="p">[</span><span class="o">-</span><span class="n">window</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">yy_v_avg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc_v_avg</span> <span class="o">/</span> <span class="n">window</span><span class="p">)</span>
                        
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">xx</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">xx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%10d</span><span class="se">\t</span><span class="si">%10.6f</span><span class="se">\t</span><span class="si">%10.6f</span><span class="s2">&quot;</span> <span class="o">%</span> \
                      <span class="p">(</span><span class="n">xx</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">yy_t</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">yy_v</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">xx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">xx</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">step</span><span class="p">)</span>
                    
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\r</span><span class="si">%10d</span><span class="se">\t</span><span class="si">%10.6f</span><span class="se">\t</span><span class="si">%10.6f</span><span class="se">\t</span><span class="si">%10.6f</span><span class="s2">&quot;</span> <span class="o">%</span> \
                          <span class="p">(</span><span class="n">xx</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">yy_t</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">yy_v</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">yy_v_avg</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> 
                      <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
            
    <span class="nb">print</span><span class="p">()</span>      
    <span class="k">return</span> <span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy_t</span><span class="p">,</span> <span class="n">yy_v</span><span class="p">,</span> <span class="n">yy_v_avg</span><span class="p">)</span>


<span class="nd">@time_type_of_func</span><span class="p">(</span><span class="n">tuning_or_training</span><span class="o">=</span><span class="s1">&#39;training&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> 
        <span class="n">train_x</span><span class="p">,</span> <span class="n">train_t</span><span class="p">,</span> 
        <span class="n">valid_x</span><span class="p">,</span> <span class="n">valid_t</span><span class="p">,</span> <span class="n">traces</span><span class="p">,</span>
        <span class="n">n_batch</span><span class="o">=</span><span class="n">BATCHSIZE</span><span class="p">,</span> 
        <span class="n">n_iterations</span><span class="o">=</span><span class="n">n_iterations</span><span class="p">,</span> 
        <span class="n">traces_step</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> 
        <span class="n">traces_window</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
        <span class="n">save_model</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>

    <span class="n">learning_rate</span><span class="o">=</span> <span class="n">best_learning_rate</span>
    <span class="c1">#add weight decay (important regularization to reduce overfitting)</span>
    <span class="n">L2</span><span class="o">=</span><span class="mf">1e-3</span>
    <span class="c1"># optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=L2)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">optimizer_name</span><span class="p">)(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">best_learning_rate</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">momentum</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">L2</span><span class="p">)</span>
    
    <span class="c1">#starting at 10^-3	    </span>
    <span class="n">traces</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> 
                      <span class="n">average_quantile_loss</span><span class="p">,</span>
                      <span class="n">get_batch</span><span class="p">,</span>
                      <span class="n">train_x</span><span class="p">,</span> <span class="n">train_t</span><span class="p">,</span> 
                      <span class="n">valid_x</span><span class="p">,</span> <span class="n">valid_t</span><span class="p">,</span>
                      <span class="n">n_batch</span><span class="p">,</span> 
                  <span class="n">n_iterations</span><span class="p">,</span>
                  <span class="n">traces</span><span class="p">,</span>
                  <span class="n">step</span><span class="o">=</span><span class="n">traces_step</span><span class="p">,</span> 
                  <span class="n">window</span><span class="o">=</span><span class="n">traces_window</span><span class="p">)</span>
    
    <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="o">/</span><span class="mi">100</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">optimizer_name</span><span class="p">)(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">best_learning_rate</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">momentum</span><span class="p">)</span>
    <span class="c1">#10^-4</span>
    <span class="n">traces</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> 
                      <span class="n">average_quantile_loss</span><span class="p">,</span>
                      <span class="n">get_batch</span><span class="p">,</span>
                      <span class="n">train_x</span><span class="p">,</span> <span class="n">train_t</span><span class="p">,</span> 
                      <span class="n">valid_x</span><span class="p">,</span> <span class="n">valid_t</span><span class="p">,</span>
                      <span class="n">n_batch</span><span class="p">,</span> 
                  <span class="n">n_iterations</span><span class="p">,</span>
                  <span class="n">traces</span><span class="p">,</span>
                  <span class="n">step</span><span class="o">=</span><span class="n">traces_step</span><span class="p">,</span> 
                  <span class="n">window</span><span class="o">=</span><span class="n">traces_window</span><span class="p">)</span>


<span class="c1">#     learning_rate=learning_rate/100</span>
<span class="c1">#     optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) </span>
<span class="c1">#     #10^-6</span>
<span class="c1">#     traces = train(model, optimizer, </span>
<span class="c1">#                       average_quantile_loss,</span>
<span class="c1">#                       get_batch,</span>
<span class="c1">#                       train_x, train_t, </span>
<span class="c1">#                       valid_x, valid_t,</span>
<span class="c1">#                       n_batch, </span>
<span class="c1">#                   n_iterations,</span>
<span class="c1">#                   traces,</span>
<span class="c1">#                   step=traces_step, </span>
<span class="c1">#                   window=traces_window)</span>

    <span class="c1"># plot_average_loss(traces)</span>

    <span class="k">if</span> <span class="n">save_model</span><span class="p">:</span>
        <span class="n">filename</span><span class="o">=</span><span class="s1">&#39;Trained_IQNx4_</span><span class="si">%s</span><span class="s1">_</span><span class="si">%s</span><span class="s1">K_iter.dict&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_iterations</span><span class="o">/</span><span class="mi">1000</span><span class="p">))</span> <span class="p">)</span>
        <span class="n">PATH</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">IQN_BASE</span><span class="p">,</span> <span class="s1">&#39;trained_models&#39;</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">trained model dictionary saved in </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">PATH</span><span class="p">)</span>
    <span class="k">return</span>  <span class="n">model</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="see-if-trainig-works-on-t-ratio">
<h2>See if trainig works on T ratio<a class="headerlink" href="#see-if-trainig-works-on-t-ratio" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">IQN_trace</span><span class="o">=</span><span class="p">([],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[])</span>
<span class="n">traces_step</span> <span class="o">=</span> <span class="mi">800</span>
<span class="n">traces_window</span><span class="o">=</span><span class="n">traces_step</span>
<span class="n">n_iterations</span><span class="o">=</span><span class="mi">100000</span>
<span class="n">IQN</span> <span class="o">=</span> <span class="n">run</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span><span class="n">train_x</span><span class="o">=</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_t</span><span class="o">=</span><span class="n">train_t_ratio</span><span class="p">,</span> 
        <span class="n">valid_x</span><span class="o">=</span><span class="n">test_x</span><span class="p">,</span> <span class="n">valid_t</span><span class="o">=</span><span class="n">test_t_ratio</span><span class="p">,</span> <span class="n">traces</span><span class="o">=</span><span class="n">IQN_trace</span><span class="p">,</span> <span class="n">n_batch</span><span class="o">=</span><span class="n">BATCHSIZE</span><span class="p">,</span> 
        <span class="n">n_iterations</span><span class="o">=</span><span class="n">n_iterations</span><span class="p">,</span> <span class="n">traces_step</span><span class="o">=</span><span class="n">traces_step</span><span class="p">,</span> <span class="n">traces_window</span><span class="o">=</span><span class="n">traces_window</span><span class="p">,</span>
        <span class="n">save_model</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>training IQN to estimate RecoDatam
Iteration vs average loss
 iteration	 train-set	  test-set
         0	  0.383932	  0.383932
     99200	  0.273795	  0.273795	  0.273795
Iteration vs average loss
 iteration	 train-set	  test-set
    199200	  0.273961	  0.273961	  0.273961
training target RecoDatam using &#39;run&#39; in 614.7817 secs
</pre></div>
</div>
</div>
</div>
</section>
<section id="save-trained-model-if-its-good-and-if-you-haven-t-saved-above-and-load-trained-model-if-you-saved-it">
<h2>Save trained model (if its good, and if you haven’t saved above) and load trained model (if you saved it)<a class="headerlink" href="#save-trained-model-if-its-good-and-if-you-haven-t-saved-above-and-load-trained-model-if-you-saved-it" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;Trained_IQNx4_</span><span class="si">%s</span><span class="s1">_</span><span class="si">%s</span><span class="s1">K_iter.dict&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_iterations</span><span class="o">/</span><span class="mi">1000</span><span class="p">))</span> <span class="p">)</span>
<span class="n">trained_models_dir</span><span class="o">=</span><span class="s1">&#39;trained_models&#39;</span>
<span class="n">mkdir</span><span class="p">(</span><span class="n">trained_models_dir</span><span class="p">)</span>
<span class="n">PATH</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">IQN_BASE</span><span class="p">,</span><span class="n">trained_models_dir</span> <span class="p">,</span> <span class="n">filename</span><span class="p">)</span>

<span class="nd">@debug</span>
<span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">trained model dictionary saved in </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">PATH</span><span class="p">)</span>

<span class="nd">@debug</span>
<span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="n">PATH</span><span class="p">):</span>
    <span class="c1"># n_layers = int(BEST_PARAMS[&quot;n_layers&quot;]) </span>
    <span class="c1"># hidden_size = int(BEST_PARAMS[&quot;hidden_size&quot;])</span>
    <span class="c1"># dropout = float(BEST_PARAMS[&quot;dropout&quot;])</span>
    <span class="c1"># optimizer_name = BEST_PARAMS[&quot;optimizer_name&quot;].to_string().split()[1]</span>
    <span class="c1"># learning_rate =  float(BEST_PARAMS[&quot;learning_rate&quot;])</span>
    <span class="c1"># batch_size = int(BEST_PARAMS[&quot;batch_size&quot;])</span>
    <span class="n">model</span> <span class="o">=</span>  <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
        <span class="n">nfeatures</span><span class="o">=</span><span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
        <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">nlayers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span> 
        <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> 
        <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span>
        <span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span> <span class="p">)</span>
    <span class="c1">#OR</span>
    <span class="c1">#model=torch.load(PATH)#BUT HERE IT WILL BE A DICT (CANT BE EVALUATED RIGHT AWAY) DISCOURAGED!</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">save_model</span><span class="p">(</span><span class="n">IQN</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Calling save_model(RegularizedRegressionModel(
  (model): Sequential(
    (0): Linear(in_features=5, out_features=20, bias=True)
    (1): Dropout(p=0.141346858975224, inplace=False)
    (2): LeakyReLU(negative_slope=0.01)
    (3): Linear(in_features=20, out_features=20, bias=True)
    (4): LeakyReLU(negative_slope=0.01)
    (5): Linear(in_features=20, out_features=20, bias=True)
    (6): LeakyReLU(negative_slope=0.01)
    (7): Linear(in_features=20, out_features=1, bias=True)
  )
))
RegularizedRegressionModel(
  (model): Sequential(
    (0): Linear(in_features=5, out_features=20, bias=True)
    (1): Dropout(p=0.141346858975224, inplace=False)
    (2): LeakyReLU(negative_slope=0.01)
    (3): Linear(in_features=20, out_features=20, bias=True)
    (4): LeakyReLU(negative_slope=0.01)
    (5): Linear(in_features=20, out_features=20, bias=True)
    (6): LeakyReLU(negative_slope=0.01)
    (7): Linear(in_features=20, out_features=1, bias=True)
  )
)

trained model dictionary saved in /home/ali/Desktop/Pulled_Github_Repositories/torchQN/trained_models/Trained_IQNx4_RecoDatam_100K_iter.dict
&#39;save_model&#39; returned None
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">IQN</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RegularizedRegressionModel(
  (model): Sequential(
    (0): Linear(in_features=5, out_features=20, bias=True)
    (1): Dropout(p=0.141346858975224, inplace=False)
    (2): LeakyReLU(negative_slope=0.01)
    (3): Linear(in_features=20, out_features=20, bias=True)
    (4): LeakyReLU(negative_slope=0.01)
    (5): Linear(in_features=20, out_features=20, bias=True)
    (6): LeakyReLU(negative_slope=0.01)
    (7): Linear(in_features=20, out_features=1, bias=True)
  )
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">valid_t_ratio</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;post-z ratio target&#39;</span><span class="p">);</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NFEATURES</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">valid_x</span><span class="p">[:,</span><span class="n">i</span><span class="p">],</span> <span class="n">label</span> <span class="o">=</span><span class="sa">f</span><span class="s2">&quot;feature </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.35</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1_Setup_and_Preprocess_88_0.svg" src="_images/1_Setup_and_Preprocess_88_0.svg" /></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">simple_eval</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">valid_x_tensor</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">valid_x</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">IQN</span><span class="p">(</span><span class="n">valid_x_tensor</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">label</span><span class="o">=</span><span class="n">FIELDS</span><span class="p">[</span><span class="n">target</span><span class="p">][</span><span class="s1">&#39;ylabel&#39;</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Predicted post-z ratio for </span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">orig_ratio</span> <span class="o">=</span> <span class="n">z</span><span class="p">(</span><span class="n">T</span><span class="p">(</span><span class="s1">&#39;m&#39;</span><span class="p">,</span> <span class="n">scaled_df</span><span class="o">=</span><span class="n">train_data_m</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">orig_ratio</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">orig_ratio</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;original post-z ratio for </span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
    <span class="n">set_axes</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;predicted $T$&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;predicted ratio shape: &#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span>
    
<span class="n">p</span> <span class="o">=</span> <span class="n">simple_eval</span><span class="p">(</span><span class="n">IQN</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    0.479708
1    0.453907
2    0.453907
3    0.453907
4    0.099661
dtype: float64
predicted ratio shape:  (1000000, 1)
</pre></div>
</div>
<img alt="_images/1_Setup_and_Preprocess_89_2.svg" src="_images/1_Setup_and_Preprocess_89_2.svg" /></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># IQN.eval()</span>
<span class="c1"># valid_x_tensor=torch.from_numpy(valid_x).float()</span>
<span class="c1"># pred = IQN(valid_x_tensor)</span>
<span class="c1"># p = pred.detach().numpy()</span>
<span class="c1"># plt.hist(p, label=&#39;predicted $T$ ratio&#39;);plt.legend();plt.show()</span>
</pre></div>
</div>
</div>
</div>
<div class="math notranslate nohighlight">
\[
        f_{\text{IQN}} (\mathcal{O}) =  z \left( \frac{\mathbb{L} (\mathcal{O}^{\text{reco}}) +10 }{\mathbb{L}(\mathcal{O}^{\text{gen}}) +10} \right),
\]</div>
<p>So, to de-scale, (for our observable <span class="math notranslate nohighlight">\(\mathcal{O}=m\)</span> ),</p>
<div class="math notranslate nohighlight">
\[
    m^{\text{predicted}} = \mathbb{L}^{-1} \left[ z^{-1} (f_{\text{IQN}} ) \left[ \mathbb{L} (m^\text{gen})+10 \right] -10 \right]
\]</div>
<p>Note that <span class="math notranslate nohighlight">\(z^{-1} (f_{\text{IQN}} )\)</span> should use the mean and std of the ratio thing for the target</p>
<div class="math notranslate nohighlight">
\[z^{-1} (f_{\text{IQN}} ) = z^{-1}\left( y_{pred}, \text{mean}=\text{mean}(\mathbb{T}(\text{target_variable})), std=std (\mathbb{T}(\text{target_variable} ) \right)\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">z_inverse</span><span class="p">(</span><span class="n">xprime</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">xprime</span> <span class="o">*</span> <span class="n">std</span> <span class="o">+</span> <span class="n">mean</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">recom_unsc_mean</span><span class="o">=</span><span class="n">TEST_SCALE_DICT</span><span class="p">[</span><span class="n">target</span><span class="p">][</span><span class="s1">&#39;mean&#39;</span><span class="p">]</span>
<span class="n">recom_unsc_std</span><span class="o">=</span><span class="n">TEST_SCALE_DICT</span><span class="p">[</span><span class="n">target</span><span class="p">][</span><span class="s1">&#39;std&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">recom_unsc_mean</span><span class="p">,</span><span class="n">recom_unsc_std</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5.554066938043617 2.644892802850232
</pre></div>
</div>
</div>
</div>
<p>Get unscaled dataframe again, just to verify</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">raw_train_data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span><span class="s1">&#39;train_data_10M_2.csv&#39;</span><span class="p">),</span>
                      <span class="n">usecols</span><span class="o">=</span><span class="n">all_cols</span><span class="p">,</span>
                      <span class="n">nrows</span><span class="o">=</span><span class="n">SUBSAMPLE</span>
                      <span class="p">)</span>

<span class="n">raw_test_data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span><span class="s1">&#39;test_data_10M_2.csv&#39;</span><span class="p">),</span>
                      <span class="n">usecols</span><span class="o">=</span><span class="n">all_cols</span><span class="p">,</span>
                     <span class="n">nrows</span><span class="o">=</span><span class="n">SUBSAMPLE</span>
                     <span class="p">)</span>
<span class="n">raw_test_data</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
<span class="n">m_reco</span> <span class="o">=</span> <span class="n">raw_test_data</span><span class="p">[</span><span class="s1">&#39;RecoDatam&#39;</span><span class="p">]</span>
<span class="n">m_gen</span> <span class="o">=</span> <span class="n">raw_test_data</span><span class="p">[</span><span class="s1">&#39;genDatam&#39;</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">m_reco</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$m_</span><span class="si">{gen}</span><span class="s1">^{test \ data}$&#39;</span><span class="p">);</span><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1_Setup_and_Preprocess_95_0.svg" src="_images/1_Setup_and_Preprocess_95_0.svg" /></div>
</div>
<p>Apply the descaling formula for our observable</p>
<div class="math notranslate nohighlight">
\[
    m^{\text{predicted}} = \mathbb{L}^{-1} \left[ z^{-1} (f_{\text{IQN}} ) \left[ \mathbb{L} (m^\text{gen})+10 \right] -10 \right]
\]</div>
<ul class="simple">
<li><p>First, calculate <span class="math notranslate nohighlight">\(z^{-1} (f_{\text{IQN}} )\)</span></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">valid_t_ratio</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">valid_t_ratio</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(8000000,) [0.47970804 0.45390654 0.45390654 0.45390654 0.09966065]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">orig_ratio</span> <span class="o">=</span> <span class="n">T</span><span class="p">(</span><span class="s1">&#39;m&#39;</span><span class="p">,</span> <span class="n">scaled_df</span><span class="o">=</span><span class="n">train_data_m</span><span class="p">)</span>
<span class="n">orig_ratio</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    0.995290
1    0.994742
2    0.994742
3    0.994742
4    0.987216
dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">z_inv_f</span> <span class="o">=</span><span class="n">z_inverse</span><span class="p">(</span><span class="n">xprime</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">orig_ratio</span><span class="p">),</span> <span class="n">std</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">orig_ratio</span><span class="p">))</span>
<span class="n">z_inv_f</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[1.010673  ],
       [1.0099984 ],
       [0.98119617],
       [0.97980946],
       [0.98448396]], dtype=float32)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Now</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbb{L}(\mathcal{O^{\text{gen}}}) = \mathbb{L} (m^{\text{gen}})\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">L_obs</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">orig_observable</span><span class="o">=</span><span class="n">m_gen</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;m&#39;</span><span class="p">)</span>
<span class="n">L_obs</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([2.07104388, 2.07104388, 2.24205984, 2.28661525, 1.97173801])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">L_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">z_inv_f</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1000000,) (1000000, 1)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">z_inv_f</span> <span class="o">=</span> <span class="n">z_inv_f</span><span class="o">.</span><span class="n">flatten</span><span class="p">();</span><span class="nb">print</span><span class="p">(</span><span class="n">z_inv_f</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1000000,)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>“factor” <span class="math notranslate nohighlight">\( = z^{-1} (f_{\text{IQN}} ) \left[ \mathbb{L} (m^\text{gen})+10 \right] -10 \)</span></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">factor</span> <span class="o">=</span> <span class="p">(</span><span class="n">z_inv_f</span> <span class="o">*</span> <span class="p">(</span><span class="n">L_obs</span>  <span class="o">+</span> <span class="mi">10</span><span class="p">)</span> <span class="p">)</span><span class="o">-</span><span class="mi">10</span>
<span class="n">factor</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([2.19987869, 2.1917355 , 2.01186217, 2.03854189, 1.78598401])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m_pred</span> <span class="o">=</span> <span class="n">L_inverse</span><span class="p">(</span><span class="n">L_observable</span><span class="o">=</span><span class="n">factor</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;m&#39;</span><span class="p">)</span>
<span class="c1"># pT_pred=get_finite(pT_pred)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m_pred</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([7.02391872, 6.95073361, 5.47722825, ..., 2.41978714, 3.13010808,
       5.48240938])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">m_pred</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;predicted&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">m_reco</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$m_</span><span class="si">{reco}</span><span class="s1">^{test \ data}$&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">);</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1_Setup_and_Preprocess_108_0.svg" src="_images/1_Setup_and_Preprocess_108_0.svg" /></div>
</div>
<hr class="docutils" />
<section id="paper-plotting">
<h3>Paper plotting<a class="headerlink" href="#paper-plotting" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">range_</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">25</span><span class="p">]</span>
<span class="n">bins</span><span class="o">=</span><span class="mi">50</span>
<span class="n">data</span><span class="o">=</span><span class="n">raw_train_data</span>
<span class="n">YLIM</span><span class="o">=</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span><span class="mf">1.2</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="s1">&#39;RecoDatapT&#39;</span><span class="p">,</span><span class="s1">&#39;RecoDataeta&#39;</span><span class="p">,</span><span class="s1">&#39;RecoDataphi&#39;</span><span class="p">,</span><span class="s1">&#39;RecoDatam&#39;</span><span class="p">]]</span>
<span class="n">data</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;realpT&#39;</span><span class="p">,</span><span class="s1">&#39;realeta&#39;</span><span class="p">,</span><span class="s1">&#39;realphi&#39;</span><span class="p">,</span><span class="s1">&#39;realm&#39;</span><span class="p">]</span>
<span class="n">REAL_DIST</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;realm&#39;</span><span class="p">]</span>
<span class="n">norm_data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">AUTOREGRESSIVE_DIST</span> <span class="o">=</span> <span class="n">m_pred</span>
<span class="n">norm_IQN</span><span class="o">=</span><span class="n">AUTOREGRESSIVE_DIST</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">norm_autoregressive</span><span class="o">=</span><span class="n">AUTOREGRESSIVE_DIST</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">norm_IQN</span><span class="o">=</span><span class="n">norm_autoregressive</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;norm_data&#39;</span><span class="p">,</span><span class="n">norm_data</span><span class="p">,</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">norm IQN&#39;</span><span class="p">,</span><span class="n">norm_IQN</span><span class="p">,</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">norm_autoregressive&#39;</span><span class="p">,</span> <span class="n">norm_autoregressive</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>norm_data 8000000 
norm IQN 1000000 
norm_autoregressive 1000000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_hist</span><span class="p">(</span><span class="n">label</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;label could be &quot;pT&quot;, &quot;eta&quot;, &quot;phi&quot;, &quot;m&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">predicted_label_counts</span><span class="p">,</span> <span class="n">label_edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">JETS_DICT</span><span class="p">[</span><span class="s1">&#39;Predicted_RecoData&#39;</span><span class="o">+</span><span class="n">label</span><span class="p">][</span><span class="s1">&#39;dist&#39;</span><span class="p">],</span> 
    <span class="nb">range</span><span class="o">=</span><span class="n">JETS_DICT</span><span class="p">[</span><span class="s1">&#39;Predicted_RecoData&#39;</span><span class="o">+</span><span class="n">label</span><span class="p">][</span><span class="s1">&#39;range&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">)</span>
    <span class="n">real_label_counts</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">JETS_DICT</span><span class="p">[</span><span class="s1">&#39;Real_RecoData&#39;</span><span class="o">+</span><span class="n">label</span><span class="p">][</span><span class="s1">&#39;dist&#39;</span><span class="p">],</span> 
    <span class="nb">range</span><span class="o">=</span><span class="n">JETS_DICT</span><span class="p">[</span><span class="s1">&#39;Real_RecoData&#39;</span><span class="o">+</span><span class="n">label</span><span class="p">][</span><span class="s1">&#39;range&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">)</span>
    <span class="n">label_edges</span> <span class="o">=</span> <span class="n">label_edges</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">/</span><span class="mi">2</span><span class="o">+</span><span class="n">label_edges</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span>

    <span class="k">return</span> <span class="n">real_label_counts</span><span class="p">,</span> <span class="n">predicted_label_counts</span><span class="p">,</span> <span class="n">label_edges</span>

<span class="k">def</span> <span class="nf">get_hist_simple</span><span class="p">(</span><span class="n">label</span><span class="p">):</span>
    <span class="n">predicted_label_counts</span><span class="p">,</span> <span class="n">label_edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">m_pred</span> <span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="n">range_</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">)</span>
    <span class="n">real_label_counts</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">REAL_DIST</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="n">range_</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">)</span>
    <span class="n">label_edges</span> <span class="o">=</span> <span class="n">label_edges</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">/</span><span class="mi">2</span><span class="o">+</span><span class="n">label_edges</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span>
    <span class="k">return</span> <span class="n">real_label_counts</span><span class="p">,</span> <span class="n">predicted_label_counts</span><span class="p">,</span> <span class="n">label_edges</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">real_label_counts_m</span><span class="p">,</span> <span class="n">predicted_label_counts_m</span><span class="p">,</span> <span class="n">label_edges_m</span> <span class="o">=</span> <span class="n">get_hist_simple</span><span class="p">(</span><span class="s1">&#39;m&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_one_m</span><span class="p">():</span>
    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">3.5</span><span class="o">*</span><span class="mi">3</span><span class="o">/</span><span class="mf">2.5</span><span class="p">,</span><span class="mf">3.8</span><span class="p">),</span> <span class="n">gridspec_kw</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;height_ratios&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mf">0.5</span><span class="p">]})</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">label_edges_m</span><span class="p">,</span> <span class="n">real_label_counts_m</span><span class="o">/</span><span class="n">norm_data</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="s2">&quot;mid&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span><span class="c1"># step real_count_pt</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">label_edges_m</span><span class="p">,</span> <span class="n">predicted_label_counts_m</span><span class="o">/</span><span class="n">norm_IQN</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="s2">&quot;mid&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#D7301F&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span><span class="c1"># step predicted_count_pt</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">label_edges_m</span><span class="p">,</span> <span class="n">real_label_counts_m</span><span class="o">/</span><span class="n">norm_data</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;reco&quot;</span><span class="p">,</span>  <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span><span class="n">facecolors</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">label_edges_m</span><span class="p">,</span><span class="n">predicted_label_counts_m</span><span class="o">/</span><span class="n">norm_IQN</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;predicted sbatch 1&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#D7301F&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">range_</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">predicted_label_counts_m</span><span class="o">/</span><span class="n">norm_IQN</span><span class="p">)</span><span class="o">*</span><span class="mf">1.1</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;counts&quot;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([])</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>

    <span class="n">ratio</span><span class="o">=</span><span class="p">(</span><span class="n">predicted_label_counts_m</span><span class="o">/</span><span class="n">norm_IQN</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">real_label_counts_m</span><span class="o">/</span><span class="n">norm_data</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">label_edges_m</span><span class="p">,</span> <span class="n">ratio</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span><span class="c1">#PREDICTED (IQN)/Reco (Data)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">label_edges_m</span><span class="p">,</span> <span class="n">ratio</span><span class="o">/</span><span class="n">ratio</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span><span class="n">facecolors</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">range_</span><span class="p">)</span>
    <span class="c1"># ax2.set_xlabel(labels[3])</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\frac{\textnormal</span><span class="si">{predicted}</span><span class="s2">}{\textnormal</span><span class="si">{reco}</span><span class="s2">}$&quot;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">((</span><span class="n">YLIM</span><span class="p">))</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">range_</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="c1"># plt.savefig(DIR+&#39;AUTOREGRESSIVE_m_TUNEND_MLP_OCT_18.pdf&#39;)</span>
    <span class="c1">#   plt.savefig(&#39;images/all_m_g2r.pdf&#39;)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span> 
    <span class="c1"># fig.show()</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_position</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_one_m</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1_Setup_and_Preprocess_114_0.svg" src="_images/1_Setup_and_Preprocess_114_0.svg" /></div>
</div>
<hr class="docutils" />
<hr class="docutils" />
<hr class="docutils" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">target</span><span class="o">==</span> <span class="s1">&#39;RecoDatapT&#39;</span><span class="p">:</span>
    <span class="n">label</span><span class="o">=</span> <span class="s1">&#39;$p_T$ [GeV]&#39;</span>
    <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">60</span>
<span class="k">elif</span> <span class="n">target</span><span class="o">==</span> <span class="s1">&#39;RecoDataeta&#39;</span><span class="p">:</span>
    <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;$\eta$&#39;</span>
    <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="o">-</span><span class="mf">5.4</span><span class="p">,</span> <span class="mf">5.4</span>
<span class="k">elif</span> <span class="n">target</span> <span class="o">==</span><span class="s1">&#39;RecoDataphi&#39;</span><span class="p">:</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$\phi$&#39;</span>
    <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="o">-</span><span class="mf">3.4</span><span class="p">,</span> <span class="mf">3.4</span>
<span class="k">elif</span> <span class="n">target</span> <span class="o">==</span> <span class="s1">&#39;RecoDatam&#39;</span><span class="p">:</span>
    <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39; $m$ [GeV]&#39;</span>
    <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">18</span>


    
<span class="k">def</span> <span class="nf">evaluate_model</span><span class="p">(</span><span class="n">dnn</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span>
               <span class="n">fgsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> 
               <span class="n">ftsize</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">save_image</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">save_pred</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
               <span class="n">show_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">eval_data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span><span class="s1">&#39;test_data_10M_2.csv&#39;</span><span class="p">))</span>
    <span class="n">ev_features</span><span class="o">=</span><span class="n">X</span>
    <span class="c1">#[&#39;genDatapT&#39;, &#39;genDataeta&#39;, &#39;genDataphi&#39;, &#39;genDatam&#39;,&#39;tau&#39;]</span>
    
    <span class="n">eval_data</span><span class="o">=</span><span class="n">eval_data</span><span class="p">[</span><span class="n">ev_features</span><span class="p">]</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;EVALUATION DATA OLD INDEX</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">eval_data</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

    

                            
    <span class="n">dnn</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">dnn</span><span class="p">(</span><span class="n">eval_data</span><span class="p">)</span>
    <span class="n">eval_data</span><span class="p">[</span><span class="s1">&#39;RecoDatam&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">y</span>
    <span class="n">new_cols</span><span class="o">=</span> <span class="p">[</span><span class="s1">&#39;RecoDatam&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span>
    <span class="n">eval_data</span><span class="o">=</span><span class="n">eval_data</span><span class="o">.</span><span class="n">reindex</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">new_cols</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;EVALUATION DATA NEW INDEX</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">eval_data</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

    <span class="n">eval_data</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;AUTOREGRESSIVE_m_Prime.csv&#39;</span><span class="p">)</span>


    <span class="k">if</span> <span class="n">save_pred</span><span class="p">:</span>
        <span class="n">pred_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="n">T</span><span class="o">+</span><span class="s1">&#39;_predicted&#39;</span><span class="p">:</span><span class="n">y</span><span class="p">})</span>
        <span class="n">pred_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;predicted_data/dataset2/&#39;</span><span class="o">+</span><span class="n">T</span><span class="o">+</span><span class="s1">&#39;_predicted_MLP_iter_5000000.csv&#39;</span><span class="p">)</span>
        
    <span class="k">if</span> <span class="n">save_image</span> <span class="ow">or</span> <span class="n">show_plot</span><span class="p">:</span>
        <span class="n">gfile</span> <span class="o">=</span><span class="s1">&#39;fig_model_</span><span class="si">%s</span><span class="s1">.png&#39;</span> <span class="o">%</span> <span class="n">target</span>
        <span class="n">xbins</span> <span class="o">=</span> <span class="mi">100</span>
        <span class="n">xmin</span>  <span class="o">=</span> <span class="n">src</span><span class="p">[</span><span class="s1">&#39;xmin&#39;</span><span class="p">]</span>
        <span class="n">xmax</span>  <span class="o">=</span> <span class="n">src</span><span class="p">[</span><span class="s1">&#39;xmax&#39;</span><span class="p">]</span>
        <span class="n">xlabel</span><span class="o">=</span> <span class="n">src</span><span class="p">[</span><span class="s1">&#39;xlabel&#39;</span><span class="p">]</span>
        <span class="n">xstep</span> <span class="o">=</span> <span class="p">(</span><span class="n">xmax</span> <span class="o">-</span> <span class="n">xmin</span><span class="p">)</span><span class="o">/</span><span class="n">xbins</span>

        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="n">fgsize</span><span class="p">)</span>
        
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">ftsize</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;reco jet &#39;</span><span class="o">+</span><span class="n">label</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">ftsize</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">y_label_dict</span><span class="p">[</span><span class="n">target</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">ftsize</span><span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="s1">&#39;RecoDatam&#39;</span><span class="p">],</span> 
                <span class="n">bins</span><span class="o">=</span><span class="n">xbins</span><span class="p">,</span> 
                <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">),</span> 
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> 
                <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> 
                <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                <span class="n">label</span><span class="o">=</span><span class="s1">&#39;simulation&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> 
                <span class="n">bins</span><span class="o">=</span><span class="n">xbins</span><span class="p">,</span> 
                <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">),</span> 
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> 
                <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> 
                <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$y^\prime$&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        
        
        <span class="k">if</span> <span class="n">save_image</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;images/&#39;</span><span class="o">+</span><span class="n">T</span><span class="o">+</span><span class="s1">&#39;IQN_Consecutive_&#39;</span><span class="o">+</span><span class="n">N</span><span class="o">+</span><span class="s1">&#39;.png&#39;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;images/&#39;</span><span class="o">+</span><span class="n">T</span><span class="o">+</span><span class="s1">&#39;IQN_Consecutive_&#39;</span><span class="o">+</span><span class="n">N</span><span class="o">+</span><span class="s1">&#39;.png&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">show_plot</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="c1">##########</span>
<span class="c1">################################################CNN</span>







<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">start</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;estimating mass</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span>  <span class="n">utils</span><span class="o">.</span><span class="n">RegularizedRegressionModel</span><span class="p">(</span><span class="n">nfeatures</span><span class="o">=</span><span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">nlayers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">n_hidden</span><span class="p">)</span>
    <span class="n">traces</span> <span class="o">=</span> <span class="p">([],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[])</span>
    <span class="n">dnn</span> <span class="o">=</span> <span class="n">run</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">scalers</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">train_t</span><span class="p">,</span> <span class="n">valid_x</span><span class="p">,</span> <span class="n">valid_t</span><span class="p">,</span> <span class="n">traces</span><span class="p">)</span>
    <span class="n">evaluate_model</span><span class="p">(</span> <span class="n">dnn</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">source</span><span class="p">)</span>



<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>estimating mass
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_282404</span><span class="o">/</span><span class="mf">1611009616.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">    </span><span class="mi">102</span> 
<span class="g g-Whitespace">    </span><span class="mi">103</span> <span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">104</span>     <span class="n">main</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">105</span> 

<span class="nn">/tmp/ipykernel_282404/1611009616.py</span> in <span class="ni">main</span><span class="nt">()</span>
<span class="g g-Whitespace">     </span><span class="mi">96</span>     <span class="n">model</span> <span class="o">=</span>  <span class="n">utils</span><span class="o">.</span><span class="n">RegularizedRegressionModel</span><span class="p">(</span><span class="n">nfeatures</span><span class="o">=</span><span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">nlayers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">n_hidden</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">97</span>     <span class="n">traces</span> <span class="o">=</span> <span class="p">([],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[])</span>
<span class="ne">---&gt; </span><span class="mi">98</span>     <span class="n">dnn</span> <span class="o">=</span> <span class="n">run</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">scalers</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">train_t</span><span class="p">,</span> <span class="n">valid_x</span><span class="p">,</span> <span class="n">valid_t</span><span class="p">,</span> <span class="n">traces</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">99</span>     <span class="n">evaluate_model</span><span class="p">(</span> <span class="n">dnn</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">source</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">100</span> 

<span class="ne">NameError</span>: name &#39;scalers&#39; is not defined
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="plot-predicted-vs-real-reco-in-our-paper-s-format">
<h1>Plot predicted vs real reco (in our paper’s format)<a class="headerlink" href="#plot-predicted-vs-real-reco-in-our-paper-s-format" title="Permalink to this headline">#</a></h1>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="train-p-t-using-saved-variables-above">
<h1>Train <span class="math notranslate nohighlight">\(p_T\)</span> using saved variables above<a class="headerlink" href="#train-p-t-using-saved-variables-above" title="Permalink to this headline">#</a></h1>
<p>Evaluate <span class="math notranslate nohighlight">\(p_T\)</span> and save predicted distribution</p>
<p>Plot reco <span class="math notranslate nohighlight">\(p_T\)</span> and  predicted reco <span class="math notranslate nohighlight">\(p_T\)</span> marginal densities</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># show_jupyter_image(&#39;screenshot.png&#39;)</span>
</pre></div>
</div>
</div>
</div>
<!-- > I guess it works now --><p>commented new ideas below</p>
<!-- ### Ideas for a future paper

me and Harrison would like to use this method for on-the-fly stochastic folding of events in MC generators (potentially even including CMSSW formats like [nanoaod](https://github.com/cms-nanoAOD/nanoAOD-tools), such as in Madminer (but using IQN as opposed to Delphes for detector simulation) for any observable. This also beings the possibility of using LFI methods for much better inference on models (such as SMEFT) using any observable post-detector simulation. If you're interested in helping out on this, me and Harrison would like to do most of the code/ideas, but your occasional ideas/input would be incredibly valuable! --></section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="intro.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Welcome to the <em>torchIQNx4</em></p>
        </div>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ali Al Kadhim<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>