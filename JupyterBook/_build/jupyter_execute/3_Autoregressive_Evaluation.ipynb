{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37d6920b-1452-45a8-8751-0b7d6e8e8fd0",
   "metadata": {},
   "source": [
    "# IQNx4: Chapter 3: Autoregressive Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c623666-defa-4463-adfe-f7667c7d385d",
   "metadata": {},
   "source": [
    "## 3.1: Imports and Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31994c2b-a804-4348-a5a9-8bd8c89ff64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using torch version 1.11.0.post2\n",
      "matplotlib version=  3.5.3\n",
      "using (optional) optuna version 3.0.0\n",
      "BASE directoy properly set =  /home/ali/Desktop/Pulled_Github_Repositories/torchQN\n",
      "using torch version 1.11.0.post2\n",
      "matplotlib version=  3.5.3\n",
      "using (optional) optuna version 3.0.0\n",
      "BASE directoy properly set =  /home/ali/Desktop/Pulled_Github_Repositories/torchQN\n",
      "DATA directory also properly set, in /home/ali/Desktop/Pulled_Github_Repositories/IQN_HEP/Davidson/data\n",
      "DATA directory also properly set, in /home/ali/Desktop/Pulled_Github_Repositories/IQN_HEP/Davidson/data\n",
      "BASE directoy properly set =  /home/ali/Desktop/Pulled_Github_Repositories/torchQN\n",
      "using DATA_DIR=/home/ali/Desktop/Pulled_Github_Repositories/IQN_HEP/Davidson/data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_68922/2263036294.py:54: MatplotlibDeprecationWarning: Support for setting an rcParam that expects a str value to a non-str value is deprecated since 3.5 and support will be removed two minor releases later.\n",
      "  mp.rcParams[\"text.latex.preamble\"] = [r\"\\usepackage{amsmath}\"]  # for \\text command\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import scipy as sp; import scipy.stats as st\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "print(f\"using torch version {torch.__version__}\")\n",
    "# use numba's just-in-time compiler to speed things up\n",
    "# from numba import njit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib as mp\n",
    "\n",
    "print(\"matplotlib version= \", mp.__version__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# reset matplotlib stle/parameters\n",
    "# reset matplotlib parameters to their defaults\n",
    "# plt.style.use('seaborn-deep')\n",
    "# mp.rcParams['agg.path.chunksize'] = 10000\n",
    "font_legend = 15\n",
    "font_axes = 15\n",
    "# %matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# from IPython.display import Image, display\n",
    "# from importlib import import_module\n",
    "# import plotly\n",
    "try:\n",
    "    import optuna\n",
    "\n",
    "    print(f\"using (optional) optuna version {optuna.__version__}\")\n",
    "except Exception:\n",
    "    print(\"optuna is only used for hyperparameter tuning, not critical!\")\n",
    "    pass\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "# import sympy as sy\n",
    "# import ipywidgets as wid;\n",
    "\n",
    "# update fonts\n",
    "font = {\"family\": \"serif\", \"size\": 10}\n",
    "mp.rc(\"font\", **font)\n",
    "\n",
    "# set usetex = False if LaTex is not\n",
    "# available on your system or if the\n",
    "# rendering is too slow\n",
    "mp.rcParams.update({\"text.usetex\": True})\n",
    "# plt.rcParams['text.usetex'] = True\n",
    "mp.rcParams[\"text.latex.preamble\"] = [r\"\\usepackage{amsmath}\"]  # for \\text command\n",
    "\n",
    "\n",
    "# set a seed to ensure reproducibility\n",
    "# seed = 128\n",
    "# rnd  = np.random.RandomState(seed)\n",
    "# sometimes jupyter doesnt initialize MathJax automatically for latex, so do this:\n",
    "\n",
    "try:\n",
    "    IQN_BASE = os.environ[\"IQN_BASE\"]\n",
    "    print(\"BASE directoy properly set = \", IQN_BASE)\n",
    "    utils_dir = os.path.join(IQN_BASE, 'utils/')\n",
    "    sys.path.append(utils_dir)\n",
    "    import utils\n",
    "\n",
    "    # usually its not recommended to import everything from a module, but we know\n",
    "    # whats in it so its fine\n",
    "    # from utils import *\n",
    "    print(\"DATA directory also properly set, in %s\" % os.environ[\"DATA_DIR\"])\n",
    "except Exception:\n",
    "    # IQN_BASE=os.getcwd()\n",
    "    print(\n",
    "        \"\"\"\\nBASE directory not properly set. Read repo README.    If you need a function from utils, use the decorator below, or add utils to sys.path\\n\n",
    "    You can also do \n",
    "    os.environ['IQN_BASE']=<ABSOLUTE PATH FOR THE IQN REPO>\n",
    "    or\n",
    "    os.environ['IQN_BASE']=os.getcwd()\"\"\"\n",
    "    )\n",
    "    pass\n",
    "\n",
    "\n",
    "IQN_BASE = os.environ[\"IQN_BASE\"]\n",
    "print(\"BASE directoy properly set = \", IQN_BASE)\n",
    "utils_dir = os.path.join(IQN_BASE, \"utils/\")\n",
    "sys.path.append(utils_dir)\n",
    "# usually its not recommended to import everything from a module, but we know\n",
    "# whats in it so its fine\n",
    "\n",
    "# or use joblib for caching on disk\n",
    "from joblib import Memory\n",
    "\n",
    "\n",
    "################################### CONFIGURATIONS ###################################\n",
    "DATA_DIR = os.environ[\"DATA_DIR\"]\n",
    "print(f\"using DATA_DIR={DATA_DIR}\")\n",
    "JUPYTER = False\n",
    "use_subsample = False\n",
    "# use_subsample=True\n",
    "if use_subsample:\n",
    "    SUBSAMPLE = int(\n",
    "        1e5\n",
    "    )  # subsample use for development - in production use whole dataset\n",
    "else:\n",
    "    SUBSAMPLE = None\n",
    "\n",
    "memory = Memory(DATA_DIR)\n",
    "\n",
    "\n",
    "###############################################################################################\n",
    "y_label_dict = {\n",
    "    \"RecoDatapT\": \"$p(p_T)$\" + \" [ GeV\" + \"$^{-1} $\" + \"]\",\n",
    "    \"RecoDataeta\": \"$p(\\eta)$\",\n",
    "    \"RecoDataphi\": \"$p(\\phi)$\",\n",
    "    \"RecoDatam\": \"$p(m)$\" + \" [ GeV\" + \"$^{-1} $\" + \"]\",\n",
    "}\n",
    "\n",
    "loss_y_label_dict = {\n",
    "    \"RecoDatapT\": \"$p_T^{reco}$\",\n",
    "    \"RecoDataeta\": \"$\\eta^{reco}$\",\n",
    "    \"RecoDataphi\": \"$\\phi^{reco}$\",\n",
    "    \"RecoDatam\": \"$m^{reco}$\",\n",
    "}\n",
    "\n",
    "\n",
    "################################### SET DATA CONFIGURATIONS ###################################\n",
    "X = [\"genDatapT\", \"genDataeta\", \"genDataphi\", \"genDatam\", \"tau\"]\n",
    "\n",
    "# set order of training:\n",
    "# pT_first: pT->>m->eta->phi\n",
    "# m_first: m->pT->eta->phi\n",
    "\n",
    "\n",
    "ORDER = \"m_First\"\n",
    "\n",
    "if ORDER == \"m_First\":\n",
    "    FIELDS = {\n",
    "        \"RecoDatam\": {\n",
    "            \"inputs\": X,\n",
    "            \"xlabel\": r\"$m$ (GeV)\",\n",
    "            \"ylabel\": \"$m^{reco}$\",\n",
    "            \"xmin\": 0,\n",
    "            \"xmax\": 25,\n",
    "        },\n",
    "        \"RecoDatapT\": {\n",
    "            \"inputs\": [\"RecoDatam\"] + X,\n",
    "            \"xlabel\": r\"$p_T$ (GeV)\",\n",
    "            \"ylabel\": \"$p_T^{reco}$\",\n",
    "            \"xmin\": 20,\n",
    "            \"xmax\": 80,\n",
    "        },\n",
    "        \"RecoDataeta\": {\n",
    "            \"inputs\": [\"RecoDatam\", \"RecoDatapT\"] + X,\n",
    "            \"xlabel\": r\"$\\eta$\",\n",
    "            \"ylabel\": \"$\\eta^{reco}$\",\n",
    "            \"xmin\": -5,\n",
    "            \"xmax\": 5,\n",
    "        },\n",
    "        \"RecoDataphi\": {\n",
    "            \"inputs\": [\"RecoDatam\", \"RecoDatapT\", \"RecoDataeta\"] + X,\n",
    "            \"xlabel\": r\"$\\phi$\",\n",
    "            \"ylabel\": \"$\\phi^{reco}$\",\n",
    "            \"xmin\": -3.2,\n",
    "            \"xmax\": 3.2,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "# Load and explore raw (unscaled) dataframes\n",
    "\n",
    "\n",
    "all_variable_cols = [\n",
    "    \"genDatapT\",\n",
    "    \"genDataeta\",\n",
    "    \"genDataphi\",\n",
    "    \"genDatam\",\n",
    "    \"RecoDatapT\",\n",
    "    \"RecoDataeta\",\n",
    "    \"RecoDataphi\",\n",
    "    \"RecoDatam\",\n",
    "]\n",
    "all_cols = [\n",
    "    \"genDatapT\",\n",
    "    \"genDataeta\",\n",
    "    \"genDataphi\",\n",
    "    \"genDatam\",\n",
    "    \"RecoDatapT\",\n",
    "    \"RecoDataeta\",\n",
    "    \"RecoDataphi\",\n",
    "    \"RecoDatam\",\n",
    "    \"tau\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdb2b41-f128-45d0-993a-cfdd421b768d",
   "metadata": {},
   "source": [
    "## 3.2: Needed Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29814968-1591-409f-9655-42a962b5eddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features:\n",
      " ['genDatapT', 'genDataeta', 'genDataphi', 'genDatam', 'tau']\n",
      "\n",
      "Target =  RecoDatam\n",
      "USING NEW DATASET\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target = \"RecoDatam\"\n",
    "source = FIELDS[target]\n",
    "features = source[\"inputs\"]\n",
    "print(\"Training Features:\\n\", features)\n",
    "print(\"\\nTarget = \", target)\n",
    "AUTOREGRESSIVE_DIST_NAME = \"AUTOREGRESSIVE_m_Prime.csv\"\n",
    "print(\"USING NEW DATASET\\n\")\n",
    "######################################\n",
    "USE_BRADEN_SCALING = False\n",
    "#####################################\n",
    "################################### CONFIGURATIONS ###################################\n",
    "\n",
    "JUPYTER = True\n",
    "use_subsample = False\n",
    "# use_subsample = True\n",
    "if use_subsample:\n",
    "    SUBSAMPLE = int(\n",
    "        1e5\n",
    "    )  # subsample use for development - in production use whole dataset\n",
    "else:\n",
    "    SUBSAMPLE = None\n",
    "\n",
    "########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d3c5cc4-9f36-4642-b4c2-9fc9e3150955",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## Load unscaled dataframes ###################################\n",
    "@memory.cache\n",
    "def load_raw_data():\n",
    "    \"\"\"Dont use AUTOREGRESSIVE_DIST_NAME for training of any variable. \n",
    "    For mass evaluation: dont use AUTOREGRESSIVE_DIST_NAME. For pT evaluation use AUTOREGRESSIVE_DIST_NAME \n",
    "    as the distribution predicted by mass, etc.  \"\"\"\n",
    "    print(f\"\\nSUBSAMPLE = {SUBSAMPLE}\\n\")\n",
    "    raw_train_data = pd.read_csv(\n",
    "        os.path.join(DATA_DIR, \"train_data_10M_2.csv\"),\n",
    "        usecols=all_cols,\n",
    "        nrows=SUBSAMPLE,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    raw_valid_data = pd.read_csv(\n",
    "        os.path.join(DATA_DIR, \"validation_data_10M_2.csv\"),\n",
    "        usecols=all_cols,\n",
    "        nrows=SUBSAMPLE,\n",
    "    )\n",
    "    \n",
    "\n",
    "    \n",
    "    raw_test_data = pd.read_csv(\n",
    "    os.path.join(DATA_DIR, \"test_data_10M_2.csv\"), \n",
    "    usecols=all_cols, \n",
    "    nrows=SUBSAMPLE\n",
    "    )\n",
    "\n",
    "    print(\"\\n RAW TRAIN DATA\\n\")\n",
    "    print(raw_train_data.shape)\n",
    "    raw_train_data.describe()  # unscaled\n",
    "    print(\"\\n RAW TEST DATA\\n\")\n",
    "    print(raw_test_data.shape)\n",
    "    raw_test_data.describe()  # unscaled\n",
    "\n",
    "    return raw_train_data, raw_test_data, raw_valid_data\n",
    "\n",
    "\n",
    "########## Generate scaled data###############\n",
    "# scaled_train_data = L_scale_df(raw_train_data, title='scaled_train_data_10M_2.csv',\n",
    "#                              save=True)\n",
    "# print('\\n\\n')\n",
    "# scaled_test_data = L_scale_df(raw_test_data,  title='scaled_test_data_10M_2.csv',\n",
    "#                             save=True)\n",
    "# print('\\n\\n')\n",
    "\n",
    "# scaled_valid_data = L_scale_df(raw_valid_data,  title='scaled_valid_data_10M_2.csv',\n",
    "#                             save=True)\n",
    "\n",
    "# explore_data(df=scaled_train_data, title='Braden Kronheim-L-scaled Dataframe', scaled=True)\n",
    "\n",
    "################ Load scaled data##############\n",
    "@utils.time_type_of_func(tuning_or_training=\"loading\")\n",
    "# @memory.cache\n",
    "def load_scaled_dataframes():\n",
    "    print(\"SCALED TRAIN DATA\")\n",
    "    scaled_train_data = pd.read_csv(\n",
    "        os.path.join(DATA_DIR, \"scaled_train_data_10M_2.csv\"),\n",
    "        usecols=all_cols,\n",
    "        nrows=SUBSAMPLE,\n",
    "    )\n",
    "\n",
    "    print(\"TRAINING FEATURES\\n\", scaled_train_data.head())\n",
    "\n",
    "    scaled_test_data = pd.read_csv(\n",
    "        os.path.join(DATA_DIR, \"scaled_test_data_10M_2.csv\"),\n",
    "        usecols=all_cols,\n",
    "        nrows=SUBSAMPLE,\n",
    "    )\n",
    "\n",
    "    scaled_valid_data = pd.read_csv(\n",
    "        os.path.join(DATA_DIR, \"scaled_valid_data_10M_2.csv\"),\n",
    "        usecols=all_cols,\n",
    "        nrows=SUBSAMPLE,\n",
    "    )\n",
    "    return scaled_train_data, scaled_test_data, scaled_valid_data\n",
    "\n",
    "\n",
    "#######################################\n",
    "#\n",
    "# # print('\\nTESTING FEATURES\\n', scaled_test_data.head())\n",
    "\n",
    "# print('\\ntrain set shape:',  scaled_train_data.shape)\n",
    "# print('\\ntest set shape:  ', scaled_test_data.shape)\n",
    "# # print('validation set shape:', valid_data.shape)\n",
    "# @memory.cache\n",
    "def get_train_scale_dict(USE_BRADEN_SCALING):\n",
    "    if USE_BRADEN_SCALING==True:\n",
    "        TRAIN_SCALE_DICT = utils.get_scaling_info(scaled_train_data)\n",
    "        print(\"BRADEN SCALING DICTIONARY\")\n",
    "        print(TRAIN_SCALE_DICT)\n",
    "        print(\"\\n\\n\")\n",
    "        # TEST_SCALE_DICT = get_scaling_info(scaled_test_data)\n",
    "        # print(TEST_SCALE_DICT)\n",
    "    else:\n",
    "        print(\"NORMAL UNSCALED DICTIONARY\")\n",
    "        TRAIN_SCALE_DICT = utils.get_scaling_info(raw_train_data)\n",
    "        print(TRAIN_SCALE_DICT)\n",
    "        print(\"\\n\\n\")\n",
    "        # TEST_SCALE_DICT = get_scaling_info(scaled_test_data)\n",
    "        # print(TEST_SCALE_DICT)\n",
    "    return TRAIN_SCALE_DICT\n",
    "\n",
    "\n",
    "################################ SPLIT###########\n",
    "# @memory.cache\n",
    "def T(variable, scaled_df):\n",
    "    if variable == \"pT\":\n",
    "        L_pT_gen = scaled_df[\"genDatapT\"]\n",
    "        L_pT_reco = scaled_df[\"RecoDatapT\"]\n",
    "        target = (L_pT_reco + 10) / (L_pT_gen + 10)\n",
    "    if variable == \"eta\":\n",
    "        L_eta_gen = scaled_df[\"genDataeta\"]\n",
    "        L_eta_reco = scaled_df[\"RecoDataeta\"]\n",
    "        target = (L_eta_reco + 10) / (L_eta_gen + 10)\n",
    "    if variable == \"phi\":\n",
    "        L_phi_gen = scaled_df[\"genDataphi\"]\n",
    "        L_phi_reco = scaled_df[\"RecoDataphi\"]\n",
    "        target = (L_phi_reco + 10) / (L_phi_gen + 10)\n",
    "    if variable == \"m\":\n",
    "        L_m_gen = scaled_df[\"genDatam\"]\n",
    "        L_m_reco = scaled_df[\"RecoDatam\"]\n",
    "        target = (L_m_reco + 10) / (L_m_gen + 10)\n",
    "\n",
    "    return target\n",
    "\n",
    "\n",
    "# @memory.cache\n",
    "def split_t_x(df, target, input_features):\n",
    "    \"\"\"Get teh target as the ratio, according to the T equation\"\"\"\n",
    "\n",
    "    if target == \"RecoDatam\":\n",
    "        t = T(\"m\", scaled_df=scaled_train_data)\n",
    "    if target == \"RecoDatapT\":\n",
    "        t = T(\"pT\", scaled_df=scaled_train_data)\n",
    "    if target == \"RecoDataeta\":\n",
    "        t = T(\"eta\", scaled_df=scaled_train_data)\n",
    "    if target == \"RecoDataphi\":\n",
    "        t = T(\"phi\", scaled_df=scaled_train_data)\n",
    "    x = np.array(df[input_features])\n",
    "    return np.array(t), x\n",
    "\n",
    "\n",
    "# @memory.cache\n",
    "def split_t_x_test(df, target, input_features):\n",
    "    \"\"\"Get teh target as the ratio, according to the T equation\"\"\"\n",
    "\n",
    "    if target == \"RecoDatam\":\n",
    "        t = T(\"m\", scaled_df=scaled_test_data)\n",
    "    if target == \"RecoDatapT\":\n",
    "        t = T(\"pT\", scaled_df=scaled_test_data)\n",
    "    if target == \"RecoDataeta\":\n",
    "        t = T(\"eta\", scaled_df=scaled_test_data)\n",
    "    if target == \"RecoDataphi\":\n",
    "        t = T(\"phi\", scaled_df=scaled_test_data)\n",
    "    x = np.array(df[input_features])\n",
    "    return np.array(t), x\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "# @memory.cache\n",
    "def normal_split_t_x(df, target, input_features):\n",
    "    # change from pandas dataframe format to a numpy\n",
    "    # array of the specified types\n",
    "    # t = np.array(df[target])\n",
    "    t = np.array(df[target])\n",
    "    x = np.array(df[input_features])\n",
    "    return t, x\n",
    "\n",
    "\n",
    "################ Apply Z scaling############\n",
    "def z(x):\n",
    "    eps = 1e-20\n",
    "    return (x - np.mean(x)) / (np.std(x) + eps)\n",
    "\n",
    "\n",
    "def z_inverse(xprime, x):\n",
    "    return xprime * np.std(x) + np.mean(x)\n",
    "\n",
    "\n",
    "# @memory.cache\n",
    "def z2(x, mean, std):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x ([type]): [description]\n",
    "        mean ([type]): [description]\n",
    "        std ([type]): [description]\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "    eps = 1e-20\n",
    "    scaled = (x - mean) / (std + eps)\n",
    "    return np.array(scaled, dtype=np.float64)\n",
    "\n",
    "\n",
    "def z_inverse(xprime, x):\n",
    "    unscaled = xprime * np.std(x) + np.mean(x)\n",
    "    return np.array(unscaled, dtype=np.float64)\n",
    "\n",
    "\n",
    "# @memory.cache\n",
    "def z_inverse2(xprime, train_mean, train_std):\n",
    "    \"\"\"mean original train mean, std: original. Probably not needed\"\"\"\n",
    "    return xprime * train_std + train_mean\n",
    "\n",
    "\n",
    "# @memory.cache\n",
    "def apply_z_to_features(TRAIN_SCALE_DICT, train_x, test_x, valid_x):\n",
    "    \"\"\"TO ensure this z scaling is only applied once to the training features, we use a generator.\n",
    "    This doesn't change the shapes of anything, just applies z to all the feature columns other than tau\"\"\"\n",
    "    NFEATURES = train_x.shape[1]\n",
    "    for i in range(NFEATURES - 1):\n",
    "        variable = list(TRAIN_SCALE_DICT)[i]\n",
    "        train_mean = float(TRAIN_SCALE_DICT[variable][\"mean\"])\n",
    "        train_std = float(TRAIN_SCALE_DICT[variable][\"std\"])\n",
    "        train_x[:, i] = z2(train_x[:, i], mean=train_mean, std=train_std)\n",
    "        test_x[:, i] = z2(test_x[:, i], mean=train_mean, std=train_std)\n",
    "        valid_x[:, i] = z2(valid_x[:, i], mean=train_mean, std=train_std)\n",
    "    yield train_x\n",
    "    yield test_x\n",
    "    yield valid_x\n",
    "\n",
    "\n",
    "# @memory.cache\n",
    "def apply_z_to_targets(train_t, test_t, valid_t):\n",
    "    train_mean = np.mean(train_t)\n",
    "    train_std = np.std(train_t)\n",
    "    train_t_ = z2(train_t, mean=train_mean, std=train_std)\n",
    "    test_t_ = z2(test_t, mean=train_mean, std=train_std)\n",
    "    valid_t_ = z2(valid_t, mean=train_mean, std=train_std)\n",
    "\n",
    "    yield train_t_\n",
    "    yield test_t_\n",
    "    yield valid_t_\n",
    "\n",
    "\n",
    "# @utils.debug\n",
    "def save_model(model, PATH):\n",
    "    print(model)\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    print(\"\\ntrained model dictionary saved in %s\" % PATH)\n",
    "\n",
    "\n",
    "# @utils.debug\n",
    "def load_model(PATH, PARAMS):\n",
    "    # n_layers = int(BEST_PARAMS[\"n_layers\"])\n",
    "    # hidden_size = int(BEST_PARAMS[\"hidden_size\"])\n",
    "    # dropout = float(BEST_PARAMS[\"dropout\"])\n",
    "    # optimizer_name = BEST_PARAMS[\"optimizer_name\"].to_string().split()[1]\n",
    "    # learning_rate =  float(BEST_PARAMS[\"learning_rate\"])\n",
    "    # batch_size = int(BEST_PARAMS[\"batch_size\"])\n",
    "    model = utils.RegularizedRegressionModel(\n",
    "        nfeatures=NFEATURES,\n",
    "        ntargets=1,\n",
    "        nlayers=PARAMS[\"n_layers\"],\n",
    "        hidden_size=PARAMS[\"hidden_size\"],\n",
    "        dropout_1=PARAMS[\"dropout_1\"],\n",
    "        dropout_2=PARAMS[\"dropout_2\"],\n",
    "        activation=PARAMS[\"activation\"],\n",
    "    )\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    # OR\n",
    "    # model=torch.load(PATH)#BUT HERE IT WILL BE A DICT (CANT BE EVALUATED RIGHT AWAY) DISCOURAGED! Also, use dictionary \".pth\" which has both the model state dict and the PARAMS dict\n",
    "    model.eval()\n",
    "    print(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "# @memory.cache\n",
    "def simple_eval(model, test_x_z_scaled):\n",
    "    model.eval()\n",
    "    # evaluate on the scaled features\n",
    "    valid_x_tensor = torch.from_numpy(test_x_z_scaled).float()\n",
    "    # valid_x_tensor=torch.from_numpy(train_x).float()\n",
    "    pred = model(valid_x_tensor)\n",
    "    p = pred.detach().numpy()\n",
    "    # if USE_BRADEN_SCALING:\n",
    "    #     fig, ax = plt.subplots(1,1)\n",
    "    #     label=FIELDS[target]['ylabel']\n",
    "    #     ax.hist(p, label=f'Predicted post-z ratio for {label}', alpha=0.4, density=True)\n",
    "    #     # orig_ratio = z(T('m', scaled_df=scaled_train_data))\n",
    "    #     orig_ratio = z(T('m', scaled_df=scaled_test_data))\n",
    "    #     print(orig_ratio[:5])\n",
    "    #     ax.hist(orig_ratio, label = f'original post-z ratio for {label}', alpha=0.4,density=True)\n",
    "    #     ax.grid()\n",
    "    #     set_axes(ax, xlabel='predicted $T$')\n",
    "    # print('predicted ratio shape: ', p.shape)\n",
    "    return p\n",
    "\n",
    "def get_previous_autoregressive_dist(AUTOREGRESSIVE_DIST_NAME):\n",
    "        \n",
    "    print(f'Test (evaluation) Data is Autoregressive, loading {AUTOREGRESSIVE_DIST_NAME}')\n",
    "    eval_data = pd.read_csv(\n",
    "        os.path.join(\n",
    "            IQN_BASE,\n",
    "            \"JupyterBook\",\n",
    "            \"Cluster\",\n",
    "            \"EVALUATE\",\n",
    "            AUTOREGRESSIVE_DIST_NAME,\n",
    "        )\n",
    "    )\n",
    "    return eval_data\n",
    "\n",
    "\n",
    "# @memory.cache\n",
    "def get_hist(label):\n",
    "    \"\"\"label could be \"pT\", \"eta\", \"phi\", \"m\" \"\"\"\n",
    "    predicted_label_counts, label_edges = np.histogram(\n",
    "        JETS_DICT[\"Predicted_RecoData\" + label][\"dist\"],\n",
    "        range=JETS_DICT[\"Predicted_RecoData\" + label][\"range\"],\n",
    "        bins=bins,\n",
    "    )\n",
    "    real_label_counts, _ = np.histogram(\n",
    "        JETS_DICT[\"Real_RecoData\" + label][\"dist\"],\n",
    "        range=JETS_DICT[\"Real_RecoData\" + label][\"range\"],\n",
    "        bins=bins,\n",
    "    )\n",
    "    label_edges = label_edges[1:] / 2 + label_edges[:-1] / 2\n",
    "\n",
    "    return real_label_counts, predicted_label_counts, label_edges\n",
    "\n",
    "\n",
    "# @memory.cache\n",
    "def get_hist_simple(predicted_dist, target):\n",
    "    \n",
    "    range_ = (FIELDS[target][\"xmin\"], FIELDS[target][\"xmax\"])\n",
    "    bins=50\n",
    "    predicted_label_counts, label_edges = np.histogram(\n",
    "        predicted_dist, range=range_, bins=bins\n",
    "    )\n",
    "    \n",
    "    \n",
    "    real_label_counts, _ = np.histogram(REAL_DIST, range=range_, bins=bins)\n",
    "    label_edges = label_edges[1:] / 2 + label_edges[:-1] / 2\n",
    "    return real_label_counts, predicted_label_counts, label_edges\n",
    "\n",
    "\n",
    "# @memory.cache\n",
    "def plot_one(\n",
    "    target, real_edges, real_counts, predicted_counts, save_plot=False, PARAMS=None, JUPYTER=True\n",
    "):\n",
    "    fig, (ax1, ax2) = plt.subplots(\n",
    "        2, 1, figsize=(3.5 * 3 / 2.5, 3.8), gridspec_kw={\"height_ratios\": [2, 0.5]}\n",
    "    )\n",
    "    ax1.step(\n",
    "        real_edges, real_counts / norm_data, where=\"mid\", color=\"k\", linewidth=0.5\n",
    "    )  # step real_count_pt\n",
    "    ax1.step(\n",
    "        real_edges,\n",
    "        predicted_counts / norm_IQN,\n",
    "        where=\"mid\",\n",
    "        color=\"#D7301F\",\n",
    "        linewidth=0.5,\n",
    "    )  # step predicted_count_pt\n",
    "    ax1.scatter(\n",
    "        real_edges,\n",
    "        real_counts / norm_data,\n",
    "        label=\"reco\",\n",
    "        color=\"k\",\n",
    "        facecolors=\"none\",\n",
    "        marker=\"o\",\n",
    "        s=5,\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "    ax1.scatter(\n",
    "        real_edges,\n",
    "        predicted_counts / norm_IQN,\n",
    "        label=\"predicted\",\n",
    "        color=\"#D7301F\",\n",
    "        marker=\"x\",\n",
    "        s=5,\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "    ax1.set_xlim(range_)\n",
    "    ax1.set_ylim(0, max(predicted_counts / norm_IQN) * 1.1)\n",
    "    ax1.set_ylabel(\"counts\")\n",
    "    ax1.set_xticklabels([])\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "\n",
    "    ratio = (predicted_counts / norm_IQN) / (real_counts / norm_data)\n",
    "    ax2.scatter(\n",
    "        real_edges, ratio, color=\"r\", marker=\"x\", s=5, linewidth=0.5\n",
    "    )  # PREDICTED (IQN)/Reco (Data)\n",
    "    ax2.scatter(\n",
    "        real_edges,\n",
    "        ratio / ratio,\n",
    "        color=\"k\",\n",
    "        marker=\"o\",\n",
    "        facecolors=\"none\",\n",
    "        s=5,\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "    ax2.set_xlim(range_)\n",
    "    ax2.set_xlabel(FIELDS[target][\"xlabel\"])\n",
    "    ax2.set_ylabel(\n",
    "        r\"$\\frac{\\textnormal{predicted}}{\\textnormal{reco}}$\"\n",
    "        #    , fontsize=10\n",
    "    )\n",
    "    ax2.set_ylim((YLIM))\n",
    "    ax2.set_xlim(range_)\n",
    "    ax2.set_yticklabels([0.8, 1.0, 1.2])\n",
    "    if JUPYTER==True:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.tight_layout()\n",
    "        fig.subplots_adjust(wspace=0.5, hspace=0.2)\n",
    "        fig.subplots_adjust(wspace=0.0, hspace=0.1)\n",
    "        plt.axis('off')\n",
    "\n",
    "    # plt.gca().set_position([0, 0, 1, 1])\n",
    "    if save_plot:\n",
    "        plot_filename = utils.get_model_filename(target, PARAMS).split(\".dict\")[0] + \".png\"\n",
    "        plt.savefig(\n",
    "            os.path.join(IQN_BASE, \"JupyterBook\", \"Cluster\", \"EVALUATE\", plot_filename)\n",
    "        )\n",
    "\n",
    "    \n",
    "    # fig.show()\n",
    "    # plt.show();\n",
    "    # plt.axis(\"off\")\n",
    "    # plt.gca().set_position([0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3336b47e-6e8a-43ba-a93a-5067d6b44dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__--tmp-ipykernel-3379445305.load_raw_data...\n",
      "load_raw_data()\n",
      "\n",
      "SUBSAMPLE = None\n",
      "\n",
      "\n",
      " RAW TRAIN DATA\n",
      "\n",
      "(8000000, 9)\n",
      "\n",
      " RAW TEST DATA\n",
      "\n",
      "(1000000, 9)\n",
      "___________________________________________________load_raw_data - 21.4s, 0.4min\n"
     ]
    }
   ],
   "source": [
    "#load data only once, and with caching!\n",
    "raw_train_data, raw_test_data, raw_valid_data = load_raw_data()\n",
    "\n",
    "# Load scaled data\n",
    "# scaled_train_data, scaled_test_data, scaled_valid_data = load_scaled_dataframes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d40d613-52be-4b51-ab10-822df7976083",
   "metadata": {},
   "source": [
    "## 3.3: Evaluate Mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a42c5cef-a246-45ea-9ee4-d4d22452a547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features:\n",
      " ['genDatapT', 'genDataeta', 'genDataphi', 'genDatam', 'tau']\n",
      "\n",
      "Target =  RecoDatam\n",
      "USING NEW DATASET\n",
      "\n",
      "spliting data for RecoDatam\n",
      "train_t shape =  (8000000,) train_x shape =  (8000000, 5)\n",
      "\n",
      " Training features:\n",
      "\n",
      "[[29.4452      0.828187    2.90213     2.85348     0.36130954]\n",
      " [24.3193     -1.16351     0.636469    5.83685     0.12689925]\n",
      " [24.3193     -1.16351     0.636469    5.83685     0.96230681]\n",
      " ...\n",
      " [41.4192     -2.23358    -2.81921     7.19348     0.08421659]\n",
      " [35.4637     -1.12318     0.356494    6.06597     0.05535172]\n",
      " [26.5586     -1.09427    -1.49334     4.25409     0.07489863]]\n",
      "valid_t shape =  (1000000,) valid_x shape =  (1000000, 5)\n",
      "test_t shape =  (1000000,) test_x shape =  (1000000, 5)\n",
      "no need to train_test_split since we already have the split dataframes\n",
      "[ 3.27223764e+01  6.98189368e-04 -8.95543973e-04  6.96116528e+00\n",
      "  5.00485136e-01] [15.19914133  2.20425356  1.81362773  2.78097831  0.28852734]\n",
      "[ 3.26952341e+01 -1.78188172e-03 -3.83090331e-04  6.96299435e+00\n",
      "  4.99915289e-01] [14.93793254  2.20430976  1.81382516  2.78133203  0.28867295]\n",
      "5.5514112643334546 2.664124544901276\n",
      "5.555567451922438 2.664339857066051\n",
      "NORMAL UNSCALED DICTIONARY\n",
      "{'genDatapT': {'mean': 32.695234084987476, 'std': 14.937932540562551}, 'genDataeta': {'mean': -0.0017818817154031672, 'std': 2.204309760627079}, 'genDataphi': {'mean': -0.0003830903308450233, 'std': 1.8138251604791067}, 'genDatam': {'mean': 6.962994352358474, 'std': 2.781332025286383}, 'RecoDatapT': {'mean': 32.86720151648752, 'std': 15.829355769531851}, 'RecoDataeta': {'mean': -0.0017898858568513964, 'std': 2.197968491495457}, 'RecoDataphi': {'mean': -0.0004719170328962474, 'std': 1.8144739820043825}, 'RecoDatam': {'mean': 5.555567451922438, 'std': 2.664339857066051}}\n",
      "\n",
      "\n",
      "\n",
      "[ 1.81700902e-03  1.12510099e-03 -2.82526482e-04 -6.57626105e-04\n",
      "  5.00485136e-01] [1.01748627 0.9999745  0.99989115 0.99987283 0.28852734]\n",
      "[ 1.61650249e-15 -1.10134124e-18 -3.12905257e-17  5.01036723e-15\n",
      "  4.99915289e-01] [1.         1.         1.         1.         0.28867295]\n",
      "-0.0015599314696879494 0.9999191874249058\n",
      "6.996216939114674e-16 1.0000000000000002\n",
      "<class 'str'>\n",
      "This model was trained for 2000000 iteration, which is  256.0 epochs\n",
      "RegularizedRegressionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=6, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.3)\n",
      "    (2): Linear(in_features=6, out_features=6, bias=True)\n",
      "    (3): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.3)\n",
      "    (5): Linear(in_features=6, out_features=6, bias=True)\n",
      "    (6): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.3)\n",
      "    (8): Linear(in_features=6, out_features=6, bias=True)\n",
      "    (9): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.3)\n",
      "    (11): Linear(in_features=6, out_features=6, bias=True)\n",
      "    (12): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): LeakyReLU(negative_slope=0.3)\n",
      "    (14): Linear(in_features=6, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "EVALUATION DATA NEW INDEX\n",
      "    RecoDatam  genDatapT  genDataeta  genDataphi  genDatam       tau\n",
      "0   4.849958    43.6113    0.824891    -1.26949   5.93310  0.250046\n",
      "1   6.718066    43.6113    0.824891    -1.26949   5.93310  0.847493\n",
      "2   5.235002    26.0153    3.529970     1.55495   7.41270  0.851995\n",
      "3   3.737100    28.4944   -1.159650     1.82602   7.84157  0.052378\n",
      "4   3.313682    21.9840    2.747660     2.03085   5.18315  0.542549\n",
      "norm_data 1000000 \n",
      "norm IQN 1000000 \n",
      "norm_autoregressive 1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_68922/3379445305.py:403: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax2.set_yticklabels([0.8, 1.0, 1.2])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 420x380 with 2 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/_build/jupyter_execute/3_Autoregressive_Evaluation_8_2.png"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: plot the loss curves (train and valid) of all 4 networks on the same plot,\n",
    "# and with the learning rate plotted on the same plot but on a different y axis \n",
    "# (x axis being iteration, with marks indicating epochs)\n",
    "\n",
    "target = \"RecoDatam\"\n",
    "source = FIELDS[target]\n",
    "features = source[\"inputs\"]\n",
    "print(\"Training Features:\\n\", features)\n",
    "print(\"\\nTarget = \", target)\n",
    "AUTOREGRESSIVE_DIST_NAME = \"AUTOREGRESSIVE_m_Prime.csv\"\n",
    "print(\"USING NEW DATASET\\n\")\n",
    "######################################\n",
    "USE_BRADEN_SCALING = False\n",
    "#####################################\n",
    "################################### CONFIGURATIONS ###################################\n",
    "\n",
    "JUPYTER = True\n",
    "use_subsample = False\n",
    "# use_subsample = True\n",
    "if use_subsample:\n",
    "    SUBSAMPLE = int(\n",
    "        1e5\n",
    "    )  # subsample use for development - in production use whole dataset\n",
    "else:\n",
    "    SUBSAMPLE = None\n",
    "\n",
    "########################################################################################\n",
    "# Get targets and features\n",
    "if USE_BRADEN_SCALING==True:\n",
    "    print(f\"spliting data for {target}\")\n",
    "    train_t, train_x = split_t_x(\n",
    "        df=scaled_train_data, target=target, input_features=features\n",
    "    )\n",
    "    print(\"train_t shape = \", train_t.shape, \"train_x shape = \", train_x.shape)\n",
    "    print(\"\\n Training features:\\n\")\n",
    "    print(train_x)\n",
    "    valid_t, valid_x = split_t_x(\n",
    "        df=scaled_valid_data, target=target, input_features=features\n",
    "    )\n",
    "    print(\"valid_t shape = \", valid_t.shape, \"valid_x shape = \", valid_x.shape)\n",
    "    test_t, test_x = split_t_x(\n",
    "        df=scaled_test_data, target=target, input_features=features\n",
    "    )\n",
    "    print(\"test_t shape = \", test_t.shape, \"test_x shape = \", test_x.shape)\n",
    "\n",
    "else:\n",
    "    print(f\"spliting data for {target}\")\n",
    "    train_t, train_x = normal_split_t_x(\n",
    "        df=raw_train_data, target=target, input_features=features\n",
    "    )\n",
    "    print(\"train_t shape = \", train_t.shape, \"train_x shape = \", train_x.shape)\n",
    "    print(\"\\n Training features:\\n\")\n",
    "    print(train_x)\n",
    "    valid_t, valid_x = normal_split_t_x(\n",
    "        df=raw_valid_data, target=target, input_features=features\n",
    "    )\n",
    "    print(\"valid_t shape = \", valid_t.shape, \"valid_x shape = \", valid_x.shape)\n",
    "    test_t, test_x = normal_split_t_x(\n",
    "        df=raw_test_data, target=target, input_features=features\n",
    "    )\n",
    "    print(\"test_t shape = \", test_t.shape, \"test_x shape = \", test_x.shape)\n",
    "\n",
    "print(\"no need to train_test_split since we already have the split dataframes\")\n",
    "print(valid_x.mean(axis=0), valid_x.std(axis=0))\n",
    "print(train_x.mean(axis=0), train_x.std(axis=0))\n",
    "print(valid_t.mean(), valid_t.std())\n",
    "print(train_t.mean(), train_t.std())\n",
    "######################################################\n",
    "\n",
    "# Apply z scaling to features and targets\n",
    "# to features\n",
    "\n",
    "NFEATURES = train_x.shape[1]\n",
    "TRAIN_SCALE_DICT = get_train_scale_dict(USE_BRADEN_SCALING)\n",
    "# to features\n",
    "apply_z_generator = apply_z_to_features(TRAIN_SCALE_DICT, train_x, test_x, valid_x)\n",
    "train_x_z_scaled = next(apply_z_generator)\n",
    "test_x_z_scaled = next(apply_z_generator)\n",
    "valid_x_z_scaled = next(apply_z_generator)\n",
    "print(valid_x_z_scaled.mean(axis=0), valid_x_z_scaled.std(axis=0))\n",
    "print(train_x_z_scaled.mean(axis=0), train_x_z_scaled.std(axis=0))\n",
    "# to targets\n",
    "apply_z_to_targets_generator = apply_z_to_targets(train_t, test_t, valid_t)\n",
    "train_t_z_scaled = next(apply_z_to_targets_generator)\n",
    "test_t_z_scaled = next(apply_z_to_targets_generator)\n",
    "valid_t_z_scaled = next(apply_z_to_targets_generator)\n",
    "print(valid_t_z_scaled.mean(), valid_t_z_scaled.std())\n",
    "print(train_t_z_scaled.mean(), train_t_z_scaled.std())\n",
    "\n",
    "###########################################################\n",
    "# Get the  parameters for this model and training\n",
    "PARAMS_m = {\n",
    "\"n_layers\": int(5),\n",
    "\"hidden_size\": int(6),\n",
    "\"dropout_1\": float(0.6),\n",
    "\"dropout_2\": float(0.1),\n",
    "\"activation\": \"LeakyReLU\",\n",
    "    'optimizer_name':'NAdam',\n",
    "    'starting_learning_rate':float(0.5),\n",
    "    'momentum':float(0.6),\n",
    "    'batch_size':int(1024),\n",
    "    'n_iterations': int(2e6),\n",
    "}\n",
    "\n",
    "optimizer_name = PARAMS_m[\"optimizer_name\"]\n",
    "print(type(optimizer_name))\n",
    "# optimizer_name = BEST_PARAMS[\"optimizer_name\"].to_string().split()[1]\n",
    "NITERATIONS = PARAMS_m[\"n_iterations\"]\n",
    "BATCHSIZE = PARAMS_m[\"batch_size\"]\n",
    "comment = \"\"\n",
    "\n",
    "# N_epochs X N_train_examples = N_iterations X batch_size\n",
    "N_epochs = (NITERATIONS * BATCHSIZE) / int(train_x.shape[0])\n",
    "print(\n",
    "    f\"This model was trained for {NITERATIONS} iteration, which is  {N_epochs} epochs\"\n",
    ")\n",
    "\n",
    "# 'Trained_IQNx4_%s_TUNED.dict' % target\n",
    "filename_model = utils.get_model_filename(target, PARAMS_m)\n",
    "# OR, if you know a model filename directly, you can also specify it, \n",
    "# BUT, if you pull a trained model explicitly, you have to make sure its parameters in the PARAMS dictionary above match\n",
    "# Nominal one is 'Trained_IQNx4_RecoDatam_ 8_layer5_hiddenLeakyReLU_activation1024_batchsize300_Kiteration.dict', also in backup\n",
    "# filename_model='Trained_IQNx4_RecoDatam_ 8_layer5_hiddenLeakyReLU_activation1024_batchsize300_Kiteration.dict'\n",
    "# filename_model='Trained_IQNx4_RecoDatapT_10_layer6_hiddenLeakyReLU_activation512_batchsize300_Kiteration.dict'\n",
    "trained_models_dir = \"trained_models\"\n",
    "utils.mkdir(trained_models_dir)\n",
    "# on cluster, Im using another TRAIN directory\n",
    "PATH_model = os.path.join(\n",
    "    IQN_BASE,  # the loaction of the repo\n",
    "    \"JupyterBook\",  # up tp TRAIN could be combined in a srs dicretory\n",
    "    \"Cluster\",\n",
    "    \"TRAIN\",\n",
    "    trained_models_dir,  # /trained_models\n",
    "    filename_model,  # utils.get_model_filename has the saved file format\n",
    ")\n",
    "\n",
    "# Load trained model\n",
    "IQN_m = load_model(PATH_model, PARAMS_m)\n",
    "# Get predicted distribution\n",
    "p = simple_eval(IQN_m, test_x_z_scaled)\n",
    "\n",
    "range_ = (FIELDS[target][\"xmin\"], FIELDS[target][\"xmax\"])\n",
    "bins = 50\n",
    "REAL_RAW_DATA = raw_test_data\n",
    "\n",
    "YLIM = (0.8, 1.2)\n",
    "###########GET REAL DIST###########\n",
    "REAL_RAW_DATA = REAL_RAW_DATA[\n",
    "    [\"RecoDatapT\", \"RecoDataeta\", \"RecoDataphi\", \"RecoDatam\"]\n",
    "]\n",
    "REAL_RAW_DATA.columns = [\"realpT\", \"realeta\", \"realphi\", \"realm\"]\n",
    "REAL_DIST = REAL_RAW_DATA[\"realm\"]\n",
    "norm_data = REAL_RAW_DATA.shape[0]\n",
    "#############GET EVALUATION DIST#############\n",
    "raw_test_data.describe()\n",
    "m_reco = raw_test_data[\"RecoDatam\"]\n",
    "m_gen = raw_test_data[\"genDatam\"]\n",
    "# plt.hist(m_reco,label=r'$m_{gen}^{test \\ data}$');plt.legend();plt.show()\n",
    "\n",
    "\n",
    "def descale_Braden_scaled_prediction(label, p):\n",
    "    \"\"\"Label could be m. p is the outcome of the model evaluation, e.g. \n",
    "    IQN_m = load_model(PATH_model, PARAMS_m)\n",
    "    p = simple_eval(IQN_m, test_x_z_scaled)\n",
    "    \n",
    "    \"\"\"\n",
    "    # make sure you've set braden scaling global variable to use this function.\n",
    "    assert USE_BRADEN_SCALING==True\n",
    "    orig_ratio = T(label, scaled_df=scaled_train_data)\n",
    "    z_inv_f = z_inverse(xprime=p, mean=np.mean(orig_ratio), std=np.std(orig_ratio))\n",
    "    L_obs = L(orig_observable=m_gen, label=label)\n",
    "    z_inv_f = z_inv_f.flatten()\n",
    "    print(z_inv_f.shape)\n",
    "\n",
    "    factor = (z_inv_f * (L_obs + 10)) - 10\n",
    "    label_pred = L_inverse(L_observable=factor, label=label)\n",
    "    return label_pred\n",
    "    \n",
    "    \n",
    "m_pred = z_inverse2(\n",
    "    xprime=p,\n",
    "    train_mean=TRAIN_SCALE_DICT[target][\"mean\"],\n",
    "    train_std=TRAIN_SCALE_DICT[target][\"std\"],\n",
    ")\n",
    "m_pred = m_pred.flatten()\n",
    "\n",
    "# Get histogram of predicted distribution\n",
    "real_label_counts_m, predicted_label_counts_m, label_edges_m = get_hist_simple(\n",
    "    predicted_dist=m_pred, target=target\n",
    ")\n",
    "# eval_data=pd.read_csv(DATA_DIR+'/test_data_10M_2.csv')\n",
    "# Get evaluation data\n",
    "eval_data = pd.read_csv(DATA_DIR + \"/test_data_10M_2.csv\")\n",
    "ev_features = features\n",
    "eval_data = eval_data[ev_features]\n",
    "# save new distribution (m) in the eval data as autoregressive eval for next IQN\n",
    "eval_data[target] = m_pred\n",
    "\n",
    "new_cols = [target] + features\n",
    "eval_data = eval_data.reindex(columns=new_cols)\n",
    "print(\"EVALUATION DATA NEW INDEX\\n\", eval_data.head())\n",
    "\n",
    "eval_data.to_csv(\n",
    "    os.path.join(\n",
    "        IQN_BASE, \"JupyterBook\", \"Cluster\", \"EVALUATE\", AUTOREGRESSIVE_DIST_NAME\n",
    "    )\n",
    ")\n",
    "\n",
    "# Load this saved predited autoregressive distribution\n",
    "AUTOREGRESSIVE_DIST = pd.read_csv(\n",
    "    os.path.join(\n",
    "        IQN_BASE, \"JupyterBook\", \"Cluster\", \"EVALUATE\", AUTOREGRESSIVE_DIST_NAME\n",
    "    )\n",
    ")\n",
    "\n",
    "# norm_IQN=AUTOREGRESSIVE_DIST.shape[0]\n",
    "# get normalization values\n",
    "norm_autoregressive = AUTOREGRESSIVE_DIST.shape[0]\n",
    "norm_IQN = norm_autoregressive\n",
    "print(\n",
    "    \"norm_data\",\n",
    "    norm_data,\n",
    "    \"\\nnorm IQN\",\n",
    "    norm_IQN,\n",
    "    \"\\nnorm_autoregressive\",\n",
    "    norm_autoregressive,\n",
    ")\n",
    "\n",
    "# Finally, plot predicted distribution\n",
    "\n",
    "plot_one(\n",
    "    target=target,\n",
    "    real_edges=label_edges_m,\n",
    "    real_counts=real_label_counts_m,\n",
    "    predicted_counts=predicted_label_counts_m,\n",
    "    save_plot=True,\n",
    "    PARAMS=PARAMS_m\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df205105-a24d-4694-a182-ef84c08bfd4c",
   "metadata": {},
   "source": [
    "## 3.4: Evaluate $p_T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95d0ccc6-5576-4e09-9423-9ed7cb07fa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test (evaluation) Data is Autoregressive, loading AUTOREGRESSIVE_m_Prime.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RecoDatam</th>\n",
       "      <th>genDatapT</th>\n",
       "      <th>genDataeta</th>\n",
       "      <th>genDataphi</th>\n",
       "      <th>genDatam</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.797721</td>\n",
       "      <td>43.6113</td>\n",
       "      <td>0.824891</td>\n",
       "      <td>-1.26949</td>\n",
       "      <td>5.93310</td>\n",
       "      <td>0.250046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6.829849</td>\n",
       "      <td>43.6113</td>\n",
       "      <td>0.824891</td>\n",
       "      <td>-1.26949</td>\n",
       "      <td>5.93310</td>\n",
       "      <td>0.847493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.645979</td>\n",
       "      <td>26.0153</td>\n",
       "      <td>3.529970</td>\n",
       "      <td>1.55495</td>\n",
       "      <td>7.41270</td>\n",
       "      <td>0.851995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.593726</td>\n",
       "      <td>28.4944</td>\n",
       "      <td>-1.159650</td>\n",
       "      <td>1.82602</td>\n",
       "      <td>7.84157</td>\n",
       "      <td>0.052378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.501870</td>\n",
       "      <td>21.9840</td>\n",
       "      <td>2.747660</td>\n",
       "      <td>2.03085</td>\n",
       "      <td>5.18315</td>\n",
       "      <td>0.542549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  RecoDatam  genDatapT  genDataeta  genDataphi  genDatam  \\\n",
       "0           0   4.797721    43.6113    0.824891    -1.26949   5.93310   \n",
       "1           1   6.829849    43.6113    0.824891    -1.26949   5.93310   \n",
       "2           2   5.645979    26.0153    3.529970     1.55495   7.41270   \n",
       "3           3   3.593726    28.4944   -1.159650     1.82602   7.84157   \n",
       "4           4   3.501870    21.9840    2.747660     2.03085   5.18315   \n",
       "\n",
       "        tau  \n",
       "0  0.250046  \n",
       "1  0.847493  \n",
       "2  0.851995  \n",
       "3  0.052378  \n",
       "4  0.542549  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data_df = get_previous_autoregressive_dist(AUTOREGRESSIVE_DIST_NAME=PREVIOUS_AUTOREGRESSIVE_DIST_NAME)\n",
    "eval_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed548cae-19f9-44d7-b30f-1328fd8fb454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features:\n",
      " ['RecoDatam', 'genDatapT', 'genDataeta', 'genDataphi', 'genDatam', 'tau']\n",
      "\n",
      "Target =  RecoDatapT\n",
      "USING NEW DATASET\n",
      "\n",
      "spliting autoregressive evaluation data for RecoDatapT\n",
      "train_t shape =  (8000000,) train_x shape =  (8000000, 6)\n",
      "\n",
      " Training features:\n",
      "\n",
      "[[ 2.59587    29.4452      0.828187    2.90213     2.85348     0.36130954]\n",
      " [ 5.35538    24.3193     -1.16351     0.636469    5.83685     0.12689925]\n",
      " [ 5.35538    24.3193     -1.16351     0.636469    5.83685     0.96230681]\n",
      " ...\n",
      " [ 6.25659    41.4192     -2.23358    -2.81921     7.19348     0.08421659]\n",
      " [ 6.11213    35.4637     -1.12318     0.356494    6.06597     0.05535172]\n",
      " [ 4.17483    26.5586     -1.09427    -1.49334     4.25409     0.07489863]]\n",
      "valid_t shape =  (1000000,) valid_x shape =  (1000000, 6)\n",
      "test_t shape =  (1000000,) test_x shape =  (1000000, 6)\n",
      "no need to train_test_split since we already have the split dataframes\n",
      "[ 5.55141126e+00  3.27223764e+01  6.98189368e-04 -8.95543973e-04\n",
      "  6.96116528e+00  5.00485136e-01] [ 2.66412454 15.19914133  2.20425356  1.81362773  2.78097831  0.28852734]\n",
      "[ 5.55556745e+00  3.26952341e+01 -1.78188172e-03 -3.83090331e-04\n",
      "  6.96299435e+00  4.99915289e-01] [ 2.66433986 14.93793254  2.20430976  1.81382516  2.78133203  0.28867295]\n",
      "32.881453465999996 16.02400426348493\n",
      "32.86720151648752 15.829355769531851\n",
      "NORMAL UNSCALED DICTIONARY\n",
      "{'genDatapT': {'mean': 32.695234084987476, 'std': 14.937932540562551}, 'genDataeta': {'mean': -0.0017818817154031672, 'std': 2.204309760627079}, 'genDataphi': {'mean': -0.0003830903308450233, 'std': 1.8138251604791067}, 'genDatam': {'mean': 6.962994352358474, 'std': 2.781332025286383}, 'RecoDatapT': {'mean': 32.86720151648752, 'std': 15.829355769531851}, 'RecoDataeta': {'mean': -0.0017898858568513964, 'std': 2.197968491495457}, 'RecoDataphi': {'mean': -0.0004719170328962474, 'std': 1.8144739820043825}, 'RecoDatam': {'mean': 5.555567451922438, 'std': 2.664339857066051}}\n",
      "\n",
      "\n",
      "\n",
      "[-1.81710707e+00  1.48455353e+01  5.96132264e-04 -2.50379668e+00\n",
      " -1.63658184e+00  5.00485136e-01] [0.17834627 6.89519305 1.2152514  0.65207164 0.17568487 0.28852734]\n",
      "[-1.81682884e+00  1.48332220e+01 -7.71183141e-04 -2.50361243e+00\n",
      " -1.63646629e+00  4.99915289e-01] [0.17836068 6.77669391 1.21528238 0.65214262 0.17570722 0.28867295]\n",
      "0.0009003493079555966 1.0122966781963252\n",
      "-1.2048033681821834e-15 1.0000000000000002\n",
      "<class 'str'>\n",
      "This model was trained for 2000000 iteration, which is  256.0 epochs\n",
      "RegularizedRegressionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.3)\n",
      "    (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.3)\n",
      "    (5): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (6): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.3)\n",
      "    (8): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Test (evaluation) Data is Autoregressive, loading AUTOREGRESSIVE_m_Prime.csv\n",
      "EVALUATION DATA NEW INDEX\n",
      "    RecoDatam  RecoDatapT  genDatapT  genDataeta  genDataphi  genDatam  \\\n",
      "0   4.840795   41.525097    43.6113    0.824891    -1.26949   5.93310   \n",
      "1   7.059293   49.677708    43.6113    0.824891    -1.26949   5.93310   \n",
      "2   5.725040   27.880127    26.0153    3.529970     1.55495   7.41270   \n",
      "3   3.605120   26.332504    28.4944   -1.159650     1.82602   7.84157   \n",
      "4   3.521224   22.635612    21.9840    2.747660     2.03085   5.18315   \n",
      "\n",
      "        tau  \n",
      "0  0.250046  \n",
      "1  0.847493  \n",
      "2  0.851995  \n",
      "3  0.052378  \n",
      "4  0.542549  \n",
      "norm_data 1000000 \n",
      "norm IQN 1000000 \n",
      "norm_autoregressive 1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_378619/3379445305.py:403: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax2.set_yticklabels([0.8, 1.0, 1.2])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 420x380 with 2 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/_build/jupyter_execute/3_Autoregressive_Evaluation_11_2.png"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target = \"RecoDatapT\"\n",
    "source = FIELDS[target]\n",
    "features = source[\"inputs\"]\n",
    "print(\"Training Features:\\n\", features)\n",
    "print(\"\\nTarget = \", target)\n",
    "PREVIOUS_AUTOREGRESSIVE_DIST_NAME = \"AUTOREGRESSIVE_m_Prime.csv\"\n",
    "AUTOREGRESSIVE_DIST_NAME = \"AUTOREGRESSIVE_m_Prime_pT_Prime.csv\"\n",
    "print(\"USING NEW DATASET\\n\")\n",
    "######################################\n",
    "USE_BRADEN_SCALING = False\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "raw_train_data, raw_test_data, raw_valid_data = load_raw_data()\n",
    "\n",
    "\n",
    "# Load scaled data\n",
    "# scaled_train_data, scaled_test_data, scaled_valid_data = load_scaled_dataframes()\n",
    "\n",
    "\n",
    "################################################## Load Evaluation Data\n",
    "#eval_data=pd.read_csv(DATA_DIR+'/test_data_10M_2.csv')\n",
    "# Or test on actual test (evaluation) data for development\n",
    "# eval_data=pd.read_csv(DATA_DIR+'/test_data_10M_2.csv')\n",
    "\n",
    "# Get targets and features\n",
    "if USE_BRADEN_SCALING == True:\n",
    "    print(f\"spliting data for {target}\")\n",
    "    train_t, train_x = split_t_x(\n",
    "        df=scaled_train_data, target=target, input_features=features\n",
    "    )\n",
    "    print(\"train_t shape = \", train_t.shape, \"train_x shape = \", train_x.shape)\n",
    "    print(\"\\n Training features:\\n\")\n",
    "    print(train_x)\n",
    "    valid_t, valid_x = split_t_x(\n",
    "        df=scaled_valid_data, target=target, input_features=features\n",
    "    )\n",
    "    print(\"valid_t shape = \", valid_t.shape, \"valid_x shape = \", valid_x.shape)\n",
    "        \n",
    "    ##### WHAT MATTERS IS TEST (EVALUATION)\n",
    "\n",
    "    test_t, test_x = split_t_x(\n",
    "        df=scaled_test_data, target=target, input_features=features\n",
    "    )\n",
    "    print(\"test_t shape = \", test_t.shape, \"test_x shape = \", test_x.shape)\n",
    "\n",
    "else:\n",
    "    print(f\"spliting autoregressive evaluation data for {target}\")\n",
    "    train_t, train_x = normal_split_t_x(\n",
    "            df=raw_train_data, target=target, input_features=features\n",
    "        )\n",
    "    print(\"train_t shape = \", train_t.shape, \"train_x shape = \", train_x.shape)\n",
    "    print(\"\\n Training features:\\n\")\n",
    "    print(train_x)\n",
    "    valid_t, valid_x = normal_split_t_x(\n",
    "        df=raw_valid_data, target=target, input_features=features\n",
    "    )\n",
    "    print(\"valid_t shape = \", valid_t.shape, \"valid_x shape = \", valid_x.shape)\n",
    "    ##### WHAT MATTERS IS TEST (EVALUATION)\n",
    "    test_t, test_x = normal_split_t_x(\n",
    "        df=raw_test_data, target=target, input_features=features\n",
    "    )\n",
    "    print(\"test_t shape = \", test_t.shape, \"test_x shape = \", test_x.shape)\n",
    "\n",
    "print(\"no need to train_test_split since we already have the split dataframes\")\n",
    "print(valid_x.mean(axis=0), valid_x.std(axis=0))\n",
    "print(train_x.mean(axis=0), train_x.std(axis=0))\n",
    "print(valid_t.mean(), valid_t.std())\n",
    "print(train_t.mean(), train_t.std())\n",
    "######################################################\n",
    "# Replace test_x with eval_data\n",
    "\n",
    "# ev_features = features\n",
    "# eval_data_df = eval_data[ev_features]\n",
    "# eval_data = np.array(eval_data_df)\n",
    "# test_x = eval_data\n",
    "\n",
    "# eval_data=pd.read_csv(DATA_DIR+'/test_data_10M_2.csv')\n",
    "    \n",
    "# eval_data=raw_train_data[:raw_test_data.shape[0]]\n",
    "# test_x = np.array\n",
    "\n",
    "# Apply z scaling to features and targets\n",
    "# to features\n",
    "#####################################################################\n",
    "NFEATURES = train_x.shape[1]\n",
    "# GET EVALUATION DATASET\n",
    "# eval_data= get_previous_autoregressive_dist(AUTOREGRESSIVE_DIST_NAME=PREVIOUS_AUTOREGRESSIVE_DIST_NAME)\n",
    "# test_x = np.array(eval_data[features])\n",
    "\n",
    "\n",
    "\n",
    "TRAIN_SCALE_DICT = get_train_scale_dict(USE_BRADEN_SCALING)\n",
    "# to features\n",
    "apply_z_generator = apply_z_to_features(TRAIN_SCALE_DICT, train_x, test_x, valid_x)\n",
    "train_x_z_scaled = next(apply_z_generator)\n",
    "test_x_z_scaled = next(apply_z_generator)\n",
    "valid_x_z_scaled = next(apply_z_generator)\n",
    "print(valid_x_z_scaled.mean(axis=0), valid_x_z_scaled.std(axis=0))\n",
    "print(train_x_z_scaled.mean(axis=0), train_x_z_scaled.std(axis=0))\n",
    "# to targets\n",
    "apply_z_to_targets_generator = apply_z_to_targets(train_t, test_t, valid_t)\n",
    "train_t_z_scaled = next(apply_z_to_targets_generator)\n",
    "test_t_z_scaled = next(apply_z_to_targets_generator)\n",
    "valid_t_z_scaled = next(apply_z_to_targets_generator)\n",
    "print(valid_t_z_scaled.mean(), valid_t_z_scaled.std())\n",
    "print(train_t_z_scaled.mean(), train_t_z_scaled.std())\n",
    "\n",
    "###########################################################\n",
    "# Get the  parameters for this model and training\n",
    "PARAMS_pT = {\n",
    "\"n_layers\": int(3),\n",
    "\"hidden_size\": int(16),\n",
    "\"dropout_1\": float(0.6),\n",
    "\"dropout_2\": float(0.1),\n",
    "\"activation\": \"LeakyReLU\",\n",
    "    'optimizer_name':'NAdam',\n",
    "    'starting_learning_rate':float(0.5),\n",
    "    'momentum':float(0.6),\n",
    "    'batch_size':int(1024),\n",
    "    'n_iterations': int(2e6),\n",
    "}\n",
    "\n",
    "optimizer_name = PARAMS_pT[\"optimizer_name\"]\n",
    "print(type(optimizer_name))\n",
    "# optimizer_name = BEST_PARAMS[\"optimizer_name\"].to_string().split()[1]\n",
    "NITERATIONS = PARAMS_pT[\"n_iterations\"]\n",
    "BATCHSIZE = PARAMS_pT[\"batch_size\"]\n",
    "comment = \"\"\n",
    "\n",
    "# N_epochs X N_train_examples = N_iterations X batch_size\n",
    "N_epochs = (NITERATIONS * BATCHSIZE) / int(train_x.shape[0])\n",
    "print(\n",
    "    f\"This model was trained for {NITERATIONS} iteration, which is  {N_epochs} epochs\"\n",
    ")\n",
    "\n",
    "\n",
    "filename_model = utils.get_model_filename(target, PARAMS_pT)\n",
    "# filename_model = 'Trained_IQNx4_RecoDatapT_ 13_layer6_hiddenLeakyReLU_activation1024_batchsize200_Kiteration.dict'\n",
    "# filename_model = 'Trained_IQNx4_RecoDatapT_10_layer6_hiddenLeakyReLU_activation512_batchsize300_Kiteration.dict'\n",
    "trained_models_dir = \"trained_models\"\n",
    "utils.mkdir(trained_models_dir)\n",
    "# on cluster, Im using another TRAIN directory\n",
    "PATH_model = os.path.join(\n",
    "    IQN_BASE,  # the loaction of the repo\n",
    "    \"JupyterBook\",  # up tp TRAIN could be combined in a srs dicretory\n",
    "    \"Cluster\",\n",
    "    \"TRAIN\",\n",
    "    trained_models_dir,  # /trained_models\n",
    "    filename_model,  # utils.get_model_filename has the saved file format\n",
    ")\n",
    "\n",
    "# Load trained model\n",
    "IQN_pT = load_model(PATH_model, PARAMS_pT)\n",
    "# Get predicted distribution\n",
    "p = simple_eval(IQN_pT, test_x_z_scaled)\n",
    "\n",
    "range_ = (FIELDS[target][\"xmin\"], FIELDS[target][\"xmax\"])\n",
    "bins = 50\n",
    "REAL_RAW_DATA = raw_test_data\n",
    "\n",
    "YLIM = (0.8, 1.2)\n",
    "###########GET REAL DIST###########\n",
    "REAL_RAW_DATA = REAL_RAW_DATA[\n",
    "    [\"RecoDatapT\", \"RecoDataeta\", \"RecoDataphi\", \"RecoDatam\"]\n",
    "]\n",
    "REAL_RAW_DATA.columns = [\"realpT\", \"realeta\", \"realphi\", \"realm\"]\n",
    "REAL_DIST = REAL_RAW_DATA[\"realpT\"]\n",
    "norm_data = REAL_RAW_DATA.shape[0]\n",
    "#############GET EVALUATION DIST#############\n",
    "raw_test_data.describe()\n",
    "pT_reco = raw_test_data[\"RecoDatapT\"]\n",
    "pT_gen = raw_test_data[\"genDatapT\"]\n",
    "# plt.hist(m_reco,label=r'$m_{gen}^{test \\ data}$');plt.legend();plt.show()\n",
    "\n",
    "def descale_Braden_scaled_prediction(label, p):\n",
    "    \"\"\"Label could be m. p is the outcome of the model evaluation, e.g. \n",
    "    IQN_m = load_model(PATH_model, PARAMS_m)\n",
    "    p = simple_eval(IQN_m, test_x_z_scaled)\n",
    "\n",
    "    \"\"\"\n",
    "    # make sure you've set braden scaling global variable to use this function.\n",
    "    assert USE_BRADEN_SCALING==True\n",
    "    orig_ratio = T(label, scaled_df=scaled_train_data)\n",
    "    z_inv_f = z_inverse(xprime=p, mean=np.mean(orig_ratio), std=np.std(orig_ratio))\n",
    "    L_obs = L(orig_observable=pT_gen, label=label)\n",
    "    z_inv_f = z_inv_f.flatten()\n",
    "    print(z_inv_f.shape)\n",
    "\n",
    "    factor = (z_inv_f * (L_obs + 10)) - 10\n",
    "    label_pred = L_inverse(L_observable=factor, label=label)\n",
    "    return label_pred\n",
    "\n",
    "\n",
    "pT_pred = z_inverse2(\n",
    "    xprime=p,\n",
    "    train_mean=TRAIN_SCALE_DICT[target][\"mean\"],\n",
    "    train_std=TRAIN_SCALE_DICT[target][\"std\"],\n",
    ")\n",
    "pT_pred = pT_pred.flatten()\n",
    "\n",
    "# Get histogram of predicted distribution\n",
    "real_label_counts_pT, predicted_label_counts_pT, label_edges_pT = get_hist_simple(\n",
    "    predicted_dist=pT_pred, target=target\n",
    ")\n",
    "\n",
    "# Get evaluation data as test data for development\n",
    "\n",
    "# eval_data_df=pd.read_csv(DATA_DIR+'/test_data_10M_2.csv')#[features]\n",
    "\n",
    "\n",
    "eval_data_df = get_previous_autoregressive_dist(AUTOREGRESSIVE_DIST_NAME=PREVIOUS_AUTOREGRESSIVE_DIST_NAME)\n",
    "\n",
    "ev_features = features\n",
    "eval_data = eval_data_df[ev_features]\n",
    "# save new distribution (pT) in the eval data as autoregressive eval for next IQN\n",
    "eval_data_df[target] = pT_pred\n",
    "#change order of columns\n",
    "new_cols = [\"RecoDatam\", target] + X\n",
    "eval_data_df = eval_data_df.reindex(columns=new_cols)\n",
    "print(\"EVALUATION DATA NEW INDEX\\n\", eval_data_df.head())\n",
    "# save \n",
    "eval_data_df.to_csv(\n",
    "    os.path.join(\n",
    "        IQN_BASE, \"JupyterBook\", \"Cluster\", \"EVALUATE\", AUTOREGRESSIVE_DIST_NAME\n",
    "    )\n",
    ")\n",
    "\n",
    "# Load this saved predited autoregressive distribution\n",
    "AUTOREGRESSIVE_DIST = pd.read_csv(\n",
    "    os.path.join(\n",
    "        IQN_BASE, \"JupyterBook\", \"Cluster\", \"EVALUATE\", AUTOREGRESSIVE_DIST_NAME\n",
    "    )\n",
    ")\n",
    "\n",
    "# norm_IQN=AUTOREGRESSIVE_DIST.shape[0]\n",
    "# get normalization values\n",
    "norm_autoregressive = AUTOREGRESSIVE_DIST.shape[0]\n",
    "norm_IQN = norm_autoregressive\n",
    "print(\n",
    "    \"norm_data\",\n",
    "    norm_data,\n",
    "    \"\\nnorm IQN\",\n",
    "    norm_IQN,\n",
    "    \"\\nnorm_autoregressive\",\n",
    "    norm_autoregressive,\n",
    ")\n",
    "\n",
    "# Finally, plot predicted distribution\n",
    "plot_one(\n",
    "    target=target,\n",
    "    real_edges=label_edges_pT,\n",
    "    real_counts=real_label_counts_pT,\n",
    "    predicted_counts=predicted_label_counts_pT,\n",
    "    save_plot=True,\n",
    "    PARAMS=PARAMS_pT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48801bd-6864-425d-b4cd-fbe5fdf89790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}