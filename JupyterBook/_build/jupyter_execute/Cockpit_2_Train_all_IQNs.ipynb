{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de81fd7f-8c91-44e5-9b5e-878882120c1e",
   "metadata": {},
   "source": [
    "# IQNx4 Chapter 2: Train All Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ddfd24-43c6-44ac-b171-7269c28f4f93",
   "metadata": {},
   "source": [
    "# 2.1 Imports and Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faf410b4-9e3a-4b0d-9bac-fd65f3997d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using torch version 1.13.1+cu117\n",
      "matplotlib version=  3.5.1\n",
      "using (optional) optuna version 2.8.0\n",
      "BASE directoy properly set =  /home/ali/Desktop/Pulled_Github_Repositories/torchQN\n",
      "using torch version 1.13.1+cu117\n",
      "matplotlib version=  3.5.1\n",
      "using (optional) optuna version 2.8.0\n",
      "BASE directoy properly set =  /home/ali/Desktop/Pulled_Github_Repositories/torchQN\n",
      "DATA directory also properly set, in /home/ali/Desktop/Pulled_Github_Repositories/IQN_HEP/Davidson/data\n",
      "using DATA_DIR=/home/ali/Desktop/Pulled_Github_Repositories/IQN_HEP/Davidson/data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import scipy as sp; import scipy.stats as st\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "print(f\"using torch version {torch.__version__}\")#old torch version: 1.9.0\n",
    "# use numba's just-in-time compiler to speed things up\n",
    "# from numba import njit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib as mp\n",
    "\n",
    "print(\"matplotlib version= \", mp.__version__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# reset matplotlib stle/parameters\n",
    "import matplotlib as mpl\n",
    "\n",
    "# reset matplotlib parameters to their defaults\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "plt.style.use(\"seaborn-deep\")\n",
    "mp.rcParams[\"agg.path.chunksize\"] = 10000\n",
    "font_legend = 15\n",
    "font_axes = 15\n",
    "# %matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "#or use joblib for caching on disk\n",
    "from joblib import  Memory\n",
    "# from IPython.display import Image, display\n",
    "# from importlib import import_module\n",
    "# import plotly\n",
    "try:\n",
    "    import optuna\n",
    "\n",
    "    print(f\"using (optional) optuna version {optuna.__version__}\")\n",
    "except Exception:\n",
    "    print(\"optuna is only used for hyperparameter tuning, not critical!\")\n",
    "    pass\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "# import sympy as sy\n",
    "# import ipywidgets as wid;\n",
    "\n",
    "\n",
    "# try:\n",
    "#     IQN_BASE = os.environ[\"IQN_BASE\"]\n",
    "#     print(\"BASE directoy properly set = \", IQN_BASE)\n",
    "#     utils_dir = os.path.join(IQN_BASE, \"utils/\")\n",
    "#     sys.path.append(utils_dir)\n",
    "#     import utils\n",
    "\n",
    "#     # usually its not recommended to import everything from a module, but we know\n",
    "#     # whats in it so its fine\n",
    "#     from utils import *\n",
    "\n",
    "#     print(\"DATA directory also properly set, in %s\" % os.environ[\"DATA_DIR\"])\n",
    "# except Exception:\n",
    "#     # IQN_BASE=os.getcwd()\n",
    "#     print(\n",
    "#         \"\"\"\\nBASE directory not properly set. Read repo README.    If you need a function from utils, use the decorator below, or add utils to sys.path\\n\n",
    "#     You can also do \n",
    "#     os.environ['IQN_BASE']=<ABSOLUTE PATH FOR THE IQN REPO>\n",
    "#     or\n",
    "#     os.environ['IQN_BASE']=os.getcwd()\"\"\"\n",
    "#     )\n",
    "#     pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from IPython.core.magic import register_cell_magic\n",
    "\n",
    "\n",
    "# @debug\n",
    "# def get_model_params_simple():\n",
    "#     dropout=0.2\n",
    "#     n_layers = 2\n",
    "#     n_hidden=32\n",
    "#     starting_learning_rate=1e-3\n",
    "#     print('n_iterations, n_layers, n_hidden, starting_learning_rate, dropout')\n",
    "#     return n_iterations, n_layers, n_hidden, starting_learning_rate, dropout\n",
    "\n",
    "\n",
    "# update fonts\n",
    "FONTSIZE = 14\n",
    "font = {\"family\": \"serif\", \"weight\": \"normal\", \"size\": FONTSIZE}\n",
    "mp.rc(\"font\", **font)\n",
    "\n",
    "# set usetex = False if LaTex is not\n",
    "# available on your system or if the\n",
    "# rendering is too slow\n",
    "mp.rc(\"text\", usetex=True)\n",
    "\n",
    "# set a seed to ensure reproducibility\n",
    "# seed = 128\n",
    "# rnd  = np.random.RandomState(seed)\n",
    "# sometimes jupyter doesnt initialize MathJax automatically for latex, so do this:\n",
    "#######\n",
    "\n",
    "\n",
    "IQN_BASE = os.environ[\"IQN_BASE\"]# BASE GIT REPO PATH\n",
    "print(\"BASE directoy properly set = \", IQN_BASE)\n",
    "utils_dir = os.path.join(IQN_BASE, \"utils/\")\n",
    "sys.path.append(utils_dir)\n",
    "import utils\n",
    "\n",
    "# usually its not recommended to import everything from a module, but we know\n",
    "# whats in it so its fine\n",
    "from utils import *\n",
    "\n",
    "\n",
    "DATA_DIR = os.environ[\"DATA_DIR\"]\n",
    "print(f\"using DATA_DIR={DATA_DIR}\")\n",
    "\n",
    "memory = Memory(DATA_DIR)\n",
    "################################### SET DATA CONFIGURATIONS ###################################\n",
    "\n",
    "y_label_dict = {\n",
    "    \"RecoDatapT\": \"$p(p_T)$\" + \" [ GeV\" + \"$^{-1} $\" + \"]\",\n",
    "    \"RecoDataeta\": \"$p(\\eta)$\",\n",
    "    \"RecoDataphi\": \"$p(\\phi)$\",\n",
    "    \"RecoDatam\": \"$p(m)$\" + \" [ GeV\" + \"$^{-1} $\" + \"]\",\n",
    "}\n",
    "\n",
    "loss_y_label_dict = {\n",
    "    \"RecoDatapT\": \"$p_T^{reco}$\",\n",
    "    \"RecoDataeta\": \"$\\eta^{reco}$\",\n",
    "    \"RecoDataphi\": \"$\\phi^{reco}$\",\n",
    "    \"RecoDatam\": \"$m^{reco}$\",\n",
    "}\n",
    "\n",
    "X = [\"genDatapT\", \"genDataeta\", \"genDataphi\", \"genDatam\", \"tau\"]\n",
    "\n",
    "# set order of training:\n",
    "# pT_first: pT->>m->eta->phi\n",
    "# m_first: m->pT->eta->phi\n",
    "\n",
    "\n",
    "ORDER = \"m_First\"\n",
    "\n",
    "if ORDER == \"m_First\":\n",
    "    FIELDS = {\n",
    "        \"RecoDatam\": {\n",
    "            \"inputs\": X,\n",
    "            \"xlabel\": r\"$m$ (GeV)\",\n",
    "            \"ylabel\": \"$m^{reco}$\",\n",
    "            \"xmin\": 0,\n",
    "            \"xmax\": 25,\n",
    "        },\n",
    "        \"RecoDatapT\": {\n",
    "            \"inputs\": [\"RecoDatam\"] + X,\n",
    "            \"xlabel\": r\"$p_T$ (GeV)\",\n",
    "            \"ylabel\": \"$p_T^{reco}$\",\n",
    "            \"xmin\": 20,\n",
    "            \"xmax\": 80,\n",
    "        },\n",
    "        \"RecoDataeta\": {\n",
    "            \"inputs\": [\"RecoDatam\", \"RecoDatapT\"] + X,\n",
    "            \"xlabel\": r\"$\\eta$\",\n",
    "            \"ylabel\": \"$\\eta^{reco}$\",\n",
    "            \"xmin\": -5,\n",
    "            \"xmax\": 5,\n",
    "        },\n",
    "        \"RecoDataphi\": {\n",
    "            \"inputs\": [\"RecoDatam\", \"RecoDatapT\", \"RecoDataeta\"] + X,\n",
    "            \"xlabel\": r\"$\\phi$\",\n",
    "            \"ylabel\": \"$\\phi^{reco}$\",\n",
    "            \"xmin\": -3.2,\n",
    "            \"xmax\": 3.2,\n",
    "        },\n",
    "    }\n",
    "elif ORDER== \"phi_first\":\n",
    "    FIELDS = {\n",
    "        \"RecoDataphi\": {\n",
    "        \"inputs\": X,\n",
    "        \"xlabel\": r\"$\\phi$\",\n",
    "        \"ylabel\": \"$\\phi^{reco}$\",\n",
    "        \"xmin\": -3.2,\n",
    "        \"xmax\": 3.2,\n",
    "    },\n",
    "\n",
    "    \"RecoDatam\": {\n",
    "        \"inputs\": ['RecoDataphi'] + X,\n",
    "        \"xlabel\": r\"$m$ (GeV)\",\n",
    "        \"ylabel\": \"$m^{reco}$\",\n",
    "        \"xmin\": 0,\n",
    "        \"xmax\": 25,\n",
    "    },\n",
    "    \"RecoDatapT\": {\n",
    "        \"inputs\": [\"RecoDataphi\", \"RecoDatam\"] + X,\n",
    "        \"xlabel\": r\"$p_T$ (GeV)\",\n",
    "        \"ylabel\": \"$p_T^{reco}$\",\n",
    "        \"xmin\": 20,\n",
    "        \"xmax\": 80,\n",
    "    },\n",
    "    \"RecoDataeta\": {\n",
    "        \"inputs\": [\"RecoDataphi\", \"RecoDatam\", \"RecoDatapT\"]  + X,\n",
    "        \"xlabel\": r\"$\\eta$\",\n",
    "        \"ylabel\": \"$\\eta^{reco}$\",\n",
    "        \"xmin\": -5,\n",
    "        \"xmax\": 5,\n",
    "    },\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "# Load and explore raw (unscaled) dataframes\n",
    "\n",
    "\n",
    "all_variable_cols = [\n",
    "    \"genDatapT\",\n",
    "    \"genDataeta\",\n",
    "    \"genDataphi\",\n",
    "    \"genDatam\",\n",
    "    \"RecoDatapT\",\n",
    "    \"RecoDataeta\",\n",
    "    \"RecoDataphi\",\n",
    "    \"RecoDatam\",\n",
    "]\n",
    "all_cols = [\n",
    "    \"genDatapT\",\n",
    "    \"genDataeta\",\n",
    "    \"genDataphi\",\n",
    "    \"genDatam\",\n",
    "    \"RecoDatapT\",\n",
    "    \"RecoDataeta\",\n",
    "    \"RecoDataphi\",\n",
    "    \"RecoDatam\",\n",
    "    \"tau\",\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "105088f1-c9e7-4286-81f4-da4f1dde29b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cockpit\n",
    "from backpack import extend\n",
    "\n",
    "from cockpit import Cockpit, CockpitPlotter\n",
    "from cockpit.utils.configuration import configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9654c3-0337-4d13-b223-c9750abd0afc",
   "metadata": {},
   "source": [
    "# 2.2: Load Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90f34e6d-4f15-4e82-96ae-64d047b38eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LR_Cooler:\n",
    "    def __init__(self, starting_lr: float, total_iterations: int, iter_: int) -> float:\n",
    "        self.starting_lr=starting_lr\n",
    "        self.iter_=iter_\n",
    "        self.total_iterations= total_iterations\n",
    "    def exponential_decay(self):\n",
    "        return self.starting_lr * (np.exp(-  self.iter_/1e5 ))\n",
    "    def exponential_decay_2(self):\n",
    "        decay_rate=1e-3\n",
    "        return self.starting_lr * np.exp(- decay_rate* self.iter)\n",
    "    \n",
    "    def fractional_decay(self):\n",
    "        final_time = 1\n",
    "        return self.starting_lr/(self.iter + final_time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30f02bc1-6d36-44e8-b412-5356ef425eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/_build/jupyter_execute/Cockpit_2_Train_all_IQNs_6_0.png"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LR_sched = LR_Cooler(1e-3, np.arange(1e6), np.arange(1e6))\n",
    "LR = LR_sched.exponential_decay()\n",
    "plt.plot(np.arange(1e6), LR);plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f9d1692-0259-40e5-8859-3fbbfc76f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### Load unscaled dataframes ###################################\n",
    "@memory.cache\n",
    "def load_raw_data():\n",
    "    \"\"\"Load raw train, test, and validation raw (unscaled) dataframes, in that order.\n",
    "\n",
    "    Returns:\n",
    "        list(pandas.DataFrame): train, test, valid raw datafranes\n",
    "    \"\"\"\n",
    "    print(f'SUBSAMPLE = {SUBSAMPLE}')\n",
    "    raw_train_data=pd.read_csv(os.path.join(DATA_DIR,'train_data_10M_2.csv'),\n",
    "                        usecols=all_cols,\n",
    "                        nrows=SUBSAMPLE\n",
    "                        )\n",
    "\n",
    "    raw_test_data=pd.read_csv(os.path.join(DATA_DIR,'test_data_10M_2.csv'),\n",
    "                        usecols=all_cols,\n",
    "                        nrows=SUBSAMPLE\n",
    "                        )\n",
    "\n",
    "    raw_valid_data=pd.read_csv(os.path.join(DATA_DIR,'validation_data_10M_2.csv'),\n",
    "                        usecols=all_cols,\n",
    "                        nrows=SUBSAMPLE\n",
    "                        )\n",
    "\n",
    "\n",
    "    print('\\n RAW TRAIN DATA SHAPE\\n')\n",
    "    print(raw_train_data.shape)\n",
    "    print('\\n RAW TRAIN DATA\\n')\n",
    "    raw_train_data.describe()#unscaled\n",
    "    print('\\n RAW TEST DATA\\ SHAPEn')\n",
    "    print(raw_test_data.shape)\n",
    "    print('\\n RAW TEST DATA\\n')\n",
    "    raw_test_data.describe()#unscaled\n",
    "\n",
    "    return raw_train_data, raw_test_data, raw_valid_data\n",
    "\n",
    "\n",
    "########## Generate scaled data###############\n",
    "# scaled_train_data = L_scale_df(raw_train_data, title='scaled_train_data_10M_2.csv',\n",
    "#                              save=True)\n",
    "# print('\\n\\n')\n",
    "# scaled_test_data = L_scale_df(raw_test_data,  title='scaled_test_data_10M_2.csv',\n",
    "#                             save=True)\n",
    "# print('\\n\\n')\n",
    "\n",
    "# scaled_valid_data = L_scale_df(raw_valid_data,  title='scaled_valid_data_10M_2.csv',\n",
    "#                             save=True)\n",
    "\n",
    "# explore_data(df=scaled_train_data, title='Braden Kronheim-L-scaled Dataframe', scaled=True)\n",
    "\n",
    "################ Load scaled data##############\n",
    "@utils.time_type_of_func(tuning_or_training='loading')\n",
    "@memory.cache\n",
    "def load_scaled_dataframes():\n",
    "    \"\"\"Load L-scaled train, test and validation according to Braden scaling, in that order.\n",
    "\n",
    "    Returns:\n",
    "        list(pandas.DataFarme): L-scaled train, test, validation dataframes, in that order.\n",
    "    \"\"\"\n",
    "    # print(\"SCALED TRAIN DATA\")\n",
    "    scaled_train_data = pd.read_csv(\n",
    "        os.path.join(DATA_DIR, \"scaled_train_data_10M_2.csv\"),\n",
    "        usecols=all_cols,\n",
    "        nrows=SUBSAMPLE,\n",
    "    )\n",
    "\n",
    "    # print(\"TRAINING FEATURES\\n\", scaled_train_data.head())\n",
    "\n",
    "    scaled_test_data = pd.read_csv(\n",
    "        os.path.join(DATA_DIR, \"scaled_test_data_10M_2.csv\"),\n",
    "        usecols=all_cols,\n",
    "        nrows=SUBSAMPLE,\n",
    "    )\n",
    "\n",
    "    scaled_valid_data = pd.read_csv(\n",
    "        os.path.join(DATA_DIR, \"scaled_valid_data_10M_2.csv\"),\n",
    "        usecols=all_cols,\n",
    "        nrows=SUBSAMPLE,\n",
    "    )\n",
    "    return scaled_train_data, scaled_test_data, scaled_valid_data\n",
    "\n",
    "# print('\\nTESTING FEATURES\\n', test_data_m.head())\n",
    "\n",
    "# print('\\ntrain set shape:',  train_data_m.shape)\n",
    "# print('\\ntest set shape:  ', test_data_m.shape)\n",
    "# # print('validation set shape:', valid_data.shape)\n",
    "\n",
    "\n",
    "\n",
    "def get_train_scale_dict(USE_BRADEN_SCALING):\n",
    "    \"\"\"Get a dictionary containing mean and standard deviation of each gen and reco feature. \n",
    "\n",
    "    Args:\n",
    "        USE_BRADEN_SCALING (bool): Whether you wish to use the Braden scaling. If True, it uses the L-scaled train dataframe. If False, it uses the unscaled dataframe.\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary of floats containing mean and standard deviation of each gen and reco feature. \n",
    "    \"\"\"\n",
    "    if USE_BRADEN_SCALING==True:\n",
    "        TRAIN_SCALE_DICT = get_scaling_info(scaled_train_data)\n",
    "        print('BRADEN SCALING DICTIONARY')\n",
    "        print(TRAIN_SCALE_DICT)\n",
    "        print(\"\\n\\n\")\n",
    "        # TEST_SCALE_DICT = get_scaling_info(scaled_test_data)\n",
    "        # print(TEST_SCALE_DICT)\n",
    "    else:\n",
    "        print('NORMAL UNSCALED DICTIONARY')\n",
    "        TRAIN_SCALE_DICT = get_scaling_info(raw_train_data)\n",
    "        print(TRAIN_SCALE_DICT)\n",
    "        print(\"\\n\\n\")\n",
    "        # TEST_SCALE_DICT = get_scaling_info(scaled_test_data)\n",
    "        # print(TEST_SCALE_DICT)\n",
    "    return TRAIN_SCALE_DICT\n",
    "\n",
    "\n",
    "\n",
    "################################ SPLIT###########\n",
    "# Currently need the split function again here\n",
    "# @memory.cache\n",
    "def split_t_x(df, target, input_features):\n",
    "    \"\"\"Get the target as the ratio, according to the T equation.\n",
    "    \n",
    "    Returns:\n",
    "    list(numpy.array): list of numpy array of target and training features\"\"\"\n",
    "\n",
    "    if target == \"RecoDatam\":\n",
    "        t = T(\"m\", scaled_df=scaled_train_data)\n",
    "    if target == \"RecoDatapT\":\n",
    "        t = T(\"pT\", scaled_df=scaled_train_data)\n",
    "    if target == \"RecoDataeta\":\n",
    "        t = T(\"eta\", scaled_df=scaled_train_data)\n",
    "    if target == \"RecoDataphi\":\n",
    "        t = T(\"phi\", scaled_df=scaled_train_data)\n",
    "    x = np.array(df[input_features])\n",
    "    return np.array(t), x\n",
    "\n",
    "# @memory.cache\n",
    "def normal_split_t_x(df, target, input_features):\n",
    "    \"\"\"splot dataframe into targets and feature arrays.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): Dataframe of train, test or validation data.\n",
    "        target (str): Choice of \"RecoDatapT\", \"RecoDataeta\", \"RecoDataphi\",\"RecoDatam\" as target.\n",
    "        input_features (list(str)): list of training features labels\n",
    "\n",
    "    Returns:\n",
    "    list(numpy.array): list of numpy array of target and training features\n",
    " \"\"\"\n",
    "    # change from pandas dataframe format to a numpy \n",
    "    # array of the specified types\n",
    "    # t = np.array(df[target])\n",
    "    t = np.array(df[target])\n",
    "    x = np.array(df[input_features])\n",
    "    return t, x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################ Apply Z scaling############\n",
    "def z(x):\n",
    "    \"\"\"Simple z-score standardization. Used for targets\"\"\"\n",
    "    eps = 1e-20\n",
    "    return (x - np.mean(x)) / (np.std(x) + eps)\n",
    "def z_inverse(xprime, x):\n",
    "    return xprime * np.std(x) + np.mean(x)\n",
    "\n",
    "# @memory.cache\n",
    "def z2(x, mean, std):\n",
    "    \"\"\"\n",
    "    The main z score function. Args:\n",
    "        x (numpy.array): feature 1-D array\n",
    "        mean (float): mean of the feature (in the training set)\n",
    "        std (float): standard deviation of the feature (in the training set)\n",
    "\n",
    "    Returns:\n",
    "        numpy.array: z-score-scaled 1-D feature\n",
    "    \"\"\"\n",
    "    eps = 1e-20\n",
    "    scaled = (x - mean) / (std + eps)\n",
    "    return np.array(scaled, dtype=np.float64)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# @memory.cache\n",
    "def z_inverse2(xprime, train_mean, train_std):\n",
    "    \"\"\"\n",
    "        The main z score de-scaling function. \n",
    "        \n",
    "        Args:\n",
    "        xprime (numpy.array): z-score-scaled feature 1-D array\n",
    "        train_mean (float): mean of the feature (in the training set)\n",
    "        train_std (float): standard deviation of the feature (in the training set)\n",
    "        \"\"\"\n",
    "    return xprime * train_std + train_mean\n",
    "\n",
    "# @memory.cache\n",
    "def apply_z_to_features(TRAIN_SCALE_DICT, train_x, test_x, valid_x):\n",
    "    \"\"\"TO ensure this z scaling is only applied once to the training features, we use a generator.\n",
    "    This doesn't change the shapes of anything, just applies z to all the feature columns other than tau.\n",
    "    \n",
    "    Args:\n",
    "    TRAIN_SCALE_DICT (dict(float)): dictionary of train set mean and standard deviation values\n",
    "    train_x (numpy.array): 2-D numpy array of training features\n",
    "    test_x (numpy.array):  2-D numpy array of test features\n",
    "    valid_x (numpy.array):  2-D numpy array of validation features\n",
    "    \"\"\"\n",
    "    # NFEATURES - 1 if not using tau, NFEATURES if using tau\n",
    "    for i in range(NFEATURES - 1):\n",
    "        variable = list(TRAIN_SCALE_DICT)[i]\n",
    "        train_mean = float(TRAIN_SCALE_DICT[variable][\"mean\"])\n",
    "        train_std = float(TRAIN_SCALE_DICT[variable][\"std\"])\n",
    "        train_x[:, i] = z2(train_x[:, i], mean=train_mean, std=train_std)\n",
    "        test_x[:, i] = z2(test_x[:, i], mean=train_mean, std=train_std)\n",
    "        valid_x[:, i] = z2(valid_x[:, i], mean=train_mean, std=train_std)\n",
    "    yield train_x\n",
    "    yield test_x\n",
    "    yield valid_x\n",
    "\n",
    "\n",
    "# @memory.cache\n",
    "def apply_z_to_targets(train_t, test_t, valid_t):\n",
    "    \"\"\"apply z-score scaling to target columns\n",
    "\n",
    "    Args:\n",
    "        train_t (numpy.array): target column in the training set\n",
    "        test_t (numpy.array): target column in the test set\n",
    "        valid_t (numpy.array): target column in the validation set\n",
    "\n",
    "    Yields:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "    train_mean = np.mean(train_t)\n",
    "    train_std = np.std(train_t)\n",
    "    train_t_ = z2(train_t, mean=train_mean, std=train_std)\n",
    "    test_t_ = z2(test_t, mean=train_mean, std=train_std)\n",
    "    valid_t_ = z2(valid_t, mean=train_mean, std=train_std)\n",
    "\n",
    "    yield train_t_\n",
    "    yield test_t_\n",
    "    yield valid_t_\n",
    "\n",
    "\n",
    "\n",
    "# check that it looks correct\n",
    "# fig = plt.figure(figsize=(10, 4))\n",
    "# ax = fig.add_subplot(autoscale_on=True)\n",
    "# ax.grid()\n",
    "# for i in range(NFEATURES):\n",
    "#     ax.hist(train_x[:,i], alpha=0.35, label=f'feature {i}' )\n",
    "#     # set_axes(ax=ax, xlabel=\"Transformed features X' \",title=\"training features post-z score: X'=z(L(X))\")\n",
    "# ax.legend()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "######### Get beset hyperparameters\n",
    "# tuned_dir = os.path.join(IQN_BASE,'best_params')\n",
    "# tuned_filename=os.path.join(tuned_dir,'best_params_mass_%s_trials.csv' % str(int(n_trials)))\n",
    "# BEST_PARAMS = pd.read_csv(os.path.join(IQN_BASE, 'best_params','best_params_Test_Trials.csv'))\n",
    "# BEST_PARAMS=pd.read_csv(tuned_filename)\n",
    "# print(BEST_PARAMS)\n",
    "\n",
    "\n",
    "\n",
    "def load_untrained_model(PARAMS):\n",
    "    \"\"\"Load an untrained model (with weights initiatted) according to model paramateters in the \n",
    "    PARAMS dictionary\n",
    "\n",
    "    Args:\n",
    "        PARAMS (dict): dictionary of model/training parameters: i.e. hyperparameters and training parameters.\n",
    "\n",
    "    Returns:\n",
    "        utils.RegularizedRegressionModel object\n",
    "    \"\"\"\n",
    "    model = utils.RegularizedRegressionModel(\n",
    "        nfeatures=NFEATURES,\n",
    "        ntargets=1,\n",
    "        nlayers=PARAMS[\"n_layers\"],\n",
    "        hidden_size=PARAMS[\"hidden_size\"],\n",
    "        dropout_1=PARAMS[\"dropout_1\"],\n",
    "        dropout_2=PARAMS[\"dropout_2\"],\n",
    "        activation=PARAMS[\"activation\"],\n",
    "    )\n",
    "    # model.apply(initialize_weights)\n",
    "    print(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SaveModelCheckpoint:\n",
    "    \"\"\"Continuous model-checkpointing class. Updates the latest checkpoint of an object based o validation loss each time its called. \n",
    "    \"\"\"\n",
    "    def __init__(self, best_valid_loss=np.inf):\n",
    "        \"\"\"Initiate an instance of the class based on filename and best_valid_loss/\n",
    "\n",
    "        Args:\n",
    "            best_valid_loss (float, optional): Best possible validation loss of a checkpoint object. Defaults to np.inf.\n",
    "        \"\"\"\n",
    "        self.best_valid_loss = best_valid_loss\n",
    "        self.filename_model=filename_model\n",
    "\n",
    "    def __call__(self, model, current_valid_loss, filename_model):\n",
    "        \"\"\"When an object of the calss is called, its validation loss gets updated and the model based \n",
    "        on the latest validation loss is saved.\n",
    "\n",
    "        Args:\n",
    "            model: utils.RegularizedRegressionModel object.\n",
    "            current_valid_loss (float): current (latest) validation loss of this model during the training process.\n",
    "            filename_model (str): filename in which the latest model will be saved. Can be a relative or local path. \n",
    "        \"\"\"\n",
    "        if current_valid_loss < self.best_valid_loss:\n",
    "            # update the best loss\n",
    "            self.best_valid_loss = current_valid_loss\n",
    "            # filename_model='Trained_IQNx4_%s_%sK_iter.dict' % (target, str(int(n_iterations/1000)) )\n",
    "            # filename_model = \"Trained_IQNx4_%s_TUNED_2lin_with_noise.dict\" % target\n",
    "\n",
    "            # note that n_iterations is the total n_iterations, we dont want to save a million files for each iteration\n",
    "            trained_models_dir = \"trained_models\"\n",
    "            mkdir(trained_models_dir)\n",
    "            # on cluster, Im using another TRAIN directory\n",
    "            PATH_model = os.path.join(\n",
    "                IQN_BASE,\n",
    "                \"JupyterBook\",\n",
    "                \"Cluster\",\n",
    "                \"TRAIN\",\n",
    "                trained_models_dir,\n",
    "                filename_model,\n",
    "            )\n",
    "            torch.save(model.state_dict(), PATH_model)\n",
    "            print(\n",
    "                f\"\\nCurrent valid loss: {current_valid_loss};  saved better model at {PATH_model}\"\n",
    "            )\n",
    "            # save using .pth object which if a dictionary of dicionaries, so that I can have PARAMS saved in the same file\n",
    "\n",
    "\n",
    "def train(\n",
    "    target,\n",
    "    model,\n",
    "    avloss,\n",
    "    getbatch,\n",
    "    train_x,\n",
    "    train_t,\n",
    "    valid_x,\n",
    "    valid_t,\n",
    "    PARAMS,\n",
    "    traces,\n",
    "    step,\n",
    "    window,\n",
    "):\n",
    "    \"\"\"Training Function. \n",
    "\n",
    "    Args:\n",
    "        target (str): hoice of \"RecoDatapT\", \"RecoDataeta\", \"RecoDataphi\",\"RecoDatam\" as target.\n",
    "        model a torch NN model, e.g utils.RegularizedRegressionModel.\n",
    "        avloss (float): average training losss\n",
    "        getbatch (function): a get_batch function\n",
    "        train_x (numpy.DataFrame): 2-D numpy array of training features\n",
    "        train_t (numpy.DataFrame:  1-D numpy array of training targets\n",
    "        valid_x (numpy.DataFrame): 2-D numpy array of validation features\n",
    "        valid_t (numpy.DataFrame: 1-D numpy array of validation targets\n",
    "        PARAMS (dict): dictionary of model/training parameters \n",
    "        traces (tuple): tuple of  \n",
    "        (iteration, training accuracy, validation accuracy, running average of validation accuracy) \n",
    "        = (xx, yy_t, yy_v, yy_v_avg) \n",
    "        step (int): number of iterations to take a printout step of the traces\n",
    "        window (int): window of running average of validation loss  \n",
    "\n",
    "    Returns:\n",
    "        tuple: traces\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: obviously, for reference, the \"traces\" should be saved as a 2D numpy array\n",
    "    # with the same naming format as the \"model_filename\", so that it can be opened later and \n",
    "    # plot loss curves for different models.\n",
    "    \n",
    "    # TODO: decay the stepsize, such that steps (and hence checkpointing) are large in the beginnig to the learning\n",
    "    # process (which corresponds to high learning rates), and decrease as time steps increase.\n",
    "    batch_size = PARAMS['batch_size']\n",
    "    n_iterations = PARAMS['n_iterations']\n",
    "    # to keep track of average losses\n",
    "    xx, yy_t, yy_v, yy_v_avg = traces\n",
    "    model_checkpoint = SaveModelCheckpoint()\n",
    "    n = len(valid_x)\n",
    "    \n",
    "    print(\"Iteration vs average loss\")\n",
    "    print(\"%10s\\t%10s\\t%10s\" % (\"iteration\", \"train-set\", \"test-set\"))\n",
    "    \n",
    "    fifth_n_iterations=int(n_iterations//5)\n",
    "    starting_learning_rate = PARAMS['starting_learning_rate']\n",
    "    for ii in range(n_iterations):\n",
    "        #experiment with annealing LR from beginning\n",
    "\n",
    "#         # starting learning rate (first fifth)\n",
    "        Cutoff_from_initial_LR = 15000\n",
    "        if ii< Cutoff_from_initial_LR:\n",
    "            learning_rate= starting_learning_rate\n",
    "        \n",
    "#         #second fifth\n",
    "\n",
    "#         if 2* fifth_n_iterations < ii < 3*fifth_n_iterations:\n",
    "#             learning_rate=starting_learning_rate/10 #1e-2\n",
    "        if ii > Cutoff_from_initial_LR:\n",
    "            LR_sched=LR_Cooler(starting_lr=starting_learning_rate, total_iterations=n_iterations, iter_=ii)\n",
    "            learning_rate=LR_sched.exponential_decay()\n",
    "#         #third fifth\n",
    "#         if 3*fifth_n_iterations < ii < 4*fifth_n_iterations:\n",
    "#             learning_rate=starting_learning_rate/100 #1e-3\n",
    "#         #frouth fifth: stary decay LR\n",
    "#         if ii > 4*fifth_n_iterations:\n",
    "#             learning_rate = decay_LR(ii)\n",
    "            \n",
    "        \n",
    "        # add weight decay (important regularization to reduce overfitting)\n",
    "        L2 = 1\n",
    "        # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=L2)\n",
    "        #SGD allows for: momentum=0, dampening=0, weight_decay=0, nesterov=boolean, differentiable=boolean\n",
    "\n",
    "        optimizer = getattr(torch.optim, optimizer_name)(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "         # amsgrad=True, \n",
    "\n",
    "        #  weight_decay=L2,#\n",
    "        # differentiable=True,\n",
    "        #For SGD nesterov, it requires momentum and zero dampening\n",
    "        # dampening=0,\n",
    "        # momentum=momentum,\n",
    "        # nesterov=True\n",
    "        # BUT no one should ever use SGD in 2022! Adam converges much better and faster.\n",
    "        )\n",
    "        \n",
    "        #if ii > 1e4: learning_rate=1e-4\n",
    "        # set mode to training so that training specific\n",
    "        # operations such as dropout are enabled.\n",
    "        # time_p_start = time.perf_counter()\n",
    "        model.train()\n",
    "\n",
    "        # get a random sample (a batch) of data (as numpy arrays)\n",
    "        batch_x, batch_t = getbatch(train_x, train_t, batch_size)\n",
    "        # Take df/ dtau\n",
    "        # x = torch.from_numpy(batch_x).float()\n",
    "        # # print('x is leaf: ', x.is_leaf)\n",
    "        # x.requires_grad_(True)\n",
    "        # # x.retain_grad()\n",
    "        # # print('x is leaf after retain: ', x.is_leaf)\n",
    "        # # x.requires_grad_(True)\n",
    "        # # x.retain_grad()\n",
    "        # f = model(x)\n",
    "        # f = f.view(-1)\n",
    "        # #multiply the model by its ransverse, remember we can only take gradients of scalars\n",
    "        # #and f will be a vector before this\n",
    "        # f = f @ f.t()\n",
    "        # f.retain_grad()\n",
    "        # f.backward(gradient=torch.ones_like(f), retain_graph=True)\n",
    "        # df_dx = x.grad\n",
    "        # df_dtau = df_dx[:,-1]\n",
    "        # x.grad.zero_()\n",
    "        \n",
    "        #add noise to training data\n",
    "        # batch_x = add_noise(batch_x)\n",
    "        # batch_t = add_noise(batch_t)\n",
    "        \n",
    "        # Try torch scheduler\n",
    "        scheduler=torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)\n",
    "\n",
    "        with torch.no_grad():  # no need to compute gradients\n",
    "            # wrt. x and t\n",
    "            x = torch.from_numpy(batch_x).float()\n",
    "            t = torch.from_numpy(batch_t).float()\n",
    "\n",
    "        outputs = model(x).reshape(t.shape)\n",
    "\n",
    "        empirical_risk = avloss(outputs, t, x)\n",
    "\n",
    "        optimizer.zero_grad()  # clear previous gradients\n",
    "        empirical_risk.backward()  # compute gradients\n",
    "\n",
    "        optimizer.step()  # move one step towards the minimum of the loss function using an SGD-like algorithm.\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "        if ii % step == 0:\n",
    "\n",
    "            print(f\"\\t\\tCURRENT LEARNING RATE: {learning_rate}\")\n",
    "            acc_t = validate(model, avloss, train_x[:n], train_t[:n])\n",
    "            #acc_t: list of training losses\n",
    "            acc_v = validate(model, avloss, valid_x[:n], valid_t[:n])\n",
    "            #acc_v: list of validation losses\n",
    "            yy_t.append(acc_t)\n",
    "            yy_v.append(acc_v)\n",
    "            previous_iter_valid_loss = yy_v[-1]\n",
    "            print(f'previous_iter_valid_loss : {previous_iter_valid_loss}\\n')\n",
    "            # save better models based on valid loss\n",
    "            # filename_model=\"Trained_IQNx4_%s_TUNED_0lin_with_high_noise3.dict\" % target\n",
    "            filename_model=get_model_filename(target, PARAMS)\n",
    "             \n",
    "            model_checkpoint(model=model, filename_model =filename_model ,current_valid_loss=acc_v)\n",
    "            # compute running average for validation data\n",
    "            len_yy_v = len(yy_v)\n",
    "            if len_yy_v < window:\n",
    "                yy_v_avg.append(yy_v[-1])\n",
    "            elif len_yy_v == window:\n",
    "                yy_v_avg.append(sum(yy_v) / window)\n",
    "            else:\n",
    "                acc_v_avg = yy_v_avg[-1] * window\n",
    "                acc_v_avg += yy_v[-1] - yy_v[-window - 1]\n",
    "                yy_v_avg.append(acc_v_avg / window)\n",
    "\n",
    "            if len(xx) < 1:\n",
    "                xx.append(0)\n",
    "                print(\"%10d\\t%10.6f\\t%10.6f\" % (xx[-1], yy_t[-1], yy_v[-1]))\n",
    "            else:\n",
    "                xx.append(xx[-1] + step)\n",
    "\n",
    "                print(\n",
    "                    \"\\r%10d\\t%10.6f\\t%10.6f\\t%10.6f\"\n",
    "                    % (xx[-1], yy_t[-1], yy_v[-1], yy_v_avg[-1]),\n",
    "                    end=\"\",\n",
    "                )\n",
    "        # time_p_end = time.perf_counter()\n",
    "        # time_for_this_iter = time_p_end-time_p_start\n",
    "        # time_per_example = time_for_this_iter/batch_size\n",
    "        # print(f'training time for one example: {time_per_example}')\n",
    "\n",
    "    print()\n",
    "    return (xx, yy_t, yy_v, yy_v_avg)\n",
    "\n",
    "\n",
    "@utils.time_type_of_func(tuning_or_training=\"training\")\n",
    "def run(\n",
    "    target,\n",
    "    model,\n",
    "    train_x,\n",
    "    train_t,\n",
    "    valid_x,\n",
    "    valid_t,\n",
    "    traces,\n",
    "    PARAMS,\n",
    "    traces_step,\n",
    "    traces_window,\n",
    "    save_model,\n",
    "):\n",
    "\n",
    "\n",
    "    traces = train(\n",
    "        target,\n",
    "        model,\n",
    "        average_quantile_loss,\n",
    "        get_batch,\n",
    "        train_x,\n",
    "        train_t,\n",
    "        valid_x,\n",
    "        valid_t,\n",
    "        PARAMS,\n",
    "        traces,\n",
    "        step=traces_step,\n",
    "        window=traces_window,\n",
    "    )\n",
    "\n",
    "    if save_model:\n",
    "        filename = \"Trained_IQNx4_%s_%sK_iter.dict\" % (\n",
    "            target,\n",
    "            str(int(n_iterations / 1000)),\n",
    "        )\n",
    "        PATH = os.path.join(IQN_BASE, \"trained_models\", filename)\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "        print(\"\\ntrained model dictionary saved in %s\" % PATH)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_train_scale_dict(USE_BRADEN_SCALING):\n",
    "    if USE_BRADEN_SCALING==True:\n",
    "        TRAIN_SCALE_DICT = utils.get_scaling_info(scaled_train_data)\n",
    "        print(\"BRADEN SCALING DICTIONARY\")\n",
    "        print(TRAIN_SCALE_DICT)\n",
    "        print(\"\\n\\n\")\n",
    "        # TEST_SCALE_DICT = get_scaling_info(scaled_test_data)\n",
    "        # print(TEST_SCALE_DICT)\n",
    "    else:\n",
    "        print(\"NORMAL UNSCALED DICTIONARY\")\n",
    "        TRAIN_SCALE_DICT = utils.get_scaling_info(raw_train_data)\n",
    "        print(TRAIN_SCALE_DICT)\n",
    "        print(\"\\n\\n\")\n",
    "        # TEST_SCALE_DICT = get_scaling_info(scaled_test_data)\n",
    "        # print(TEST_SCALE_DICT)\n",
    "    return TRAIN_SCALE_DICT\n",
    "\n",
    "\n",
    "@utils.debug\n",
    "def save_model(model, PATH):\n",
    "    print(model)\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    print(\"\\ntrained model dictionary saved in %s\" % PATH)\n",
    "\n",
    "\n",
    "@utils.debug\n",
    "def save_model_params(model, PATH):\n",
    "    print(model)\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    print(\"\\ntrained model dictionary saved in %s\" % PATH)\n",
    "\n",
    "\n",
    "@utils.debug\n",
    "def load_model(PATH):\n",
    "    # n_layers = int(BEST_PARAMS[\"n_layers\"])\n",
    "    # hidden_size = int(BEST_PARAMS[\"hidden_size\"])\n",
    "    # dropout = float(BEST_PARAMS[\"dropout\"])\n",
    "    # optimizer_name = BEST_PARAMS[\"optimizer_name\"].to_string().split()[1]\n",
    "    # learning_rate =  float(BEST_PARAMS[\"learning_rate\"])\n",
    "    # batch_size = int(BEST_PARAMS[\"batch_size\"])\n",
    "    model = utils.RegularizedRegressionModel(\n",
    "        nfeatures=train_x.shape[1],\n",
    "        ntargets=1,\n",
    "        nlayers=n_layers,\n",
    "        hidden_size=hidden_size,\n",
    "        dropout=dropout,\n",
    "    )\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    # OR\n",
    "    # model=torch.load(PATH)#BUT HERE IT WILL BE A DICT (CANT BE EVALUATED RIGHT AWAY) DISCOURAGED!\n",
    "    model.eval()\n",
    "    print(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_trained_model(PATH, PARAMS):\n",
    "    model = utils.RegularizedRegressionModel(\n",
    "        nfeatures=NFEATURES,\n",
    "        ntargets=1,\n",
    "        nlayers=PARAMS[\"n_layers\"],\n",
    "        hidden_size=PARAMS[\"hidden_size\"],\n",
    "        dropout_1=PARAMS[\"dropout_1\"],\n",
    "        dropout_2=PARAMS[\"dropout_2\"],\n",
    "        activation=PARAMS[\"activation\"],\n",
    "    )\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    print(model)\n",
    "    model.train()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891fa0d7-ee43-4ee0-8d25-eafa4fc40b02",
   "metadata": {},
   "source": [
    "# 2.3 Load Data, split, scale, and Train Mass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1b5168-4ef0-4d5f-b115-372c5bfd2609",
   "metadata": {},
   "source": [
    "#### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38a53649-0c88-4fb8-9052-1187751e3dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "USE_BRADEN_SCALING=False\n",
    "#####################################\n",
    "################################### CONFIGURATIONS ###################################\n",
    "\n",
    "JUPYTER = True\n",
    "use_subsample = True\n",
    "# use_subsample = True\n",
    "if use_subsample:\n",
    "    SUBSAMPLE = int(1e5)  # subsample use for development - in production use whole dataset\n",
    "else:\n",
    "    SUBSAMPLE = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c91935e-8f27-4a16-a568-9302c2f91f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "# Load data only once, and with caching!\n",
    "raw_train_data, raw_test_data, raw_valid_data =load_raw_data()\n",
    "# Load scaled data\n",
    "# scaled_train_data, scaled_test_data, scaled_valid_data = load_scaled_dataframes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b293d42-feed-4966-846e-fa77e0d33e7d",
   "metadata": {},
   "source": [
    "## Oversample regions with $11 < m < 25$ GeV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c048ce8-2b83-4d3e-ae87-88bd028edb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample_mass(df, mass_min, mass_max):\n",
    "  \"\"\"df could be raw_test_data \"\"\"\n",
    "  first_mask = df.RecoDatam < 25 #I think this condition might not make sense (we want to define just a min)\n",
    "  second_mask = df.RecoDatam > 10\n",
    "  df_resampled =df[second_mask]#[first_mask]\n",
    "  frames = [df, df_resampled]\n",
    "  df_combined = pd.concat(frames)\n",
    "  return df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "027cc928-b082-4ab5-a922-da413d8fc3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_test_data_ =oversample_mass(df=raw_test_data, mass_min=10, mass_max=25)\n",
    "# raw_valid_data_ =oversample_mass(df=raw_valid_data, mass_min=10, mass_max=25)\n",
    "# raw_train_data_ =oversample_mass(df=raw_train_data, mass_min=10, mass_max=25)\n",
    "\n",
    "# raw_test_data, raw_valid_data, raw_train_data=raw_test_data_, raw_valid_data_, raw_train_data_\n",
    "# raw_test_data_.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a34491a-0c10-4e71-8967-c0514d211f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features:\n",
      " ['genDatapT', 'genDataeta', 'genDataphi', 'genDatam', 'tau']\n",
      "\n",
      "Target =  RecoDatam\n",
      "USING NEW DATASET\n",
      "\n",
      "spliting data for RecoDatam\n",
      "train_t shape =  (100000,) train_x shape =  (100000, 5)\n",
      "\n",
      " Training features:\n",
      "\n",
      "[[29.4452      0.828187    2.90213     2.85348     0.36130954]\n",
      " [24.3193     -1.16351     0.636469    5.83685     0.12689925]\n",
      " [24.3193     -1.16351     0.636469    5.83685     0.96230681]\n",
      " ...\n",
      " [26.863       4.46097     0.381944    6.05116     0.30971054]\n",
      " [21.3142      4.15091    -2.81233     5.26289     0.07136162]\n",
      " [34.5862      2.1022     -0.435373    4.55711     0.19148971]]\n",
      "valid_t shape =  (100000,) valid_x shape =  (100000, 5)\n",
      "test_t shape =  (100000,) test_x shape =  (100000, 5)\n",
      "no need to train_test_split since we already have the split dataframes\n",
      "[ 3.26982106e+01 -2.19061436e-03 -1.07439844e-02  6.97319550e+00\n",
      "  5.00222989e-01] [14.55610053  2.20102624  1.81151811  2.73757608  0.28808471]\n",
      "[3.28398167e+01 2.20884209e-03 7.40700042e-03 6.98953116e+00\n",
      " 5.00433356e-01] [14.90390069  2.21693324  1.80890606  2.78903949  0.28827815]\n",
      "5.561710906429678 2.6282735020527532\n",
      "5.56540205907344 2.685472287815592\n",
      "NORMAL UNSCALED DICTIONARY\n",
      "{'genDatapT': {'mean': 32.83981673500001, 'std': 14.90390068970772}, 'genDataeta': {'mean': 0.0022088420911595004, 'std': 2.2169332378187043}, 'genDataphi': {'mean': 0.007407000418604001, 'std': 1.8089060619308075}, 'genDatam': {'mean': 6.989531155823706, 'std': 2.7890394898296575}, 'RecoDatapT': {'mean': 32.967168834000006, 'std': 15.77965621193832}, 'RecoDataeta': {'mean': 0.0022161224001759983, 'std': 2.210429783644192}, 'RecoDataphi': {'mean': 0.007273818861474919, 'std': 1.8095924300645279}, 'RecoDatam': {'mean': 5.56540205907344, 'std': 2.685472287815592}}\n",
      "\n",
      "\n",
      "\n",
      "[-0.00950128 -0.00198448 -0.01003423 -0.00585709  0.50022299] [0.97666382 0.99282478 1.00144399 0.98154798 0.28808471]\n",
      "[-4.38262759e-16  3.26849658e-18  1.05870868e-17 -7.61701813e-17\n",
      "  5.00433356e-01] [1.         1.         1.         1.         0.28827815]\n",
      "-0.0013744891952560954 0.9787006605793853\n",
      "-1.7763568394002506e-16 1.0\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "target = \"RecoDatam\"\n",
    "source = FIELDS[target]\n",
    "features = source[\"inputs\"]\n",
    "print(\"Training Features:\\n\", features)\n",
    "print(\"\\nTarget = \", target)\n",
    "\n",
    "print(\"USING NEW DATASET\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get targets and features\n",
    "# if USE_BRADEN_SCALING==True:\n",
    "#     print(f\"spliting data for {target}\")\n",
    "#     train_t, train_x = split_t_x(\n",
    "#         df=scaled_train_data, target=target, input_features=features\n",
    "#     )\n",
    "#     print(\"train_t shape = \", train_t.shape, \"train_x shape = \", train_x.shape)\n",
    "#     print(\"\\n Training features:\\n\")\n",
    "#     print(train_x)\n",
    "#     valid_t, valid_x = split_t_x(\n",
    "#         df=scaled_valid_data, target=target, input_features=features\n",
    "#     )\n",
    "#     print(\"valid_t shape = \", valid_t.shape, \"valid_x shape = \", valid_x.shape)\n",
    "#     test_t, test_x = split_t_x(df=scaled_test_data, target=target, input_features=features)\n",
    "#     print(\"test_t shape = \", test_t.shape, \"test_x shape = \", test_x.shape)\n",
    "\n",
    "# else:\n",
    "#     print(f\"spliting data for {target}\")\n",
    "#     train_t, train_x = normal_split_t_x(\n",
    "#     df=raw_train_data, target=target, input_features=features\n",
    "#     )\n",
    "#     print(\"train_t shape = \", train_t.shape, \"train_x shape = \", train_x.shape)\n",
    "#     print(\"\\n Training features:\\n\")\n",
    "#     print(train_x)\n",
    "#     valid_t, valid_x = normal_split_t_x(\n",
    "#     df=raw_valid_data, target=target, input_features=features\n",
    "#     )\n",
    "#     print(\"valid_t shape = \", valid_t.shape, \"valid_x shape = \", valid_x.shape)\n",
    "#     test_t, test_x = normal_split_t_x(df=raw_test_data, target=target, input_features=features)\n",
    "#     print(\"test_t shape = \", test_t.shape, \"test_x shape = \", test_x.shape)\n",
    "\n",
    "\n",
    "print(f\"spliting data for {target}\")\n",
    "train_t, train_x = normal_split_t_x(\n",
    "df=raw_train_data, target=target, input_features=features\n",
    ")\n",
    "print(\"train_t shape = \", train_t.shape, \"train_x shape = \", train_x.shape)\n",
    "print(\"\\n Training features:\\n\")\n",
    "print(train_x)\n",
    "valid_t, valid_x = normal_split_t_x(\n",
    "df=raw_valid_data, target=target, input_features=features\n",
    ")\n",
    "print(\"valid_t shape = \", valid_t.shape, \"valid_x shape = \", valid_x.shape)\n",
    "test_t, test_x = normal_split_t_x(df=raw_test_data, target=target, input_features=features)\n",
    "print(\"test_t shape = \", test_t.shape, \"test_x shape = \", test_x.shape)\n",
    "\n",
    "\n",
    "print(\"no need to train_test_split since we already have the split dataframes\")\n",
    "print(valid_x.mean(axis=0), valid_x.std(axis=0))\n",
    "print(train_x.mean(axis=0), train_x.std(axis=0))\n",
    "print(valid_t.mean(), valid_t.std())\n",
    "print(train_t.mean(), train_t.std())\n",
    "NFEATURES = train_x.shape[1]\n",
    "######################################################\n",
    "\n",
    "# Apply z scaling to features and targets\n",
    "# to features\n",
    "TRAIN_SCALE_DICT=get_train_scale_dict(USE_BRADEN_SCALING)\n",
    "apply_z_generator = apply_z_to_features(TRAIN_SCALE_DICT, train_x, test_x, valid_x)\n",
    "train_x_z_scaled = next(apply_z_generator)\n",
    "test_x_z_scaled = next(apply_z_generator)\n",
    "valid_x_z_scaled = next(apply_z_generator)\n",
    "print(valid_x_z_scaled.mean(axis=0), valid_x_z_scaled.std(axis=0))\n",
    "print(train_x_z_scaled.mean(axis=0), train_x_z_scaled.std(axis=0))\n",
    "\n",
    "# to targets\n",
    "apply_z_to_targets_generator = apply_z_to_targets(\n",
    "    train_t, test_t, valid_t\n",
    ")\n",
    "train_t_z_scaled = next(apply_z_to_targets_generator)\n",
    "test_t_z_scaled = next(apply_z_to_targets_generator)\n",
    "valid_t_z_scaled = next(apply_z_to_targets_generator)\n",
    "print(valid_t_z_scaled.mean(), valid_t_z_scaled.std())\n",
    "print(train_t_z_scaled.mean(), train_t_z_scaled.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3087482e-fb15-4e02-a894-c5c6fc05638e",
   "metadata": {},
   "source": [
    "Decide Whether to use Braden Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d597bc6-64df-4427-b268-9f1aeb3cd183",
   "metadata": {},
   "source": [
    "# Define Mass Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b8a342c-6c66-4d39-aaeb-eb421bfa3b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# Decide on parameters for this model and training\n",
    "PARAMS_m = {\n",
    "\"n_layers\": int(3),\n",
    "\"hidden_size\": int(10),\n",
    "\"dropout_1\": float(0.6),\n",
    "\"dropout_2\": float(0.1),\n",
    "\"activation\": \"LeakyReLU\",\n",
    "    'optimizer_name':'NAdam',\n",
    "    'starting_learning_rate':float(0.5),\n",
    "    'momentum':float(0.6),\n",
    "    'batch_size':int(64),\n",
    "    'n_iterations': int(2e6),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708af01e-612a-405a-81c8-41a2e3739a07",
   "metadata": {},
   "source": [
    "## Train Mass\n",
    "\n",
    "### The model that needs the longest time in training is mass. Click here to scroll down to train $p_T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f695aaf2-a37e-4ba1-86aa-0563957f09dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "training for 2000000 iteration, which is  1280.0 epochs\n",
      "RegularizedRegressionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=10, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.3)\n",
      "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (3): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.3)\n",
      "    (5): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (6): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.3)\n",
      "    (8): Linear(in_features=10, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "training IQN \n",
      "Iteration vs average loss\n",
      " iteration\t train-set\t  test-set\n",
      "\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 3.4373116493225098\n",
      "\n",
      "\n",
      "Current valid loss: 3.4373116493225098;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_3_layer10_hiddenLeakyReLU_activation64_batchsize2000_Kiteration.dict\n",
      "         0\t  3.440834\t  3.437312\n",
      "\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 2.313009738922119\n",
      "\n",
      "\n",
      "Current valid loss: 2.313009738922119;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_3_layer10_hiddenLeakyReLU_activation64_batchsize2000_Kiteration.dict\n",
      "       200\t  2.313900\t  2.313010\t  2.313010\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 1.790529727935791\n",
      "\n",
      "\n",
      "Current valid loss: 1.790529727935791;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_3_layer10_hiddenLeakyReLU_activation64_batchsize2000_Kiteration.dict\n",
      "       400\t  1.792286\t  1.790530\t  1.790530\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 2.2069709300994873\n",
      "\n",
      "       600\t  2.208208\t  2.206971\t  2.206971\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 5.5066633224487305\n",
      "\n",
      "       800\t  5.515627\t  5.506663\t  5.506663\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 3.0318331718444824\n",
      "\n",
      "      1000\t  3.034365\t  3.031833\t  3.031833\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 7.6721673011779785\n",
      "\n",
      "      1200\t  7.662749\t  7.672167\t  7.672167\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 3.0870087146759033\n",
      "\n",
      "      1400\t  3.091507\t  3.087009\t  3.087009\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 3.746440887451172\n",
      "\n",
      "      1600\t  3.748494\t  3.746441\t  3.746441\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 2.478487253189087\n",
      "\n",
      "      1800\t  2.478855\t  2.478487\t  2.478487\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 5.734546184539795\n",
      "\n",
      "      2000\t  5.751131\t  5.734546\t  5.734546\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 4.55300235748291\n",
      "\n",
      "      2200\t  4.562317\t  4.553002\t  4.553002\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 2.9482529163360596\n",
      "\n",
      "      2400\t  2.956784\t  2.948253\t  2.948253\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 4.012182712554932\n",
      "\n",
      "      2600\t  4.025727\t  4.012183\t  4.012183\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 6.367801666259766\n",
      "\n",
      "      2800\t  6.365440\t  6.367802\t  6.367802\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.6989338397979736\n",
      "\n",
      "\n",
      "Current valid loss: 0.6989338397979736;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_3_layer10_hiddenLeakyReLU_activation64_batchsize2000_Kiteration.dict\n",
      "      3000\t  0.701813\t  0.698934\t  0.698934\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 2.1136515140533447\n",
      "\n",
      "      3200\t  2.114510\t  2.113652\t  2.113652\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 1.8501721620559692\n",
      "\n",
      "      3400\t  1.852114\t  1.850172\t  1.850172"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f8cc6f0b3bdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mtraces_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraces_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mtraces_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraces_window\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0msave_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m )\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Pulled_Github_Repositories/torchQN/utils/utils.py\u001b[0m in \u001b[0;36mwrapper_timer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"timing this arbitrary function\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mrun_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-496357fd26d9>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(target, model, train_x, train_t, valid_x, valid_t, traces, PARAMS, traces_step, traces_window, save_model)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0mtraces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraces_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m         \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraces_window\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m     )\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-496357fd26d9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(target, model, avloss, getbatch, train_x, train_t, valid_x, valid_t, PARAMS, traces, step, window)\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0mempirical_risk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# move one step towards the minimum of the loss function using an SGD-like algorithm.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/nadam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    145\u001b[0m                   \u001b[0mmomentum_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                   \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                   foreach=group['foreach'])\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/nadam.py\u001b[0m in \u001b[0;36mnadam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, mu_products, state_steps, foreach, beta1, beta2, lr, weight_decay, momentum_decay, eps)\u001b[0m\n\u001b[1;32m    200\u001b[0m          \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m          \u001b[0mmomentum_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m          eps=eps)\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/nadam.py\u001b[0m in \u001b[0;36m_single_tensor_nadam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, mu_products, state_steps, beta1, beta2, lr, weight_decay, momentum_decay, eps)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer_name=PARAMS_m['optimizer_name']\n",
    "print(type(optimizer_name))\n",
    "# optimizer_name = BEST_PARAMS[\"optimizer_name\"].to_string().split()[1]\n",
    "NITERATIONS=PARAMS_m['n_iterations']\n",
    "BATCHSIZE=PARAMS_m['batch_size']\n",
    "comment=''\n",
    "\n",
    "\n",
    "\n",
    "# N_epochs X N_train_examples = N_iterations X batch_size\n",
    "N_epochs = (NITERATIONS * BATCHSIZE) / int(train_x.shape[0])\n",
    "print(f\"training for {NITERATIONS} iteration, which is  {N_epochs} epochs\")\n",
    "\n",
    "\n",
    "filename_model = get_model_filename(target, PARAMS_m)\n",
    "trained_models_dir = \"trained_models\"\n",
    "mkdir(trained_models_dir)\n",
    "# on cluster, Im using another TRAIN directory\n",
    "PATH_model = os.path.join(\n",
    "    IQN_BASE, #the loaction of the repo\n",
    "    \"JupyterBook\", #up tp TRAIN could be combined in a srs dicretory\n",
    "    \"Cluster\", \n",
    "    \"TRAIN\",\n",
    "    trained_models_dir, #/trained_models \n",
    "    filename_model # utils.get_model_filename has the saved file format \n",
    ")\n",
    "\n",
    "#LOAD EITHER TRAINED OR UNTRAINED MODEL\n",
    "# to load untrained model (start training from scratch), uncomment the next line\n",
    "untrained_model = load_untrained_model(PARAMS_m)\n",
    "# to continune training of model (pickup where the previous training left off), uncomment below\n",
    "# trained_model =load_trained_model(PATH=PATH_model, PARAMS=PARAMS_m)\n",
    "\n",
    "IQN_trace = ([], [], [], [])\n",
    "traces_step = int(200)\n",
    "traces_window = traces_step\n",
    "IQN = run(\n",
    "    target=target,\n",
    "    model=untrained_model,\n",
    "    train_x=train_x_z_scaled,\n",
    "    train_t=train_t_z_scaled,\n",
    "    valid_x=test_x_z_scaled,\n",
    "    valid_t=test_t_z_scaled,\n",
    "    traces=IQN_trace,\n",
    "    PARAMS=PARAMS_m,\n",
    "    traces_step=traces_step,\n",
    "    traces_window=traces_window,\n",
    "    save_model=False,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "SAVE_LAST_MODEL=False\n",
    "if SAVE_LAST_MODEL:\n",
    "    # ## Save last iteration of trained model \n",
    "    #dont save the last model, it might be worse than previous iterations, which were automatically savedby model checkpoints\n",
    "\n",
    "    final_path = get_model_filename(target, PARAMS_m).split('.dict')[0]+'_FINAL.dict'\n",
    "\n",
    "    trained_models_dir = \"trained_models\"\n",
    "    mkdir(trained_models_dir)\n",
    "    # on cluster, Im using another TRAIN directory\n",
    "    PATH_final_model = os.path.join(\n",
    "    IQN_BASE, \"JupyterBook\", \"Cluster\", \"TRAIN\", trained_models_dir, final_path\n",
    "    )\n",
    "\n",
    "    save_model(IQN, PATH_final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbab706-934e-4bcb-81c1-d5ca6fae9c88",
   "metadata": {},
   "source": [
    "### 2.4: Train $p_T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497e7a24-afc4-486f-9bf1-7c11cc1dbdf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features:\n",
      " ['RecoDatam', 'genDatapT', 'genDataeta', 'genDataphi', 'genDatam', 'tau']\n",
      "\n",
      "Target =  RecoDatapT\n",
      "USING NEW DATASET\n",
      "\n",
      "spliting data for RecoDatapT\n",
      "train_t shape =  (8000000,) train_x shape =  (8000000, 6)\n",
      "\n",
      " Training features:\n",
      "\n",
      "[[ 2.59587    29.4452      0.828187    2.90213     2.85348     0.36130954]\n",
      " [ 5.35538    24.3193     -1.16351     0.636469    5.83685     0.12689925]\n",
      " [ 5.35538    24.3193     -1.16351     0.636469    5.83685     0.96230681]\n",
      " ...\n",
      " [ 6.25659    41.4192     -2.23358    -2.81921     7.19348     0.08421659]\n",
      " [ 6.11213    35.4637     -1.12318     0.356494    6.06597     0.05535172]\n",
      " [ 4.17483    26.5586     -1.09427    -1.49334     4.25409     0.07489863]]\n",
      "valid_t shape =  (1000000,) valid_x shape =  (1000000, 6)\n",
      "test_t shape =  (1000000,) test_x shape =  (1000000, 6)\n",
      "no need to train_test_split since we already have the split dataframes\n",
      "[ 5.55141126e+00  3.27223764e+01  6.98189368e-04 -8.95543973e-04\n",
      "  6.96116528e+00  5.00485136e-01] [ 2.66412454 15.19914133  2.20425356  1.81362773  2.78097831  0.28852734]\n",
      "[ 5.55556745e+00  3.26952341e+01 -1.78188172e-03 -3.83090331e-04\n",
      "  6.96299435e+00  4.99915289e-01] [ 2.66433986 14.93793254  2.20430976  1.81382516  2.78133203  0.28867295]\n",
      "32.881453465999996 16.02400426348493\n",
      "32.86720151648752 15.829355769531851\n",
      "NORMAL UNSCALED DICTIONARY\n",
      "{'genDatapT': {'mean': 32.695234084987476, 'std': 14.937932540562551}, 'genDataeta': {'mean': -0.0017818817154031672, 'std': 2.204309760627079}, 'genDataphi': {'mean': -0.0003830903308450233, 'std': 1.8138251604791067}, 'genDatam': {'mean': 6.962994352358474, 'std': 2.781332025286383}, 'RecoDatapT': {'mean': 32.86720151648752, 'std': 15.829355769531851}, 'RecoDataeta': {'mean': -0.0017898858568513964, 'std': 2.197968491495457}, 'RecoDataphi': {'mean': -0.0004719170328962474, 'std': 1.8144739820043825}, 'RecoDatam': {'mean': 5.555567451922438, 'std': 2.664339857066051}}\n",
      "\n",
      "\n",
      "\n",
      "[-1.81710707e+00  1.48455353e+01  5.96132264e-04 -2.50379668e+00\n",
      " -1.63658184e+00  5.00485136e-01] [0.17834627 6.89519305 1.2152514  0.65207164 0.17568487 0.28852734]\n",
      "[-1.81682884e+00  1.48332220e+01 -7.71183141e-04 -2.50361243e+00\n",
      " -1.63646629e+00  4.99915289e-01] [0.17836068 6.77669391 1.21528238 0.65214262 0.17570722 0.28867295]\n",
      "0.0009003493079555966 1.0122966781963252\n",
      "-1.2048033681821834e-15 1.0000000000000002\n",
      "<class 'str'>\n",
      "training for 2000000 iteration, which is  256.0 epochs\n",
      "RegularizedRegressionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.3)\n",
      "    (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.3)\n",
      "    (5): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (6): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.3)\n",
      "    (8): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "training IQN \n",
      "Iteration vs average loss\n",
      " iteration\t train-set\t  test-set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/anaconda3/envs/new_torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.5987200140953064\n",
      "\n",
      "\n",
      "Current valid loss: 0.5987200140953064;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "         0\t  0.600579\t  0.598720\n",
      "\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.14327415823936462\n",
      "\n",
      "\n",
      "Current valid loss: 0.14327415823936462;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "       100\t  0.142855\t  0.143274\t  0.143274\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.1359773427248001\n",
      "\n",
      "\n",
      "Current valid loss: 0.1359773427248001;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "       200\t  0.136279\t  0.135977\t  0.135977\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.11432049423456192\n",
      "\n",
      "\n",
      "Current valid loss: 0.11432049423456192;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "       300\t  0.114511\t  0.114320\t  0.114320\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08805301040410995\n",
      "\n",
      "\n",
      "Current valid loss: 0.08805301040410995;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "       400\t  0.088157\t  0.088053\t  0.088053\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08550194650888443\n",
      "\n",
      "\n",
      "Current valid loss: 0.08550194650888443;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "       500\t  0.085494\t  0.085502\t  0.085502\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.1109614223241806\n",
      "\n",
      "       600\t  0.111296\t  0.110961\t  0.110961\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.33752644062042236\n",
      "\n",
      "       700\t  0.338428\t  0.337526\t  0.337526\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.1085544228553772\n",
      "\n",
      "       800\t  0.108280\t  0.108554\t  0.108554\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.20174911618232727\n",
      "\n",
      "       900\t  0.202449\t  0.201749\t  0.201749\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.0968456044793129\n",
      "\n",
      "      1000\t  0.096569\t  0.096846\t  0.096846\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.21917271614074707\n",
      "\n",
      "      1100\t  0.219687\t  0.219173\t  0.219173\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09528733789920807\n",
      "\n",
      "      1200\t  0.095409\t  0.095287\t  0.095287\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.13177266716957092\n",
      "\n",
      "      1300\t  0.131997\t  0.131773\t  0.131773\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.21874766051769257\n",
      "\n",
      "      1400\t  0.219383\t  0.218748\t  0.218748\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.1472843736410141\n",
      "\n",
      "      1500\t  0.146945\t  0.147284\t  0.147284\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.108138807117939\n",
      "\n",
      "      1600\t  0.107729\t  0.108139\t  0.108139\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.19834953546524048\n",
      "\n",
      "      1700\t  0.199303\t  0.198350\t  0.198350\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08799073100090027\n",
      "\n",
      "      1800\t  0.088087\t  0.087991\t  0.087991\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.07833113521337509\n",
      "\n",
      "\n",
      "Current valid loss: 0.07833113521337509;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "      1900\t  0.078295\t  0.078331\t  0.078331\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.10393134504556656\n",
      "\n",
      "      2000\t  0.103753\t  0.103931\t  0.103931\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08745770156383514\n",
      "\n",
      "      2100\t  0.087513\t  0.087458\t  0.087458\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08412045240402222\n",
      "\n",
      "      2200\t  0.084095\t  0.084120\t  0.084120\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08317507803440094\n",
      "\n",
      "      2300\t  0.083125\t  0.083175\t  0.083175\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08781371265649796\n",
      "\n",
      "      2400\t  0.087798\t  0.087814\t  0.087814\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09140736609697342\n",
      "\n",
      "      2500\t  0.091283\t  0.091407\t  0.091407\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.12309848517179489\n",
      "\n",
      "      2600\t  0.122790\t  0.123098\t  0.123098\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.1378583461046219\n",
      "\n",
      "      2700\t  0.138528\t  0.137858\t  0.137858\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08843953162431717\n",
      "\n",
      "      2800\t  0.088497\t  0.088440\t  0.088440\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09436282515525818\n",
      "\n",
      "      2900\t  0.094189\t  0.094363\t  0.094363\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.0800202488899231\n",
      "\n",
      "      3000\t  0.080035\t  0.080020\t  0.080020\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.1318553239107132\n",
      "\n",
      "      3100\t  0.132398\t  0.131855\t  0.131855\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08702273666858673\n",
      "\n",
      "      3200\t  0.086990\t  0.087023\t  0.087023\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.10442271828651428\n",
      "\n",
      "      3300\t  0.104360\t  0.104423\t  0.104423\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.07873428612947464\n",
      "\n",
      "      3400\t  0.078731\t  0.078734\t  0.078734\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.10214599221944809\n",
      "\n",
      "      3500\t  0.102306\t  0.102146\t  0.102146\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08991770446300507\n",
      "\n",
      "      3600\t  0.089934\t  0.089918\t  0.089918\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.12549999356269836\n",
      "\n",
      "      3700\t  0.125793\t  0.125500\t  0.125500\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08406978845596313\n",
      "\n",
      "      3800\t  0.083877\t  0.084070\t  0.084070\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.10047253221273422\n",
      "\n",
      "      3900\t  0.100651\t  0.100473\t  0.100473\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09253895282745361\n",
      "\n",
      "      4000\t  0.092539\t  0.092539\t  0.092539\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08424456417560577\n",
      "\n",
      "      4100\t  0.084232\t  0.084245\t  0.084245\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.18504059314727783\n",
      "\n",
      "      4200\t  0.185560\t  0.185041\t  0.185041\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.2963695824146271\n",
      "\n",
      "      4300\t  0.296985\t  0.296370\t  0.296370\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.0937710553407669\n",
      "\n",
      "      4400\t  0.093788\t  0.093771\t  0.093771\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09388059377670288\n",
      "\n",
      "      4500\t  0.093863\t  0.093881\t  0.093881\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08279455453157425\n",
      "\n",
      "      4600\t  0.082692\t  0.082795\t  0.082795\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.0929548516869545\n",
      "\n",
      "      4700\t  0.092801\t  0.092955\t  0.092955\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.12896119058132172\n",
      "\n",
      "      4800\t  0.129256\t  0.128961\t  0.128961\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.10698778182268143\n",
      "\n",
      "      4900\t  0.107053\t  0.106988\t  0.106988\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09648514539003372\n",
      "\n",
      "      5000\t  0.096366\t  0.096485\t  0.096485\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09870883822441101\n",
      "\n",
      "      5100\t  0.098508\t  0.098709\t  0.098709\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09387663751840591\n",
      "\n",
      "      5200\t  0.093801\t  0.093877\t  0.093877\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.0888291746377945\n",
      "\n",
      "      5300\t  0.088792\t  0.088829\t  0.088829\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09610298275947571\n",
      "\n",
      "      5400\t  0.095932\t  0.096103\t  0.096103\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.1551860123872757\n",
      "\n",
      "      5500\t  0.155501\t  0.155186\t  0.155186\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.1795654594898224\n",
      "\n",
      "      5600\t  0.180383\t  0.179565\t  0.179565\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.12004590779542923\n",
      "\n",
      "      5700\t  0.119923\t  0.120046\t  0.120046\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09906575083732605\n",
      "\n",
      "      5800\t  0.099161\t  0.099066\t  0.099066\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.12350724637508392\n",
      "\n",
      "      5900\t  0.123687\t  0.123507\t  0.123507\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.0858503058552742\n",
      "\n",
      "      6000\t  0.085830\t  0.085850\t  0.085850\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08146058022975922\n",
      "\n",
      "      6100\t  0.081449\t  0.081461\t  0.081461\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08426325023174286\n",
      "\n",
      "      6200\t  0.084271\t  0.084263\t  0.084263\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.10870661586523056\n",
      "\n",
      "      6300\t  0.108527\t  0.108707\t  0.108707\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09746822714805603\n",
      "\n",
      "      6400\t  0.097303\t  0.097468\t  0.097468\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.1321294754743576\n",
      "\n",
      "      6500\t  0.131962\t  0.132129\t  0.132129\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09647223353385925\n",
      "\n",
      "      6600\t  0.096457\t  0.096472\t  0.096472\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.11535345762968063\n",
      "\n",
      "      6700\t  0.115144\t  0.115353\t  0.115353\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09456070512533188\n",
      "\n",
      "      6800\t  0.094339\t  0.094561\t  0.094561\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.11577510833740234\n",
      "\n",
      "      6900\t  0.115636\t  0.115775\t  0.115775\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09180919826030731\n",
      "\n",
      "      7000\t  0.091879\t  0.091809\t  0.091809\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.1309339553117752\n",
      "\n",
      "      7100\t  0.130779\t  0.130934\t  0.130934\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.11411381512880325\n",
      "\n",
      "      7200\t  0.113903\t  0.114114\t  0.114114\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.1045396476984024\n",
      "\n",
      "      7300\t  0.104487\t  0.104540\t  0.104540\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.18942321836948395\n",
      "\n",
      "      7400\t  0.190079\t  0.189423\t  0.189423\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.10695245862007141\n",
      "\n",
      "      7500\t  0.107210\t  0.106952\t  0.106952\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09459994733333588\n",
      "\n",
      "      7600\t  0.094731\t  0.094600\t  0.094600\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08579390496015549\n",
      "\n",
      "      7700\t  0.085749\t  0.085794\t  0.085794\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.0926670953631401\n",
      "\n",
      "      7800\t  0.092481\t  0.092667\t  0.092667\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08704673498868942\n",
      "\n",
      "      7900\t  0.087027\t  0.087047\t  0.087047\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.0912131816148758\n",
      "\n",
      "      8000\t  0.091008\t  0.091213\t  0.091213\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09549988806247711\n",
      "\n",
      "      8100\t  0.095231\t  0.095500\t  0.095500\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09099157154560089\n",
      "\n",
      "      8200\t  0.090859\t  0.090992\t  0.090992\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.1419641375541687\n",
      "\n",
      "      8300\t  0.142479\t  0.141964\t  0.141964\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.10836914926767349\n",
      "\n",
      "      8400\t  0.108474\t  0.108369\t  0.108369\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.0860951766371727\n",
      "\n",
      "      8500\t  0.086029\t  0.086095\t  0.086095\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.14122559130191803\n",
      "\n",
      "      8600\t  0.141289\t  0.141226\t  0.141226\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.11224314570426941\n",
      "\n",
      "      8700\t  0.112124\t  0.112243\t  0.112243\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08431847393512726\n",
      "\n",
      "      8800\t  0.084114\t  0.084318\t  0.084318\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.10582946985960007\n",
      "\n",
      "      8900\t  0.105583\t  0.105829\t  0.105829\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.10101267695426941\n",
      "\n",
      "      9000\t  0.100757\t  0.101013\t  0.101013\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.11927693337202072\n",
      "\n",
      "      9100\t  0.119004\t  0.119277\t  0.119277\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09422948211431503\n",
      "\n",
      "      9200\t  0.094019\t  0.094229\t  0.094229\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.12899287045001984\n",
      "\n",
      "      9300\t  0.128716\t  0.128993\t  0.128993\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.1413053721189499\n",
      "\n",
      "      9400\t  0.141019\t  0.141305\t  0.141305\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.090022973716259\n",
      "\n",
      "      9500\t  0.089829\t  0.090023\t  0.090023\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.13384956121444702\n",
      "\n",
      "      9600\t  0.133796\t  0.133850\t  0.133850\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.10227558016777039\n",
      "\n",
      "      9700\t  0.102371\t  0.102276\t  0.102276\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09924706071615219\n",
      "\n",
      "      9800\t  0.098917\t  0.099247\t  0.099247\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.11046256124973297\n",
      "\n",
      "      9900\t  0.110079\t  0.110463\t  0.119696\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08762479573488235\n",
      "\n",
      "     10000\t  0.087418\t  0.087625\t  0.114585\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.11442088335752487\n",
      "\n",
      "     10100\t  0.114046\t  0.114421\t  0.114297\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09054090827703476\n",
      "\n",
      "     10200\t  0.090396\t  0.090541\t  0.113843\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.12565839290618896\n",
      "\n",
      "     10300\t  0.125325\t  0.125658\t  0.113956\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.13652268052101135\n",
      "\n",
      "     10400\t  0.136152\t  0.136523\t  0.114441\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.1302274763584137\n",
      "\n",
      "     10500\t  0.129918\t  0.130227\t  0.114888\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08429298549890518\n",
      "\n",
      "     10600\t  0.084194\t  0.084293\t  0.114621\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.12229479849338531\n",
      "\n",
      "     10700\t  0.122008\t  0.122295\t  0.112469\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09290793538093567\n",
      "\n",
      "     10800\t  0.092796\t  0.092908\t  0.112312\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.11660624295473099\n",
      "\n",
      "     10900\t  0.116242\t  0.116606\t  0.111461\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.1030367836356163\n",
      "\n",
      "     11000\t  0.103290\t  0.103037\t  0.111523\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.11631660908460617\n",
      "\n",
      "     11100\t  0.116001\t  0.116317\t  0.110494\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.13986219465732574\n",
      "\n",
      "     11200\t  0.139622\t  0.139862\t  0.110940\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.10265087336301804\n",
      "\n",
      "     11300\t  0.102608\t  0.102651\t  0.110649\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08664029836654663\n",
      "\n",
      "     11400\t  0.086700\t  0.086640\t  0.109328\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08358953148126602\n",
      "\n",
      "     11500\t  0.083664\t  0.083590\t  0.108691\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.10868518054485321\n",
      "\n",
      "     11600\t  0.108520\t  0.108685\t  0.108696\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08662819117307663\n",
      "\n",
      "     11700\t  0.086718\t  0.086628\t  0.107579\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08990690857172012\n",
      "\n",
      "     11800\t  0.090294\t  0.089907\t  0.107598\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09865636378526688\n",
      "\n",
      "     11900\t  0.098847\t  0.098656\t  0.107802\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.10415695607662201\n",
      "\n",
      "     12000\t  0.104487\t  0.104157\t  0.107804\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.14765676856040955\n",
      "\n",
      "     12100\t  0.147903\t  0.147657\t  0.108406\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.14286187291145325\n",
      "\n",
      "     12200\t  0.142601\t  0.142862\t  0.108993\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.0887325257062912\n",
      "\n",
      "     12300\t  0.088770\t  0.088733\t  0.109049\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08724970370531082\n",
      "\n",
      "     12400\t  0.087344\t  0.087250\t  0.109043\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08632771670818329\n",
      "\n",
      "     12500\t  0.086169\t  0.086328\t  0.108992\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08073397725820541\n",
      "\n",
      "     12600\t  0.080651\t  0.080734\t  0.108569\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.0844281017780304\n",
      "\n",
      "     12700\t  0.084375\t  0.084428\t  0.108034\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.12755198776721954\n",
      "\n",
      "     12800\t  0.127089\t  0.127552\t  0.108426\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08550751209259033\n",
      "\n",
      "     12900\t  0.085519\t  0.085508\t  0.108337\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.11579742282629013\n",
      "\n",
      "     13000\t  0.116109\t  0.115797\t  0.108695\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.10228379815816879\n",
      "\n",
      "     13100\t  0.102565\t  0.102284\t  0.108399\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.13491258025169373\n",
      "\n",
      "     13200\t  0.135237\t  0.134913\t  0.108878\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.16681523621082306\n",
      "\n",
      "     13300\t  0.166888\t  0.166815\t  0.109502\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.0883251428604126\n",
      "\n",
      "     13400\t  0.088246\t  0.088325\t  0.109598\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.10748699307441711\n",
      "\n",
      "     13500\t  0.107624\t  0.107487\t  0.109651\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09652940183877945\n",
      "\n",
      "     13600\t  0.096663\t  0.096529\t  0.109717\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.14641417562961578\n",
      "\n",
      "     13700\t  0.146679\t  0.146414\t  0.109926\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.11184067279100418\n",
      "\n",
      "     13800\t  0.112076\t  0.111841\t  0.110204\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.10741748660802841\n",
      "\n",
      "     13900\t  0.107577\t  0.107417\t  0.110274\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.10032019019126892\n",
      "\n",
      "     14000\t  0.100428\t  0.100320\t  0.110351\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.14485062658786774\n",
      "\n",
      "     14100\t  0.145334\t  0.144851\t  0.110957\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09206888824701309\n",
      "\n",
      "     14200\t  0.092137\t  0.092069\t  0.110028\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.10443326085805893\n",
      "\n",
      "     14300\t  0.104504\t  0.104433\t  0.108108\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.10546302050352097\n",
      "\n",
      "     14400\t  0.105725\t  0.105463\t  0.108225\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.10232437402009964\n",
      "\n",
      "     14500\t  0.102577\t  0.102324\t  0.108310\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.12320293486118317\n",
      "\n",
      "     14600\t  0.123514\t  0.123203\t  0.108714\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.12175906449556351\n",
      "\n",
      "     14700\t  0.121966\t  0.121759\t  0.109002\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08701157569885254\n",
      "\n",
      "     14800\t  0.087047\t  0.087012\t  0.108582\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09333434700965881\n",
      "\n",
      "     14900\t  0.093264\t  0.093334\t  0.108446\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.17384056746959686\n",
      "\n",
      "     15000\t  0.174302\t  0.173841\t  0.109219\t\tCURRENT LEARNING RATE: 0.42992384932960276\n",
      "previous_iter_valid_loss : 0.10141874849796295\n",
      "\n",
      "     15100\t  0.101688\t  0.101419\t  0.109246\t\tCURRENT LEARNING RATE: 0.4294941403705617\n",
      "previous_iter_valid_loss : 0.12285413593053818\n",
      "\n",
      "     15200\t  0.122755\t  0.122854\t  0.109536\t\tCURRENT LEARNING RATE: 0.4290648609056969\n",
      "previous_iter_valid_loss : 0.08151457458734512\n",
      "\n",
      "     15300\t  0.081512\t  0.081515\t  0.109463\t\tCURRENT LEARNING RATE: 0.42863601050572875\n",
      "previous_iter_valid_loss : 0.08694326132535934\n",
      "\n",
      "     15400\t  0.086978\t  0.086943\t  0.109372\t\tCURRENT LEARNING RATE: 0.42820758874180676\n",
      "previous_iter_valid_loss : 0.10293997079133987\n",
      "\n",
      "     15500\t  0.102719\t  0.102940\t  0.108849\t\tCURRENT LEARNING RATE: 0.42777959518550923\n",
      "previous_iter_valid_loss : 0.09086598455905914\n",
      "\n",
      "     15600\t  0.090973\t  0.090866\t  0.107962\t\tCURRENT LEARNING RATE: 0.42735202940884254\n",
      "previous_iter_valid_loss : 0.10195006430149078\n",
      "\n",
      "     15700\t  0.102057\t  0.101950\t  0.107781\t\tCURRENT LEARNING RATE: 0.42692489098424086\n",
      "previous_iter_valid_loss : 0.08717059344053268\n",
      "\n",
      "     15800\t  0.087142\t  0.087171\t  0.107662\t\tCURRENT LEARNING RATE: 0.42649817948456575\n",
      "previous_iter_valid_loss : 0.08689522743225098\n",
      "\n",
      "     15900\t  0.086802\t  0.086895\t  0.107296\t\tCURRENT LEARNING RATE: 0.4260718944831057\n",
      "previous_iter_valid_loss : 0.09962745010852814\n",
      "\n",
      "     16000\t  0.099350\t  0.099627\t  0.107434\t\tCURRENT LEARNING RATE: 0.42564603555357555\n",
      "previous_iter_valid_loss : 0.07949534058570862\n",
      "\n",
      "     16100\t  0.079482\t  0.079495\t  0.107414\t\tCURRENT LEARNING RATE: 0.4252206022701165\n",
      "previous_iter_valid_loss : 0.10643906146287918\n",
      "\n",
      "     16200\t  0.106230\t  0.106439\t  0.107636\t\tCURRENT LEARNING RATE: 0.4247955942072951\n",
      "previous_iter_valid_loss : 0.08017057180404663\n",
      "\n",
      "     16300\t  0.080163\t  0.080171\t  0.107351\t\tCURRENT LEARNING RATE: 0.4243710109401034\n",
      "previous_iter_valid_loss : 0.12159326672554016\n",
      "\n",
      "     16400\t  0.121319\t  0.121593\t  0.107592\t\tCURRENT LEARNING RATE: 0.42394685204395793\n",
      "previous_iter_valid_loss : 0.08025999367237091\n",
      "\n",
      "     16500\t  0.080205\t  0.080260\t  0.107073\t\tCURRENT LEARNING RATE: 0.4235231170946998\n",
      "previous_iter_valid_loss : 0.15803225338459015\n",
      "\n",
      "     16600\t  0.157634\t  0.158032\t  0.107689\t\tCURRENT LEARNING RATE: 0.4230998056685941\n",
      "previous_iter_valid_loss : 0.09385281056165695\n",
      "\n",
      "     16700\t  0.093642\t  0.093853\t  0.107474\t\tCURRENT LEARNING RATE: 0.4226769173423294\n",
      "previous_iter_valid_loss : 0.08297383040189743\n",
      "\n",
      "     16800\t  0.083064\t  0.082974\t  0.107358\t\tCURRENT LEARNING RATE: 0.4222544516930172\n",
      "previous_iter_valid_loss : 0.08481478691101074\n",
      "\n",
      "     16900\t  0.084729\t  0.084815\t  0.107048\t\tCURRENT LEARNING RATE: 0.42183240829819185\n",
      "previous_iter_valid_loss : 0.12580454349517822\n",
      "\n",
      "     17000\t  0.126174\t  0.125805\t  0.107388\t\tCURRENT LEARNING RATE: 0.42141078673580995\n",
      "previous_iter_valid_loss : 0.08796104788780212\n",
      "\n",
      "     17100\t  0.088085\t  0.087961\t  0.106958\t\tCURRENT LEARNING RATE: 0.42098958658424995\n",
      "previous_iter_valid_loss : 0.07951153069734573\n",
      "\n",
      "     17200\t  0.079405\t  0.079512\t  0.106612\t\tCURRENT LEARNING RATE: 0.4205688074223116\n",
      "previous_iter_valid_loss : 0.11137047410011292\n",
      "\n",
      "     17300\t  0.111674\t  0.111370\t  0.106681\t\tCURRENT LEARNING RATE: 0.4201484488292157\n",
      "previous_iter_valid_loss : 0.11305618286132812\n",
      "\n",
      "     17400\t  0.113259\t  0.113056\t  0.105917\t\tCURRENT LEARNING RATE: 0.4197285103846037\n",
      "previous_iter_valid_loss : 0.10236392170190811\n",
      "\n",
      "     17500\t  0.102134\t  0.102364\t  0.105871\t\tCURRENT LEARNING RATE: 0.419308991668537\n",
      "previous_iter_valid_loss : 0.13482698798179626\n",
      "\n",
      "     17600\t  0.134557\t  0.134827\t  0.106273\t\tCURRENT LEARNING RATE: 0.4188898922614969\n",
      "previous_iter_valid_loss : 0.09218914061784744\n",
      "\n",
      "     17700\t  0.092277\t  0.092189\t  0.106337\t\tCURRENT LEARNING RATE: 0.41847121174438406\n",
      "previous_iter_valid_loss : 0.08350376039743423\n",
      "\n",
      "     17800\t  0.083529\t  0.083504\t  0.106246\t\tCURRENT LEARNING RATE: 0.41805294969851775\n",
      "previous_iter_valid_loss : 0.08447667211294174\n",
      "\n",
      "     17900\t  0.084359\t  0.084477\t  0.106220\t\tCURRENT LEARNING RATE: 0.417635105705636\n",
      "previous_iter_valid_loss : 0.09834224730730057\n",
      "\n",
      "     18000\t  0.098116\t  0.098342\t  0.106291\t\tCURRENT LEARNING RATE: 0.4172176793478948\n",
      "previous_iter_valid_loss : 0.10175202786922455\n",
      "\n",
      "     18100\t  0.101400\t  0.101752\t  0.106354\t\tCURRENT LEARNING RATE: 0.41680067020786765\n",
      "previous_iter_valid_loss : 0.09671907871961594\n",
      "\n",
      "     18200\t  0.096533\t  0.096719\t  0.106411\t\tCURRENT LEARNING RATE: 0.4163840778685455\n",
      "previous_iter_valid_loss : 0.10253266245126724\n",
      "\n",
      "     18300\t  0.102732\t  0.102533\t  0.106017\t\tCURRENT LEARNING RATE: 0.4159679019133359\n",
      "previous_iter_valid_loss : 0.12955841422080994\n",
      "\n",
      "     18400\t  0.129927\t  0.129558\t  0.106229\t\tCURRENT LEARNING RATE: 0.4155521419260628\n",
      "previous_iter_valid_loss : 0.09504400193691254\n",
      "\n",
      "     18500\t  0.095032\t  0.095044\t  0.106318\t\tCURRENT LEARNING RATE: 0.4151367974909663\n",
      "previous_iter_valid_loss : 0.13741862773895264\n",
      "\n",
      "     18600\t  0.137128\t  0.137419\t  0.106280\t\tCURRENT LEARNING RATE: 0.41472186819270196\n",
      "previous_iter_valid_loss : 0.09410625696182251\n",
      "\n",
      "     18700\t  0.094120\t  0.094106\t  0.106099\t\tCURRENT LEARNING RATE: 0.4143073536163403\n",
      "previous_iter_valid_loss : 0.08786896616220474\n",
      "\n",
      "     18800\t  0.087789\t  0.087869\t  0.106134\t\tCURRENT LEARNING RATE: 0.4138932533473668\n",
      "previous_iter_valid_loss : 0.0953281819820404\n",
      "\n",
      "     18900\t  0.095057\t  0.095328\t  0.106029\t\tCURRENT LEARNING RATE: 0.41347956697168115\n",
      "previous_iter_valid_loss : 0.08834917843341827\n",
      "\n",
      "     19000\t  0.088240\t  0.088349\t  0.105903\t\tCURRENT LEARNING RATE: 0.4130662940755969\n",
      "previous_iter_valid_loss : 0.14171290397644043\n",
      "\n",
      "     19100\t  0.141476\t  0.141713\t  0.106127\t\tCURRENT LEARNING RATE: 0.41265343424584117\n",
      "previous_iter_valid_loss : 0.09213795512914658\n",
      "\n",
      "     19200\t  0.092304\t  0.092138\t  0.106106\t\tCURRENT LEARNING RATE: 0.4122409870695541\n",
      "previous_iter_valid_loss : 0.10342463850975037\n",
      "\n",
      "     19300\t  0.103192\t  0.103425\t  0.105850\t\tCURRENT LEARNING RATE: 0.41182895213428844\n",
      "previous_iter_valid_loss : 0.08726269006729126\n",
      "\n",
      "     19400\t  0.087005\t  0.087263\t  0.105310\t\tCURRENT LEARNING RATE: 0.4114173290280092\n",
      "previous_iter_valid_loss : 0.08380208164453506\n",
      "\n",
      "     19500\t  0.083680\t  0.083802\t  0.105248\t\tCURRENT LEARNING RATE: 0.41100611733909326\n",
      "previous_iter_valid_loss : 0.12828439474105835\n",
      "\n",
      "     19600\t  0.128126\t  0.128284\t  0.105192\t\tCURRENT LEARNING RATE: 0.410595316656329\n",
      "previous_iter_valid_loss : 0.16432605683803558\n",
      "\n",
      "     19700\t  0.164744\t  0.164326\t  0.105813\t\tCURRENT LEARNING RATE: 0.41018492656891553\n",
      "previous_iter_valid_loss : 0.09749063849449158\n",
      "\n",
      "     19800\t  0.097426\t  0.097491\t  0.105795\t\tCURRENT LEARNING RATE: 0.4097749466664628\n",
      "previous_iter_valid_loss : 0.09571252763271332\n",
      "\n",
      "     19900\t  0.095577\t  0.095713\t  0.105648\t\tCURRENT LEARNING RATE: 0.4093653765389909\n",
      "previous_iter_valid_loss : 0.10882081091403961\n",
      "\n",
      "     20000\t  0.108755\t  0.108821\t  0.105860\t\tCURRENT LEARNING RATE: 0.4089562157769297\n",
      "previous_iter_valid_loss : 0.089748315513134\n",
      "\n",
      "     20100\t  0.089638\t  0.089748\t  0.105613\t\tCURRENT LEARNING RATE: 0.4085474639711183\n",
      "previous_iter_valid_loss : 0.08992284536361694\n",
      "\n",
      "     20200\t  0.089846\t  0.089923\t  0.105607\t\tCURRENT LEARNING RATE: 0.40813912071280495\n",
      "previous_iter_valid_loss : 0.09649526327848434\n",
      "\n",
      "     20300\t  0.096591\t  0.096495\t  0.105315\t\tCURRENT LEARNING RATE: 0.40773118559364635\n",
      "previous_iter_valid_loss : 0.09212086349725723\n",
      "\n",
      "     20400\t  0.092132\t  0.092121\t  0.104871\t\tCURRENT LEARNING RATE: 0.40732365820570726\n",
      "previous_iter_valid_loss : 0.1533787101507187\n",
      "\n",
      "     20500\t  0.153789\t  0.153379\t  0.105102\t\tCURRENT LEARNING RATE: 0.40691653814146034\n",
      "previous_iter_valid_loss : 0.10682164132595062\n",
      "\n",
      "     20600\t  0.106695\t  0.106822\t  0.105328\t\tCURRENT LEARNING RATE: 0.4065098249937855\n",
      "previous_iter_valid_loss : 0.12628397345542908\n",
      "\n",
      "     20700\t  0.126136\t  0.126284\t  0.105368\t\tCURRENT LEARNING RATE: 0.40610351835596953\n",
      "previous_iter_valid_loss : 0.08850273489952087\n",
      "\n",
      "     20800\t  0.088578\t  0.088503\t  0.105324\t\tCURRENT LEARNING RATE: 0.4056976178217057\n",
      "previous_iter_valid_loss : 0.09927627444267273\n",
      "\n",
      "     20900\t  0.099091\t  0.099276\t  0.105150\t\tCURRENT LEARNING RATE: 0.40529212298509354\n",
      "previous_iter_valid_loss : 0.08795277774333954\n",
      "\n",
      "     21000\t  0.087708\t  0.087953\t  0.104999\t\tCURRENT LEARNING RATE: 0.40488703344063814\n",
      "previous_iter_valid_loss : 0.09203683584928513\n",
      "\n",
      "     21100\t  0.092021\t  0.092037\t  0.104757\t\tCURRENT LEARNING RATE: 0.4044823487832499\n",
      "previous_iter_valid_loss : 0.12322340160608292\n",
      "\n",
      "     21200\t  0.122918\t  0.123223\t  0.104590\t\tCURRENT LEARNING RATE: 0.4040780686082442\n",
      "previous_iter_valid_loss : 0.08938281983137131\n",
      "\n",
      "     21300\t  0.089299\t  0.089383\t  0.104458\t\tCURRENT LEARNING RATE: 0.40367419251134073\n",
      "previous_iter_valid_loss : 0.10979052633047104\n",
      "\n",
      "     21400\t  0.109646\t  0.109791\t  0.104689\t\tCURRENT LEARNING RATE: 0.40327072008866344\n",
      "previous_iter_valid_loss : 0.0893155187368393\n",
      "\n",
      "     21500\t  0.089206\t  0.089316\t  0.104746\t\tCURRENT LEARNING RATE: 0.4028676509367398\n",
      "previous_iter_valid_loss : 0.12437214702367783\n",
      "\n",
      "     21600\t  0.124188\t  0.124372\t  0.104903\t\tCURRENT LEARNING RATE: 0.40246498465250075\n",
      "previous_iter_valid_loss : 0.09067587554454803\n",
      "\n",
      "     21700\t  0.090701\t  0.090676\t  0.104944\t\tCURRENT LEARNING RATE: 0.4020627208332798\n",
      "previous_iter_valid_loss : 0.10242900252342224\n",
      "\n",
      "     21800\t  0.102620\t  0.102429\t  0.105069\t\tCURRENT LEARNING RATE: 0.40166085907681326\n",
      "previous_iter_valid_loss : 0.08718515187501907\n",
      "\n",
      "     21900\t  0.087217\t  0.087185\t  0.104954\t\tCURRENT LEARNING RATE: 0.40125939898123925\n",
      "previous_iter_valid_loss : 0.09717357903718948\n",
      "\n",
      "     22000\t  0.097296\t  0.097174\t  0.104884\t\tCURRENT LEARNING RATE: 0.40085834014509764\n",
      "previous_iter_valid_loss : 0.13749022781848907\n",
      "\n",
      "     22100\t  0.137874\t  0.137490\t  0.104783\t\tCURRENT LEARNING RATE: 0.4004576821673296\n",
      "previous_iter_valid_loss : 0.12022849917411804\n",
      "\n",
      "     22200\t  0.120487\t  0.120228\t  0.104556\t\tCURRENT LEARNING RATE: 0.40005742464727706\n",
      "previous_iter_valid_loss : 0.11457132548093796\n",
      "\n",
      "     22300\t  0.114802\t  0.114571\t  0.104815\t\tCURRENT LEARNING RATE: 0.39965756718468254\n",
      "previous_iter_valid_loss : 0.08894907683134079\n",
      "\n",
      "     22400\t  0.089141\t  0.088949\t  0.104832\t\tCURRENT LEARNING RATE: 0.39925810937968853\n",
      "previous_iter_valid_loss : 0.09392176568508148\n",
      "\n",
      "     22500\t  0.094075\t  0.093922\t  0.104908\t\tCURRENT LEARNING RATE: 0.3988590508328371\n",
      "previous_iter_valid_loss : 0.0983455628156662\n",
      "\n",
      "     22600\t  0.098563\t  0.098346\t  0.105084\t\tCURRENT LEARNING RATE: 0.3984603911450698\n",
      "previous_iter_valid_loss : 0.08470027148723602\n",
      "\n",
      "     22700\t  0.084761\t  0.084700\t  0.105087\t\tCURRENT LEARNING RATE: 0.3980621299177269\n",
      "previous_iter_valid_loss : 0.09216451644897461\n",
      "\n",
      "     22800\t  0.092348\t  0.092165\t  0.104733\t\tCURRENT LEARNING RATE: 0.39766426675254696\n",
      "previous_iter_valid_loss : 0.09065820276737213\n",
      "\n",
      "     22900\t  0.090810\t  0.090658\t  0.104784\t\tCURRENT LEARNING RATE: 0.397266801251667\n",
      "previous_iter_valid_loss : 0.09497220069169998\n",
      "\n",
      "     23000\t  0.095213\t  0.094972\t  0.104576\t\tCURRENT LEARNING RATE: 0.39686973301762135\n",
      "previous_iter_valid_loss : 0.12236075103282928\n",
      "\n",
      "     23100\t  0.122728\t  0.122361\t  0.104777\t\tCURRENT LEARNING RATE: 0.39647306165334184\n",
      "previous_iter_valid_loss : 0.10625285655260086\n",
      "\n",
      "     23200\t  0.106498\t  0.106253\t  0.104490\t\tCURRENT LEARNING RATE: 0.396076786762157\n",
      "previous_iter_valid_loss : 0.09927107393741608\n",
      "\n",
      "     23300\t  0.099470\t  0.099271\t  0.103815\t\tCURRENT LEARNING RATE: 0.3956809079477919\n",
      "previous_iter_valid_loss : 0.10133687406778336\n",
      "\n",
      "     23400\t  0.101084\t  0.101337\t  0.103945\t\tCURRENT LEARNING RATE: 0.3952854248143678\n",
      "previous_iter_valid_loss : 0.1321852207183838\n",
      "\n",
      "     23500\t  0.132323\t  0.132185\t  0.104192\t\tCURRENT LEARNING RATE: 0.39489033696640136\n",
      "previous_iter_valid_loss : 0.1472516506910324\n",
      "\n",
      "     23600\t  0.147553\t  0.147252\t  0.104699\t\tCURRENT LEARNING RATE: 0.3944956440088049\n",
      "previous_iter_valid_loss : 0.11934874206781387\n",
      "\n",
      "     23700\t  0.119608\t  0.119349\t  0.104428\t\tCURRENT LEARNING RATE: 0.3941013455468852\n",
      "previous_iter_valid_loss : 0.12819111347198486\n",
      "\n",
      "     23800\t  0.128018\t  0.128191\t  0.104592\t\tCURRENT LEARNING RATE: 0.393707441186344\n",
      "previous_iter_valid_loss : 0.09793074429035187\n",
      "\n",
      "     23900\t  0.097917\t  0.097931\t  0.104497\t\tCURRENT LEARNING RATE: 0.39331393053327673\n",
      "previous_iter_valid_loss : 0.09872864186763763\n",
      "\n",
      "     24000\t  0.098715\t  0.098729\t  0.104481\t\tCURRENT LEARNING RATE: 0.39292081319417277\n",
      "previous_iter_valid_loss : 0.08851319551467896\n",
      "\n",
      "     24100\t  0.088361\t  0.088513\t  0.103918\t\tCURRENT LEARNING RATE: 0.3925280887759148\n",
      "previous_iter_valid_loss : 0.08196848630905151\n",
      "\n",
      "     24200\t  0.081827\t  0.081968\t  0.103817\t\tCURRENT LEARNING RATE: 0.39213575688577823\n",
      "previous_iter_valid_loss : 0.08515111356973648\n",
      "\n",
      "     24300\t  0.084954\t  0.085151\t  0.103624\t\tCURRENT LEARNING RATE: 0.39174381713143125\n",
      "previous_iter_valid_loss : 0.08591873943805695\n",
      "\n",
      "     24400\t  0.085706\t  0.085919\t  0.103428\t\tCURRENT LEARNING RATE: 0.39135226912093407\n",
      "previous_iter_valid_loss : 0.08599668741226196\n",
      "\n",
      "     24500\t  0.085789\t  0.085997\t  0.103265\t\tCURRENT LEARNING RATE: 0.3909611124627386\n",
      "previous_iter_valid_loss : 0.08379204571247101\n",
      "\n",
      "     24600\t  0.083604\t  0.083792\t  0.102871\t\tCURRENT LEARNING RATE: 0.39057034676568825\n",
      "previous_iter_valid_loss : 0.08277377486228943\n",
      "\n",
      "     24700\t  0.082651\t  0.082774\t  0.102481\t\tCURRENT LEARNING RATE: 0.39017997163901713\n",
      "previous_iter_valid_loss : 0.11572964489459991\n",
      "\n",
      "     24800\t  0.115526\t  0.115730\t  0.102768\t\tCURRENT LEARNING RATE: 0.3897899866923502\n",
      "previous_iter_valid_loss : 0.143362894654274\n",
      "\n",
      "     24900\t  0.143065\t  0.143363\t  0.103269\t\tCURRENT LEARNING RATE: 0.38940039153570244\n",
      "previous_iter_valid_loss : 0.09600789099931717\n",
      "\n",
      "     25000\t  0.095765\t  0.096008\t  0.102490\t\tCURRENT LEARNING RATE: 0.38901118577947863\n",
      "previous_iter_valid_loss : 0.09209823608398438\n",
      "\n",
      "     25100\t  0.091911\t  0.092098\t  0.102397\t\tCURRENT LEARNING RATE: 0.38862236903447306\n",
      "previous_iter_valid_loss : 0.12210050225257874\n",
      "\n",
      "     25200\t  0.121920\t  0.122101\t  0.102390\t\tCURRENT LEARNING RATE: 0.3882339409118689\n",
      "previous_iter_valid_loss : 0.0855553075671196\n",
      "\n",
      "     25300\t  0.085616\t  0.085555\t  0.102430\t\tCURRENT LEARNING RATE: 0.387845901023238\n",
      "previous_iter_valid_loss : 0.08252166956663132\n",
      "\n",
      "     25400\t  0.082408\t  0.082522\t  0.102386\t\tCURRENT LEARNING RATE: 0.3874582489805405\n",
      "previous_iter_valid_loss : 0.10038963705301285\n",
      "\n",
      "     25500\t  0.100206\t  0.100390\t  0.102360\t\tCURRENT LEARNING RATE: 0.3870709843961242\n",
      "previous_iter_valid_loss : 0.08776238560676575\n",
      "\n",
      "     25600\t  0.087768\t  0.087762\t  0.102329\t\tCURRENT LEARNING RATE: 0.38668410688272453\n",
      "previous_iter_valid_loss : 0.091314896941185\n",
      "\n",
      "     25700\t  0.091144\t  0.091315\t  0.102223\t\tCURRENT LEARNING RATE: 0.386297616053464\n",
      "previous_iter_valid_loss : 0.08455979824066162\n",
      "\n",
      "     25800\t  0.084457\t  0.084560\t  0.102197\t\tCURRENT LEARNING RATE: 0.3859115115218517\n",
      "previous_iter_valid_loss : 0.09570977836847305\n",
      "\n",
      "     25900\t  0.095484\t  0.095710\t  0.102285\t\tCURRENT LEARNING RATE: 0.3855257929017831\n",
      "previous_iter_valid_loss : 0.09218674898147583\n",
      "\n",
      "     26000\t  0.092199\t  0.092187\t  0.102210\t\tCURRENT LEARNING RATE: 0.3851404598075396\n",
      "previous_iter_valid_loss : 0.1052704006433487\n",
      "\n",
      "     26100\t  0.104986\t  0.105270\t  0.102468\t\tCURRENT LEARNING RATE: 0.3847555118537879\n",
      "previous_iter_valid_loss : 0.08576733618974686\n",
      "\n",
      "     26200\t  0.085658\t  0.085767\t  0.102262\t\tCURRENT LEARNING RATE: 0.38437094865558014\n",
      "previous_iter_valid_loss : 0.088468998670578\n",
      "\n",
      "     26300\t  0.088298\t  0.088469\t  0.102345\t\tCURRENT LEARNING RATE: 0.38398676982835306\n",
      "previous_iter_valid_loss : 0.08441569656133652\n",
      "\n",
      "     26400\t  0.084267\t  0.084416\t  0.101973\t\tCURRENT LEARNING RATE: 0.38360297498792784\n",
      "previous_iter_valid_loss : 0.08242955058813095\n",
      "\n",
      "     26500\t  0.082311\t  0.082430\t  0.101994\t\tCURRENT LEARNING RATE: 0.3832195637505096\n",
      "previous_iter_valid_loss : 0.1164826899766922\n",
      "\n",
      "     26600\t  0.116281\t  0.116483\t  0.101579\t\tCURRENT LEARNING RATE: 0.38283653573268694\n",
      "previous_iter_valid_loss : 0.11609163880348206\n",
      "\n",
      "     26700\t  0.115917\t  0.116092\t  0.101801\t\tCURRENT LEARNING RATE: 0.382453890551432\n",
      "previous_iter_valid_loss : 0.09664051234722137\n",
      "\n",
      "     26800\t  0.096522\t  0.096641\t  0.101938\t\tCURRENT LEARNING RATE: 0.3820716278240995\n",
      "previous_iter_valid_loss : 0.11276381462812424\n",
      "\n",
      "     26900\t  0.112506\t  0.112764\t  0.102217\t\tCURRENT LEARNING RATE: 0.3816897471684266\n",
      "previous_iter_valid_loss : 0.08674507588148117\n",
      "\n",
      "     27000\t  0.086567\t  0.086745\t  0.101827\t\tCURRENT LEARNING RATE: 0.3813082482025327\n",
      "previous_iter_valid_loss : 0.12127192318439484\n",
      "\n",
      "     27100\t  0.121042\t  0.121272\t  0.102160\t\tCURRENT LEARNING RATE: 0.3809271305449188\n",
      "previous_iter_valid_loss : 0.1265217661857605\n",
      "\n",
      "     27200\t  0.126265\t  0.126522\t  0.102630\t\tCURRENT LEARNING RATE: 0.38054639381446714\n",
      "previous_iter_valid_loss : 0.13486288487911224\n",
      "\n",
      "     27300\t  0.134589\t  0.134863\t  0.102865\t\tCURRENT LEARNING RATE: 0.38016603763044104\n",
      "previous_iter_valid_loss : 0.09395608305931091\n",
      "\n",
      "     27400\t  0.093835\t  0.093956\t  0.102674\t\tCURRENT LEARNING RATE: 0.37978606161248424\n",
      "previous_iter_valid_loss : 0.08425984531641006\n",
      "\n",
      "     27500\t  0.084087\t  0.084260\t  0.102493\t\tCURRENT LEARNING RATE: 0.37940646538062067\n",
      "previous_iter_valid_loss : 0.10050422698259354\n",
      "\n",
      "     27600\t  0.100243\t  0.100504\t  0.102150\t\tCURRENT LEARNING RATE: 0.37902724855525416\n",
      "previous_iter_valid_loss : 0.10180951654911041\n",
      "\n",
      "     27700\t  0.101532\t  0.101810\t  0.102246\t\tCURRENT LEARNING RATE: 0.37864841075716776\n",
      "previous_iter_valid_loss : 0.09129150211811066\n",
      "\n",
      "     27800\t  0.091035\t  0.091292\t  0.102324\t\tCURRENT LEARNING RATE: 0.3782699516075237\n",
      "previous_iter_valid_loss : 0.08090167492628098\n",
      "\n",
      "     27900\t  0.080816\t  0.080902\t  0.102288\t\tCURRENT LEARNING RATE: 0.37789187072786273\n",
      "previous_iter_valid_loss : 0.09493912756443024\n",
      "\n",
      "     28000\t  0.094679\t  0.094939\t  0.102254\t\tCURRENT LEARNING RATE: 0.377514167740104\n",
      "previous_iter_valid_loss : 0.09305892884731293\n",
      "\n",
      "     28100\t  0.092871\t  0.093059\t  0.102167\t\tCURRENT LEARNING RATE: 0.3771368422665445\n",
      "previous_iter_valid_loss : 0.0960196852684021\n",
      "\n",
      "     28200\t  0.095885\t  0.096020\t  0.102160\t\tCURRENT LEARNING RATE: 0.37675989392985865\n",
      "previous_iter_valid_loss : 0.1396554410457611\n",
      "\n",
      "     28300\t  0.139448\t  0.139655\t  0.102531\t\tCURRENT LEARNING RATE: 0.3763833223530981\n",
      "previous_iter_valid_loss : 0.10893946886062622\n",
      "\n",
      "     28400\t  0.108695\t  0.108939\t  0.102325\t\tCURRENT LEARNING RATE: 0.3760071271596913\n",
      "previous_iter_valid_loss : 0.0853106901049614\n",
      "\n",
      "     28500\t  0.085285\t  0.085311\t  0.102228\t\tCURRENT LEARNING RATE: 0.375631307973443\n",
      "previous_iter_valid_loss : 0.09893658012151718\n",
      "\n",
      "     28600\t  0.098700\t  0.098937\t  0.101843\t\tCURRENT LEARNING RATE: 0.375255864418534\n",
      "previous_iter_valid_loss : 0.11211526393890381\n",
      "\n",
      "     28700\t  0.111877\t  0.112115\t  0.102023\t\tCURRENT LEARNING RATE: 0.37488079611952063\n",
      "previous_iter_valid_loss : 0.11418966203927994\n",
      "\n",
      "     28800\t  0.113946\t  0.114190\t  0.102286\t\tCURRENT LEARNING RATE: 0.37450610270133466\n",
      "previous_iter_valid_loss : 0.09575623273849487\n",
      "\n",
      "     28900\t  0.095573\t  0.095756\t  0.102291\t\tCURRENT LEARNING RATE: 0.37413178378928263\n",
      "previous_iter_valid_loss : 0.08961904793977737\n",
      "\n",
      "     29000\t  0.089332\t  0.089619\t  0.102303\t\tCURRENT LEARNING RATE: 0.3737578390090455\n",
      "previous_iter_valid_loss : 0.1363552212715149\n",
      "\n",
      "     29100\t  0.136126\t  0.136355\t  0.102250\t\tCURRENT LEARNING RATE: 0.37338426798667856\n",
      "previous_iter_valid_loss : 0.14224280416965485\n",
      "\n",
      "     29200\t  0.141957\t  0.142243\t  0.102751\t\tCURRENT LEARNING RATE: 0.37301107034861075\n",
      "previous_iter_valid_loss : 0.1262453943490982\n",
      "\n",
      "     29300\t  0.126020\t  0.126245\t  0.102979\t\tCURRENT LEARNING RATE: 0.37263824572164433\n",
      "previous_iter_valid_loss : 0.09876969456672668\n",
      "\n",
      "     29400\t  0.098611\t  0.098770\t  0.103094\t\tCURRENT LEARNING RATE: 0.3722657937329547\n",
      "previous_iter_valid_loss : 0.16633997857570648\n",
      "\n",
      "     29500\t  0.166228\t  0.166340\t  0.103919\t\tCURRENT LEARNING RATE: 0.3718937140100898\n",
      "previous_iter_valid_loss : 0.12651264667510986\n",
      "\n",
      "     29600\t  0.126280\t  0.126513\t  0.103902\t\tCURRENT LEARNING RATE: 0.3715220061809699\n",
      "previous_iter_valid_loss : 0.10816919058561325\n",
      "\n",
      "     29700\t  0.107931\t  0.108169\t  0.103340\t\tCURRENT LEARNING RATE: 0.3711506698738872\n",
      "previous_iter_valid_loss : 0.09137509018182755\n",
      "\n",
      "     29800\t  0.091326\t  0.091375\t  0.103279\t\tCURRENT LEARNING RATE: 0.37077970471750527\n",
      "previous_iter_valid_loss : 0.1651495099067688\n",
      "\n",
      "     29900\t  0.164912\t  0.165150\t  0.103973\t\tCURRENT LEARNING RATE: 0.37040911034085894\n",
      "previous_iter_valid_loss : 0.12522153556346893\n",
      "\n",
      "     30000\t  0.125350\t  0.125222\t  0.104137\t\tCURRENT LEARNING RATE: 0.3700388863733538\n",
      "previous_iter_valid_loss : 0.09030041843652725\n",
      "\n",
      "     30100\t  0.090208\t  0.090300\t  0.104143\t\tCURRENT LEARNING RATE: 0.36966903244476595\n",
      "previous_iter_valid_loss : 0.08383217453956604\n",
      "\n",
      "     30200\t  0.083844\t  0.083832\t  0.104082\t\tCURRENT LEARNING RATE: 0.3692995481852413\n",
      "previous_iter_valid_loss : 0.1311464011669159\n",
      "\n",
      "     30300\t  0.131382\t  0.131146\t  0.104428\t\tCURRENT LEARNING RATE: 0.36893043322529556\n",
      "previous_iter_valid_loss : 0.09958239644765854\n",
      "\n",
      "     30400\t  0.099610\t  0.099582\t  0.104503\t\tCURRENT LEARNING RATE: 0.3685616871958139\n",
      "previous_iter_valid_loss : 0.13169309496879578\n",
      "\n",
      "     30500\t  0.131534\t  0.131693\t  0.104286\t\tCURRENT LEARNING RATE: 0.36819330972805003\n",
      "previous_iter_valid_loss : 0.09909709542989731\n",
      "\n",
      "     30600\t  0.098909\t  0.099097\t  0.104209\t\tCURRENT LEARNING RATE: 0.36782530045362666\n",
      "previous_iter_valid_loss : 0.11169499903917313\n",
      "\n",
      "     30700\t  0.111466\t  0.111695\t  0.104063\t\tCURRENT LEARNING RATE: 0.36745765900453436\n",
      "previous_iter_valid_loss : 0.088705874979496\n",
      "\n",
      "     30800\t  0.088600\t  0.088706\t  0.104065\t\tCURRENT LEARNING RATE: 0.3670903850131317\n",
      "previous_iter_valid_loss : 0.12366500496864319\n",
      "\n",
      "     30900\t  0.123502\t  0.123665\t  0.104309\t\tCURRENT LEARNING RATE: 0.3667234781121446\n",
      "previous_iter_valid_loss : 0.08835713565349579\n",
      "\n",
      "     31000\t  0.088328\t  0.088357\t  0.104313\t\tCURRENT LEARNING RATE: 0.3663569379346662\n",
      "previous_iter_valid_loss : 0.10767855495214462\n",
      "\n",
      "     31100\t  0.107462\t  0.107679\t  0.104469\t\tCURRENT LEARNING RATE: 0.3659907641141563\n",
      "previous_iter_valid_loss : 0.10302754491567612\n",
      "\n",
      "     31200\t  0.102852\t  0.103028\t  0.104268\t\tCURRENT LEARNING RATE: 0.365624956284441\n",
      "previous_iter_valid_loss : 0.1270969808101654\n",
      "\n",
      "     31300\t  0.126869\t  0.127097\t  0.104645\t\tCURRENT LEARNING RATE: 0.36525951407971247\n",
      "previous_iter_valid_loss : 0.12633496522903442\n",
      "\n",
      "     31400\t  0.126046\t  0.126335\t  0.104810\t\tCURRENT LEARNING RATE: 0.3648944371345284\n",
      "previous_iter_valid_loss : 0.10726732015609741\n",
      "\n",
      "     31500\t  0.107007\t  0.107267\t  0.104990\t\tCURRENT LEARNING RATE: 0.3645297250838119\n",
      "previous_iter_valid_loss : 0.10439161211252213\n",
      "\n",
      "     31600\t  0.104209\t  0.104392\t  0.104790\t\tCURRENT LEARNING RATE: 0.36416537756285083\n",
      "previous_iter_valid_loss : 0.13874609768390656\n",
      "\n",
      "     31700\t  0.138620\t  0.138746\t  0.105271\t\tCURRENT LEARNING RATE: 0.36380139420729773\n",
      "previous_iter_valid_loss : 0.08183712512254715\n",
      "\n",
      "     31800\t  0.081863\t  0.081837\t  0.105065\t\tCURRENT LEARNING RATE: 0.3634377746531691\n",
      "previous_iter_valid_loss : 0.09981681406497955\n",
      "\n",
      "     31900\t  0.099621\t  0.099817\t  0.105191\t\tCURRENT LEARNING RATE: 0.36307451853684547\n",
      "previous_iter_valid_loss : 0.10977133363485336\n",
      "\n",
      "     32000\t  0.109585\t  0.109771\t  0.105317\t\tCURRENT LEARNING RATE: 0.3627116254950706\n",
      "previous_iter_valid_loss : 0.11210214346647263\n",
      "\n",
      "     32100\t  0.111994\t  0.112102\t  0.105063\t\tCURRENT LEARNING RATE: 0.36234909516495145\n",
      "previous_iter_valid_loss : 0.16093824803829193\n",
      "\n",
      "     32200\t  0.160739\t  0.160938\t  0.105470\t\tCURRENT LEARNING RATE: 0.36198692718395764\n",
      "previous_iter_valid_loss : 0.09911143779754639\n",
      "\n",
      "     32300\t  0.098950\t  0.099111\t  0.105316\t\tCURRENT LEARNING RATE: 0.3616251211899212\n",
      "previous_iter_valid_loss : 0.15209414064884186\n",
      "\n",
      "     32400\t  0.151953\t  0.152094\t  0.105947\t\tCURRENT LEARNING RATE: 0.3612636768210361\n",
      "previous_iter_valid_loss : 0.10105939209461212\n",
      "\n",
      "     32500\t  0.100882\t  0.101059\t  0.106018\t\tCURRENT LEARNING RATE: 0.3609025937158579\n",
      "previous_iter_valid_loss : 0.10993076860904694\n",
      "\n",
      "     32600\t  0.109771\t  0.109931\t  0.106134\t\tCURRENT LEARNING RATE: 0.3605418715133035\n",
      "previous_iter_valid_loss : 0.11987842619419098\n",
      "\n",
      "     32700\t  0.120082\t  0.119878\t  0.106486\t\tCURRENT LEARNING RATE: 0.3601815098526507\n",
      "previous_iter_valid_loss : 0.10195080935955048\n",
      "\n",
      "     32800\t  0.101809\t  0.101951\t  0.106584\t\tCURRENT LEARNING RATE: 0.3598215083735377\n",
      "previous_iter_valid_loss : 0.08726280182600021\n",
      "\n",
      "     32900\t  0.087321\t  0.087263\t  0.106550\t\tCURRENT LEARNING RATE: 0.3594618667159631\n",
      "previous_iter_valid_loss : 0.18525399267673492\n",
      "\n",
      "     33000\t  0.186076\t  0.185254\t  0.107453\t\tCURRENT LEARNING RATE: 0.35910258452028515\n",
      "previous_iter_valid_loss : 0.09613440930843353\n",
      "\n",
      "     33100\t  0.095879\t  0.096134\t  0.107190\t\tCURRENT LEARNING RATE: 0.35874366142722164\n",
      "previous_iter_valid_loss : 0.09636104851961136\n",
      "\n",
      "     33200\t  0.096366\t  0.096361\t  0.107092\t\tCURRENT LEARNING RATE: 0.3583850970778495\n",
      "previous_iter_valid_loss : 0.14216512441635132\n",
      "\n",
      "     33300\t  0.142370\t  0.142165\t  0.107520\t\tCURRENT LEARNING RATE: 0.35802689111360425\n",
      "previous_iter_valid_loss : 0.12682123482227325\n",
      "\n",
      "     33400\t  0.126663\t  0.126821\t  0.107775\t\tCURRENT LEARNING RATE: 0.35766904317627995\n",
      "previous_iter_valid_loss : 0.0910254642367363\n",
      "\n",
      "     33500\t  0.090986\t  0.091025\t  0.107364\t\tCURRENT LEARNING RATE: 0.35731155290802863\n",
      "previous_iter_valid_loss : 0.14651893079280853\n",
      "\n",
      "     33600\t  0.146334\t  0.146519\t  0.107356\t\tCURRENT LEARNING RATE: 0.35695441995136\n",
      "previous_iter_valid_loss : 0.12450253218412399\n",
      "\n",
      "     33700\t  0.124226\t  0.124503\t  0.107408\t\tCURRENT LEARNING RATE: 0.3565976439491411\n",
      "previous_iter_valid_loss : 0.10143040120601654\n",
      "\n",
      "     33800\t  0.101262\t  0.101430\t  0.107140\t\tCURRENT LEARNING RATE: 0.3562412245445959\n",
      "previous_iter_valid_loss : 0.09921354055404663\n",
      "\n",
      "     33900\t  0.099532\t  0.099214\t  0.107153\t\tCURRENT LEARNING RATE: 0.3558851613813048\n",
      "previous_iter_valid_loss : 0.11343451589345932\n",
      "\n",
      "     34000\t  0.113472\t  0.113435\t  0.107300\t\tCURRENT LEARNING RATE: 0.35552945410320486\n",
      "previous_iter_valid_loss : 0.16037985682487488\n",
      "\n",
      "     34100\t  0.160259\t  0.160380\t  0.108019\t\tCURRENT LEARNING RATE: 0.35517410235458863\n",
      "previous_iter_valid_loss : 0.11542438715696335\n",
      "\n",
      "     34200\t  0.115622\t  0.115424\t  0.108353\t\tCURRENT LEARNING RATE: 0.35481910578010434\n",
      "previous_iter_valid_loss : 0.11572015285491943\n",
      "\n",
      "     34300\t  0.115923\t  0.115720\t  0.108659\t\tCURRENT LEARNING RATE: 0.3544644640247554\n",
      "previous_iter_valid_loss : 0.10866004228591919\n",
      "\n",
      "     34400\t  0.108491\t  0.108660\t  0.108887\t\tCURRENT LEARNING RATE: 0.3541101767339\n",
      "previous_iter_valid_loss : 0.12263309955596924\n",
      "\n",
      "     34500\t  0.122849\t  0.122633\t  0.109253\t\tCURRENT LEARNING RATE: 0.35375624355325086\n",
      "previous_iter_valid_loss : 0.11570873111486435\n",
      "\n",
      "     34600\t  0.115537\t  0.115709\t  0.109572\t\tCURRENT LEARNING RATE: 0.3534026641288747\n",
      "previous_iter_valid_loss : 0.1041320413351059\n",
      "\n",
      "     34700\t  0.103927\t  0.104132\t  0.109786\t\tCURRENT LEARNING RATE: 0.3530494381071922\n",
      "previous_iter_valid_loss : 0.09164367616176605\n",
      "\n",
      "     34800\t  0.091580\t  0.091644\t  0.109545\t\tCURRENT LEARNING RATE: 0.3526965651349772\n",
      "previous_iter_valid_loss : 0.13053035736083984\n",
      "\n",
      "     34900\t  0.130676\t  0.130530\t  0.109416\t\tCURRENT LEARNING RATE: 0.3523440448593567\n",
      "previous_iter_valid_loss : 0.09243594855070114\n",
      "\n",
      "     35000\t  0.092407\t  0.092436\t  0.109381\t\tCURRENT LEARNING RATE: 0.3519918769278105\n",
      "previous_iter_valid_loss : 0.0886850580573082\n",
      "\n",
      "     35100\t  0.088592\t  0.088685\t  0.109347\t\tCURRENT LEARNING RATE: 0.35164006098817047\n",
      "previous_iter_valid_loss : 0.0996028482913971\n",
      "\n",
      "     35200\t  0.099364\t  0.099603\t  0.109122\t\tCURRENT LEARNING RATE: 0.3512885966886208\n",
      "previous_iter_valid_loss : 0.09351246803998947\n",
      "\n",
      "     35300\t  0.093301\t  0.093512\t  0.109201\t\tCURRENT LEARNING RATE: 0.350937483677697\n",
      "previous_iter_valid_loss : 0.10243789106607437\n",
      "\n",
      "     35400\t  0.102276\t  0.102438\t  0.109400\t\tCURRENT LEARNING RATE: 0.3505867216042862\n",
      "previous_iter_valid_loss : 0.09568509459495544\n",
      "\n",
      "     35500\t  0.095674\t  0.095685\t  0.109353\t\tCURRENT LEARNING RATE: 0.3502363101176262\n",
      "previous_iter_valid_loss : 0.10462941229343414\n",
      "\n",
      "     35600\t  0.104714\t  0.104629\t  0.109522\t\tCURRENT LEARNING RATE: 0.3498862488673055\n",
      "previous_iter_valid_loss : 0.1248648464679718\n",
      "\n",
      "     35700\t  0.125141\t  0.124865\t  0.109858\t\tCURRENT LEARNING RATE: 0.34953653750326286\n",
      "previous_iter_valid_loss : 0.12563298642635345\n",
      "\n",
      "     35800\t  0.125862\t  0.125633\t  0.110268\t\tCURRENT LEARNING RATE: 0.3491871756757868\n",
      "previous_iter_valid_loss : 0.13850611448287964\n",
      "\n",
      "     35900\t  0.138850\t  0.138506\t  0.110696\t\tCURRENT LEARNING RATE: 0.3488381630355155\n",
      "previous_iter_valid_loss : 0.09006308019161224\n",
      "\n",
      "     36000\t  0.090013\t  0.090063\t  0.110675\t\tCURRENT LEARNING RATE: 0.34848949923343636\n",
      "previous_iter_valid_loss : 0.09618927538394928\n",
      "\n",
      "     36100\t  0.096137\t  0.096189\t  0.110584\t\tCURRENT LEARNING RATE: 0.3481411839208855\n",
      "previous_iter_valid_loss : 0.10546843707561493\n",
      "\n",
      "     36200\t  0.105330\t  0.105468\t  0.110781\t\tCURRENT LEARNING RATE: 0.34779321674954755\n",
      "previous_iter_valid_loss : 0.13633939623832703\n",
      "\n",
      "     36300\t  0.136221\t  0.136339\t  0.111260\t\tCURRENT LEARNING RATE: 0.3474455973714553\n",
      "previous_iter_valid_loss : 0.15073031187057495\n",
      "\n",
      "     36400\t  0.151077\t  0.150730\t  0.111923\t\tCURRENT LEARNING RATE: 0.34709832543898944\n",
      "previous_iter_valid_loss : 0.11261563748121262\n",
      "\n",
      "     36500\t  0.112502\t  0.112616\t  0.112225\t\tCURRENT LEARNING RATE: 0.3467514006048779\n",
      "previous_iter_valid_loss : 0.09772790968418121\n",
      "\n",
      "     36600\t  0.097616\t  0.097728\t  0.112037\t\tCURRENT LEARNING RATE: 0.34640482252219584\n",
      "previous_iter_valid_loss : 0.1221037358045578\n",
      "\n",
      "     36700\t  0.122406\t  0.122104\t  0.112097\t\tCURRENT LEARNING RATE: 0.3460585908443652\n",
      "previous_iter_valid_loss : 0.15455062687397003\n",
      "\n",
      "     36800\t  0.154961\t  0.154551\t  0.112677\t\tCURRENT LEARNING RATE: 0.34571270522515424\n",
      "previous_iter_valid_loss : 0.11071690917015076\n",
      "\n",
      "     36900\t  0.110937\t  0.110717\t  0.112656\t\tCURRENT LEARNING RATE: 0.34536716531867734\n",
      "previous_iter_valid_loss : 0.08863630145788193\n",
      "\n",
      "     37000\t  0.088548\t  0.088636\t  0.112675\t\tCURRENT LEARNING RATE: 0.3450219707793945\n",
      "previous_iter_valid_loss : 0.1078014075756073\n",
      "\n",
      "     37100\t  0.107622\t  0.107801\t  0.112540\t\tCURRENT LEARNING RATE: 0.3446771212621112\n",
      "previous_iter_valid_loss : 0.08622020483016968\n",
      "\n",
      "     37200\t  0.086049\t  0.086220\t  0.112137\t\tCURRENT LEARNING RATE: 0.3443326164219779\n",
      "previous_iter_valid_loss : 0.1003781110048294\n",
      "\n",
      "     37300\t  0.100206\t  0.100378\t  0.111792\t\tCURRENT LEARNING RATE: 0.34398845591448973\n",
      "previous_iter_valid_loss : 0.10376420617103577\n",
      "\n",
      "     37400\t  0.103593\t  0.103764\t  0.111891\t\tCURRENT LEARNING RATE: 0.3436446393954861\n",
      "previous_iter_valid_loss : 0.09096792340278625\n",
      "\n",
      "     37500\t  0.090844\t  0.090968\t  0.111958\t\tCURRENT LEARNING RATE: 0.3433011665211505\n",
      "previous_iter_valid_loss : 0.0954994186758995\n",
      "\n",
      "     37600\t  0.095408\t  0.095499\t  0.111908\t\tCURRENT LEARNING RATE: 0.3429580369480101\n",
      "previous_iter_valid_loss : 0.0908980444073677\n",
      "\n",
      "     37700\t  0.090783\t  0.090898\t  0.111798\t\tCURRENT LEARNING RATE: 0.34261525033293516\n",
      "previous_iter_valid_loss : 0.12758320569992065\n",
      "\n",
      "     37800\t  0.127348\t  0.127583\t  0.112161\t\tCURRENT LEARNING RATE: 0.3422728063331391\n",
      "previous_iter_valid_loss : 0.16527898609638214\n",
      "\n",
      "     37900\t  0.165066\t  0.165279\t  0.113005\t\tCURRENT LEARNING RATE: 0.3419307046061779\n",
      "previous_iter_valid_loss : 0.0966026708483696\n",
      "\n",
      "     38000\t  0.096466\t  0.096603\t  0.113022\t\tCURRENT LEARNING RATE: 0.34158894480994983\n",
      "previous_iter_valid_loss : 0.14499224722385406\n",
      "\n",
      "     38100\t  0.144875\t  0.144992\t  0.113541\t\tCURRENT LEARNING RATE: 0.34124752660269503\n",
      "previous_iter_valid_loss : 0.10280416905879974\n",
      "\n",
      "     38200\t  0.102718\t  0.102804\t  0.113609\t\tCURRENT LEARNING RATE: 0.34090644964299527\n",
      "previous_iter_valid_loss : 0.10235586017370224\n",
      "\n",
      "     38300\t  0.102228\t  0.102356\t  0.113236\t\tCURRENT LEARNING RATE: 0.34056571358977356\n",
      "previous_iter_valid_loss : 0.08064392954111099\n",
      "\n",
      "     38400\t  0.080590\t  0.080644\t  0.112953\t\tCURRENT LEARNING RATE: 0.34022531810229384\n",
      "previous_iter_valid_loss : 0.11118976026773453\n",
      "\n",
      "     38500\t  0.111376\t  0.111190\t  0.113212\t\tCURRENT LEARNING RATE: 0.3398852628401605\n",
      "previous_iter_valid_loss : 0.09554728865623474\n",
      "\n",
      "     38600\t  0.095708\t  0.095547\t  0.113178\t\tCURRENT LEARNING RATE: 0.3395455474633184\n",
      "previous_iter_valid_loss : 0.146156907081604\n",
      "\n",
      "     38700\t  0.146522\t  0.146157\t  0.113518\t\tCURRENT LEARNING RATE: 0.339206171632052\n",
      "previous_iter_valid_loss : 0.11264656484127045\n",
      "\n",
      "     38800\t  0.112921\t  0.112647\t  0.113503\t\tCURRENT LEARNING RATE: 0.33886713500698556\n",
      "previous_iter_valid_loss : 0.09077232331037521\n",
      "\n",
      "     38900\t  0.090761\t  0.090772\t  0.113453\t\tCURRENT LEARNING RATE: 0.3385284372490823\n",
      "previous_iter_valid_loss : 0.1094791516661644\n",
      "\n",
      "     39000\t  0.109539\t  0.109479\t  0.113652\t\tCURRENT LEARNING RATE: 0.33819007801964457\n",
      "previous_iter_valid_loss : 0.0951555073261261\n",
      "\n",
      "     39100\t  0.095110\t  0.095156\t  0.113240\t\tCURRENT LEARNING RATE: 0.337852056980313\n",
      "previous_iter_valid_loss : 0.09265194088220596\n",
      "\n",
      "     39200\t  0.092798\t  0.092652\t  0.112744\t\tCURRENT LEARNING RATE: 0.3375143737930666\n",
      "previous_iter_valid_loss : 0.09794074296951294\n",
      "\n",
      "     39300\t  0.098106\t  0.097941\t  0.112461\t\tCURRENT LEARNING RATE: 0.3371770281202221\n",
      "previous_iter_valid_loss : 0.12476977705955505\n",
      "\n",
      "     39400\t  0.125213\t  0.124770\t  0.112721\t\tCURRENT LEARNING RATE: 0.33684001962443383\n",
      "previous_iter_valid_loss : 0.1000494733452797\n",
      "\n",
      "     39500\t  0.100141\t  0.100049\t  0.112058\t\tCURRENT LEARNING RATE: 0.3365033479686932\n",
      "previous_iter_valid_loss : 0.1205260306596756\n",
      "\n",
      "     39600\t  0.120725\t  0.120526\t  0.111998\t\tCURRENT LEARNING RATE: 0.3361670128163286\n",
      "previous_iter_valid_loss : 0.116043820977211\n",
      "\n",
      "     39700\t  0.116199\t  0.116044\t  0.112077\t\tCURRENT LEARNING RATE: 0.3358310138310049\n",
      "previous_iter_valid_loss : 0.13751840591430664\n",
      "\n",
      "     39800\t  0.137886\t  0.137518\t  0.112538\t\tCURRENT LEARNING RATE: 0.3354953506767229\n",
      "previous_iter_valid_loss : 0.14282958209514618\n",
      "\n",
      "     39900\t  0.143313\t  0.142830\t  0.112315\t\tCURRENT LEARNING RATE: 0.33516002301781966\n",
      "previous_iter_valid_loss : 0.11795996874570847\n",
      "\n",
      "     40000\t  0.118335\t  0.117960\t  0.112242\t\tCURRENT LEARNING RATE: 0.3348250305189673\n",
      "previous_iter_valid_loss : 0.09415736794471741\n",
      "\n",
      "     40100\t  0.094387\t  0.094157\t  0.112281\t\tCURRENT LEARNING RATE: 0.33449037284517336\n",
      "previous_iter_valid_loss : 0.11405572295188904\n",
      "\n",
      "     40200\t  0.114407\t  0.114056\t  0.112583\t\tCURRENT LEARNING RATE: 0.33415604966178014\n",
      "previous_iter_valid_loss : 0.08707379549741745\n",
      "\n",
      "     40300\t  0.087290\t  0.087074\t  0.112142\t\tCURRENT LEARNING RATE: 0.33382206063446446\n",
      "previous_iter_valid_loss : 0.09478344023227692\n",
      "\n",
      "     40400\t  0.094982\t  0.094783\t  0.112094\t\tCURRENT LEARNING RATE: 0.3334884054292372\n",
      "previous_iter_valid_loss : 0.10836593061685562\n",
      "\n",
      "     40500\t  0.108311\t  0.108366\t  0.111861\t\tCURRENT LEARNING RATE: 0.3331550837124432\n",
      "previous_iter_valid_loss : 0.11336249858140945\n",
      "\n",
      "     40600\t  0.113554\t  0.113362\t  0.112004\t\tCURRENT LEARNING RATE: 0.3328220951507606\n",
      "previous_iter_valid_loss : 0.13480915129184723\n",
      "\n",
      "     40700\t  0.135187\t  0.134809\t  0.112235\t\tCURRENT LEARNING RATE: 0.33248943941120096\n",
      "previous_iter_valid_loss : 0.09945613890886307\n",
      "\n",
      "     40800\t  0.099540\t  0.099456\t  0.112342\t\tCURRENT LEARNING RATE: 0.3321571161611084\n",
      "previous_iter_valid_loss : 0.11043991893529892\n",
      "\n",
      "     40900\t  0.110741\t  0.110440\t  0.112210\t\tCURRENT LEARNING RATE: 0.3318251250681597\n",
      "previous_iter_valid_loss : 0.09805972129106522\n",
      "\n",
      "     41000\t  0.098219\t  0.098060\t  0.112307\t\tCURRENT LEARNING RATE: 0.3314934658003637\n",
      "previous_iter_valid_loss : 0.0961456224322319\n",
      "\n",
      "     41100\t  0.096177\t  0.096146\t  0.112192\t\tCURRENT LEARNING RATE: 0.33116213802606115\n",
      "previous_iter_valid_loss : 0.09831403940916061\n",
      "\n",
      "     41200\t  0.098456\t  0.098314\t  0.112145\t\tCURRENT LEARNING RATE: 0.33083114141392417\n",
      "previous_iter_valid_loss : 0.09668917208909988\n",
      "\n",
      "     41300\t  0.096646\t  0.096689\t  0.111841\t\tCURRENT LEARNING RATE: 0.33050047563295626\n",
      "previous_iter_valid_loss : 0.10814699530601501\n",
      "\n",
      "     41400\t  0.108378\t  0.108147\t  0.111659\t\tCURRENT LEARNING RATE: 0.3301701403524914\n",
      "previous_iter_valid_loss : 0.12178361415863037\n",
      "\n",
      "     41500\t  0.122000\t  0.121784\t  0.111804\t\tCURRENT LEARNING RATE: 0.3298401352421945\n",
      "previous_iter_valid_loss : 0.10891389846801758\n",
      "\n",
      "     41600\t  0.108985\t  0.108914\t  0.111849\t\tCURRENT LEARNING RATE: 0.32951045997206035\n",
      "previous_iter_valid_loss : 0.10512981563806534\n",
      "\n",
      "     41700\t  0.105292\t  0.105130\t  0.111513\t\tCURRENT LEARNING RATE: 0.3291811142124136\n",
      "previous_iter_valid_loss : 0.11437064409255981\n",
      "\n",
      "     41800\t  0.114598\t  0.114371\t  0.111838\t\tCURRENT LEARNING RATE: 0.3288520976339085\n",
      "previous_iter_valid_loss : 0.11585374921560287\n",
      "\n",
      "     41900\t  0.116081\t  0.115854\t  0.111999\t\tCURRENT LEARNING RATE: 0.3285234099075284\n",
      "previous_iter_valid_loss : 0.09383751451969147\n",
      "\n",
      "     42000\t  0.093794\t  0.093838\t  0.111839\t\tCURRENT LEARNING RATE: 0.3281950507045856\n",
      "previous_iter_valid_loss : 0.08799322694540024\n",
      "\n",
      "     42100\t  0.087949\t  0.087993\t  0.111598\t\tCURRENT LEARNING RATE: 0.3278670196967209\n",
      "previous_iter_valid_loss : 0.09382109344005585\n",
      "\n",
      "     42200\t  0.093734\t  0.093821\t  0.110927\t\tCURRENT LEARNING RATE: 0.3275393165559031\n",
      "previous_iter_valid_loss : 0.12048470228910446\n",
      "\n",
      "     42300\t  0.120330\t  0.120485\t  0.111141\t\tCURRENT LEARNING RATE: 0.3272119409544293\n",
      "previous_iter_valid_loss : 0.08679228276014328\n",
      "\n",
      "     42400\t  0.086691\t  0.086792\t  0.110488\t\tCURRENT LEARNING RATE: 0.32688489256492365\n",
      "previous_iter_valid_loss : 0.14452821016311646\n",
      "\n",
      "     42500\t  0.144331\t  0.144528\t  0.110922\t\tCURRENT LEARNING RATE: 0.3265581710603378\n",
      "previous_iter_valid_loss : 0.08283314108848572\n",
      "\n",
      "     42600\t  0.082742\t  0.082833\t  0.110651\t\tCURRENT LEARNING RATE: 0.3262317761139502\n",
      "previous_iter_valid_loss : 0.08315511047840118\n",
      "\n",
      "     42700\t  0.083167\t  0.083155\t  0.110284\t\tCURRENT LEARNING RATE: 0.325905707399366\n",
      "previous_iter_valid_loss : 0.10274989902973175\n",
      "\n",
      "     42800\t  0.102594\t  0.102750\t  0.110292\t\tCURRENT LEARNING RATE: 0.32557996459051625\n",
      "previous_iter_valid_loss : 0.08724098652601242\n",
      "\n",
      "     42900\t  0.087140\t  0.087241\t  0.110292\t\tCURRENT LEARNING RATE: 0.32525454736165826\n",
      "previous_iter_valid_loss : 0.12704136967658997\n",
      "\n",
      "     43000\t  0.126735\t  0.127041\t  0.109710\t\tCURRENT LEARNING RATE: 0.3249294553873748\n",
      "previous_iter_valid_loss : 0.10767338424921036\n",
      "\n",
      "     43100\t  0.107427\t  0.107673\t  0.109825\t\tCURRENT LEARNING RATE: 0.3246046883425737\n",
      "previous_iter_valid_loss : 0.11594488471746445\n",
      "\n",
      "     43200\t  0.116208\t  0.115945\t  0.110021\t\tCURRENT LEARNING RATE: 0.32428024590248805\n",
      "previous_iter_valid_loss : 0.09585385024547577\n",
      "\n",
      "     43300\t  0.095917\t  0.095854\t  0.109558\t\tCURRENT LEARNING RATE: 0.3239561277426753\n",
      "previous_iter_valid_loss : 0.10243693739175797\n",
      "\n",
      "     43400\t  0.102696\t  0.102437\t  0.109314\t\tCURRENT LEARNING RATE: 0.3236323335390173\n",
      "previous_iter_valid_loss : 0.11150677502155304\n",
      "\n",
      "     43500\t  0.111663\t  0.111507\t  0.109519\t\tCURRENT LEARNING RATE: 0.3233088629677198\n",
      "previous_iter_valid_loss : 0.09120018780231476\n",
      "\n",
      "     43600\t  0.091248\t  0.091200\t  0.108966\t\tCURRENT LEARNING RATE: 0.32298571570531226\n",
      "previous_iter_valid_loss : 0.09764761477708817\n",
      "\n",
      "     43700\t  0.097730\t  0.097648\t  0.108697\t\tCURRENT LEARNING RATE: 0.3226628914286473\n",
      "previous_iter_valid_loss : 0.11119037866592407\n",
      "\n",
      "     43800\t  0.111070\t  0.111190\t  0.108795\t\tCURRENT LEARNING RATE: 0.32234038981490065\n",
      "previous_iter_valid_loss : 0.10211717337369919\n",
      "\n",
      "     43900\t  0.102049\t  0.102117\t  0.108824\t\tCURRENT LEARNING RATE: 0.3220182105415707\n",
      "previous_iter_valid_loss : 0.11959504336118698\n",
      "\n",
      "     44000\t  0.119489\t  0.119595\t  0.108885\t\tCURRENT LEARNING RATE: 0.3216963532864781\n",
      "previous_iter_valid_loss : 0.08964052051305771\n",
      "\n",
      "     44100\t  0.089460\t  0.089641\t  0.108178\t\tCURRENT LEARNING RATE: 0.3213748177277656\n",
      "previous_iter_valid_loss : 0.10707646608352661\n",
      "\n",
      "     44200\t  0.106837\t  0.107076\t  0.108095\t\tCURRENT LEARNING RATE: 0.3210536035438976\n",
      "previous_iter_valid_loss : 0.08980307728052139\n",
      "\n",
      "     44300\t  0.089803\t  0.089803\t  0.107835\t\tCURRENT LEARNING RATE: 0.3207327104136599\n",
      "previous_iter_valid_loss : 0.13411086797714233\n",
      "\n",
      "     44400\t  0.133917\t  0.134111\t  0.108090\t\tCURRENT LEARNING RATE: 0.32041213801615936\n",
      "previous_iter_valid_loss : 0.1150795966386795\n",
      "\n",
      "     44500\t  0.114923\t  0.115080\t  0.108014\t\tCURRENT LEARNING RATE: 0.32009188603082356\n",
      "previous_iter_valid_loss : 0.10544431209564209\n",
      "\n",
      "     44600\t  0.105260\t  0.105444\t  0.107912\t\tCURRENT LEARNING RATE: 0.31977195413740045\n",
      "previous_iter_valid_loss : 0.0831368938088417\n",
      "\n",
      "     44700\t  0.083021\t  0.083137\t  0.107702\t\tCURRENT LEARNING RATE: 0.3194523420159581\n",
      "previous_iter_valid_loss : 0.09167855978012085\n",
      "\n",
      "     44800\t  0.091550\t  0.091679\t  0.107702\t\tCURRENT LEARNING RATE: 0.3191330493468844\n",
      "previous_iter_valid_loss : 0.1197531595826149\n",
      "\n",
      "     44900\t  0.119534\t  0.119753\t  0.107594\t\tCURRENT LEARNING RATE: 0.31881407581088667\n",
      "previous_iter_valid_loss : 0.09642300009727478\n",
      "\n",
      "     45000\t  0.096298\t  0.096423\t  0.107634\t\tCURRENT LEARNING RATE: 0.31849542108899126\n",
      "previous_iter_valid_loss : 0.08281798660755157\n",
      "\n",
      "     45100\t  0.082755\t  0.082818\t  0.107576\t\tCURRENT LEARNING RATE: 0.31817708486254354\n",
      "previous_iter_valid_loss : 0.11990877240896225\n",
      "\n",
      "     45200\t  0.119772\t  0.119909\t  0.107779\t\tCURRENT LEARNING RATE: 0.31785906681320714\n",
      "previous_iter_valid_loss : 0.10205124318599701\n",
      "\n",
      "     45300\t  0.101915\t  0.102051\t  0.107864\t\tCURRENT LEARNING RATE: 0.31754136662296406\n",
      "previous_iter_valid_loss : 0.09560459107160568\n",
      "\n",
      "     45400\t  0.095478\t  0.095605\t  0.107796\t\tCURRENT LEARNING RATE: 0.3172239839741141\n",
      "previous_iter_valid_loss : 0.0954190045595169\n",
      "\n",
      "     45500\t  0.095251\t  0.095419\t  0.107793\t\tCURRENT LEARNING RATE: 0.3169069185492745\n",
      "previous_iter_valid_loss : 0.10788042843341827\n",
      "\n",
      "     45600\t  0.107707\t  0.107880\t  0.107826\t\tCURRENT LEARNING RATE: 0.3165901700313799\n",
      "previous_iter_valid_loss : 0.08785378187894821\n",
      "\n",
      "     45700\t  0.087802\t  0.087854\t  0.107455\t\tCURRENT LEARNING RATE: 0.3162737381036817\n",
      "previous_iter_valid_loss : 0.10440871864557266\n",
      "\n",
      "     45800\t  0.104272\t  0.104409\t  0.107243\t\tCURRENT LEARNING RATE: 0.31595762244974795\n",
      "previous_iter_valid_loss : 0.1023348942399025\n",
      "\n",
      "     45900\t  0.102197\t  0.102335\t  0.106882\t\tCURRENT LEARNING RATE: 0.315641822753463\n",
      "previous_iter_valid_loss : 0.11520854383707047\n",
      "\n",
      "     46000\t  0.115091\t  0.115209\t  0.107133\t\tCURRENT LEARNING RATE: 0.3153263386990271\n",
      "previous_iter_valid_loss : 0.08406348526477814\n",
      "\n",
      "     46100\t  0.084051\t  0.084063\t  0.107012\t\tCURRENT LEARNING RATE: 0.31501116997095613\n",
      "previous_iter_valid_loss : 0.08031827956438065\n",
      "\n",
      "     46200\t  0.080358\t  0.080318\t  0.106760\t\tCURRENT LEARNING RATE: 0.31469631625408145\n",
      "previous_iter_valid_loss : 0.15165476500988007\n",
      "\n",
      "     46300\t  0.152048\t  0.151655\t  0.106913\t\tCURRENT LEARNING RATE: 0.3143817772335492\n",
      "previous_iter_valid_loss : 0.11816371977329254\n",
      "\n",
      "     46400\t  0.118328\t  0.118164\t  0.106588\t\tCURRENT LEARNING RATE: 0.3140675525948204\n",
      "previous_iter_valid_loss : 0.1403590887784958\n",
      "\n",
      "     46500\t  0.140201\t  0.140359\t  0.106865\t\tCURRENT LEARNING RATE: 0.31375364202367034\n",
      "previous_iter_valid_loss : 0.11625605821609497\n",
      "\n",
      "     46600\t  0.116284\t  0.116256\t  0.107050\t\tCURRENT LEARNING RATE: 0.3134400452061885\n",
      "previous_iter_valid_loss : 0.09502896666526794\n",
      "\n",
      "     46700\t  0.095080\t  0.095029\t  0.106780\t\tCURRENT LEARNING RATE: 0.31312676182877797\n",
      "previous_iter_valid_loss : 0.09209839254617691\n",
      "\n",
      "     46800\t  0.092208\t  0.092098\t  0.106155\t\tCURRENT LEARNING RATE: 0.31281379157815536\n",
      "previous_iter_valid_loss : 0.11614784598350525\n",
      "\n",
      "     46900\t  0.116125\t  0.116148\t  0.106209\t\tCURRENT LEARNING RATE: 0.3125011341413504\n",
      "previous_iter_valid_loss : 0.1049671620130539\n",
      "\n",
      "     47000\t  0.104919\t  0.104967\t  0.106373\t\tCURRENT LEARNING RATE: 0.31218878920570564\n",
      "previous_iter_valid_loss : 0.12909294664859772\n",
      "\n",
      "     47100\t  0.129295\t  0.129093\t  0.106586\t\tCURRENT LEARNING RATE: 0.3118767564588761\n",
      "previous_iter_valid_loss : 0.08562346547842026\n",
      "\n",
      "     47200\t  0.085555\t  0.085623\t  0.106580\t\tCURRENT LEARNING RATE: 0.3115650355888289\n",
      "previous_iter_valid_loss : 0.1053413525223732\n",
      "\n",
      "     47300\t  0.105254\t  0.105341\t  0.106629\t\tCURRENT LEARNING RATE: 0.3112536262838434\n",
      "previous_iter_valid_loss : 0.10250051319599152\n",
      "\n",
      "     47400\t  0.102455\t  0.102501\t  0.106617\t\tCURRENT LEARNING RATE: 0.31094252823251006\n",
      "previous_iter_valid_loss : 0.09096085280179977\n",
      "\n",
      "     47500\t  0.090960\t  0.090961\t  0.106617\t\tCURRENT LEARNING RATE: 0.3106317411237309\n",
      "previous_iter_valid_loss : 0.08952971547842026\n",
      "\n",
      "     47600\t  0.089535\t  0.089530\t  0.106557\t\tCURRENT LEARNING RATE: 0.31032126464671866\n",
      "previous_iter_valid_loss : 0.08999692648649216\n",
      "\n",
      "     47700\t  0.089850\t  0.089997\t  0.106548\t\tCURRENT LEARNING RATE: 0.310011098490997\n",
      "previous_iter_valid_loss : 0.09845775365829468\n",
      "\n",
      "     47800\t  0.098447\t  0.098458\t  0.106257\t\tCURRENT LEARNING RATE: 0.3097012423463996\n",
      "previous_iter_valid_loss : 0.1353062391281128\n",
      "\n",
      "     47900\t  0.135174\t  0.135306\t  0.105957\t\tCURRENT LEARNING RATE: 0.3093916959030704\n",
      "previous_iter_valid_loss : 0.09948360919952393\n",
      "\n",
      "     48000\t  0.099410\t  0.099484\t  0.105986\t\tCURRENT LEARNING RATE: 0.3090824588514629\n",
      "previous_iter_valid_loss : 0.1284775286912918\n",
      "\n",
      "     48100\t  0.128752\t  0.128478\t  0.105821\t\tCURRENT LEARNING RATE: 0.30877353088234\n",
      "previous_iter_valid_loss : 0.10018936544656754\n",
      "\n",
      "     48200\t  0.100340\t  0.100189\t  0.105794\t\tCURRENT LEARNING RATE: 0.3084649116867737\n",
      "previous_iter_valid_loss : 0.08814780414104462\n",
      "\n",
      "     48300\t  0.087973\t  0.088148\t  0.105652\t\tCURRENT LEARNING RATE: 0.30815660095614483\n",
      "previous_iter_valid_loss : 0.09162117540836334\n",
      "\n",
      "     48400\t  0.092040\t  0.091621\t  0.105762\t\tCURRENT LEARNING RATE: 0.30784859838214257\n",
      "previous_iter_valid_loss : 0.09940982609987259\n",
      "\n",
      "     48500\t  0.099554\t  0.099410\t  0.105644\t\tCURRENT LEARNING RATE: 0.30754090365676434\n",
      "previous_iter_valid_loss : 0.08433296531438828\n",
      "\n",
      "     48600\t  0.084423\t  0.084333\t  0.105532\t\tCURRENT LEARNING RATE: 0.3072335164723154\n",
      "previous_iter_valid_loss : 0.08610039204359055\n",
      "\n",
      "     48700\t  0.086127\t  0.086100\t  0.104932\t\tCURRENT LEARNING RATE: 0.30692643652140855\n",
      "previous_iter_valid_loss : 0.09620263427495956\n",
      "\n",
      "     48800\t  0.096346\t  0.096203\t  0.104767\t\tCURRENT LEARNING RATE: 0.30661966349696373\n",
      "previous_iter_valid_loss : 0.10386303067207336\n",
      "\n",
      "     48900\t  0.103877\t  0.103863\t  0.104898\t\tCURRENT LEARNING RATE: 0.30631319709220806\n",
      "previous_iter_valid_loss : 0.09778489172458649\n",
      "\n",
      "     49000\t  0.098147\t  0.097785\t  0.104781\t\tCURRENT LEARNING RATE: 0.30600703700067494\n",
      "previous_iter_valid_loss : 0.08812340348958969\n",
      "\n",
      "     49100\t  0.088284\t  0.088123\t  0.104711\t\tCURRENT LEARNING RATE: 0.30570118291620435\n",
      "previous_iter_valid_loss : 0.09725047647953033\n",
      "\n",
      "     49200\t  0.097302\t  0.097250\t  0.104757\t\tCURRENT LEARNING RATE: 0.3053956345329421\n",
      "previous_iter_valid_loss : 0.08464011549949646\n",
      "\n",
      "     49300\t  0.084604\t  0.084640\t  0.104624\t\tCURRENT LEARNING RATE: 0.3050903915453399\n",
      "previous_iter_valid_loss : 0.1661348193883896\n",
      "\n",
      "     49400\t  0.165945\t  0.166135\t  0.105037\t\tCURRENT LEARNING RATE: 0.3047854536481546\n",
      "previous_iter_valid_loss : 0.10127337276935577\n",
      "\n",
      "     49500\t  0.101255\t  0.101273\t  0.105050\t\tCURRENT LEARNING RATE: 0.3044808205364484\n",
      "previous_iter_valid_loss : 0.08729583024978638\n",
      "\n",
      "     49600\t  0.087487\t  0.087296\t  0.104717\t\tCURRENT LEARNING RATE: 0.30417649190558815\n",
      "previous_iter_valid_loss : 0.12818415462970734\n",
      "\n",
      "     49700\t  0.128042\t  0.128184\t  0.104839\t\tCURRENT LEARNING RATE: 0.3038724674512451\n",
      "previous_iter_valid_loss : 0.10543975234031677\n",
      "\n",
      "     49800\t  0.105568\t  0.105440\t  0.104518\t\tCURRENT LEARNING RATE: 0.30356874686939483\n",
      "previous_iter_valid_loss : 0.11933688819408417\n",
      "\n",
      "     49900\t  0.119259\t  0.119337\t  0.104283\t\tCURRENT LEARNING RATE: 0.3032653298563167\n",
      "previous_iter_valid_loss : 0.10663320124149323\n",
      "\n",
      "     50000\t  0.106540\t  0.106633\t  0.104170\t\tCURRENT LEARNING RATE: 0.30296221610859375\n",
      "previous_iter_valid_loss : 0.1024366021156311\n",
      "\n",
      "     50100\t  0.102376\t  0.102437\t  0.104253\t\tCURRENT LEARNING RATE: 0.30265940532311214\n",
      "previous_iter_valid_loss : 0.09483630955219269\n",
      "\n",
      "     50200\t  0.094753\t  0.094836\t  0.104060\t\tCURRENT LEARNING RATE: 0.30235689719706105\n",
      "previous_iter_valid_loss : 0.08874307572841644\n",
      "\n",
      "     50300\t  0.088793\t  0.088743\t  0.104077\t\tCURRENT LEARNING RATE: 0.30205469142793234\n",
      "previous_iter_valid_loss : 0.09257412701845169\n",
      "\n",
      "     50400\t  0.092461\t  0.092574\t  0.104055\t\tCURRENT LEARNING RATE: 0.30175278771352027\n",
      "previous_iter_valid_loss : 0.09538578242063522\n",
      "\n",
      "     50500\t  0.095401\t  0.095386\t  0.103925\t\tCURRENT LEARNING RATE: 0.30145118575192104\n",
      "previous_iter_valid_loss : 0.08831580728292465\n",
      "\n",
      "     50600\t  0.088198\t  0.088316\t  0.103675\t\tCURRENT LEARNING RATE: 0.3011498852415327\n",
      "previous_iter_valid_loss : 0.09975399821996689\n",
      "\n",
      "     50700\t  0.099776\t  0.099754\t  0.103324\t\tCURRENT LEARNING RATE: 0.3008488858810547\n",
      "previous_iter_valid_loss : 0.09194225817918777\n",
      "\n",
      "     50800\t  0.091952\t  0.091942\t  0.103249\t\tCURRENT LEARNING RATE: 0.30054818736948763\n",
      "previous_iter_valid_loss : 0.1395755112171173\n",
      "\n",
      "     50900\t  0.139797\t  0.139576\t  0.103540\t\tCURRENT LEARNING RATE: 0.30024778940613295\n",
      "previous_iter_valid_loss : 0.11256876587867737\n",
      "\n",
      "     51000\t  0.112672\t  0.112569\t  0.103685\t\tCURRENT LEARNING RATE: 0.29994769169059277\n",
      "previous_iter_valid_loss : 0.13623374700546265\n",
      "\n",
      "     51100\t  0.136528\t  0.136234\t  0.104086\t\tCURRENT LEARNING RATE: 0.2996478939227692\n",
      "previous_iter_valid_loss : 0.10943804681301117\n",
      "\n",
      "     51200\t  0.109553\t  0.109438\t  0.104198\t\tCURRENT LEARNING RATE: 0.2993483958028646\n",
      "previous_iter_valid_loss : 0.11923748254776001\n",
      "\n",
      "     51300\t  0.119584\t  0.119237\t  0.104423\t\tCURRENT LEARNING RATE: 0.29904919703138066\n",
      "previous_iter_valid_loss : 0.17700503766536713\n",
      "\n",
      "     51400\t  0.177016\t  0.177005\t  0.105112\t\tCURRENT LEARNING RATE: 0.29875029730911873\n",
      "previous_iter_valid_loss : 0.1630498319864273\n",
      "\n",
      "     51500\t  0.163381\t  0.163050\t  0.105524\t\tCURRENT LEARNING RATE: 0.298451696337179\n",
      "previous_iter_valid_loss : 0.1054920181632042\n",
      "\n",
      "     51600\t  0.105585\t  0.105492\t  0.105490\t\tCURRENT LEARNING RATE: 0.2981533938169605\n",
      "previous_iter_valid_loss : 0.10685461759567261\n",
      "\n",
      "     51700\t  0.106967\t  0.106855\t  0.105507\t\tCURRENT LEARNING RATE: 0.2978553894501606\n",
      "previous_iter_valid_loss : 0.11280091851949692\n",
      "\n",
      "     51800\t  0.112911\t  0.112801\t  0.105492\t\tCURRENT LEARNING RATE: 0.29755768293877505\n",
      "previous_iter_valid_loss : 0.10887020081281662\n",
      "\n",
      "     51900\t  0.108955\t  0.108870\t  0.105422\t\tCURRENT LEARNING RATE: 0.2972602739850972\n",
      "previous_iter_valid_loss : 0.10750147700309753\n",
      "\n",
      "     52000\t  0.107686\t  0.107501\t  0.105558\t\tCURRENT LEARNING RATE: 0.29696316229171804\n",
      "previous_iter_valid_loss : 0.09177859872579575\n",
      "\n",
      "     52100\t  0.091870\t  0.091779\t  0.105596\t\tCURRENT LEARNING RATE: 0.296666347561526\n",
      "previous_iter_valid_loss : 0.10212303698062897\n",
      "\n",
      "     52200\t  0.102256\t  0.102123\t  0.105679\t\tCURRENT LEARNING RATE: 0.29636982949770624\n",
      "previous_iter_valid_loss : 0.11268626898527145\n",
      "\n",
      "     52300\t  0.112917\t  0.112686\t  0.105601\t\tCURRENT LEARNING RATE: 0.29607360780374065\n",
      "previous_iter_valid_loss : 0.10650499910116196\n",
      "\n",
      "     52400\t  0.106583\t  0.106505\t  0.105798\t\tCURRENT LEARNING RATE: 0.29577768218340755\n",
      "previous_iter_valid_loss : 0.09806253015995026\n",
      "\n",
      "     52500\t  0.098115\t  0.098063\t  0.105334\t\tCURRENT LEARNING RATE: 0.2954820523407813\n",
      "previous_iter_valid_loss : 0.10942843556404114\n",
      "\n",
      "     52600\t  0.109610\t  0.109428\t  0.105600\t\tCURRENT LEARNING RATE: 0.29518671798023194\n",
      "previous_iter_valid_loss : 0.09342773258686066\n",
      "\n",
      "     52700\t  0.093509\t  0.093428\t  0.105703\t\tCURRENT LEARNING RATE: 0.2948916788064252\n",
      "previous_iter_valid_loss : 0.11406415700912476\n",
      "\n",
      "     52800\t  0.114210\t  0.114064\t  0.105816\t\tCURRENT LEARNING RATE: 0.29459693452432184\n",
      "previous_iter_valid_loss : 0.11493764817714691\n",
      "\n",
      "     52900\t  0.115223\t  0.114938\t  0.106093\t\tCURRENT LEARNING RATE: 0.2943024848391776\n",
      "previous_iter_valid_loss : 0.11778444051742554\n",
      "\n",
      "     53000\t  0.117926\t  0.117784\t  0.106000\t\tCURRENT LEARNING RATE: 0.2940083294565427\n",
      "previous_iter_valid_loss : 0.10321055352687836\n",
      "\n",
      "     53100\t  0.103277\t  0.103211\t  0.105955\t\tCURRENT LEARNING RATE: 0.2937144680822617\n",
      "previous_iter_valid_loss : 0.09901183098554611\n",
      "\n",
      "     53200\t  0.099023\t  0.099012\t  0.105786\t\tCURRENT LEARNING RATE: 0.2934209004224733\n",
      "previous_iter_valid_loss : 0.10281557589769363\n",
      "\n",
      "     53300\t  0.102797\t  0.102816\t  0.105856\t\tCURRENT LEARNING RATE: 0.2931276261836098\n",
      "previous_iter_valid_loss : 0.13038143515586853\n",
      "\n",
      "     53400\t  0.130172\t  0.130381\t  0.106135\t\tCURRENT LEARNING RATE: 0.29283464507239687\n",
      "previous_iter_valid_loss : 0.11827082186937332\n",
      "\n",
      "     53500\t  0.118770\t  0.118271\t  0.106203\t\tCURRENT LEARNING RATE: 0.29254195679585343\n",
      "previous_iter_valid_loss : 0.18220871686935425\n",
      "\n",
      "     53600\t  0.182630\t  0.182209\t  0.107113\t\tCURRENT LEARNING RATE: 0.2922495610612912\n",
      "previous_iter_valid_loss : 0.12099520862102509\n",
      "\n",
      "     53700\t  0.121037\t  0.120995\t  0.107346\t\tCURRENT LEARNING RATE: 0.29195745757631436\n",
      "previous_iter_valid_loss : 0.16186833381652832\n",
      "\n",
      "     53800\t  0.162057\t  0.161868\t  0.107853\t\tCURRENT LEARNING RATE: 0.2916656460488194\n",
      "previous_iter_valid_loss : 0.11281844973564148\n",
      "\n",
      "     53900\t  0.112489\t  0.112818\t  0.107960\t\tCURRENT LEARNING RATE: 0.2913741261869948\n",
      "previous_iter_valid_loss : 0.08925281465053558\n",
      "\n",
      "     54000\t  0.089081\t  0.089253\t  0.107657\t\tCURRENT LEARNING RATE: 0.2910828976993207\n",
      "previous_iter_valid_loss : 0.09904725104570389\n",
      "\n",
      "     54100\t  0.098875\t  0.099047\t  0.107751\t\tCURRENT LEARNING RATE: 0.29079196029456855\n",
      "previous_iter_valid_loss : 0.12307108938694\n",
      "\n",
      "     54200\t  0.123139\t  0.123071\t  0.107911\t\tCURRENT LEARNING RATE: 0.29050131368180093\n",
      "previous_iter_valid_loss : 0.09091538190841675\n",
      "\n",
      "     54300\t  0.090877\t  0.090915\t  0.107922\t\tCURRENT LEARNING RATE: 0.2902109575703712\n",
      "previous_iter_valid_loss : 0.10796163976192474\n",
      "\n",
      "     54400\t  0.107831\t  0.107962\t  0.107660\t\tCURRENT LEARNING RATE: 0.2899208916699232\n",
      "previous_iter_valid_loss : 0.13220755755901337\n",
      "\n",
      "     54500\t  0.132264\t  0.132208\t  0.107832\t\tCURRENT LEARNING RATE: 0.289631115690391\n",
      "previous_iter_valid_loss : 0.14014531672000885\n",
      "\n",
      "     54600\t  0.140364\t  0.140145\t  0.108179\t\tCURRENT LEARNING RATE: 0.2893416293419987\n",
      "previous_iter_valid_loss : 0.12262271344661713\n",
      "\n",
      "     54700\t  0.122912\t  0.122623\t  0.108574\t\tCURRENT LEARNING RATE: 0.2890524323352598\n",
      "previous_iter_valid_loss : 0.19311222434043884\n",
      "\n",
      "     54800\t  0.193440\t  0.193112\t  0.109588\t\tCURRENT LEARNING RATE: 0.28876352438097735\n",
      "previous_iter_valid_loss : 0.12302795052528381\n",
      "\n",
      "     54900\t  0.123088\t  0.123028\t  0.109621\t\tCURRENT LEARNING RATE: 0.2884749051902433\n",
      "previous_iter_valid_loss : 0.1626885086297989\n",
      "\n",
      "     55000\t  0.162899\t  0.162689\t  0.110283\t\tCURRENT LEARNING RATE: 0.2881865744744386\n",
      "previous_iter_valid_loss : 0.15247370302677155\n",
      "\n",
      "     55100\t  0.152483\t  0.152474\t  0.110980\t\tCURRENT LEARNING RATE: 0.28789853194523224\n",
      "previous_iter_valid_loss : 0.11988821625709534\n",
      "\n",
      "     55200\t  0.120014\t  0.119888\t  0.110980\t\tCURRENT LEARNING RATE: 0.2876107773145819\n",
      "previous_iter_valid_loss : 0.1693728119134903\n",
      "\n",
      "     55300\t  0.169715\t  0.169373\t  0.111653\t\tCURRENT LEARNING RATE: 0.28732331029473285\n",
      "previous_iter_valid_loss : 0.12071296572685242\n",
      "\n",
      "     55400\t  0.120863\t  0.120713\t  0.111904\t\tCURRENT LEARNING RATE: 0.287036130598218\n",
      "previous_iter_valid_loss : 0.10393699258565903\n",
      "\n",
      "     55500\t  0.103949\t  0.103937\t  0.111989\t\tCURRENT LEARNING RATE: 0.28674923793785767\n",
      "previous_iter_valid_loss : 0.09465103596448898\n",
      "\n",
      "     55600\t  0.094487\t  0.094651\t  0.111857\t\tCURRENT LEARNING RATE: 0.2864626320267592\n",
      "previous_iter_valid_loss : 0.10933075845241547\n",
      "\n",
      "     55700\t  0.109061\t  0.109331\t  0.112072\t\tCURRENT LEARNING RATE: 0.2861763125783166\n",
      "previous_iter_valid_loss : 0.11855850368738174\n",
      "\n",
      "     55800\t  0.118771\t  0.118559\t  0.112213\t\tCURRENT LEARNING RATE: 0.28589027930621047\n",
      "previous_iter_valid_loss : 0.11647379398345947\n",
      "\n",
      "     55900\t  0.116554\t  0.116474\t  0.112354\t\tCURRENT LEARNING RATE: 0.28560453192440743\n",
      "previous_iter_valid_loss : 0.12088998407125473\n",
      "\n",
      "     56000\t  0.120869\t  0.120890\t  0.112411\t\tCURRENT LEARNING RATE: 0.2853190701471601\n",
      "previous_iter_valid_loss : 0.11537837982177734\n",
      "\n",
      "     56100\t  0.115367\t  0.115378\t  0.112724\t\tCURRENT LEARNING RATE: 0.2850338936890067\n",
      "previous_iter_valid_loss : 0.10167977213859558\n",
      "\n",
      "     56200\t  0.101646\t  0.101680\t  0.112938\t\tCURRENT LEARNING RATE: 0.28474900226477085\n",
      "previous_iter_valid_loss : 0.18188993632793427\n",
      "\n",
      "     56300\t  0.181737\t  0.181890\t  0.113240\t\tCURRENT LEARNING RATE: 0.2844643955895609\n",
      "previous_iter_valid_loss : 0.12599842250347137\n",
      "\n",
      "     56400\t  0.126130\t  0.125998\t  0.113319\t\tCURRENT LEARNING RATE: 0.28418007337877027\n",
      "previous_iter_valid_loss : 0.17090550065040588\n",
      "\n",
      "     56500\t  0.171347\t  0.170906\t  0.113624\t\tCURRENT LEARNING RATE: 0.28389603534807667\n",
      "previous_iter_valid_loss : 0.1788066178560257\n",
      "\n",
      "     56600\t  0.179319\t  0.178807\t  0.114250\t\tCURRENT LEARNING RATE: 0.28361228121344206\n",
      "previous_iter_valid_loss : 0.1563185155391693\n",
      "\n",
      "     56700\t  0.155978\t  0.156319\t  0.114863\t\tCURRENT LEARNING RATE: 0.2833288106911123\n",
      "previous_iter_valid_loss : 0.17112518846988678\n",
      "\n",
      "     56800\t  0.170830\t  0.171125\t  0.115653\t\tCURRENT LEARNING RATE: 0.2830456234976169\n",
      "previous_iter_valid_loss : 0.14165790379047394\n",
      "\n",
      "     56900\t  0.141907\t  0.141658\t  0.115908\t\tCURRENT LEARNING RATE: 0.28276271934976854\n",
      "previous_iter_valid_loss : 0.12230861186981201\n",
      "\n",
      "     57000\t  0.122518\t  0.122309\t  0.116081\t\tCURRENT LEARNING RATE: 0.2824800979646631\n",
      "previous_iter_valid_loss : 0.17444531619548798\n",
      "\n",
      "     57100\t  0.174878\t  0.174445\t  0.116535\t\tCURRENT LEARNING RATE: 0.2821977590596792\n",
      "previous_iter_valid_loss : 0.13725855946540833\n",
      "\n",
      "     57200\t  0.137899\t  0.137259\t  0.117051\t\tCURRENT LEARNING RATE: 0.28191570235247787\n",
      "previous_iter_valid_loss : 0.13806405663490295\n",
      "\n",
      "     57300\t  0.138735\t  0.138064\t  0.117378\t\tCURRENT LEARNING RATE: 0.28163392756100236\n",
      "previous_iter_valid_loss : 0.10636543482542038\n",
      "\n",
      "     57400\t  0.106680\t  0.106365\t  0.117417\t\tCURRENT LEARNING RATE: 0.28135243440347785\n",
      "previous_iter_valid_loss : 0.13004432618618011\n",
      "\n",
      "     57500\t  0.130102\t  0.130044\t  0.117808\t\tCURRENT LEARNING RATE: 0.2810712225984112\n",
      "previous_iter_valid_loss : 0.146540567278862\n",
      "\n",
      "     57600\t  0.146623\t  0.146541\t  0.118378\t\tCURRENT LEARNING RATE: 0.28079029186459065\n",
      "previous_iter_valid_loss : 0.12720635533332825\n",
      "\n",
      "     57700\t  0.127308\t  0.127206\t  0.118750\t\tCURRENT LEARNING RATE: 0.2805096419210853\n",
      "previous_iter_valid_loss : 0.14505714178085327\n",
      "\n",
      "     57800\t  0.145024\t  0.145057\t  0.119216\t\tCURRENT LEARNING RATE: 0.2802292724872452\n",
      "previous_iter_valid_loss : 0.11979607492685318\n",
      "\n",
      "     57900\t  0.120275\t  0.119796\t  0.119061\t\tCURRENT LEARNING RATE: 0.279949183282701\n",
      "previous_iter_valid_loss : 0.13891002535820007\n",
      "\n",
      "     58000\t  0.139341\t  0.138910\t  0.119455\t\tCURRENT LEARNING RATE: 0.2796693740273634\n",
      "previous_iter_valid_loss : 0.10903854668140411\n",
      "\n",
      "     58100\t  0.109709\t  0.109039\t  0.119261\t\tCURRENT LEARNING RATE: 0.2793898444414232\n",
      "previous_iter_valid_loss : 0.12832848727703094\n",
      "\n",
      "     58200\t  0.128212\t  0.128328\t  0.119542\t\tCURRENT LEARNING RATE: 0.2791105942453506\n",
      "previous_iter_valid_loss : 0.10447899997234344\n",
      "\n",
      "     58300\t  0.104619\t  0.104479\t  0.119706\t\tCURRENT LEARNING RATE: 0.2788316231598956\n",
      "previous_iter_valid_loss : 0.1206066831946373\n",
      "\n",
      "     58400\t  0.120818\t  0.120607\t  0.119995\t\tCURRENT LEARNING RATE: 0.27855293090608696\n",
      "previous_iter_valid_loss : 0.12711161375045776\n",
      "\n",
      "     58500\t  0.127142\t  0.127112\t  0.120272\t\tCURRENT LEARNING RATE: 0.27827451720523244\n",
      "previous_iter_valid_loss : 0.11030193418264389\n",
      "\n",
      "     58600\t  0.110200\t  0.110302\t  0.120532\t\tCURRENT LEARNING RATE: 0.27799638177891833\n",
      "previous_iter_valid_loss : 0.13890309631824493\n",
      "\n",
      "     58700\t  0.139552\t  0.138903\t  0.121060\t\tCURRENT LEARNING RATE: 0.2777185243490091\n",
      "previous_iter_valid_loss : 0.11186394095420837\n",
      "\n",
      "     58800\t  0.112024\t  0.111864\t  0.121217\t\tCURRENT LEARNING RATE: 0.27744094463764746\n",
      "previous_iter_valid_loss : 0.11020328104496002\n",
      "\n",
      "     58900\t  0.110342\t  0.110203\t  0.121280\t\tCURRENT LEARNING RATE: 0.27716364236725355\n",
      "previous_iter_valid_loss : 0.17828160524368286\n",
      "\n",
      "     59000\t  0.178320\t  0.178282\t  0.122085\t\tCURRENT LEARNING RATE: 0.27688661726052505\n",
      "previous_iter_valid_loss : 0.11434690654277802\n",
      "\n",
      "     59100\t  0.114560\t  0.114347\t  0.122347\t\tCURRENT LEARNING RATE: 0.27660986904043694\n",
      "previous_iter_valid_loss : 0.13470883667469025\n",
      "\n",
      "     59200\t  0.134742\t  0.134709\t  0.122722\t\tCURRENT LEARNING RATE: 0.2763333974302409\n",
      "previous_iter_valid_loss : 0.10810084640979767\n",
      "\n",
      "     59300\t  0.108529\t  0.108101\t  0.122957\t\tCURRENT LEARNING RATE: 0.2760572021534653\n",
      "previous_iter_valid_loss : 0.20177243649959564\n",
      "\n",
      "     59400\t  0.202224\t  0.201772\t  0.123313\t\tCURRENT LEARNING RATE: 0.2757812829339149\n",
      "previous_iter_valid_loss : 0.11136766523122787\n",
      "\n",
      "     59500\t  0.111277\t  0.111368\t  0.123414\t\tCURRENT LEARNING RATE: 0.27550563949567036\n",
      "previous_iter_valid_loss : 0.10481578856706619\n",
      "\n",
      "     59600\t  0.104886\t  0.104816\t  0.123589\t\tCURRENT LEARNING RATE: 0.2752302715630883\n",
      "previous_iter_valid_loss : 0.12897683680057526\n",
      "\n",
      "     59700\t  0.129414\t  0.128977\t  0.123597\t\tCURRENT LEARNING RATE: 0.2749551788608008\n",
      "previous_iter_valid_loss : 0.10734729468822479\n",
      "\n",
      "     59800\t  0.107582\t  0.107347\t  0.123616\t\tCURRENT LEARNING RATE: 0.274680361113715\n",
      "previous_iter_valid_loss : 0.13165660202503204\n",
      "\n",
      "     59900\t  0.131784\t  0.131657\t  0.123739\t\tCURRENT LEARNING RATE: 0.2744058180470132\n",
      "previous_iter_valid_loss : 0.10997194051742554\n",
      "\n",
      "     60000\t  0.109994\t  0.109972\t  0.123773\t\tCURRENT LEARNING RATE: 0.27413154938615236\n",
      "previous_iter_valid_loss : 0.10331501066684723\n",
      "\n",
      "     60100\t  0.103216\t  0.103315\t  0.123782\t\tCURRENT LEARNING RATE: 0.27385755485686375\n",
      "previous_iter_valid_loss : 0.16316920518875122\n",
      "\n",
      "     60200\t  0.163154\t  0.163169\t  0.124465\t\tCURRENT LEARNING RATE: 0.27358383418515275\n",
      "previous_iter_valid_loss : 0.1228930801153183\n",
      "\n",
      "     60300\t  0.122851\t  0.122893\t  0.124806\t\tCURRENT LEARNING RATE: 0.2733103870972988\n",
      "previous_iter_valid_loss : 0.09867504984140396\n",
      "\n",
      "     60400\t  0.098859\t  0.098675\t  0.124867\t\tCURRENT LEARNING RATE: 0.2730372133198547\n",
      "previous_iter_valid_loss : 0.10625994950532913\n",
      "\n",
      "     60500\t  0.106108\t  0.106260\t  0.124976\t\tCURRENT LEARNING RATE: 0.2727643125796467\n",
      "previous_iter_valid_loss : 0.16107046604156494\n",
      "\n",
      "     60600\t  0.160932\t  0.161070\t  0.125704\t\tCURRENT LEARNING RATE: 0.272491684603774\n",
      "previous_iter_valid_loss : 0.12148407101631165\n",
      "\n",
      "     60700\t  0.121673\t  0.121484\t  0.125921\t\tCURRENT LEARNING RATE: 0.27221932911960856\n",
      "previous_iter_valid_loss : 0.1260213851928711\n",
      "\n",
      "     60800\t  0.126314\t  0.126021\t  0.126262\t\tCURRENT LEARNING RATE: 0.27194724585479496\n",
      "previous_iter_valid_loss : 0.16988913714885712\n",
      "\n",
      "     60900\t  0.170044\t  0.169889\t  0.126565\t\tCURRENT LEARNING RATE: 0.2716754345372499\n",
      "previous_iter_valid_loss : 0.13386930525302887\n",
      "\n",
      "     61000\t  0.133765\t  0.133869\t  0.126778\t\tCURRENT LEARNING RATE: 0.271403894895162\n",
      "previous_iter_valid_loss : 0.13192781805992126\n",
      "\n",
      "     61100\t  0.131917\t  0.131928\t  0.126735\t\tCURRENT LEARNING RATE: 0.2711326266569916\n",
      "previous_iter_valid_loss : 0.11195313930511475\n",
      "\n",
      "     61200\t  0.111833\t  0.111953\t  0.126760\t\tCURRENT LEARNING RATE: 0.2708616295514705\n",
      "previous_iter_valid_loss : 0.12064829468727112\n",
      "\n",
      "     61300\t  0.120780\t  0.120648\t  0.126774\t\tCURRENT LEARNING RATE: 0.27059090330760144\n",
      "previous_iter_valid_loss : 0.12487748265266418\n",
      "\n",
      "     61400\t  0.125048\t  0.124877\t  0.126253\t\tCURRENT LEARNING RATE: 0.2703204476546583\n",
      "previous_iter_valid_loss : 0.13628555834293365\n",
      "\n",
      "     61500\t  0.137036\t  0.136286\t  0.125985\t\tCURRENT LEARNING RATE: 0.2700502623221853\n",
      "previous_iter_valid_loss : 0.1191275343298912\n",
      "\n",
      "     61600\t  0.119206\t  0.119128\t  0.126121\t\tCURRENT LEARNING RATE: 0.26978034703999715\n",
      "previous_iter_valid_loss : 0.1091669499874115\n",
      "\n",
      "     61700\t  0.109246\t  0.109167\t  0.126145\t\tCURRENT LEARNING RATE: 0.2695107015381785\n",
      "previous_iter_valid_loss : 0.11874358355998993\n",
      "\n",
      "     61800\t  0.118747\t  0.118744\t  0.126204\t\tCURRENT LEARNING RATE: 0.2692413255470839\n",
      "previous_iter_valid_loss : 0.1426088809967041\n",
      "\n",
      "     61900\t  0.143080\t  0.142609\t  0.126541\t\tCURRENT LEARNING RATE: 0.26897221879733724\n",
      "previous_iter_valid_loss : 0.1181892678141594\n",
      "\n",
      "     62000\t  0.118146\t  0.118189\t  0.126648\t\tCURRENT LEARNING RATE: 0.2687033810198318\n",
      "previous_iter_valid_loss : 0.10027223080396652\n",
      "\n",
      "     62100\t  0.100197\t  0.100272\t  0.126733\t\tCURRENT LEARNING RATE: 0.26843481194572977\n",
      "previous_iter_valid_loss : 0.11283345520496368\n",
      "\n",
      "     62200\t  0.113319\t  0.112833\t  0.126840\t\tCURRENT LEARNING RATE: 0.2681665113064621\n",
      "previous_iter_valid_loss : 0.1157369613647461\n",
      "\n",
      "     62300\t  0.116063\t  0.115737\t  0.126871\t\tCURRENT LEARNING RATE: 0.267898478833728\n",
      "previous_iter_valid_loss : 0.13161981105804443\n",
      "\n",
      "     62400\t  0.132203\t  0.131620\t  0.127122\t\tCURRENT LEARNING RATE: 0.26763071425949514\n",
      "previous_iter_valid_loss : 0.1195092648267746\n",
      "\n",
      "     62500\t  0.119946\t  0.119509\t  0.127336\t\tCURRENT LEARNING RATE: 0.26736321731599877\n",
      "previous_iter_valid_loss : 0.11824768036603928\n",
      "\n",
      "     62600\t  0.118438\t  0.118248\t  0.127425\t\tCURRENT LEARNING RATE: 0.26709598773574206\n",
      "previous_iter_valid_loss : 0.11300834268331528\n",
      "\n",
      "     62700\t  0.113301\t  0.113008\t  0.127620\t\tCURRENT LEARNING RATE: 0.2668290252514953\n",
      "previous_iter_valid_loss : 0.12897446751594543\n",
      "\n",
      "     62800\t  0.129514\t  0.128974\t  0.127770\t\tCURRENT LEARNING RATE: 0.26656232959629605\n",
      "previous_iter_valid_loss : 0.11350899189710617\n",
      "\n",
      "     62900\t  0.113522\t  0.113509\t  0.127755\t\tCURRENT LEARNING RATE: 0.2662959005034486\n",
      "previous_iter_valid_loss : 0.15037015080451965\n",
      "\n",
      "     63000\t  0.150386\t  0.150370\t  0.128081\t\tCURRENT LEARNING RATE: 0.26602973770652383\n",
      "previous_iter_valid_loss : 0.12253891676664352\n",
      "\n",
      "     63100\t  0.122886\t  0.122539\t  0.128274\t\tCURRENT LEARNING RATE: 0.26576384093935895\n",
      "previous_iter_valid_loss : 0.12683610618114471\n",
      "\n",
      "     63200\t  0.127337\t  0.126836\t  0.128553\t\tCURRENT LEARNING RATE: 0.26549820993605716\n",
      "previous_iter_valid_loss : 0.15977224707603455\n",
      "\n",
      "     63300\t  0.160206\t  0.159772\t  0.129122\t\tCURRENT LEARNING RATE: 0.26523284443098744\n",
      "previous_iter_valid_loss : 0.131491556763649\n",
      "\n",
      "     63400\t  0.131664\t  0.131492\t  0.129133\t\tCURRENT LEARNING RATE: 0.26496774415878427\n",
      "previous_iter_valid_loss : 0.12492664903402328\n",
      "\n",
      "     63500\t  0.124905\t  0.124927\t  0.129200\t\tCURRENT LEARNING RATE: 0.2647029088543473\n",
      "previous_iter_valid_loss : 0.14268627762794495\n",
      "\n",
      "     63600\t  0.142669\t  0.142686\t  0.128805\t\tCURRENT LEARNING RATE: 0.26443833825284124\n",
      "previous_iter_valid_loss : 0.1352114975452423\n",
      "\n",
      "     63700\t  0.135614\t  0.135211\t  0.128947\t\tCURRENT LEARNING RATE: 0.2641740320896955\n",
      "previous_iter_valid_loss : 0.21039354801177979\n",
      "\n",
      "     63800\t  0.211089\t  0.210394\t  0.129432\t\tCURRENT LEARNING RATE: 0.26390999010060384\n",
      "previous_iter_valid_loss : 0.1643722802400589\n",
      "\n",
      "     63900\t  0.165202\t  0.164372\t  0.129948\t\tCURRENT LEARNING RATE: 0.2636462120215243\n",
      "previous_iter_valid_loss : 0.15185411274433136\n",
      "\n",
      "     64000\t  0.152137\t  0.151854\t  0.130574\t\tCURRENT LEARNING RATE: 0.2633826975886787\n",
      "previous_iter_valid_loss : 0.17420731484889984\n",
      "\n",
      "     64100\t  0.175136\t  0.174207\t  0.131325\t\tCURRENT LEARNING RATE: 0.2631194465385527\n",
      "previous_iter_valid_loss : 0.21076065301895142\n",
      "\n",
      "     64200\t  0.210984\t  0.210761\t  0.132202\t\tCURRENT LEARNING RATE: 0.26285645860789514\n",
      "previous_iter_valid_loss : 0.13754276931285858\n",
      "\n",
      "     64300\t  0.137686\t  0.137543\t  0.132668\t\tCURRENT LEARNING RATE: 0.26259373353371807\n",
      "previous_iter_valid_loss : 0.1699838787317276\n",
      "\n",
      "     64400\t  0.169599\t  0.169984\t  0.133289\t\tCURRENT LEARNING RATE: 0.26233127105329646\n",
      "previous_iter_valid_loss : 0.19909945130348206\n",
      "\n",
      "     64500\t  0.200419\t  0.199099\t  0.133958\t\tCURRENT LEARNING RATE: 0.2620690709041677\n",
      "previous_iter_valid_loss : 0.2815985083580017\n",
      "\n",
      "     64600\t  0.281338\t  0.281599\t  0.135372\t\tCURRENT LEARNING RATE: 0.26180713282413176\n",
      "previous_iter_valid_loss : 0.22585910558700562\n",
      "\n",
      "     64700\t  0.226733\t  0.225859\t  0.136404\t\tCURRENT LEARNING RATE: 0.2615454565512504\n",
      "previous_iter_valid_loss : 0.1548367440700531\n",
      "\n",
      "     64800\t  0.155420\t  0.154837\t  0.136022\t\tCURRENT LEARNING RATE: 0.2612840418238474\n",
      "previous_iter_valid_loss : 0.1570092886686325\n",
      "\n",
      "     64900\t  0.157373\t  0.157009\t  0.136362\t\tCURRENT LEARNING RATE: 0.261022888380508\n",
      "previous_iter_valid_loss : 0.2641580104827881\n",
      "\n",
      "     65000\t  0.264574\t  0.264158\t  0.137376\t\tCURRENT LEARNING RATE: 0.26076199596007876\n",
      "previous_iter_valid_loss : 0.17756257951259613\n",
      "\n",
      "     65100\t  0.178438\t  0.177563\t  0.137627\t\tCURRENT LEARNING RATE: 0.2605013643016672\n",
      "previous_iter_valid_loss : 0.14561371505260468\n",
      "\n",
      "     65200\t  0.145660\t  0.145614\t  0.137884\t\tCURRENT LEARNING RATE: 0.2602409931446416\n",
      "previous_iter_valid_loss : 0.14027155935764313\n",
      "\n",
      "     65300\t  0.140050\t  0.140272\t  0.137593\t\tCURRENT LEARNING RATE: 0.2599808822286309\n",
      "previous_iter_valid_loss : 0.24470125138759613\n",
      "\n",
      "     65400\t  0.245704\t  0.244701\t  0.138833\t\tCURRENT LEARNING RATE: 0.2597210312935241\n",
      "previous_iter_valid_loss : 0.17199598252773285\n",
      "\n",
      "     65500\t  0.173320\t  0.171996\t  0.139514\t\tCURRENT LEARNING RATE: 0.2594614400794702\n",
      "previous_iter_valid_loss : 0.3931347727775574\n",
      "\n",
      "     65600\t  0.395755\t  0.393135\t  0.142499\t\tCURRENT LEARNING RATE: 0.25920210832687796\n",
      "previous_iter_valid_loss : 0.23000994324684143\n",
      "\n",
      "     65700\t  0.231151\t  0.230010\t  0.143705\t\tCURRENT LEARNING RATE: 0.2589430357764157\n",
      "previous_iter_valid_loss : 0.15258292853832245\n",
      "\n",
      "     65800\t  0.153885\t  0.152583\t  0.144046\t\tCURRENT LEARNING RATE: 0.2586842221690108\n",
      "previous_iter_valid_loss : 0.19850397109985352\n",
      "\n",
      "     65900\t  0.200287\t  0.198504\t  0.144866\t\tCURRENT LEARNING RATE: 0.2584256672458496\n",
      "previous_iter_valid_loss : 0.1833125501871109\n",
      "\n",
      "     66000\t  0.184106\t  0.183313\t  0.145490\t\tCURRENT LEARNING RATE: 0.2581673707483772\n",
      "previous_iter_valid_loss : 0.16471922397613525\n",
      "\n",
      "     66100\t  0.166796\t  0.164719\t  0.145984\t\tCURRENT LEARNING RATE: 0.25790933241829705\n",
      "previous_iter_valid_loss : 0.14622652530670166\n",
      "\n",
      "     66200\t  0.146196\t  0.146227\t  0.146429\t\tCURRENT LEARNING RATE: 0.25765155199757084\n",
      "previous_iter_valid_loss : 0.18849141895771027\n",
      "\n",
      "     66300\t  0.188692\t  0.188491\t  0.146495\t\tCURRENT LEARNING RATE: 0.2573940292284181\n",
      "previous_iter_valid_loss : 0.14969748258590698\n",
      "\n",
      "     66400\t  0.148875\t  0.149697\t  0.146732\t\tCURRENT LEARNING RATE: 0.25713676385331596\n",
      "previous_iter_valid_loss : 0.14953848719596863\n",
      "\n",
      "     66500\t  0.150268\t  0.149538\t  0.146518\t\tCURRENT LEARNING RATE: 0.25687975561499915\n",
      "previous_iter_valid_loss : 0.1737443059682846\n",
      "\n",
      "     66600\t  0.174821\t  0.173744\t  0.146468\t\tCURRENT LEARNING RATE: 0.2566230042564594\n",
      "previous_iter_valid_loss : 0.16320131719112396\n",
      "\n",
      "     66700\t  0.163400\t  0.163201\t  0.146537\t\tCURRENT LEARNING RATE: 0.25636650952094525\n",
      "previous_iter_valid_loss : 0.1737571805715561\n",
      "\n",
      "     66800\t  0.173513\t  0.173757\t  0.146563\t\tCURRENT LEARNING RATE: 0.256110271151962\n",
      "previous_iter_valid_loss : 0.16561654210090637\n",
      "\n",
      "     66900\t  0.166789\t  0.165617\t  0.146802\t\tCURRENT LEARNING RATE: 0.2558542888932712\n",
      "previous_iter_valid_loss : 0.20274831354618073\n",
      "\n",
      "     67000\t  0.204298\t  0.202748\t  0.147607\t\tCURRENT LEARNING RATE: 0.2555985624888907\n",
      "previous_iter_valid_loss : 0.12830857932567596\n",
      "\n",
      "     67100\t  0.129352\t  0.128309\t  0.147146\t\tCURRENT LEARNING RATE: 0.25534309168309394\n",
      "previous_iter_valid_loss : 0.23126216232776642\n",
      "\n",
      "     67200\t  0.232590\t  0.231262\t  0.148086\t\tCURRENT LEARNING RATE: 0.2550878762204101\n",
      "previous_iter_valid_loss : 0.14158058166503906\n",
      "\n",
      "     67300\t  0.141592\t  0.141581\t  0.148121\t\tCURRENT LEARNING RATE: 0.2548329158456238\n",
      "previous_iter_valid_loss : 0.14319251477718353\n",
      "\n",
      "     67400\t  0.143825\t  0.143193\t  0.148489\t\tCURRENT LEARNING RATE: 0.2545782103037746\n",
      "previous_iter_valid_loss : 0.10660335421562195\n",
      "\n",
      "     67500\t  0.106616\t  0.106603\t  0.148255\t\tCURRENT LEARNING RATE: 0.25432375934015683\n",
      "previous_iter_valid_loss : 0.2180967777967453\n",
      "\n",
      "     67600\t  0.219832\t  0.218097\t  0.148970\t\tCURRENT LEARNING RATE: 0.25406956270031966\n",
      "previous_iter_valid_loss : 0.1260339468717575\n",
      "\n",
      "     67700\t  0.125720\t  0.126034\t  0.148958\t\tCURRENT LEARNING RATE: 0.25381562013006637\n",
      "previous_iter_valid_loss : 0.16563677787780762\n",
      "\n",
      "     67800\t  0.165604\t  0.165637\t  0.149164\t\tCURRENT LEARNING RATE: 0.2535619313754543\n",
      "previous_iter_valid_loss : 0.1400383561849594\n",
      "\n",
      "     67900\t  0.141183\t  0.140038\t  0.149367\t\tCURRENT LEARNING RATE: 0.2533084961827948\n",
      "previous_iter_valid_loss : 0.18033145368099213\n",
      "\n",
      "     68000\t  0.180393\t  0.180331\t  0.149781\t\tCURRENT LEARNING RATE: 0.2530553142986526\n",
      "previous_iter_valid_loss : 0.230265274643898\n",
      "\n",
      "     68100\t  0.231369\t  0.230265\t  0.150993\t\tCURRENT LEARNING RATE: 0.25280238546984574\n",
      "previous_iter_valid_loss : 0.1579490303993225\n",
      "\n",
      "     68200\t  0.157678\t  0.157949\t  0.151289\t\tCURRENT LEARNING RATE: 0.2525497094434454\n",
      "previous_iter_valid_loss : 0.1579264998435974\n",
      "\n",
      "     68300\t  0.158234\t  0.157926\t  0.151824\t\tCURRENT LEARNING RATE: 0.2522972859667756\n",
      "previous_iter_valid_loss : 0.1947307139635086\n",
      "\n",
      "     68400\t  0.196204\t  0.194731\t  0.152565\t\tCURRENT LEARNING RATE: 0.25204511478741276\n",
      "previous_iter_valid_loss : 0.11117365211248398\n",
      "\n",
      "     68500\t  0.111233\t  0.111174\t  0.152406\t\tCURRENT LEARNING RATE: 0.2517931956531857\n",
      "previous_iter_valid_loss : 0.11432934552431107\n",
      "\n",
      "     68600\t  0.114885\t  0.114329\t  0.152446\t\tCURRENT LEARNING RATE: 0.2515415283121753\n",
      "previous_iter_valid_loss : 0.143791064620018\n",
      "\n",
      "     68700\t  0.144541\t  0.143791\t  0.152495\t\tCURRENT LEARNING RATE: 0.2512901125127142\n",
      "previous_iter_valid_loss : 0.1325177103281021\n",
      "\n",
      "     68800\t  0.133540\t  0.132518\t  0.152701\t\tCURRENT LEARNING RATE: 0.25103894800338655\n",
      "previous_iter_valid_loss : 0.17392121255397797\n",
      "\n",
      "     68900\t  0.174665\t  0.173921\t  0.153338\t\tCURRENT LEARNING RATE: 0.2507880345330278\n",
      "previous_iter_valid_loss : 0.1708492487668991\n",
      "\n",
      "     69000\t  0.171671\t  0.170849\t  0.153264\t\tCURRENT LEARNING RATE: 0.25053737185072444\n",
      "previous_iter_valid_loss : 0.18430186808109283\n",
      "\n",
      "     69100\t  0.185249\t  0.184302\t  0.153964\t\tCURRENT LEARNING RATE: 0.2502869597058139\n",
      "previous_iter_valid_loss : 0.1527101993560791\n",
      "\n",
      "     69200\t  0.153970\t  0.152710\t  0.154144\t\tCURRENT LEARNING RATE: 0.25003679784788385\n",
      "previous_iter_valid_loss : 0.11383169889450073\n",
      "\n",
      "     69300\t  0.114181\t  0.113832\t  0.154201\t\tCURRENT LEARNING RATE: 0.2497868860267725\n",
      "previous_iter_valid_loss : 0.1832360327243805\n",
      "\n",
      "     69400\t  0.184946\t  0.183236\t  0.154016\t\tCURRENT LEARNING RATE: 0.249537223992568\n",
      "previous_iter_valid_loss : 0.14634771645069122\n",
      "\n",
      "     69500\t  0.147518\t  0.146348\t  0.154365\t\tCURRENT LEARNING RATE: 0.24928781149560827\n",
      "previous_iter_valid_loss : 0.12458407878875732\n",
      "\n",
      "     69600\t  0.124817\t  0.124584\t  0.154563\t\tCURRENT LEARNING RATE: 0.24903864828648084\n",
      "previous_iter_valid_loss : 0.17584888637065887\n",
      "\n",
      "     69700\t  0.177056\t  0.175849\t  0.155032\t\tCURRENT LEARNING RATE: 0.24878973411602243\n",
      "previous_iter_valid_loss : 0.3162616193294525\n",
      "\n",
      "     69800\t  0.316125\t  0.316262\t  0.157121\t\tCURRENT LEARNING RATE: 0.24854106873531887\n",
      "previous_iter_valid_loss : 0.19096234440803528\n",
      "\n",
      "     69900\t  0.191482\t  0.190962\t  0.157714\t\tCURRENT LEARNING RATE: 0.24829265189570476\n",
      "previous_iter_valid_loss : 0.14739057421684265\n",
      "\n",
      "     70000\t  0.148357\t  0.147391\t  0.158088\t\tCURRENT LEARNING RATE: 0.24804448334876325\n",
      "previous_iter_valid_loss : 0.25150924921035767\n",
      "\n",
      "     70100\t  0.251829\t  0.251509\t  0.159570\t\tCURRENT LEARNING RATE: 0.24779656284632573\n",
      "previous_iter_valid_loss : 0.1606667935848236\n",
      "\n",
      "     70200\t  0.160379\t  0.160667\t  0.159545\t\tCURRENT LEARNING RATE: 0.24754889014047174\n",
      "previous_iter_valid_loss : 0.2633017599582672\n",
      "\n",
      "     70300\t  0.264558\t  0.263302\t  0.160949\t\tCURRENT LEARNING RATE: 0.2473014649835285\n",
      "previous_iter_valid_loss : 0.20193904638290405\n",
      "\n",
      "     70400\t  0.202453\t  0.201939\t  0.161982\t\tCURRENT LEARNING RATE: 0.24705428712807084\n",
      "previous_iter_valid_loss : 0.16568714380264282\n",
      "\n",
      "     70500\t  0.165767\t  0.165687\t  0.162576\t\tCURRENT LEARNING RATE: 0.2468073563269209\n",
      "previous_iter_valid_loss : 0.1673429161310196\n",
      "\n",
      "     70600\t  0.167486\t  0.167343\t  0.162639\t\tCURRENT LEARNING RATE: 0.24656067233314788\n",
      "previous_iter_valid_loss : 0.22277261316776276\n",
      "\n",
      "     70700\t  0.223604\t  0.222773\t  0.163652\t\tCURRENT LEARNING RATE: 0.24631423490006774\n",
      "previous_iter_valid_loss : 0.19772343337535858\n",
      "\n",
      "     70800\t  0.199333\t  0.197723\t  0.164369\t\tCURRENT LEARNING RATE: 0.246068043781243\n",
      "previous_iter_valid_loss : 0.19225506484508514\n",
      "\n",
      "     70900\t  0.192349\t  0.192255\t  0.164592\t\tCURRENT LEARNING RATE: 0.24582209873048255\n",
      "previous_iter_valid_loss : 0.222642719745636\n",
      "\n",
      "     71000\t  0.223047\t  0.222643\t  0.165480\t\tCURRENT LEARNING RATE: 0.24557639950184132\n",
      "previous_iter_valid_loss : 0.1955225020647049\n",
      "\n",
      "     71100\t  0.195999\t  0.195523\t  0.166116\t\tCURRENT LEARNING RATE: 0.24533094584962006\n",
      "previous_iter_valid_loss : 0.237925723195076\n",
      "\n",
      "     71200\t  0.238682\t  0.237926\t  0.167376\t\tCURRENT LEARNING RATE: 0.2450857375283651\n",
      "previous_iter_valid_loss : 0.2432265281677246\n",
      "\n",
      "     71300\t  0.245016\t  0.243227\t  0.168602\t\tCURRENT LEARNING RATE: 0.2448407742928681\n",
      "previous_iter_valid_loss : 0.22067496180534363\n",
      "\n",
      "     71400\t  0.221137\t  0.220675\t  0.169560\t\tCURRENT LEARNING RATE: 0.24459605589816577\n",
      "previous_iter_valid_loss : 0.3819999694824219\n",
      "\n",
      "     71500\t  0.384458\t  0.382000\t  0.172017\t\tCURRENT LEARNING RATE: 0.24435158209953975\n",
      "previous_iter_valid_loss : 0.1712937206029892\n",
      "\n",
      "     71600\t  0.171388\t  0.171294\t  0.172538\t\tCURRENT LEARNING RATE: 0.24410735265251615\n",
      "previous_iter_valid_loss : 0.3258943259716034\n",
      "\n",
      "     71700\t  0.326439\t  0.325894\t  0.174706\t\tCURRENT LEARNING RATE: 0.2438633673128656\n",
      "previous_iter_valid_loss : 0.17939144372940063\n",
      "\n",
      "     71800\t  0.179537\t  0.179391\t  0.175312\t\tCURRENT LEARNING RATE: 0.24361962583660263\n",
      "previous_iter_valid_loss : 0.4491672217845917\n",
      "\n",
      "     71900\t  0.449942\t  0.449167\t  0.178378\t\tCURRENT LEARNING RATE: 0.24337612797998584\n",
      "previous_iter_valid_loss : 0.4498920738697052\n",
      "\n",
      "     72000\t  0.452032\t  0.449892\t  0.181695\t\tCURRENT LEARNING RATE: 0.2431328734995173\n",
      "previous_iter_valid_loss : 0.18365763127803802\n",
      "\n",
      "     72100\t  0.184256\t  0.183658\t  0.182529\t\tCURRENT LEARNING RATE: 0.2428898621519425\n",
      "previous_iter_valid_loss : 0.20718948543071747\n",
      "\n",
      "     72200\t  0.207581\t  0.207189\t  0.183472\t\tCURRENT LEARNING RATE: 0.2426470936942501\n",
      "previous_iter_valid_loss : 0.3040449917316437\n",
      "\n",
      "     72300\t  0.305148\t  0.304045\t  0.185355\t\tCURRENT LEARNING RATE: 0.24240456788367162\n",
      "previous_iter_valid_loss : 0.29453906416893005\n",
      "\n",
      "     72400\t  0.296005\t  0.294539\t  0.186984\t\tCURRENT LEARNING RATE: 0.24216228447768123\n",
      "previous_iter_valid_loss : 0.22013446688652039\n",
      "\n",
      "     72500\t  0.220584\t  0.220134\t  0.187991\t\tCURRENT LEARNING RATE: 0.2419202432339955\n",
      "previous_iter_valid_loss : 0.2597969174385071\n",
      "\n",
      "     72600\t  0.259403\t  0.259797\t  0.189406\t\tCURRENT LEARNING RATE: 0.24167844391057317\n",
      "previous_iter_valid_loss : 0.39047351479530334\n",
      "\n",
      "     72700\t  0.391381\t  0.390474\t  0.192181\t\tCURRENT LEARNING RATE: 0.24143688626561488\n",
      "previous_iter_valid_loss : 0.29389917850494385\n",
      "\n",
      "     72800\t  0.294241\t  0.293899\t  0.193830\t\tCURRENT LEARNING RATE: 0.24119557005756295\n",
      "previous_iter_valid_loss : 0.2329312562942505\n",
      "\n",
      "     72900\t  0.232213\t  0.232931\t  0.195024\t\tCURRENT LEARNING RATE: 0.24095449504510122\n",
      "previous_iter_valid_loss : 0.19807922840118408\n",
      "\n",
      "     73000\t  0.198072\t  0.198079\t  0.195501\t\tCURRENT LEARNING RATE: 0.2407136609871546\n",
      "previous_iter_valid_loss : 0.28913065791130066\n",
      "\n",
      "     73100\t  0.289589\t  0.289131\t  0.197167\t\tCURRENT LEARNING RATE: 0.240473067642889\n",
      "previous_iter_valid_loss : 0.1878165900707245\n",
      "\n",
      "     73200\t  0.187890\t  0.187817\t  0.197777\t\tCURRENT LEARNING RATE: 0.24023271477171113\n",
      "previous_iter_valid_loss : 0.4289723038673401\n",
      "\n",
      "     73300\t  0.429527\t  0.428972\t  0.200469\t\tCURRENT LEARNING RATE: 0.239992602133268\n",
      "previous_iter_valid_loss : 0.23852483928203583\n",
      "\n",
      "     73400\t  0.239163\t  0.238525\t  0.201540\t\tCURRENT LEARNING RATE: 0.23975272948744705\n",
      "previous_iter_valid_loss : 0.2138507068157196\n",
      "\n",
      "     73500\t  0.214098\t  0.213851\t  0.202429\t\tCURRENT LEARNING RATE: 0.23951309659437556\n",
      "previous_iter_valid_loss : 0.2299024909734726\n",
      "\n",
      "     73600\t  0.230548\t  0.229902\t  0.203301\t\tCURRENT LEARNING RATE: 0.2392737032144206\n",
      "previous_iter_valid_loss : 0.3277130722999573\n",
      "\n",
      "     73700\t  0.328772\t  0.327713\t  0.205226\t\tCURRENT LEARNING RATE: 0.2390345491081888\n",
      "previous_iter_valid_loss : 0.3458576202392578\n",
      "\n",
      "     73800\t  0.345127\t  0.345858\t  0.206581\t\tCURRENT LEARNING RATE: 0.23879563403652604\n",
      "previous_iter_valid_loss : 0.2601795494556427\n",
      "\n",
      "     73900\t  0.260641\t  0.260180\t  0.207539\t\tCURRENT LEARNING RATE: 0.2385569577605172\n",
      "previous_iter_valid_loss : 0.23089106380939484\n",
      "\n",
      "     74000\t  0.231080\t  0.230891\t  0.208329\t\tCURRENT LEARNING RATE: 0.23831852004148601\n",
      "previous_iter_valid_loss : 0.4532659351825714\n",
      "\n",
      "     74100\t  0.454375\t  0.453266\t  0.211120\t\tCURRENT LEARNING RATE: 0.2380803206409947\n",
      "previous_iter_valid_loss : 0.19564040005207062\n",
      "\n",
      "     74200\t  0.195939\t  0.195640\t  0.210968\t\tCURRENT LEARNING RATE: 0.2378423593208439\n",
      "previous_iter_valid_loss : 0.20857445895671844\n",
      "\n",
      "     74300\t  0.208964\t  0.208574\t  0.211679\t\tCURRENT LEARNING RATE: 0.23760463584307223\n",
      "previous_iter_valid_loss : 0.47438767552375793\n",
      "\n",
      "     74400\t  0.475435\t  0.474388\t  0.214723\t\tCURRENT LEARNING RATE: 0.2373671499699562\n",
      "previous_iter_valid_loss : 0.4387768507003784\n",
      "\n",
      "     74500\t  0.438070\t  0.438777\t  0.217120\t\tCURRENT LEARNING RATE: 0.23712990146400995\n",
      "previous_iter_valid_loss : 0.5443402528762817\n",
      "\n",
      "     74600\t  0.547432\t  0.544340\t  0.219747\t\tCURRENT LEARNING RATE: 0.2368928900879849\n",
      "previous_iter_valid_loss : 0.3781405985355377\n",
      "\n",
      "     74700\t  0.377836\t  0.378141\t  0.221270\t\tCURRENT LEARNING RATE: 0.23665611560486965\n",
      "previous_iter_valid_loss : 0.25960713624954224\n",
      "\n",
      "     74800\t  0.260154\t  0.259607\t  0.222317\t\tCURRENT LEARNING RATE: 0.23641957777788977\n",
      "previous_iter_valid_loss : 0.29192379117012024\n",
      "\n",
      "     74900\t  0.293024\t  0.291924\t  0.223667\t\tCURRENT LEARNING RATE: 0.23618327637050734\n",
      "previous_iter_valid_loss : 0.24055728316307068\n",
      "\n",
      "     75000\t  0.241596\t  0.240557\t  0.223431\t\tCURRENT LEARNING RATE: 0.235947211146421\n",
      "previous_iter_valid_loss : 0.4427243769168854\n",
      "\n",
      "     75100\t  0.443602\t  0.442724\t  0.226082\t\tCURRENT LEARNING RATE: 0.23571138186956545\n",
      "previous_iter_valid_loss : 0.30830690264701843\n",
      "\n",
      "     75200\t  0.308135\t  0.308307\t  0.227709\t\tCURRENT LEARNING RATE: 0.2354757883041114\n",
      "previous_iter_valid_loss : 0.18783831596374512\n",
      "\n",
      "     75300\t  0.187292\t  0.187838\t  0.228185\t\tCURRENT LEARNING RATE: 0.23524043021446528\n",
      "previous_iter_valid_loss : 0.36517757177352905\n",
      "\n",
      "     75400\t  0.364450\t  0.365178\t  0.229390\t\tCURRENT LEARNING RATE: 0.23500530736526898\n",
      "previous_iter_valid_loss : 0.27995049953460693\n",
      "\n",
      "     75500\t  0.280904\t  0.279950\t  0.230469\t\tCURRENT LEARNING RATE: 0.23477041952139963\n",
      "previous_iter_valid_loss : 0.26264694333076477\n",
      "\n",
      "     75600\t  0.263743\t  0.262647\t  0.229164\t\tCURRENT LEARNING RATE: 0.23453576644796936\n",
      "previous_iter_valid_loss : 0.3068944811820984\n",
      "\n",
      "     75700\t  0.306415\t  0.306894\t  0.229933\t\tCURRENT LEARNING RATE: 0.23430134791032511\n",
      "previous_iter_valid_loss : 0.2575395405292511\n",
      "\n",
      "     75800\t  0.257388\t  0.257540\t  0.230983\t\tCURRENT LEARNING RATE: 0.23406716367404826\n",
      "previous_iter_valid_loss : 0.2699860632419586\n",
      "\n",
      "     75900\t  0.270564\t  0.269986\t  0.231697\t\tCURRENT LEARNING RATE: 0.23383321350495462\n",
      "previous_iter_valid_loss : 0.8461505770683289\n",
      "\n",
      "     76000\t  0.849140\t  0.846151\t  0.238326\t\tCURRENT LEARNING RATE: 0.23359949716909395\n",
      "previous_iter_valid_loss : 0.19207172095775604\n",
      "\n",
      "     76100\t  0.193511\t  0.192072\t  0.238599\t\tCURRENT LEARNING RATE: 0.23336601443274993\n",
      "previous_iter_valid_loss : 0.4923899471759796\n",
      "\n",
      "     76200\t  0.492580\t  0.492390\t  0.242061\t\tCURRENT LEARNING RATE: 0.23313276506243977\n",
      "previous_iter_valid_loss : 0.25611719489097595\n",
      "\n",
      "     76300\t  0.255704\t  0.256117\t  0.242737\t\tCURRENT LEARNING RATE: 0.23289974882491413\n",
      "previous_iter_valid_loss : 0.3324451744556427\n",
      "\n",
      "     76400\t  0.332610\t  0.332445\t  0.244565\t\tCURRENT LEARNING RATE: 0.2326669654871567\n",
      "previous_iter_valid_loss : 0.3973842263221741\n",
      "\n",
      "     76500\t  0.397213\t  0.397384\t  0.247043\t\tCURRENT LEARNING RATE: 0.23243441481638413\n",
      "previous_iter_valid_loss : 0.9807999134063721\n",
      "\n",
      "     76600\t  0.982489\t  0.980800\t  0.255114\t\tCURRENT LEARNING RATE: 0.23220209658004579\n",
      "previous_iter_valid_loss : 0.20804566144943237\n",
      "\n",
      "     76700\t  0.207982\t  0.208046\t  0.255562\t\tCURRENT LEARNING RATE: 0.23197001054582336\n",
      "previous_iter_valid_loss : 0.3548106849193573\n",
      "\n",
      "     76800\t  0.356082\t  0.354811\t  0.257373\t\tCURRENT LEARNING RATE: 0.2317381564816308\n",
      "previous_iter_valid_loss : 0.24448950588703156\n",
      "\n",
      "     76900\t  0.244295\t  0.244490\t  0.258161\t\tCURRENT LEARNING RATE: 0.23150653415561404\n",
      "previous_iter_valid_loss : 0.26809296011924744\n",
      "\n",
      "     77000\t  0.268754\t  0.268093\t  0.258815\t\tCURRENT LEARNING RATE: 0.2312751433361507\n",
      "previous_iter_valid_loss : 0.23444068431854248\n",
      "\n",
      "     77100\t  0.234907\t  0.234441\t  0.259876\t\tCURRENT LEARNING RATE: 0.23104398379185\n",
      "previous_iter_valid_loss : 0.2775888442993164\n",
      "\n",
      "     77200\t  0.278144\t  0.277589\t  0.260339\t\tCURRENT LEARNING RATE: 0.23081305529155235\n",
      "previous_iter_valid_loss : 0.6114619970321655\n",
      "\n",
      "     77300\t  0.612394\t  0.611462\t  0.265038\t\tCURRENT LEARNING RATE: 0.2305823576043292\n",
      "previous_iter_valid_loss : 0.5063275694847107\n",
      "\n",
      "     77400\t  0.507675\t  0.506328\t  0.268670\t\tCURRENT LEARNING RATE: 0.2303518904994829\n",
      "previous_iter_valid_loss : 0.3289245069026947\n",
      "\n",
      "     77500\t  0.328461\t  0.328925\t  0.270893\t\tCURRENT LEARNING RATE: 0.23012165374654628\n",
      "previous_iter_valid_loss : 0.3713109791278839\n",
      "\n",
      "     77600\t  0.371315\t  0.371311\t  0.272425\t\tCURRENT LEARNING RATE: 0.2298916471152826\n",
      "previous_iter_valid_loss : 0.5250962376594543\n",
      "\n",
      "     77700\t  0.523960\t  0.525096\t  0.276416\t\tCURRENT LEARNING RATE: 0.22966187037568517\n",
      "previous_iter_valid_loss : 0.2381364405155182\n",
      "\n",
      "     77800\t  0.239940\t  0.238136\t  0.277141\t\tCURRENT LEARNING RATE: 0.22943232329797725\n",
      "previous_iter_valid_loss : 0.4291289746761322\n",
      "\n",
      "     77900\t  0.430269\t  0.429129\t  0.280032\t\tCURRENT LEARNING RATE: 0.22920300565261176\n",
      "previous_iter_valid_loss : 0.2343161553144455\n",
      "\n",
      "     78000\t  0.236040\t  0.234316\t  0.280571\t\tCURRENT LEARNING RATE: 0.22897391721027102\n",
      "previous_iter_valid_loss : 0.20692245662212372\n",
      "\n",
      "     78100\t  0.208522\t  0.206922\t  0.280338\t\tCURRENT LEARNING RATE: 0.22874505774186657\n",
      "previous_iter_valid_loss : 0.33617374300956726\n",
      "\n",
      "     78200\t  0.338654\t  0.336174\t  0.282120\t\tCURRENT LEARNING RATE: 0.22851642701853894\n",
      "previous_iter_valid_loss : 0.19898174703121185\n",
      "\n",
      "     78300\t  0.199704\t  0.198982\t  0.282531\t\tCURRENT LEARNING RATE: 0.22828802481165736\n",
      "previous_iter_valid_loss : 0.28798824548721313\n",
      "\n",
      "     78400\t  0.289706\t  0.287988\t  0.283463\t\tCURRENT LEARNING RATE: 0.2280598508928196\n",
      "previous_iter_valid_loss : 0.20987026393413544\n",
      "\n",
      "     78500\t  0.210877\t  0.209870\t  0.284450\t\tCURRENT LEARNING RATE: 0.22783190503385176\n",
      "previous_iter_valid_loss : 0.33518365025520325\n",
      "\n",
      "     78600\t  0.336458\t  0.335184\t  0.286659\t\tCURRENT LEARNING RATE: 0.22760418700680793\n",
      "previous_iter_valid_loss : 0.2482379972934723\n",
      "\n",
      "     78700\t  0.249334\t  0.248238\t  0.287703\t\tCURRENT LEARNING RATE: 0.22737669658397008\n",
      "previous_iter_valid_loss : 0.4674381911754608\n",
      "\n",
      "     78800\t  0.468461\t  0.467438\t  0.291053\t\tCURRENT LEARNING RATE: 0.22714943353784775\n",
      "previous_iter_valid_loss : 0.27488112449645996\n",
      "\n",
      "     78900\t  0.275664\t  0.274881\t  0.292062\t\tCURRENT LEARNING RATE: 0.22692239764117791\n",
      "previous_iter_valid_loss : 0.18733206391334534\n",
      "\n",
      "     79000\t  0.187690\t  0.187332\t  0.292227\t\tCURRENT LEARNING RATE: 0.2266955886669246\n",
      "previous_iter_valid_loss : 0.2631548345088959\n",
      "\n",
      "     79100\t  0.263753\t  0.263155\t  0.293016\t\tCURRENT LEARNING RATE: 0.22646900638827885\n",
      "previous_iter_valid_loss : 0.3648971617221832\n",
      "\n",
      "     79200\t  0.367046\t  0.364897\t  0.295137\t\tCURRENT LEARNING RATE: 0.22624265057865836\n",
      "previous_iter_valid_loss : 0.37563449144363403\n",
      "\n",
      "     79300\t  0.376736\t  0.375634\t  0.297755\t\tCURRENT LEARNING RATE: 0.22601652101170733\n",
      "previous_iter_valid_loss : 0.43486523628234863\n",
      "\n",
      "     79400\t  0.435646\t  0.434865\t  0.300272\t\tCURRENT LEARNING RATE: 0.2257906174612961\n",
      "previous_iter_valid_loss : 0.27541518211364746\n",
      "\n",
      "     79500\t  0.275978\t  0.275415\t  0.301562\t\tCURRENT LEARNING RATE: 0.22556493970152117\n",
      "previous_iter_valid_loss : 0.33490344882011414\n",
      "\n",
      "     79600\t  0.337754\t  0.334903\t  0.303666\t\tCURRENT LEARNING RATE: 0.22533948750670474\n",
      "previous_iter_valid_loss : 0.21005618572235107\n",
      "\n",
      "     79700\t  0.210366\t  0.210056\t  0.304008\t\tCURRENT LEARNING RATE: 0.22511426065139462\n",
      "previous_iter_valid_loss : 0.5052704811096191\n",
      "\n",
      "     79800\t  0.505998\t  0.505270\t  0.305898\t\tCURRENT LEARNING RATE: 0.22488925891036388\n",
      "previous_iter_valid_loss : 0.33439144492149353\n",
      "\n",
      "     79900\t  0.336325\t  0.334391\t  0.307332\t\tCURRENT LEARNING RATE: 0.22466448205861078\n",
      "previous_iter_valid_loss : 0.3898635506629944\n",
      "\n",
      "     80000\t  0.389837\t  0.389864\t  0.309757\t\tCURRENT LEARNING RATE: 0.2244399298713585\n",
      "previous_iter_valid_loss : 0.573021650314331\n",
      "\n",
      "     80100\t  0.574095\t  0.573022\t  0.312972\t\tCURRENT LEARNING RATE: 0.22421560212405475\n",
      "previous_iter_valid_loss : 0.30427518486976624\n",
      "\n",
      "     80200\t  0.304767\t  0.304275\t  0.314408\t\tCURRENT LEARNING RATE: 0.22399149859237183\n",
      "previous_iter_valid_loss : 0.22851575911045074\n",
      "\n",
      "     80300\t  0.228775\t  0.228516\t  0.314060\t\tCURRENT LEARNING RATE: 0.22376761905220618\n",
      "previous_iter_valid_loss : 0.22185516357421875\n",
      "\n",
      "     80400\t  0.222508\t  0.221855\t  0.314259\t\tCURRENT LEARNING RATE: 0.2235439632796782\n",
      "previous_iter_valid_loss : 0.3338373005390167\n",
      "\n",
      "     80500\t  0.333913\t  0.333837\t  0.315941\t\tCURRENT LEARNING RATE: 0.22332053105113217\n",
      "previous_iter_valid_loss : 0.29366225004196167\n",
      "\n",
      "     80600\t  0.294966\t  0.293662\t  0.317204\t\tCURRENT LEARNING RATE: 0.22309732214313577\n",
      "previous_iter_valid_loss : 0.36910635232925415\n",
      "\n",
      "     80700\t  0.370342\t  0.369106\t  0.318667\t\tCURRENT LEARNING RATE: 0.2228743363324801\n",
      "previous_iter_valid_loss : 0.3250657021999359\n",
      "\n",
      "     80800\t  0.324779\t  0.325066\t  0.319941\t\tCURRENT LEARNING RATE: 0.22265157339617936\n",
      "previous_iter_valid_loss : 0.19370298087596893\n",
      "\n",
      "     80900\t  0.194199\t  0.193703\t  0.319955\t\tCURRENT LEARNING RATE: 0.22242903311147055\n",
      "previous_iter_valid_loss : 0.24690082669258118\n",
      "\n",
      "     81000\t  0.248112\t  0.246901\t  0.320198\t\tCURRENT LEARNING RATE: 0.2222067152558134\n",
      "previous_iter_valid_loss : 0.35485753417015076\n",
      "\n",
      "     81100\t  0.355030\t  0.354858\t  0.321791\t\tCURRENT LEARNING RATE: 0.22198461960689003\n",
      "previous_iter_valid_loss : 0.2551872432231903\n",
      "\n",
      "     81200\t  0.256835\t  0.255187\t  0.321964\t\tCURRENT LEARNING RATE: 0.22176274594260476\n",
      "previous_iter_valid_loss : 0.3029402494430542\n",
      "\n",
      "     81300\t  0.304902\t  0.302940\t  0.322561\t\tCURRENT LEARNING RATE: 0.2215410940410839\n",
      "previous_iter_valid_loss : 0.2810514271259308\n",
      "\n",
      "     81400\t  0.282315\t  0.281051\t  0.323165\t\tCURRENT LEARNING RATE: 0.22131966368067557\n",
      "previous_iter_valid_loss : 0.17043696343898773\n",
      "\n",
      "     81500\t  0.170573\t  0.170437\t  0.321049\t\tCURRENT LEARNING RATE: 0.22109845463994934\n",
      "previous_iter_valid_loss : 0.2199794501066208\n",
      "\n",
      "     81600\t  0.222138\t  0.219979\t  0.321536\t\tCURRENT LEARNING RATE: 0.22087746669769617\n",
      "previous_iter_valid_loss : 0.17064540088176727\n",
      "\n",
      "     81700\t  0.170938\t  0.170645\t  0.319983\t\tCURRENT LEARNING RATE: 0.2206566996329281\n",
      "previous_iter_valid_loss : 0.5930619239807129\n",
      "\n",
      "     81800\t  0.594657\t  0.593062\t  0.324120\t\tCURRENT LEARNING RATE: 0.22043615322487808\n",
      "previous_iter_valid_loss : 0.17858590185642242\n",
      "\n",
      "     81900\t  0.179546\t  0.178586\t  0.321414\t\tCURRENT LEARNING RATE: 0.22021582725299965\n",
      "previous_iter_valid_loss : 0.6843196749687195\n",
      "\n",
      "     82000\t  0.687637\t  0.684320\t  0.323759\t\tCURRENT LEARNING RATE: 0.2199957214969668\n",
      "previous_iter_valid_loss : 0.3327908217906952\n",
      "\n",
      "     82100\t  0.334436\t  0.332791\t  0.325250\t\tCURRENT LEARNING RATE: 0.2197758357366738\n",
      "previous_iter_valid_loss : 0.1887965053319931\n",
      "\n",
      "     82200\t  0.190236\t  0.188797\t  0.325066\t\tCURRENT LEARNING RATE: 0.21955616975223485\n",
      "previous_iter_valid_loss : 0.24551038444042206\n",
      "\n",
      "     82300\t  0.246440\t  0.245510\t  0.324481\t\tCURRENT LEARNING RATE: 0.21933672332398393\n",
      "previous_iter_valid_loss : 0.36932462453842163\n",
      "\n",
      "     82400\t  0.370125\t  0.369325\t  0.325229\t\tCURRENT LEARNING RATE: 0.21911749623247462\n",
      "previous_iter_valid_loss : 0.27148744463920593\n",
      "\n",
      "     82500\t  0.272693\t  0.271487\t  0.325742\t\tCURRENT LEARNING RATE: 0.21889848825847982\n",
      "previous_iter_valid_loss : 0.22057278454303741\n",
      "\n",
      "     82600\t  0.220600\t  0.220573\t  0.325350\t\tCURRENT LEARNING RATE: 0.2186796991829915\n",
      "previous_iter_valid_loss : 0.1912127137184143\n",
      "\n",
      "     82700\t  0.192147\t  0.191213\t  0.323357\t\tCURRENT LEARNING RATE: 0.2184611287872206\n",
      "previous_iter_valid_loss : 0.20547109842300415\n",
      "\n",
      "     82800\t  0.206717\t  0.205471\t  0.322473\t\tCURRENT LEARNING RATE: 0.2182427768525967\n",
      "previous_iter_valid_loss : 0.24662253260612488\n",
      "\n",
      "     82900\t  0.248394\t  0.246623\t  0.322610\t\tCURRENT LEARNING RATE: 0.2180246431607678\n",
      "previous_iter_valid_loss : 0.39683008193969727\n",
      "\n",
      "     83000\t  0.397742\t  0.396830\t  0.324597\t\tCURRENT LEARNING RATE: 0.21780672749360025\n",
      "previous_iter_valid_loss : 0.18956074118614197\n",
      "\n",
      "     83100\t  0.191050\t  0.189561\t  0.323602\t\tCURRENT LEARNING RATE: 0.21758902963317836\n",
      "previous_iter_valid_loss : 0.1902480572462082\n",
      "\n",
      "     83200\t  0.191120\t  0.190248\t  0.323626\t\tCURRENT LEARNING RATE: 0.21737154936180422\n",
      "previous_iter_valid_loss : 0.17706061899662018\n",
      "\n",
      "     83300\t  0.177481\t  0.177061\t  0.321107\t\tCURRENT LEARNING RATE: 0.21715428646199755\n",
      "previous_iter_valid_loss : 0.23294419050216675\n",
      "\n",
      "     83400\t  0.233381\t  0.232944\t  0.321051\t\tCURRENT LEARNING RATE: 0.21693724071649545\n",
      "previous_iter_valid_loss : 0.17886297404766083\n",
      "\n",
      "     83500\t  0.180467\t  0.178863\t  0.320701\t\tCURRENT LEARNING RATE: 0.21672041190825214\n",
      "previous_iter_valid_loss : 0.1710590422153473\n",
      "\n",
      "     83600\t  0.172247\t  0.171059\t  0.320113\t\tCURRENT LEARNING RATE: 0.21650379982043882\n",
      "previous_iter_valid_loss : 0.2393714040517807\n",
      "\n",
      "     83700\t  0.239947\t  0.239371\t  0.319229\t\tCURRENT LEARNING RATE: 0.21628740423644333\n",
      "previous_iter_valid_loss : 0.1595042198896408\n",
      "\n",
      "     83800\t  0.159633\t  0.159504\t  0.317366\t\tCURRENT LEARNING RATE: 0.21607122493987013\n",
      "previous_iter_valid_loss : 0.17846746742725372\n",
      "\n",
      "     83900\t  0.178293\t  0.178467\t  0.316549\t\tCURRENT LEARNING RATE: 0.21585526171453986\n",
      "previous_iter_valid_loss : 0.20250645279884338\n",
      "\n",
      "     84000\t  0.202704\t  0.202506\t  0.316265\t\tCURRENT LEARNING RATE: 0.21563951434448927\n",
      "previous_iter_valid_loss : 0.16877204179763794\n",
      "\n",
      "     84100\t  0.168793\t  0.168772\t  0.313420\t\tCURRENT LEARNING RATE: 0.21542398261397103\n",
      "previous_iter_valid_loss : 0.1819935142993927\n",
      "\n",
      "     84200\t  0.182361\t  0.181994\t  0.313283\t\tCURRENT LEARNING RATE: 0.21520866630745333\n",
      "previous_iter_valid_loss : 0.18850965797901154\n",
      "\n",
      "     84300\t  0.188749\t  0.188510\t  0.313083\t\tCURRENT LEARNING RATE: 0.2149935652096199\n",
      "previous_iter_valid_loss : 0.37936830520629883\n",
      "\n",
      "     84400\t  0.380796\t  0.379368\t  0.312133\t\tCURRENT LEARNING RATE: 0.21477867910536957\n",
      "previous_iter_valid_loss : 0.2360735982656479\n",
      "\n",
      "     84500\t  0.236970\t  0.236074\t  0.310106\t\tCURRENT LEARNING RATE: 0.21456400777981627\n",
      "previous_iter_valid_loss : 0.12359359860420227\n",
      "\n",
      "     84600\t  0.123751\t  0.123594\t  0.305898\t\tCURRENT LEARNING RATE: 0.21434955101828862\n",
      "previous_iter_valid_loss : 0.4560547471046448\n",
      "\n",
      "     84700\t  0.456398\t  0.456055\t  0.306677\t\tCURRENT LEARNING RATE: 0.21413530860632984\n",
      "previous_iter_valid_loss : 0.14131294190883636\n",
      "\n",
      "     84800\t  0.141519\t  0.141313\t  0.305494\t\tCURRENT LEARNING RATE: 0.2139212803296975\n",
      "previous_iter_valid_loss : 0.33538711071014404\n",
      "\n",
      "     84900\t  0.335975\t  0.335387\t  0.305929\t\tCURRENT LEARNING RATE: 0.21370746597436335\n",
      "previous_iter_valid_loss : 0.2014133185148239\n",
      "\n",
      "     85000\t  0.202922\t  0.201413\t  0.305537\t\tCURRENT LEARNING RATE: 0.21349386532651296\n",
      "previous_iter_valid_loss : 0.16189731657505035\n",
      "\n",
      "     85100\t  0.162764\t  0.161897\t  0.302729\t\tCURRENT LEARNING RATE: 0.2132804781725457\n",
      "previous_iter_valid_loss : 0.2188674956560135\n",
      "\n",
      "     85200\t  0.219845\t  0.218867\t  0.301835\t\tCURRENT LEARNING RATE: 0.21306730429907436\n",
      "previous_iter_valid_loss : 0.12892921268939972\n",
      "\n",
      "     85300\t  0.129746\t  0.128929\t  0.301246\t\tCURRENT LEARNING RATE: 0.2128543434929251\n",
      "previous_iter_valid_loss : 0.34933483600616455\n",
      "\n",
      "     85400\t  0.350637\t  0.349335\t  0.301087\t\tCURRENT LEARNING RATE: 0.21264159554113707\n",
      "previous_iter_valid_loss : 0.12984660267829895\n",
      "\n",
      "     85500\t  0.129757\t  0.129847\t  0.299586\t\tCURRENT LEARNING RATE: 0.21242906023096228\n",
      "previous_iter_valid_loss : 0.1459851861000061\n",
      "\n",
      "     85600\t  0.146753\t  0.145985\t  0.298420\t\tCURRENT LEARNING RATE: 0.21221673734986546\n",
      "previous_iter_valid_loss : 0.18721996247768402\n",
      "\n",
      "     85700\t  0.188162\t  0.187220\t  0.297223\t\tCURRENT LEARNING RATE: 0.21200462668552364\n",
      "previous_iter_valid_loss : 0.1357443779706955\n",
      "\n",
      "     85800\t  0.136550\t  0.135744\t  0.296005\t\tCURRENT LEARNING RATE: 0.2117927280258262\n",
      "previous_iter_valid_loss : 0.19821284711360931\n",
      "\n",
      "     85900\t  0.198816\t  0.198213\t  0.295287\t\tCURRENT LEARNING RATE: 0.2115810411588744\n",
      "previous_iter_valid_loss : 0.11380529403686523\n",
      "\n",
      "     86000\t  0.113991\t  0.113805\t  0.287964\t\tCURRENT LEARNING RATE: 0.21136956587298142\n",
      "previous_iter_valid_loss : 0.12804727256298065\n",
      "\n",
      "     86100\t  0.128248\t  0.128047\t  0.287323\t\tCURRENT LEARNING RATE: 0.21115830195667193\n",
      "previous_iter_valid_loss : 0.212192103266716\n",
      "\n",
      "     86200\t  0.212416\t  0.212192\t  0.284521\t\tCURRENT LEARNING RATE: 0.21094724919868196\n",
      "previous_iter_valid_loss : 0.19399133324623108\n",
      "\n",
      "     86300\t  0.194236\t  0.193991\t  0.283900\t\tCURRENT LEARNING RATE: 0.21073640738795882\n",
      "previous_iter_valid_loss : 0.16980253159999847\n",
      "\n",
      "     86400\t  0.169680\t  0.169803\t  0.282274\t\tCURRENT LEARNING RATE: 0.2105257763136606\n",
      "previous_iter_valid_loss : 0.17114605009555817\n",
      "\n",
      "     86500\t  0.170954\t  0.171146\t  0.280011\t\tCURRENT LEARNING RATE: 0.21031535576515623\n",
      "previous_iter_valid_loss : 0.20453591644763947\n",
      "\n",
      "     86600\t  0.205335\t  0.204536\t  0.272249\t\tCURRENT LEARNING RATE: 0.21010514553202514\n",
      "previous_iter_valid_loss : 0.12978915870189667\n",
      "\n",
      "     86700\t  0.130072\t  0.129789\t  0.271466\t\tCURRENT LEARNING RATE: 0.20989514540405713\n",
      "previous_iter_valid_loss : 0.4548710286617279\n",
      "\n",
      "     86800\t  0.456320\t  0.454871\t  0.272467\t\tCURRENT LEARNING RATE: 0.20968535517125197\n",
      "previous_iter_valid_loss : 0.1863722950220108\n",
      "\n",
      "     86900\t  0.186386\t  0.186372\t  0.271886\t\tCURRENT LEARNING RATE: 0.2094757746238195\n",
      "previous_iter_valid_loss : 0.1687859147787094\n",
      "\n",
      "     87000\t  0.168496\t  0.168786\t  0.270893\t\tCURRENT LEARNING RATE: 0.20926640355217907\n",
      "previous_iter_valid_loss : 0.22117392718791962\n",
      "\n",
      "     87100\t  0.221344\t  0.221174\t  0.270760\t\tCURRENT LEARNING RATE: 0.20905724174695967\n",
      "previous_iter_valid_loss : 0.12249673157930374\n",
      "\n",
      "     87200\t  0.122560\t  0.122497\t  0.269209\t\tCURRENT LEARNING RATE: 0.2088482889989994\n",
      "previous_iter_valid_loss : 0.17186927795410156\n",
      "\n",
      "     87300\t  0.172066\t  0.171869\t  0.264813\t\tCURRENT LEARNING RATE: 0.20863954509934557\n",
      "previous_iter_valid_loss : 0.1562000960111618\n",
      "\n",
      "     87400\t  0.156473\t  0.156200\t  0.261312\t\tCURRENT LEARNING RATE: 0.2084310098392542\n",
      "previous_iter_valid_loss : 0.21861079335212708\n",
      "\n",
      "     87500\t  0.219112\t  0.218611\t  0.260209\t\tCURRENT LEARNING RATE: 0.20822268301019004\n",
      "previous_iter_valid_loss : 0.14884264767169952\n",
      "\n",
      "     87600\t  0.148632\t  0.148843\t  0.257984\t\tCURRENT LEARNING RATE: 0.20801456440382626\n",
      "previous_iter_valid_loss : 0.19516675174236298\n",
      "\n",
      "     87700\t  0.195102\t  0.195167\t  0.254685\t\tCURRENT LEARNING RATE: 0.2078066538120442\n",
      "previous_iter_valid_loss : 0.13640999794006348\n",
      "\n",
      "     87800\t  0.136468\t  0.136410\t  0.253667\t\tCURRENT LEARNING RATE: 0.2075989510269333\n",
      "previous_iter_valid_loss : 0.247078999876976\n",
      "\n",
      "     87900\t  0.247678\t  0.247079\t  0.251847\t\tCURRENT LEARNING RATE: 0.2073914558407907\n",
      "previous_iter_valid_loss : 0.1797972321510315\n",
      "\n",
      "     88000\t  0.180349\t  0.179797\t  0.251302\t\tCURRENT LEARNING RATE: 0.20718416804612122\n",
      "previous_iter_valid_loss : 0.1444658786058426\n",
      "\n",
      "     88100\t  0.144830\t  0.144466\t  0.250677\t\tCURRENT LEARNING RATE: 0.20697708743563706\n",
      "previous_iter_valid_loss : 0.1369049996137619\n",
      "\n",
      "     88200\t  0.137123\t  0.136905\t  0.248684\t\tCURRENT LEARNING RATE: 0.20677021380225757\n",
      "previous_iter_valid_loss : 0.19226188957691193\n",
      "\n",
      "     88300\t  0.191972\t  0.192262\t  0.248617\t\tCURRENT LEARNING RATE: 0.2065635469391091\n",
      "previous_iter_valid_loss : 0.17345081269741058\n",
      "\n",
      "     88400\t  0.173637\t  0.173451\t  0.247472\t\tCURRENT LEARNING RATE: 0.20635708663952482\n",
      "previous_iter_valid_loss : 0.31606805324554443\n",
      "\n",
      "     88500\t  0.316819\t  0.316068\t  0.248534\t\tCURRENT LEARNING RATE: 0.20615083269704437\n",
      "previous_iter_valid_loss : 0.16967080533504486\n",
      "\n",
      "     88600\t  0.169433\t  0.169671\t  0.246879\t\tCURRENT LEARNING RATE: 0.2059447849054138\n",
      "previous_iter_valid_loss : 0.24557463824748993\n",
      "\n",
      "     88700\t  0.245605\t  0.245575\t  0.246852\t\tCURRENT LEARNING RATE: 0.20573894305858528\n",
      "previous_iter_valid_loss : 0.16155153512954712\n",
      "\n",
      "     88800\t  0.161929\t  0.161552\t  0.243793\t\tCURRENT LEARNING RATE: 0.20553330695071698\n",
      "previous_iter_valid_loss : 0.30612432956695557\n",
      "\n",
      "     88900\t  0.306860\t  0.306124\t  0.244106\t\tCURRENT LEARNING RATE: 0.20532787637617275\n",
      "previous_iter_valid_loss : 0.1761591136455536\n",
      "\n",
      "     89000\t  0.176726\t  0.176159\t  0.243994\t\tCURRENT LEARNING RATE: 0.205122651129522\n",
      "previous_iter_valid_loss : 0.16838058829307556\n",
      "\n",
      "     89100\t  0.168807\t  0.168381\t  0.243046\t\tCURRENT LEARNING RATE: 0.20491763100553947\n",
      "previous_iter_valid_loss : 0.19807296991348267\n",
      "\n",
      "     89200\t  0.199116\t  0.198073\t  0.241378\t\tCURRENT LEARNING RATE: 0.20471281579920503\n",
      "previous_iter_valid_loss : 0.139900341629982\n",
      "\n",
      "     89300\t  0.140201\t  0.139900\t  0.239020\t\tCURRENT LEARNING RATE: 0.20450820530570346\n",
      "previous_iter_valid_loss : 0.19642890989780426\n",
      "\n",
      "     89400\t  0.195998\t  0.196429\t  0.236636\t\tCURRENT LEARNING RATE: 0.20430379932042422\n",
      "previous_iter_valid_loss : 0.1144033819437027\n",
      "\n",
      "     89500\t  0.114383\t  0.114403\t  0.235026\t\tCURRENT LEARNING RATE: 0.20409959763896135\n",
      "previous_iter_valid_loss : 0.18668624758720398\n",
      "\n",
      "     89600\t  0.186275\t  0.186686\t  0.233544\t\tCURRENT LEARNING RATE: 0.2038956000571131\n",
      "previous_iter_valid_loss : 0.18727189302444458\n",
      "\n",
      "     89700\t  0.187992\t  0.187272\t  0.233316\t\tCURRENT LEARNING RATE: 0.2036918063708819\n",
      "previous_iter_valid_loss : 0.18243075907230377\n",
      "\n",
      "     89800\t  0.183018\t  0.182431\t  0.230088\t\tCURRENT LEARNING RATE: 0.20348821637647407\n",
      "previous_iter_valid_loss : 0.1328241229057312\n",
      "\n",
      "     89900\t  0.133108\t  0.132824\t  0.228072\t\tCURRENT LEARNING RATE: 0.20328482987029955\n",
      "previous_iter_valid_loss : 0.2510569393634796\n",
      "\n",
      "     90000\t  0.251996\t  0.251057\t  0.226684\t\tCURRENT LEARNING RATE: 0.20308164664897185\n",
      "previous_iter_valid_loss : 0.20027917623519897\n",
      "\n",
      "     90100\t  0.200874\t  0.200279\t  0.222956\t\tCURRENT LEARNING RATE: 0.20287866650930772\n",
      "previous_iter_valid_loss : 0.17429737746715546\n",
      "\n",
      "     90200\t  0.174931\t  0.174297\t  0.221657\t\tCURRENT LEARNING RATE: 0.202675889248327\n",
      "previous_iter_valid_loss : 0.23117446899414062\n",
      "\n",
      "     90300\t  0.231875\t  0.231174\t  0.221683\t\tCURRENT LEARNING RATE: 0.20247331466325244\n",
      "previous_iter_valid_loss : 0.17511437833309174\n",
      "\n",
      "     90400\t  0.175013\t  0.175114\t  0.221216\t\tCURRENT LEARNING RATE: 0.2022709425515094\n",
      "previous_iter_valid_loss : 0.186366006731987\n",
      "\n",
      "     90500\t  0.185997\t  0.186366\t  0.219741\t\tCURRENT LEARNING RATE: 0.20206877271072576\n",
      "previous_iter_valid_loss : 0.17148597538471222\n",
      "\n",
      "     90600\t  0.171376\t  0.171486\t  0.218519\t\tCURRENT LEARNING RATE: 0.2018668049387317\n",
      "previous_iter_valid_loss : 0.18264935910701752\n",
      "\n",
      "     90700\t  0.182570\t  0.182649\t  0.216655\t\tCURRENT LEARNING RATE: 0.20166503903355937\n",
      "previous_iter_valid_loss : 0.2469993382692337\n",
      "\n",
      "     90800\t  0.248003\t  0.246999\t  0.215874\t\tCURRENT LEARNING RATE: 0.20146347479344287\n",
      "previous_iter_valid_loss : 0.20448358356952667\n",
      "\n",
      "     90900\t  0.205117\t  0.204484\t  0.215982\t\tCURRENT LEARNING RATE: 0.20126211201681798\n",
      "previous_iter_valid_loss : 0.1387668401002884\n",
      "\n",
      "     91000\t  0.138764\t  0.138767\t  0.214901\t\tCURRENT LEARNING RATE: 0.20106095050232187\n",
      "previous_iter_valid_loss : 0.17647263407707214\n",
      "\n",
      "     91100\t  0.175813\t  0.176473\t  0.213117\t\tCURRENT LEARNING RATE: 0.200859990048793\n",
      "previous_iter_valid_loss : 0.1386931985616684\n",
      "\n",
      "     91200\t  0.138788\t  0.138693\t  0.211952\t\tCURRENT LEARNING RATE: 0.20065923045527095\n",
      "previous_iter_valid_loss : 0.31961962580680847\n",
      "\n",
      "     91300\t  0.320345\t  0.319620\t  0.212119\t\tCURRENT LEARNING RATE: 0.20045867152099606\n",
      "previous_iter_valid_loss : 0.2456173151731491\n",
      "\n",
      "     91400\t  0.246410\t  0.245617\t  0.211764\t\tCURRENT LEARNING RATE: 0.2002583130454094\n",
      "previous_iter_valid_loss : 0.15534928441047668\n",
      "\n",
      "     91500\t  0.155547\t  0.155349\t  0.211613\t\tCURRENT LEARNING RATE: 0.20005815482815248\n",
      "previous_iter_valid_loss : 0.24812021851539612\n",
      "\n",
      "     91600\t  0.247716\t  0.248120\t  0.211895\t\tCURRENT LEARNING RATE: 0.19985819666906704\n",
      "previous_iter_valid_loss : 0.3420814275741577\n",
      "\n",
      "     91700\t  0.342685\t  0.342081\t  0.213609\t\tCURRENT LEARNING RATE: 0.19965843836819494\n",
      "previous_iter_valid_loss : 0.2713744640350342\n",
      "\n",
      "     91800\t  0.271425\t  0.271374\t  0.210392\t\tCURRENT LEARNING RATE: 0.19945887972577783\n",
      "previous_iter_valid_loss : 0.18637047708034515\n",
      "\n",
      "     91900\t  0.187228\t  0.186370\t  0.210470\t\tCURRENT LEARNING RATE: 0.19925952054225707\n",
      "previous_iter_valid_loss : 0.311688631772995\n",
      "\n",
      "     92000\t  0.311368\t  0.311689\t  0.206744\t\tCURRENT LEARNING RATE: 0.19906036061827348\n",
      "previous_iter_valid_loss : 0.1879439353942871\n",
      "\n",
      "     92100\t  0.188169\t  0.187944\t  0.205295\t\tCURRENT LEARNING RATE: 0.19886139975466707\n",
      "previous_iter_valid_loss : 0.11731027811765671\n",
      "\n",
      "     92200\t  0.117368\t  0.117310\t  0.204580\t\tCURRENT LEARNING RATE: 0.198662637752477\n",
      "previous_iter_valid_loss : 0.13510741293430328\n",
      "\n",
      "     92300\t  0.135480\t  0.135107\t  0.203476\t\tCURRENT LEARNING RATE: 0.19846407441294123\n",
      "previous_iter_valid_loss : 0.14644865691661835\n",
      "\n",
      "     92400\t  0.146662\t  0.146449\t  0.201248\t\tCURRENT LEARNING RATE: 0.19826570953749642\n",
      "previous_iter_valid_loss : 0.15336693823337555\n",
      "\n",
      "     92500\t  0.153767\t  0.153367\t  0.200066\t\tCURRENT LEARNING RATE: 0.19806754292777767\n",
      "previous_iter_valid_loss : 0.18285422027111053\n",
      "\n",
      "     92600\t  0.183427\t  0.182854\t  0.199689\t\tCURRENT LEARNING RATE: 0.19786957438561836\n",
      "previous_iter_valid_loss : 0.17039795219898224\n",
      "\n",
      "     92700\t  0.170896\t  0.170398\t  0.199481\t\tCURRENT LEARNING RATE: 0.1976718037130499\n",
      "previous_iter_valid_loss : 0.16670505702495575\n",
      "\n",
      "     92800\t  0.167259\t  0.166705\t  0.199093\t\tCURRENT LEARNING RATE: 0.19747423071230163\n",
      "previous_iter_valid_loss : 0.1425771862268448\n",
      "\n",
      "     92900\t  0.142510\t  0.142577\t  0.198053\t\tCURRENT LEARNING RATE: 0.19727685518580054\n",
      "previous_iter_valid_loss : 0.1961687058210373\n",
      "\n",
      "     93000\t  0.196482\t  0.196169\t  0.196046\t\tCURRENT LEARNING RATE: 0.1970796769361711\n",
      "previous_iter_valid_loss : 0.20374028384685516\n",
      "\n",
      "     93100\t  0.203422\t  0.203740\t  0.196188\t\tCURRENT LEARNING RATE: 0.196882695766235\n",
      "previous_iter_valid_loss : 0.1271502822637558\n",
      "\n",
      "     93200\t  0.127456\t  0.127150\t  0.195557\t\tCURRENT LEARNING RATE: 0.19668591147901104\n",
      "previous_iter_valid_loss : 0.16730190813541412\n",
      "\n",
      "     93300\t  0.167607\t  0.167302\t  0.195460\t\tCURRENT LEARNING RATE: 0.19648932387771498\n",
      "previous_iter_valid_loss : 0.2152869701385498\n",
      "\n",
      "     93400\t  0.215932\t  0.215287\t  0.195283\t\tCURRENT LEARNING RATE: 0.19629293276575918\n",
      "previous_iter_valid_loss : 0.3249877989292145\n",
      "\n",
      "     93500\t  0.325391\t  0.324988\t  0.196744\t\tCURRENT LEARNING RATE: 0.19609673794675248\n",
      "previous_iter_valid_loss : 0.18102610111236572\n",
      "\n",
      "     93600\t  0.180880\t  0.181026\t  0.196844\t\tCURRENT LEARNING RATE: 0.19590073922450008\n",
      "previous_iter_valid_loss : 0.13151942193508148\n",
      "\n",
      "     93700\t  0.131898\t  0.131519\t  0.195765\t\tCURRENT LEARNING RATE: 0.19570493640300327\n",
      "previous_iter_valid_loss : 0.15938793122768402\n",
      "\n",
      "     93800\t  0.159422\t  0.159388\t  0.195764\t\tCURRENT LEARNING RATE: 0.19550932928645912\n",
      "previous_iter_valid_loss : 0.17397555708885193\n",
      "\n",
      "     93900\t  0.174895\t  0.173976\t  0.195719\t\tCURRENT LEARNING RATE: 0.19531391767926057\n",
      "previous_iter_valid_loss : 0.20133313536643982\n",
      "\n",
      "     94000\t  0.201720\t  0.201333\t  0.195708\t\tCURRENT LEARNING RATE: 0.19511870138599596\n",
      "previous_iter_valid_loss : 0.23570027947425842\n",
      "\n",
      "     94100\t  0.235484\t  0.235700\t  0.196377\t\tCURRENT LEARNING RATE: 0.19492368021144899\n",
      "previous_iter_valid_loss : 0.2334364801645279\n",
      "\n",
      "     94200\t  0.233109\t  0.233436\t  0.196891\t\tCURRENT LEARNING RATE: 0.1947288539605985\n",
      "previous_iter_valid_loss : 0.16615857183933258\n",
      "\n",
      "     94300\t  0.166204\t  0.166159\t  0.196668\t\tCURRENT LEARNING RATE: 0.19453422243861818\n",
      "previous_iter_valid_loss : 0.18158414959907532\n",
      "\n",
      "     94400\t  0.181117\t  0.181584\t  0.194690\t\tCURRENT LEARNING RATE: 0.19433978545087652\n",
      "previous_iter_valid_loss : 0.14319241046905518\n",
      "\n",
      "     94500\t  0.143861\t  0.143192\t  0.193761\t\tCURRENT LEARNING RATE: 0.1941455428029365\n",
      "previous_iter_valid_loss : 0.17027829587459564\n",
      "\n",
      "     94600\t  0.170317\t  0.170278\t  0.194228\t\tCURRENT LEARNING RATE: 0.19395149430055544\n",
      "previous_iter_valid_loss : 0.2284150868654251\n",
      "\n",
      "     94700\t  0.227729\t  0.228415\t  0.191952\t\tCURRENT LEARNING RATE: 0.19375763974968488\n",
      "previous_iter_valid_loss : 0.2150687426328659\n",
      "\n",
      "     94800\t  0.214963\t  0.215069\t  0.192689\t\tCURRENT LEARNING RATE: 0.1935639789564702\n",
      "previous_iter_valid_loss : 0.13965678215026855\n",
      "\n",
      "     94900\t  0.139784\t  0.139657\t  0.190732\t\tCURRENT LEARNING RATE: 0.19337051172725062\n",
      "previous_iter_valid_loss : 0.19886094331741333\n",
      "\n",
      "     95000\t  0.199042\t  0.198861\t  0.190706\t\tCURRENT LEARNING RATE: 0.19317723786855887\n",
      "previous_iter_valid_loss : 0.30929329991340637\n",
      "\n",
      "     95100\t  0.308826\t  0.309293\t  0.192180\t\tCURRENT LEARNING RATE: 0.19298415718712109\n",
      "previous_iter_valid_loss : 0.20729894936084747\n",
      "\n",
      "     95200\t  0.207091\t  0.207299\t  0.192065\t\tCURRENT LEARNING RATE: 0.19279126948985656\n",
      "previous_iter_valid_loss : 0.1652153879404068\n",
      "\n",
      "     95300\t  0.165038\t  0.165215\t  0.192428\t\tCURRENT LEARNING RATE: 0.1925985745838776\n",
      "previous_iter_valid_loss : 0.15242138504981995\n",
      "\n",
      "     95400\t  0.152476\t  0.152421\t  0.190458\t\tCURRENT LEARNING RATE: 0.1924060722764893\n",
      "previous_iter_valid_loss : 0.17555809020996094\n",
      "\n",
      "     95500\t  0.175264\t  0.175558\t  0.190916\t\tCURRENT LEARNING RATE: 0.19221376237518928\n",
      "previous_iter_valid_loss : 0.17228759825229645\n",
      "\n",
      "     95600\t  0.172477\t  0.172288\t  0.191179\t\tCURRENT LEARNING RATE: 0.19202164468766764\n",
      "previous_iter_valid_loss : 0.24271385371685028\n",
      "\n",
      "     95700\t  0.242959\t  0.242714\t  0.191733\t\tCURRENT LEARNING RATE: 0.1918297190218067\n",
      "previous_iter_valid_loss : 0.19091551005840302\n",
      "\n",
      "     95800\t  0.190199\t  0.190916\t  0.192285\t\tCURRENT LEARNING RATE: 0.1916379851856808\n",
      "previous_iter_valid_loss : 0.19303488731384277\n",
      "\n",
      "     95900\t  0.192713\t  0.193035\t  0.192233\t\tCURRENT LEARNING RATE: 0.19144644298755603\n",
      "previous_iter_valid_loss : 0.1974422186613083\n",
      "\n",
      "     96000\t  0.197348\t  0.197442\t  0.193070\t\tCURRENT LEARNING RATE: 0.19125509223589018\n",
      "previous_iter_valid_loss : 0.11267165839672089\n",
      "\n",
      "     96100\t  0.112532\t  0.112672\t  0.192916\t\tCURRENT LEARNING RATE: 0.19106393273933253\n",
      "previous_iter_valid_loss : 0.13155783712863922\n",
      "\n",
      "     96200\t  0.131803\t  0.131558\t  0.192110\t\tCURRENT LEARNING RATE: 0.19087296430672354\n",
      "previous_iter_valid_loss : 0.16981922090053558\n",
      "\n",
      "     96300\t  0.169260\t  0.169819\t  0.191868\t\tCURRENT LEARNING RATE: 0.19068218674709478\n",
      "previous_iter_valid_loss : 0.110172338783741\n",
      "\n",
      "     96400\t  0.110056\t  0.110172\t  0.191272\t\tCURRENT LEARNING RATE: 0.19049159986966863\n",
      "previous_iter_valid_loss : 0.15802600979804993\n",
      "\n",
      "     96500\t  0.157732\t  0.158026\t  0.191140\t\tCURRENT LEARNING RATE: 0.19030120348385823\n",
      "previous_iter_valid_loss : 0.1317148208618164\n",
      "\n",
      "     96600\t  0.131396\t  0.131715\t  0.190412\t\tCURRENT LEARNING RATE: 0.19011099739926718\n",
      "previous_iter_valid_loss : 0.28204140067100525\n",
      "\n",
      "     96700\t  0.281506\t  0.282041\t  0.191935\t\tCURRENT LEARNING RATE: 0.18992098142568936\n",
      "previous_iter_valid_loss : 0.20393121242523193\n",
      "\n",
      "     96800\t  0.203796\t  0.203931\t  0.189425\t\tCURRENT LEARNING RATE: 0.18973115537310878\n",
      "previous_iter_valid_loss : 0.1254459023475647\n",
      "\n",
      "     96900\t  0.125442\t  0.125446\t  0.188816\t\tCURRENT LEARNING RATE: 0.18954151905169941\n",
      "previous_iter_valid_loss : 0.13739530742168427\n",
      "\n",
      "     97000\t  0.137141\t  0.137395\t  0.188502\t\tCURRENT LEARNING RATE: 0.18935207227182488\n",
      "previous_iter_valid_loss : 0.21051743626594543\n",
      "\n",
      "     97100\t  0.209939\t  0.210517\t  0.188396\t\tCURRENT LEARNING RATE: 0.1891628148440384\n",
      "previous_iter_valid_loss : 0.24645565450191498\n",
      "\n",
      "     97200\t  0.246319\t  0.246456\t  0.189635\t\tCURRENT LEARNING RATE: 0.18897374657908253\n",
      "previous_iter_valid_loss : 0.2030620276927948\n",
      "\n",
      "     97300\t  0.202595\t  0.203062\t  0.189947\t\tCURRENT LEARNING RATE: 0.18878486728788899\n",
      "previous_iter_valid_loss : 0.18793939054012299\n",
      "\n",
      "     97400\t  0.187688\t  0.187939\t  0.190265\t\tCURRENT LEARNING RATE: 0.18859617678157847\n",
      "previous_iter_valid_loss : 0.19112075865268707\n",
      "\n",
      "     97500\t  0.191245\t  0.191121\t  0.189990\t\tCURRENT LEARNING RATE: 0.18840767487146043\n",
      "previous_iter_valid_loss : 0.13042695820331573\n",
      "\n",
      "     97600\t  0.130564\t  0.130427\t  0.189805\t\tCURRENT LEARNING RATE: 0.18821936136903297\n",
      "previous_iter_valid_loss : 0.1971427947282791\n",
      "\n",
      "     97700\t  0.197753\t  0.197143\t  0.189825\t\tCURRENT LEARNING RATE: 0.18803123608598257\n",
      "previous_iter_valid_loss : 0.15852659940719604\n",
      "\n",
      "     97800\t  0.158746\t  0.158527\t  0.190046\t\tCURRENT LEARNING RATE: 0.18784329883418394\n",
      "previous_iter_valid_loss : 0.09990742057561874\n",
      "\n",
      "     97900\t  0.100107\t  0.099907\t  0.188575\t\tCURRENT LEARNING RATE: 0.18765554942569979\n",
      "previous_iter_valid_loss : 0.149430051445961\n",
      "\n",
      "     98000\t  0.149621\t  0.149430\t  0.188271\t\tCURRENT LEARNING RATE: 0.18746798767278067\n",
      "previous_iter_valid_loss : 0.18232423067092896\n",
      "\n",
      "     98100\t  0.182163\t  0.182324\t  0.188650\t\tCURRENT LEARNING RATE: 0.1872806133878649\n",
      "previous_iter_valid_loss : 0.1835341602563858\n",
      "\n",
      "     98200\t  0.183310\t  0.183534\t  0.189116\t\tCURRENT LEARNING RATE: 0.18709342638357807\n",
      "previous_iter_valid_loss : 0.16812248528003693\n",
      "\n",
      "     98300\t  0.168328\t  0.168122\t  0.188875\t\tCURRENT LEARNING RATE: 0.18690642647273326\n",
      "previous_iter_valid_loss : 0.18040330708026886\n",
      "\n",
      "     98400\t  0.180403\t  0.180403\t  0.188944\t\tCURRENT LEARNING RATE: 0.18671961346833046\n",
      "previous_iter_valid_loss : 0.20185516774654388\n",
      "\n",
      "     98500\t  0.201646\t  0.201855\t  0.187802\t\tCURRENT LEARNING RATE: 0.1865329871835567\n",
      "previous_iter_valid_loss : 0.14311394095420837\n",
      "\n",
      "     98600\t  0.143431\t  0.143114\t  0.187536\t\tCURRENT LEARNING RATE: 0.1863465474317857\n",
      "previous_iter_valid_loss : 0.12086272239685059\n",
      "\n",
      "     98700\t  0.120716\t  0.120863\t  0.186289\t\tCURRENT LEARNING RATE: 0.1861602940265776\n",
      "previous_iter_valid_loss : 0.15772825479507446\n",
      "\n",
      "     98800\t  0.157479\t  0.157728\t  0.186251\t\tCURRENT LEARNING RATE: 0.1859742267816791\n",
      "previous_iter_valid_loss : 0.14175890386104584\n",
      "\n",
      "     98900\t  0.141830\t  0.141759\t  0.184607\t\tCURRENT LEARNING RATE: 0.18578834551102286\n",
      "previous_iter_valid_loss : 0.14585259556770325\n",
      "\n",
      "     99000\t  0.145999\t  0.145853\t  0.184304\t\tCURRENT LEARNING RATE: 0.18560265002872758\n",
      "previous_iter_valid_loss : 0.15916596353054047\n",
      "\n",
      "     99100\t  0.159495\t  0.159166\t  0.184212\t\tCURRENT LEARNING RATE: 0.18541714014909783\n",
      "previous_iter_valid_loss : 0.11449739336967468\n",
      "\n",
      "     99200\t  0.114393\t  0.114497\t  0.183376\t\tCURRENT LEARNING RATE: 0.18523181568662367\n",
      "previous_iter_valid_loss : 0.19128091633319855\n",
      "\n",
      "     99300\t  0.191566\t  0.191281\t  0.183890\t\tCURRENT LEARNING RATE: 0.18504667645598064\n",
      "previous_iter_valid_loss : 0.1559116542339325\n",
      "\n",
      "     99400\t  0.156215\t  0.155912\t  0.183485\t\tCURRENT LEARNING RATE: 0.1848617222720295\n",
      "previous_iter_valid_loss : 0.14578700065612793\n",
      "\n",
      "     99500\t  0.145860\t  0.145787\t  0.183799\t\tCURRENT LEARNING RATE: 0.184676952949816\n",
      "previous_iter_valid_loss : 0.13325147330760956\n",
      "\n",
      "     99600\t  0.133018\t  0.133251\t  0.183264\t\tCURRENT LEARNING RATE: 0.1844923683045709\n",
      "previous_iter_valid_loss : 0.13035964965820312\n",
      "\n",
      "     99700\t  0.130435\t  0.130360\t  0.182695\t\tCURRENT LEARNING RATE: 0.1843079681517094\n",
      "previous_iter_valid_loss : 0.1657290756702423\n",
      "\n",
      "     99800\t  0.165818\t  0.165729\t  0.182528\t\tCURRENT LEARNING RATE: 0.18412375230683145\n",
      "previous_iter_valid_loss : 0.14804790914058685\n",
      "\n",
      "     99900\t  0.148057\t  0.148048\t  0.182681\t\tCURRENT LEARNING RATE: 0.18393972058572117\n",
      "previous_iter_valid_loss : 0.16299866139888763\n",
      "\n",
      "    100000\t  0.163010\t  0.162999\t  0.181800\t\tCURRENT LEARNING RATE: 0.1837558728043468\n",
      "previous_iter_valid_loss : 0.22129228711128235\n",
      "\n",
      "    100100\t  0.221581\t  0.221292\t  0.182010\t\tCURRENT LEARNING RATE: 0.18357220877886052\n",
      "previous_iter_valid_loss : 0.23278243839740753\n",
      "\n",
      "    100200\t  0.232857\t  0.232782\t  0.182595\t\tCURRENT LEARNING RATE: 0.18338872832559833\n",
      "previous_iter_valid_loss : 0.22742298245429993\n",
      "\n",
      "    100300\t  0.227572\t  0.227423\t  0.182557\t\tCURRENT LEARNING RATE: 0.18320543126107974\n",
      "previous_iter_valid_loss : 0.11634564399719238\n",
      "\n",
      "    100400\t  0.116200\t  0.116346\t  0.181970\t\tCURRENT LEARNING RATE: 0.1830223174020077\n",
      "previous_iter_valid_loss : 0.1385367214679718\n",
      "\n",
      "    100500\t  0.139060\t  0.138537\t  0.181492\t\tCURRENT LEARNING RATE: 0.18283938656526827\n",
      "previous_iter_valid_loss : 0.12789574265480042\n",
      "\n",
      "    100600\t  0.127797\t  0.127896\t  0.181056\t\tCURRENT LEARNING RATE: 0.18265663856793068\n",
      "previous_iter_valid_loss : 0.12832632660865784\n",
      "\n",
      "    100700\t  0.128376\t  0.128326\t  0.180512\t\tCURRENT LEARNING RATE: 0.18247407322724687\n",
      "previous_iter_valid_loss : 0.13165351748466492\n",
      "\n",
      "    100800\t  0.131777\t  0.131654\t  0.179359\t\tCURRENT LEARNING RATE: 0.18229169036065151\n",
      "previous_iter_valid_loss : 0.15809720754623413\n",
      "\n",
      "    100900\t  0.158275\t  0.158097\t  0.178895\t\tCURRENT LEARNING RATE: 0.18210948978576166\n",
      "previous_iter_valid_loss : 0.14172634482383728\n",
      "\n",
      "    101000\t  0.141876\t  0.141726\t  0.178925\t\tCURRENT LEARNING RATE: 0.18192747132037682\n",
      "previous_iter_valid_loss : 0.12308412045240402\n",
      "\n",
      "    101100\t  0.123325\t  0.123084\t  0.178391\t\tCURRENT LEARNING RATE: 0.1817456347824784\n",
      "previous_iter_valid_loss : 0.25514936447143555\n",
      "\n",
      "    101200\t  0.255144\t  0.255149\t  0.179555\t\tCURRENT LEARNING RATE: 0.18156397999022997\n",
      "previous_iter_valid_loss : 0.13461057841777802\n",
      "\n",
      "    101300\t  0.134615\t  0.134611\t  0.177705\t\tCURRENT LEARNING RATE: 0.18138250676197662\n",
      "previous_iter_valid_loss : 0.12084795534610748\n",
      "\n",
      "    101400\t  0.120997\t  0.120848\t  0.176458\t\tCURRENT LEARNING RATE: 0.1812012149162452\n",
      "previous_iter_valid_loss : 0.14349809288978577\n",
      "\n",
      "    101500\t  0.143218\t  0.143498\t  0.176339\t\tCURRENT LEARNING RATE: 0.18102010427174373\n",
      "previous_iter_valid_loss : 0.13839790225028992\n",
      "\n",
      "    101600\t  0.138481\t  0.138398\t  0.175242\t\tCURRENT LEARNING RATE: 0.18083917464736166\n",
      "previous_iter_valid_loss : 0.18705765902996063\n",
      "\n",
      "    101700\t  0.186750\t  0.187058\t  0.173692\t\tCURRENT LEARNING RATE: 0.18065842586216926\n",
      "previous_iter_valid_loss : 0.12396161258220673\n",
      "\n",
      "    101800\t  0.124048\t  0.123962\t  0.172217\t\tCURRENT LEARNING RATE: 0.18047785773541783\n",
      "previous_iter_valid_loss : 0.11206773668527603\n",
      "\n",
      "    101900\t  0.112029\t  0.112068\t  0.171474\t\tCURRENT LEARNING RATE: 0.18029747008653915\n",
      "previous_iter_valid_loss : 0.12514062225818634\n",
      "\n",
      "    102000\t  0.125009\t  0.125141\t  0.169609\t\tCURRENT LEARNING RATE: 0.1801172627351456\n",
      "previous_iter_valid_loss : 0.11398830264806747\n",
      "\n",
      "    102100\t  0.113693\t  0.113988\t  0.168869\t\tCURRENT LEARNING RATE: 0.17993723550102977\n",
      "previous_iter_valid_loss : 0.12000573426485062\n",
      "\n",
      "    102200\t  0.119933\t  0.120006\t  0.168896\t\tCURRENT LEARNING RATE: 0.17975738820416445\n",
      "previous_iter_valid_loss : 0.12326301634311676\n",
      "\n",
      "    102300\t  0.123280\t  0.123263\t  0.168778\t\tCURRENT LEARNING RATE: 0.1795777206647023\n",
      "previous_iter_valid_loss : 0.13229280710220337\n",
      "\n",
      "    102400\t  0.131998\t  0.132293\t  0.168636\t\tCURRENT LEARNING RATE: 0.1793982327029758\n",
      "previous_iter_valid_loss : 0.1314980685710907\n",
      "\n",
      "    102500\t  0.131015\t  0.131498\t  0.168418\t\tCURRENT LEARNING RATE: 0.17921892413949694\n",
      "previous_iter_valid_loss : 0.20184984803199768\n",
      "\n",
      "    102600\t  0.201586\t  0.201850\t  0.168608\t\tCURRENT LEARNING RATE: 0.17903979479495719\n",
      "previous_iter_valid_loss : 0.1621532142162323\n",
      "\n",
      "    102700\t  0.161937\t  0.162153\t  0.168525\t\tCURRENT LEARNING RATE: 0.1788608444902271\n",
      "previous_iter_valid_loss : 0.10868050903081894\n",
      "\n",
      "    102800\t  0.109023\t  0.108681\t  0.167945\t\tCURRENT LEARNING RATE: 0.17868207304635644\n",
      "previous_iter_valid_loss : 0.14518241584300995\n",
      "\n",
      "    102900\t  0.145520\t  0.145182\t  0.167971\t\tCURRENT LEARNING RATE: 0.1785034802845737\n",
      "previous_iter_valid_loss : 0.11676174402236938\n",
      "\n",
      "    103000\t  0.117104\t  0.116762\t  0.167177\t\tCURRENT LEARNING RATE: 0.17832506602628612\n",
      "previous_iter_valid_loss : 0.16160063445568085\n",
      "\n",
      "    103100\t  0.161833\t  0.161601\t  0.166755\t\tCURRENT LEARNING RATE: 0.1781468300930794\n",
      "previous_iter_valid_loss : 0.17675887048244476\n",
      "\n",
      "    103200\t  0.177278\t  0.176759\t  0.167252\t\tCURRENT LEARNING RATE: 0.17796877230671768\n",
      "previous_iter_valid_loss : 0.132703498005867\n",
      "\n",
      "    103300\t  0.132835\t  0.132703\t  0.166906\t\tCURRENT LEARNING RATE: 0.17779089248914307\n",
      "previous_iter_valid_loss : 0.11316339671611786\n",
      "\n",
      "    103400\t  0.113365\t  0.113163\t  0.165884\t\tCURRENT LEARNING RATE: 0.17761319046247576\n",
      "previous_iter_valid_loss : 0.12128333747386932\n",
      "\n",
      "    103500\t  0.121658\t  0.121283\t  0.163847\t\tCURRENT LEARNING RATE: 0.1774356660490137\n",
      "previous_iter_valid_loss : 0.11738641560077667\n",
      "\n",
      "    103600\t  0.117547\t  0.117386\t  0.163211\t\tCURRENT LEARNING RATE: 0.17725831907123252\n",
      "previous_iter_valid_loss : 0.13893002271652222\n",
      "\n",
      "    103700\t  0.139383\t  0.138930\t  0.163285\t\tCURRENT LEARNING RATE: 0.17708114935178512\n",
      "previous_iter_valid_loss : 0.13712021708488464\n",
      "\n",
      "    103800\t  0.137468\t  0.137120\t  0.163062\t\tCURRENT LEARNING RATE: 0.17690415671350188\n",
      "previous_iter_valid_loss : 0.12376021593809128\n",
      "\n",
      "    103900\t  0.124080\t  0.123760\t  0.162560\t\tCURRENT LEARNING RATE: 0.17672734097939008\n",
      "previous_iter_valid_loss : 0.12573717534542084\n",
      "\n",
      "    104000\t  0.125982\t  0.125737\t  0.161804\t\tCURRENT LEARNING RATE: 0.176550701972634\n",
      "previous_iter_valid_loss : 0.11557183414697647\n",
      "\n",
      "    104100\t  0.115864\t  0.115572\t  0.160603\t\tCURRENT LEARNING RATE: 0.17637423951659456\n",
      "previous_iter_valid_loss : 0.10170970112085342\n",
      "\n",
      "    104200\t  0.101929\t  0.101710\t  0.159286\t\tCURRENT LEARNING RATE: 0.17619795343480937\n",
      "previous_iter_valid_loss : 0.2079937607049942\n",
      "\n",
      "    104300\t  0.208539\t  0.207994\t  0.159704\t\tCURRENT LEARNING RATE: 0.1760218435509923\n",
      "previous_iter_valid_loss : 0.12764884531497955\n",
      "\n",
      "    104400\t  0.127905\t  0.127649\t  0.159165\t\tCURRENT LEARNING RATE: 0.17584590968903346\n",
      "previous_iter_valid_loss : 0.09952046722173691\n",
      "\n",
      "    104500\t  0.099502\t  0.099520\t  0.158728\t\tCURRENT LEARNING RATE: 0.1756701516729989\n",
      "previous_iter_valid_loss : 0.13960687816143036\n",
      "\n",
      "    104600\t  0.140151\t  0.139607\t  0.158421\t\tCURRENT LEARNING RATE: 0.17549456932713073\n",
      "previous_iter_valid_loss : 0.1024702936410904\n",
      "\n",
      "    104700\t  0.102620\t  0.102470\t  0.157162\t\tCURRENT LEARNING RATE: 0.17531916247584647\n",
      "previous_iter_valid_loss : 0.12539586424827576\n",
      "\n",
      "    104800\t  0.125798\t  0.125396\t  0.156265\t\tCURRENT LEARNING RATE: 0.1751439309437393\n",
      "previous_iter_valid_loss : 0.1261250376701355\n",
      "\n",
      "    104900\t  0.126299\t  0.126125\t  0.156130\t\tCURRENT LEARNING RATE: 0.17496887455557766\n",
      "previous_iter_valid_loss : 0.10072938352823257\n",
      "\n",
      "    105000\t  0.100980\t  0.100729\t  0.155148\t\tCURRENT LEARNING RATE: 0.1747939931363052\n",
      "previous_iter_valid_loss : 0.12535984814167023\n",
      "\n",
      "    105100\t  0.125940\t  0.125360\t  0.153309\t\tCURRENT LEARNING RATE: 0.1746192865110404\n",
      "previous_iter_valid_loss : 0.12305554002523422\n",
      "\n",
      "    105200\t  0.123159\t  0.123056\t  0.152467\t\tCURRENT LEARNING RATE: 0.17444475450507668\n",
      "previous_iter_valid_loss : 0.19587203860282898\n",
      "\n",
      "    105300\t  0.195836\t  0.195872\t  0.152773\t\tCURRENT LEARNING RATE: 0.174270396943882\n",
      "previous_iter_valid_loss : 0.13674665987491608\n",
      "\n",
      "    105400\t  0.136442\t  0.136747\t  0.152616\t\tCURRENT LEARNING RATE: 0.1740962136530988\n",
      "previous_iter_valid_loss : 0.12852677702903748\n",
      "\n",
      "    105500\t  0.128412\t  0.128527\t  0.152146\t\tCURRENT LEARNING RATE: 0.1739222044585437\n",
      "previous_iter_valid_loss : 0.09602806717157364\n",
      "\n",
      "    105600\t  0.095958\t  0.096028\t  0.151384\t\tCURRENT LEARNING RATE: 0.17374836918620762\n",
      "previous_iter_valid_loss : 0.19518554210662842\n",
      "\n",
      "    105700\t  0.195612\t  0.195186\t  0.150908\t\tCURRENT LEARNING RATE: 0.17357470766225516\n",
      "previous_iter_valid_loss : 0.09569922089576721\n",
      "\n",
      "    105800\t  0.095665\t  0.095699\t  0.149956\t\tCURRENT LEARNING RATE: 0.17340121971302488\n",
      "previous_iter_valid_loss : 0.1059425100684166\n",
      "\n",
      "    105900\t  0.106072\t  0.105943\t  0.149085\t\tCURRENT LEARNING RATE: 0.1732279051650287\n",
      "previous_iter_valid_loss : 0.1015143170952797\n",
      "\n",
      "    106000\t  0.101588\t  0.101514\t  0.148126\t\tCURRENT LEARNING RATE: 0.1730547638449522\n",
      "previous_iter_valid_loss : 0.26718711853027344\n",
      "\n",
      "    106100\t  0.267542\t  0.267187\t  0.149671\t\tCURRENT LEARNING RATE: 0.17288179557965389\n",
      "previous_iter_valid_loss : 0.1597471833229065\n",
      "\n",
      "    106200\t  0.160369\t  0.159747\t  0.149953\t\tCURRENT LEARNING RATE: 0.1727090001961656\n",
      "previous_iter_valid_loss : 0.13012175261974335\n",
      "\n",
      "    106300\t  0.129847\t  0.130122\t  0.149556\t\tCURRENT LEARNING RATE: 0.17253637752169187\n",
      "previous_iter_valid_loss : 0.12239893525838852\n",
      "\n",
      "    106400\t  0.122662\t  0.122399\t  0.149678\t\tCURRENT LEARNING RATE: 0.1723639273836101\n",
      "previous_iter_valid_loss : 0.1357364058494568\n",
      "\n",
      "    106500\t  0.135545\t  0.135736\t  0.149455\t\tCURRENT LEARNING RATE: 0.17219164960947\n",
      "previous_iter_valid_loss : 0.10680807381868362\n",
      "\n",
      "    106600\t  0.106557\t  0.106808\t  0.149206\t\tCURRENT LEARNING RATE: 0.17201954402699393\n",
      "previous_iter_valid_loss : 0.10258922725915909\n",
      "\n",
      "    106700\t  0.102329\t  0.102589\t  0.147412\t\tCURRENT LEARNING RATE: 0.17184761046407618\n",
      "previous_iter_valid_loss : 0.12186530977487564\n",
      "\n",
      "    106800\t  0.121730\t  0.121865\t  0.146591\t\tCURRENT LEARNING RATE: 0.17167584874878325\n",
      "previous_iter_valid_loss : 0.1692519634962082\n",
      "\n",
      "    106900\t  0.169604\t  0.169252\t  0.147029\t\tCURRENT LEARNING RATE: 0.17150425870935332\n",
      "previous_iter_valid_loss : 0.0914575457572937\n",
      "\n",
      "    107000\t  0.091315\t  0.091458\t  0.146570\t\tCURRENT LEARNING RATE: 0.17133284017419645\n",
      "previous_iter_valid_loss : 0.12231606245040894\n",
      "\n",
      "    107100\t  0.122008\t  0.122316\t  0.145688\t\tCURRENT LEARNING RATE: 0.17116159297189398\n",
      "previous_iter_valid_loss : 0.09120550751686096\n",
      "\n",
      "    107200\t  0.091060\t  0.091206\t  0.144135\t\tCURRENT LEARNING RATE: 0.1709905169311988\n",
      "previous_iter_valid_loss : 0.11308813840150833\n",
      "\n",
      "    107300\t  0.112809\t  0.113088\t  0.143236\t\tCURRENT LEARNING RATE: 0.17081961188103473\n",
      "previous_iter_valid_loss : 0.09784871339797974\n",
      "\n",
      "    107400\t  0.097874\t  0.097849\t  0.142335\t\tCURRENT LEARNING RATE: 0.17064887765049686\n",
      "previous_iter_valid_loss : 0.12488959729671478\n",
      "\n",
      "    107500\t  0.125070\t  0.124890\t  0.141672\t\tCURRENT LEARNING RATE: 0.17047831406885078\n",
      "previous_iter_valid_loss : 0.2374844253063202\n",
      "\n",
      "    107600\t  0.237350\t  0.237484\t  0.142743\t\tCURRENT LEARNING RATE: 0.17030792096553304\n",
      "previous_iter_valid_loss : 0.09017588943243027\n",
      "\n",
      "    107700\t  0.090018\t  0.090176\t  0.141673\t\tCURRENT LEARNING RATE: 0.1701376981701504\n",
      "previous_iter_valid_loss : 0.13004127144813538\n",
      "\n",
      "    107800\t  0.129890\t  0.130041\t  0.141388\t\tCURRENT LEARNING RATE: 0.16996764551248017\n",
      "previous_iter_valid_loss : 0.14308324456214905\n",
      "\n",
      "    107900\t  0.142790\t  0.143083\t  0.141820\t\tCURRENT LEARNING RATE: 0.16979776282246956\n",
      "previous_iter_valid_loss : 0.10064512491226196\n",
      "\n",
      "    108000\t  0.100409\t  0.100645\t  0.141332\t\tCURRENT LEARNING RATE: 0.16962804993023597\n",
      "previous_iter_valid_loss : 0.12329329550266266\n",
      "\n",
      "    108100\t  0.123007\t  0.123293\t  0.140742\t\tCURRENT LEARNING RATE: 0.1694585066660664\n",
      "previous_iter_valid_loss : 0.17825299501419067\n",
      "\n",
      "    108200\t  0.178030\t  0.178253\t  0.140689\t\tCURRENT LEARNING RATE: 0.16928913286041766\n",
      "previous_iter_valid_loss : 0.15192148089408875\n",
      "\n",
      "    108300\t  0.152272\t  0.151921\t  0.140527\t\tCURRENT LEARNING RATE: 0.16911992834391584\n",
      "previous_iter_valid_loss : 0.11048858612775803\n",
      "\n",
      "    108400\t  0.110788\t  0.110489\t  0.139828\t\tCURRENT LEARNING RATE: 0.16895089294735652\n",
      "previous_iter_valid_loss : 0.11598425358533859\n",
      "\n",
      "    108500\t  0.116227\t  0.115984\t  0.138969\t\tCURRENT LEARNING RATE: 0.16878202650170418\n",
      "previous_iter_valid_loss : 0.15849286317825317\n",
      "\n",
      "    108600\t  0.158289\t  0.158493\t  0.139123\t\tCURRENT LEARNING RATE: 0.16861332883809244\n",
      "previous_iter_valid_loss : 0.0902954488992691\n",
      "\n",
      "    108700\t  0.090278\t  0.090295\t  0.138817\t\tCURRENT LEARNING RATE: 0.16844479978782353\n",
      "previous_iter_valid_loss : 0.1253690868616104\n",
      "\n",
      "    108800\t  0.125104\t  0.125369\t  0.138494\t\tCURRENT LEARNING RATE: 0.1682764391823685\n",
      "previous_iter_valid_loss : 0.14617018401622772\n",
      "\n",
      "    108900\t  0.146560\t  0.146170\t  0.138538\t\tCURRENT LEARNING RATE: 0.16810824685336667\n",
      "previous_iter_valid_loss : 0.08831244707107544\n",
      "\n",
      "    109000\t  0.088205\t  0.088312\t  0.137963\t\tCURRENT LEARNING RATE: 0.1679402226326257\n",
      "previous_iter_valid_loss : 0.10041341930627823\n",
      "\n",
      "    109100\t  0.100388\t  0.100413\t  0.137375\t\tCURRENT LEARNING RATE: 0.16777236635212134\n",
      "previous_iter_valid_loss : 0.10782178491353989\n",
      "\n",
      "    109200\t  0.107537\t  0.107822\t  0.137308\t\tCURRENT LEARNING RATE: 0.16760467784399732\n",
      "previous_iter_valid_loss : 0.11182118952274323\n",
      "\n",
      "    109300\t  0.111531\t  0.111821\t  0.136514\t\tCURRENT LEARNING RATE: 0.1674371569405651\n",
      "previous_iter_valid_loss : 0.10829515010118484\n",
      "\n",
      "    109400\t  0.108104\t  0.108295\t  0.136037\t\tCURRENT LEARNING RATE: 0.1672698034743038\n",
      "previous_iter_valid_loss : 0.12993158400058746\n",
      "\n",
      "    109500\t  0.129761\t  0.129932\t  0.135879\t\tCURRENT LEARNING RATE: 0.16710261727785988\n",
      "previous_iter_valid_loss : 0.11116406321525574\n",
      "\n",
      "    109600\t  0.111064\t  0.111164\t  0.135658\t\tCURRENT LEARNING RATE: 0.1669355981840472\n",
      "previous_iter_valid_loss : 0.11119458824396133\n",
      "\n",
      "    109700\t  0.110890\t  0.111195\t  0.135466\t\tCURRENT LEARNING RATE: 0.1667687460258466\n",
      "previous_iter_valid_loss : 0.12124545872211456\n",
      "\n",
      "    109800\t  0.120929\t  0.121245\t  0.135022\t\tCURRENT LEARNING RATE: 0.16660206063640592\n",
      "previous_iter_valid_loss : 0.1544499546289444\n",
      "\n",
      "    109900\t  0.154839\t  0.154450\t  0.135086\t\tCURRENT LEARNING RATE: 0.16643554184903978\n",
      "previous_iter_valid_loss : 0.152427077293396\n",
      "\n",
      "    110000\t  0.152811\t  0.152427\t  0.134980\t\tCURRENT LEARNING RATE: 0.16626918949722935\n",
      "previous_iter_valid_loss : 0.10406351834535599\n",
      "\n",
      "    110100\t  0.104042\t  0.104064\t  0.133808\t\tCURRENT LEARNING RATE: 0.16610300341462222\n",
      "previous_iter_valid_loss : 0.13318435847759247\n",
      "\n",
      "    110200\t  0.133427\t  0.133184\t  0.132812\t\tCURRENT LEARNING RATE: 0.16593698343503244\n",
      "previous_iter_valid_loss : 0.09918411076068878\n",
      "\n",
      "    110300\t  0.099251\t  0.099184\t  0.131529\t\tCURRENT LEARNING RATE: 0.16577112939243985\n",
      "previous_iter_valid_loss : 0.1268506795167923\n",
      "\n",
      "    110400\t  0.127418\t  0.126851\t  0.131634\t\tCURRENT LEARNING RATE: 0.1656054411209905\n",
      "previous_iter_valid_loss : 0.08722826838493347\n",
      "\n",
      "    110500\t  0.087082\t  0.087228\t  0.131121\t\tCURRENT LEARNING RATE: 0.16543991845499603\n",
      "previous_iter_valid_loss : 0.11054015904664993\n",
      "\n",
      "    110600\t  0.110637\t  0.110540\t  0.130948\t\tCURRENT LEARNING RATE: 0.16527456122893386\n",
      "previous_iter_valid_loss : 0.1286126971244812\n",
      "\n",
      "    110700\t  0.128874\t  0.128613\t  0.130951\t\tCURRENT LEARNING RATE: 0.16510936927744665\n",
      "previous_iter_valid_loss : 0.09895416349172592\n",
      "\n",
      "    110800\t  0.098758\t  0.098954\t  0.130624\t\tCURRENT LEARNING RATE: 0.1649443424353425\n",
      "previous_iter_valid_loss : 0.1167871281504631\n",
      "\n",
      "    110900\t  0.116669\t  0.116787\t  0.130210\t\tCURRENT LEARNING RATE: 0.16477948053759453\n",
      "previous_iter_valid_loss : 0.09447026252746582\n",
      "\n",
      "    111000\t  0.094510\t  0.094470\t  0.129738\t\tCURRENT LEARNING RATE: 0.16461478341934083\n",
      "previous_iter_valid_loss : 0.10042651742696762\n",
      "\n",
      "    111100\t  0.100263\t  0.100427\t  0.129511\t\tCURRENT LEARNING RATE: 0.16445025091588425\n",
      "previous_iter_valid_loss : 0.10655266046524048\n",
      "\n",
      "    111200\t  0.106430\t  0.106553\t  0.128025\t\tCURRENT LEARNING RATE: 0.1642858828626923\n",
      "previous_iter_valid_loss : 0.17418783903121948\n",
      "\n",
      "    111300\t  0.173970\t  0.174188\t  0.128421\t\tCURRENT LEARNING RATE: 0.16412167909539688\n",
      "previous_iter_valid_loss : 0.14468729496002197\n",
      "\n",
      "    111400\t  0.144874\t  0.144687\t  0.128660\t\tCURRENT LEARNING RATE: 0.16395763944979427\n",
      "previous_iter_valid_loss : 0.1284545511007309\n",
      "\n",
      "    111500\t  0.128675\t  0.128455\t  0.128509\t\tCURRENT LEARNING RATE: 0.16379376376184476\n",
      "previous_iter_valid_loss : 0.17437702417373657\n",
      "\n",
      "    111600\t  0.174199\t  0.174377\t  0.128869\t\tCURRENT LEARNING RATE: 0.16363005186767265\n",
      "previous_iter_valid_loss : 0.1317915916442871\n",
      "\n",
      "    111700\t  0.131959\t  0.131792\t  0.128316\t\tCURRENT LEARNING RATE: 0.16346650360356604\n",
      "previous_iter_valid_loss : 0.12583810091018677\n",
      "\n",
      "    111800\t  0.126124\t  0.125838\t  0.128335\t\tCURRENT LEARNING RATE: 0.1633031188059767\n",
      "previous_iter_valid_loss : 0.09138841181993484\n",
      "\n",
      "    111900\t  0.091343\t  0.091388\t  0.128128\t\tCURRENT LEARNING RATE: 0.16313989731151973\n",
      "previous_iter_valid_loss : 0.11025916039943695\n",
      "\n",
      "    112000\t  0.110468\t  0.110259\t  0.127979\t\tCURRENT LEARNING RATE: 0.16297683895697368\n",
      "previous_iter_valid_loss : 0.10638720542192459\n",
      "\n",
      "    112100\t  0.106370\t  0.106387\t  0.127903\t\tCURRENT LEARNING RATE: 0.16281394357928017\n",
      "previous_iter_valid_loss : 0.125003844499588\n",
      "\n",
      "    112200\t  0.125148\t  0.125004\t  0.127953\t\tCURRENT LEARNING RATE: 0.1626512110155438\n",
      "previous_iter_valid_loss : 0.13715492188930511\n",
      "\n",
      "    112300\t  0.137467\t  0.137155\t  0.128092\t\tCURRENT LEARNING RATE: 0.162488641103032\n",
      "previous_iter_valid_loss : 0.09430032968521118\n",
      "\n",
      "    112400\t  0.094297\t  0.094300\t  0.127712\t\tCURRENT LEARNING RATE: 0.16232623367917487\n",
      "previous_iter_valid_loss : 0.09532544016838074\n",
      "\n",
      "    112500\t  0.095240\t  0.095325\t  0.127351\t\tCURRENT LEARNING RATE: 0.16216398858156494\n",
      "previous_iter_valid_loss : 0.1362486183643341\n",
      "\n",
      "    112600\t  0.136528\t  0.136249\t  0.126695\t\tCURRENT LEARNING RATE: 0.16200190564795708\n",
      "previous_iter_valid_loss : 0.1350267231464386\n",
      "\n",
      "    112700\t  0.135413\t  0.135027\t  0.126423\t\tCURRENT LEARNING RATE: 0.1618399847162684\n",
      "previous_iter_valid_loss : 0.12882982194423676\n",
      "\n",
      "    112800\t  0.129140\t  0.128830\t  0.126625\t\tCURRENT LEARNING RATE: 0.16167822562457787\n",
      "previous_iter_valid_loss : 0.17014320194721222\n",
      "\n",
      "    112900\t  0.170690\t  0.170143\t  0.126874\t\tCURRENT LEARNING RATE: 0.16151662821112647\n",
      "previous_iter_valid_loss : 0.08649896085262299\n",
      "\n",
      "    113000\t  0.086410\t  0.086499\t  0.126572\t\tCURRENT LEARNING RATE: 0.16135519231431675\n",
      "previous_iter_valid_loss : 0.11256613582372665\n",
      "\n",
      "    113100\t  0.112782\t  0.112566\t  0.126081\t\tCURRENT LEARNING RATE: 0.16119391777271277\n",
      "previous_iter_valid_loss : 0.12231222540140152\n",
      "\n",
      "    113200\t  0.122679\t  0.122312\t  0.125537\t\tCURRENT LEARNING RATE: 0.16103280442504\n",
      "previous_iter_valid_loss : 0.18640649318695068\n",
      "\n",
      "    113300\t  0.187095\t  0.186406\t  0.126074\t\tCURRENT LEARNING RATE: 0.1608718521101851\n",
      "previous_iter_valid_loss : 0.10659375041723251\n",
      "\n",
      "    113400\t  0.106869\t  0.106594\t  0.126008\t\tCURRENT LEARNING RATE: 0.16071106066719568\n",
      "previous_iter_valid_loss : 0.10638224333524704\n",
      "\n",
      "    113500\t  0.106586\t  0.106382\t  0.125859\t\tCURRENT LEARNING RATE: 0.16055042993528035\n",
      "previous_iter_valid_loss : 0.10555055737495422\n",
      "\n",
      "    113600\t  0.105551\t  0.105551\t  0.125741\t\tCURRENT LEARNING RATE: 0.1603899597538083\n",
      "previous_iter_valid_loss : 0.10863770544528961\n",
      "\n",
      "    113700\t  0.108385\t  0.108638\t  0.125438\t\tCURRENT LEARNING RATE: 0.1602296499623094\n",
      "previous_iter_valid_loss : 0.09166733175516129\n",
      "\n",
      "    113800\t  0.091461\t  0.091667\t  0.124984\t\tCURRENT LEARNING RATE: 0.1600695004004738\n",
      "previous_iter_valid_loss : 0.1178738996386528\n",
      "\n",
      "    113900\t  0.118003\t  0.117874\t  0.124925\t\tCURRENT LEARNING RATE: 0.15990951090815197\n",
      "previous_iter_valid_loss : 0.13821908831596375\n",
      "\n",
      "    114000\t  0.138616\t  0.138219\t  0.125049\t\tCURRENT LEARNING RATE: 0.15974968132535433\n",
      "previous_iter_valid_loss : 0.14106668531894684\n",
      "\n",
      "    114100\t  0.141389\t  0.141067\t  0.125304\t\tCURRENT LEARNING RATE: 0.15959001149225135\n",
      "previous_iter_valid_loss : 0.18682746589183807\n",
      "\n",
      "    114200\t  0.187282\t  0.186827\t  0.126156\t\tCURRENT LEARNING RATE: 0.15943050124917316\n",
      "previous_iter_valid_loss : 0.12291908264160156\n",
      "\n",
      "    114300\t  0.123155\t  0.122919\t  0.125305\t\tCURRENT LEARNING RATE: 0.1592711504366095\n",
      "previous_iter_valid_loss : 0.13128255307674408\n",
      "\n",
      "    114400\t  0.131485\t  0.131283\t  0.125341\t\tCURRENT LEARNING RATE: 0.15911195889520954\n",
      "previous_iter_valid_loss : 0.1814076453447342\n",
      "\n",
      "    114500\t  0.181829\t  0.181408\t  0.126160\t\tCURRENT LEARNING RATE: 0.15895292646578177\n",
      "previous_iter_valid_loss : 0.12952446937561035\n",
      "\n",
      "    114600\t  0.129252\t  0.129524\t  0.126059\t\tCURRENT LEARNING RATE: 0.15879405298929367\n",
      "previous_iter_valid_loss : 0.149509996175766\n",
      "\n",
      "    114700\t  0.149236\t  0.149510\t  0.126530\t\tCURRENT LEARNING RATE: 0.15863533830687182\n",
      "previous_iter_valid_loss : 0.09373236447572708\n",
      "\n",
      "    114800\t  0.093503\t  0.093732\t  0.126213\t\tCURRENT LEARNING RATE: 0.15847678225980147\n",
      "previous_iter_valid_loss : 0.18506677448749542\n",
      "\n",
      "    114900\t  0.184928\t  0.185067\t  0.126802\t\tCURRENT LEARNING RATE: 0.15831838468952664\n",
      "previous_iter_valid_loss : 0.1109861508011818\n",
      "\n",
      "    115000\t  0.110880\t  0.110986\t  0.126905\t\tCURRENT LEARNING RATE: 0.1581601454376496\n",
      "previous_iter_valid_loss : 0.11261726915836334\n",
      "\n",
      "    115100\t  0.112317\t  0.112617\t  0.126778\t\tCURRENT LEARNING RATE: 0.15800206434593128\n",
      "previous_iter_valid_loss : 0.09774032980203629\n",
      "\n",
      "    115200\t  0.097693\t  0.097740\t  0.126524\t\tCURRENT LEARNING RATE: 0.1578441412562904\n",
      "previous_iter_valid_loss : 0.4049408733844757\n",
      "\n",
      "    115300\t  0.404746\t  0.404941\t  0.128615\t\tCURRENT LEARNING RATE: 0.15768637601080399\n",
      "previous_iter_valid_loss : 0.1630212366580963\n",
      "\n",
      "    115400\t  0.163454\t  0.163021\t  0.128878\t\tCURRENT LEARNING RATE: 0.15752876845170666\n",
      "previous_iter_valid_loss : 0.10722161084413528\n",
      "\n",
      "    115500\t  0.107299\t  0.107222\t  0.128665\t\tCURRENT LEARNING RATE: 0.15737131842139096\n",
      "previous_iter_valid_loss : 0.17586775124073029\n",
      "\n",
      "    115600\t  0.175657\t  0.175868\t  0.129463\t\tCURRENT LEARNING RATE: 0.15721402576240678\n",
      "previous_iter_valid_loss : 0.12260197848081589\n",
      "\n",
      "    115700\t  0.122342\t  0.122602\t  0.128737\t\tCURRENT LEARNING RATE: 0.15705689031746148\n",
      "previous_iter_valid_loss : 0.10055746138095856\n",
      "\n",
      "    115800\t  0.100616\t  0.100557\t  0.128786\t\tCURRENT LEARNING RATE: 0.15689991192941954\n",
      "previous_iter_valid_loss : 0.11848422884941101\n",
      "\n",
      "    115900\t  0.118323\t  0.118484\t  0.128911\t\tCURRENT LEARNING RATE: 0.15674309044130266\n",
      "previous_iter_valid_loss : 0.18689578771591187\n",
      "\n",
      "    116000\t  0.186708\t  0.186896\t  0.129765\t\tCURRENT LEARNING RATE: 0.15658642569628925\n",
      "previous_iter_valid_loss : 0.11342363059520721\n",
      "\n",
      "    116100\t  0.113366\t  0.113424\t  0.128228\t\tCURRENT LEARNING RATE: 0.1564299175377146\n",
      "previous_iter_valid_loss : 0.09353107959032059\n",
      "\n",
      "    116200\t  0.093482\t  0.093531\t  0.127565\t\tCURRENT LEARNING RATE: 0.1562735658090705\n",
      "previous_iter_valid_loss : 0.09799788892269135\n",
      "\n",
      "    116300\t  0.097790\t  0.097998\t  0.127244\t\tCURRENT LEARNING RATE: 0.15611737035400527\n",
      "previous_iter_valid_loss : 0.09741555154323578\n",
      "\n",
      "    116400\t  0.097506\t  0.097416\t  0.126994\t\tCURRENT LEARNING RATE: 0.15596133101632337\n",
      "previous_iter_valid_loss : 0.12633392214775085\n",
      "\n",
      "    116500\t  0.126366\t  0.126334\t  0.126900\t\tCURRENT LEARNING RATE: 0.15580544763998552\n",
      "previous_iter_valid_loss : 0.12619152665138245\n",
      "\n",
      "    116600\t  0.126435\t  0.126192\t  0.127094\t\tCURRENT LEARNING RATE: 0.15564972006910824\n",
      "previous_iter_valid_loss : 0.10046686232089996\n",
      "\n",
      "    116700\t  0.100571\t  0.100467\t  0.127073\t\tCURRENT LEARNING RATE: 0.15549414814796406\n",
      "previous_iter_valid_loss : 0.08491676300764084\n",
      "\n",
      "    116800\t  0.084938\t  0.084917\t  0.126703\t\tCURRENT LEARNING RATE: 0.15533873172098092\n",
      "previous_iter_valid_loss : 0.1420454978942871\n",
      "\n",
      "    116900\t  0.142415\t  0.142045\t  0.126431\t\tCURRENT LEARNING RATE: 0.15518347063274252\n",
      "previous_iter_valid_loss : 0.09212662279605865\n",
      "\n",
      "    117000\t  0.092182\t  0.092127\t  0.126438\t\tCURRENT LEARNING RATE: 0.15502836472798762\n",
      "previous_iter_valid_loss : 0.09919921308755875\n",
      "\n",
      "    117100\t  0.099305\t  0.099199\t  0.126207\t\tCURRENT LEARNING RATE: 0.1548734138516104\n",
      "previous_iter_valid_loss : 0.108446404337883\n",
      "\n",
      "    117200\t  0.108392\t  0.108446\t  0.126379\t\tCURRENT LEARNING RATE: 0.15471861784865992\n",
      "previous_iter_valid_loss : 0.09342872351408005\n",
      "\n",
      "    117300\t  0.093501\t  0.093429\t  0.126183\t\tCURRENT LEARNING RATE: 0.1545639765643402\n",
      "previous_iter_valid_loss : 0.13588127493858337\n",
      "\n",
      "    117400\t  0.136151\t  0.135881\t  0.126563\t\tCURRENT LEARNING RATE: 0.15440948984400993\n",
      "previous_iter_valid_loss : 0.13684609532356262\n",
      "\n",
      "    117500\t  0.137246\t  0.136846\t  0.126683\t\tCURRENT LEARNING RATE: 0.15425515753318236\n",
      "previous_iter_valid_loss : 0.1089121475815773\n",
      "\n",
      "    117600\t  0.109066\t  0.108912\t  0.125397\t\tCURRENT LEARNING RATE: 0.15410097947752516\n",
      "previous_iter_valid_loss : 0.12272854894399643\n",
      "\n",
      "    117700\t  0.122984\t  0.122729\t  0.125722\t\tCURRENT LEARNING RATE: 0.1539469555228603\n",
      "previous_iter_valid_loss : 0.12334617227315903\n",
      "\n",
      "    117800\t  0.123676\t  0.123346\t  0.125655\t\tCURRENT LEARNING RATE: 0.1537930855151638\n",
      "previous_iter_valid_loss : 0.12426043301820755\n",
      "\n",
      "    117900\t  0.124545\t  0.124260\t  0.125467\t\tCURRENT LEARNING RATE: 0.15363936930056563\n",
      "previous_iter_valid_loss : 0.13830922544002533\n",
      "\n",
      "    118000\t  0.138727\t  0.138309\t  0.125844\t\tCURRENT LEARNING RATE: 0.15348580672534953\n",
      "previous_iter_valid_loss : 0.1283835768699646\n",
      "\n",
      "    118100\t  0.128736\t  0.128384\t  0.125895\t\tCURRENT LEARNING RATE: 0.153332397635953\n",
      "previous_iter_valid_loss : 0.1271432787179947\n",
      "\n",
      "    118200\t  0.127555\t  0.127143\t  0.125384\t\tCURRENT LEARNING RATE: 0.15317914187896683\n",
      "previous_iter_valid_loss : 0.18797259032726288\n",
      "\n",
      "    118300\t  0.188634\t  0.187973\t  0.125744\t\tCURRENT LEARNING RATE: 0.15302603930113534\n",
      "previous_iter_valid_loss : 0.12097248435020447\n",
      "\n",
      "    118400\t  0.121263\t  0.120972\t  0.125849\t\tCURRENT LEARNING RATE: 0.15287308974935587\n",
      "previous_iter_valid_loss : 0.12659063935279846\n",
      "\n",
      "    118500\t  0.126948\t  0.126591\t  0.125955\t\tCURRENT LEARNING RATE: 0.15272029307067894\n",
      "previous_iter_valid_loss : 0.11028759181499481\n",
      "\n",
      "    118600\t  0.110537\t  0.110288\t  0.125473\t\tCURRENT LEARNING RATE: 0.15256764911230775\n",
      "previous_iter_valid_loss : 0.1378633677959442\n",
      "\n",
      "    118700\t  0.138264\t  0.137863\t  0.125949\t\tCURRENT LEARNING RATE: 0.15241515772159842\n",
      "previous_iter_valid_loss : 0.20056647062301636\n",
      "\n",
      "    118800\t  0.201253\t  0.200566\t  0.126701\t\tCURRENT LEARNING RATE: 0.1522628187460595\n",
      "previous_iter_valid_loss : 0.10064695030450821\n",
      "\n",
      "    118900\t  0.100786\t  0.100647\t  0.126245\t\tCURRENT LEARNING RATE: 0.15211063203335204\n",
      "previous_iter_valid_loss : 0.11038476973772049\n",
      "\n",
      "    119000\t  0.110593\t  0.110385\t  0.126466\t\tCURRENT LEARNING RATE: 0.15195859743128926\n",
      "previous_iter_valid_loss : 0.1319819986820221\n",
      "\n",
      "    119100\t  0.132218\t  0.131982\t  0.126782\t\tCURRENT LEARNING RATE: 0.15180671478783658\n",
      "previous_iter_valid_loss : 0.12722960114479065\n",
      "\n",
      "    119200\t  0.127581\t  0.127230\t  0.126976\t\tCURRENT LEARNING RATE: 0.15165498395111132\n",
      "previous_iter_valid_loss : 0.18471792340278625\n",
      "\n",
      "    119300\t  0.185309\t  0.184718\t  0.127705\t\tCURRENT LEARNING RATE: 0.1515034047693827\n",
      "previous_iter_valid_loss : 0.11129757761955261\n",
      "\n",
      "    119400\t  0.111679\t  0.111298\t  0.127735\t\tCURRENT LEARNING RATE: 0.15135197709107143\n",
      "previous_iter_valid_loss : 0.16550661623477936\n",
      "\n",
      "    119500\t  0.166060\t  0.165507\t  0.128091\t\tCURRENT LEARNING RATE: 0.1512007007647499\n",
      "previous_iter_valid_loss : 0.08582711219787598\n",
      "\n",
      "    119600\t  0.085962\t  0.085827\t  0.127837\t\tCURRENT LEARNING RATE: 0.1510495756391417\n",
      "previous_iter_valid_loss : 0.10609927773475647\n",
      "\n",
      "    119700\t  0.106371\t  0.106099\t  0.127786\t\tCURRENT LEARNING RATE: 0.15089860156312174\n",
      "previous_iter_valid_loss : 0.1119694709777832\n",
      "\n",
      "    119800\t  0.112248\t  0.111969\t  0.127694\t\tCURRENT LEARNING RATE: 0.1507477783857159\n",
      "previous_iter_valid_loss : 0.14724913239479065\n",
      "\n",
      "    119900\t  0.147698\t  0.147249\t  0.127622\t\tCURRENT LEARNING RATE: 0.15059710595610107\n",
      "previous_iter_valid_loss : 0.16586458683013916\n",
      "\n",
      "    120000\t  0.166399\t  0.165865\t  0.127756\t\tCURRENT LEARNING RATE: 0.15044658412360468\n",
      "previous_iter_valid_loss : 0.17545044422149658\n",
      "\n",
      "    120100\t  0.176045\t  0.175450\t  0.128470\t\tCURRENT LEARNING RATE: 0.150296212737705\n",
      "previous_iter_valid_loss : 0.12067065387964249\n",
      "\n",
      "    120200\t  0.120998\t  0.120671\t  0.128345\t\tCURRENT LEARNING RATE: 0.15014599164803052\n",
      "previous_iter_valid_loss : 0.08619125187397003\n",
      "\n",
      "    120300\t  0.086294\t  0.086191\t  0.128215\t\tCURRENT LEARNING RATE: 0.14999592070436024\n",
      "previous_iter_valid_loss : 0.10232773423194885\n",
      "\n",
      "    120400\t  0.102530\t  0.102328\t  0.127970\t\tCURRENT LEARNING RATE: 0.14984599975662316\n",
      "previous_iter_valid_loss : 0.11044111847877502\n",
      "\n",
      "    120500\t  0.110730\t  0.110441\t  0.128202\t\tCURRENT LEARNING RATE: 0.14969622865489834\n",
      "previous_iter_valid_loss : 0.1500658094882965\n",
      "\n",
      "    120600\t  0.150516\t  0.150066\t  0.128597\t\tCURRENT LEARNING RATE: 0.14954660724941463\n",
      "previous_iter_valid_loss : 0.11925409734249115\n",
      "\n",
      "    120700\t  0.119569\t  0.119254\t  0.128503\t\tCURRENT LEARNING RATE: 0.14939713539055063\n",
      "previous_iter_valid_loss : 0.1119500920176506\n",
      "\n",
      "    120800\t  0.112213\t  0.111950\t  0.128633\t\tCURRENT LEARNING RATE: 0.14924781292883446\n",
      "previous_iter_valid_loss : 0.18978892266750336\n",
      "\n",
      "    120900\t  0.190404\t  0.189789\t  0.129363\t\tCURRENT LEARNING RATE: 0.1490986397149437\n",
      "previous_iter_valid_loss : 0.1301160454750061\n",
      "\n",
      "    121000\t  0.130434\t  0.130116\t  0.129720\t\tCURRENT LEARNING RATE: 0.14894961559970504\n",
      "previous_iter_valid_loss : 0.12389370054006577\n",
      "\n",
      "    121100\t  0.124218\t  0.123894\t  0.129954\t\tCURRENT LEARNING RATE: 0.14880074043409441\n",
      "previous_iter_valid_loss : 0.12235917896032333\n",
      "\n",
      "    121200\t  0.122684\t  0.122359\t  0.130112\t\tCURRENT LEARNING RATE: 0.1486520140692366\n",
      "previous_iter_valid_loss : 0.17976492643356323\n",
      "\n",
      "    121300\t  0.180341\t  0.179765\t  0.130168\t\tCURRENT LEARNING RATE: 0.14850343635640526\n",
      "previous_iter_valid_loss : 0.12150277197360992\n",
      "\n",
      "    121400\t  0.121823\t  0.121503\t  0.129936\t\tCURRENT LEARNING RATE: 0.14835500714702263\n",
      "previous_iter_valid_loss : 0.12098345160484314\n",
      "\n",
      "    121500\t  0.121294\t  0.120983\t  0.129862\t\tCURRENT LEARNING RATE: 0.14820672629265955\n",
      "previous_iter_valid_loss : 0.10008673369884491\n",
      "\n",
      "    121600\t  0.100331\t  0.100087\t  0.129119\t\tCURRENT LEARNING RATE: 0.14805859364503507\n",
      "previous_iter_valid_loss : 0.13609543442726135\n",
      "\n",
      "    121700\t  0.136473\t  0.136095\t  0.129162\t\tCURRENT LEARNING RATE: 0.1479106090560166\n",
      "previous_iter_valid_loss : 0.13917893171310425\n",
      "\n",
      "    121800\t  0.139588\t  0.139179\t  0.129295\t\tCURRENT LEARNING RATE: 0.1477627723776195\n",
      "previous_iter_valid_loss : 0.1505340337753296\n",
      "\n",
      "    121900\t  0.150991\t  0.150534\t  0.129887\t\tCURRENT LEARNING RATE: 0.1476150834620071\n",
      "previous_iter_valid_loss : 0.09249930828809738\n",
      "\n",
      "    122000\t  0.092577\t  0.092499\t  0.129709\t\tCURRENT LEARNING RATE: 0.14746754216149044\n",
      "previous_iter_valid_loss : 0.1109488233923912\n",
      "\n",
      "    122100\t  0.111134\t  0.110949\t  0.129755\t\tCURRENT LEARNING RATE: 0.14732014832852827\n",
      "previous_iter_valid_loss : 0.10423934459686279\n",
      "\n",
      "    122200\t  0.104457\t  0.104239\t  0.129547\t\tCURRENT LEARNING RATE: 0.14717290181572668\n",
      "previous_iter_valid_loss : 0.10942023247480392\n",
      "\n",
      "    122300\t  0.109612\t  0.109420\t  0.129270\t\tCURRENT LEARNING RATE: 0.14702580247583918\n",
      "previous_iter_valid_loss : 0.15526293218135834\n",
      "\n",
      "    122400\t  0.155672\t  0.155263\t  0.129879\t\tCURRENT LEARNING RATE: 0.14687885016176638\n",
      "previous_iter_valid_loss : 0.10846669226884842\n",
      "\n",
      "    122500\t  0.108676\t  0.108467\t  0.130011\t\tCURRENT LEARNING RATE: 0.14673204472655604\n",
      "previous_iter_valid_loss : 0.11527527868747711\n",
      "\n",
      "    122600\t  0.115509\t  0.115275\t  0.129801\t\tCURRENT LEARNING RATE: 0.1465853860234026\n",
      "previous_iter_valid_loss : 0.17591993510723114\n",
      "\n",
      "    122700\t  0.176486\t  0.175920\t  0.130210\t\tCURRENT LEARNING RATE: 0.14643887390564744\n",
      "previous_iter_valid_loss : 0.1215725839138031\n",
      "\n",
      "    122800\t  0.121909\t  0.121573\t  0.130137\t\tCURRENT LEARNING RATE: 0.14629250822677833\n",
      "previous_iter_valid_loss : 0.12827861309051514\n",
      "\n",
      "    122900\t  0.128540\t  0.128279\t  0.129719\t\tCURRENT LEARNING RATE: 0.1461462888404297\n",
      "previous_iter_valid_loss : 0.12900203466415405\n",
      "\n",
      "    123000\t  0.129287\t  0.129002\t  0.130144\t\tCURRENT LEARNING RATE: 0.14600021560038204\n",
      "previous_iter_valid_loss : 0.13589921593666077\n",
      "\n",
      "    123100\t  0.136223\t  0.135899\t  0.130377\t\tCURRENT LEARNING RATE: 0.1458542883605622\n",
      "previous_iter_valid_loss : 0.15650828182697296\n",
      "\n",
      "    123200\t  0.156956\t  0.156508\t  0.130719\t\tCURRENT LEARNING RATE: 0.14570850697504284\n",
      "previous_iter_valid_loss : 0.11465165764093399\n",
      "\n",
      "    123300\t  0.114853\t  0.114652\t  0.130002\t\tCURRENT LEARNING RATE: 0.1455628712980426\n",
      "previous_iter_valid_loss : 0.14828351140022278\n",
      "\n",
      "    123400\t  0.148680\t  0.148284\t  0.130418\t\tCURRENT LEARNING RATE: 0.14541738118392578\n",
      "previous_iter_valid_loss : 0.10635284334421158\n",
      "\n",
      "    123500\t  0.106609\t  0.106353\t  0.130418\t\tCURRENT LEARNING RATE: 0.1452720364872023\n",
      "previous_iter_valid_loss : 0.09778626263141632\n",
      "\n",
      "    123600\t  0.097916\t  0.097786\t  0.130340\t\tCURRENT LEARNING RATE: 0.14512683706252735\n",
      "previous_iter_valid_loss : 0.1010560616850853\n",
      "\n",
      "    123700\t  0.101264\t  0.101056\t  0.130265\t\tCURRENT LEARNING RATE: 0.1449817827647016\n",
      "previous_iter_valid_loss : 0.10111985355615616\n",
      "\n",
      "    123800\t  0.101303\t  0.101120\t  0.130359\t\tCURRENT LEARNING RATE: 0.1448368734486707\n",
      "previous_iter_valid_loss : 0.11799091845750809\n",
      "\n",
      "    123900\t  0.118211\t  0.117991\t  0.130360\t\tCURRENT LEARNING RATE: 0.1446921089695253\n",
      "previous_iter_valid_loss : 0.151885524392128\n",
      "\n",
      "    124000\t  0.152304\t  0.151886\t  0.130497\t\tCURRENT LEARNING RATE: 0.14454748918250093\n",
      "previous_iter_valid_loss : 0.1004459485411644\n",
      "\n",
      "    124100\t  0.100631\t  0.100446\t  0.130091\t\tCURRENT LEARNING RATE: 0.14440301394297783\n",
      "previous_iter_valid_loss : 0.1408047080039978\n",
      "\n",
      "    124200\t  0.141142\t  0.140805\t  0.129631\t\tCURRENT LEARNING RATE: 0.14425868310648066\n",
      "previous_iter_valid_loss : 0.10456471145153046\n",
      "\n",
      "    124300\t  0.104725\t  0.104565\t  0.129447\t\tCURRENT LEARNING RATE: 0.14411449652867864\n",
      "previous_iter_valid_loss : 0.11875458061695099\n",
      "\n",
      "    124400\t  0.118985\t  0.118755\t  0.129322\t\tCURRENT LEARNING RATE: 0.1439704540653851\n",
      "previous_iter_valid_loss : 0.1112070307135582\n",
      "\n",
      "    124500\t  0.111363\t  0.111207\t  0.128620\t\tCURRENT LEARNING RATE: 0.1438265555725577\n",
      "previous_iter_valid_loss : 0.10027699917554855\n",
      "\n",
      "    124600\t  0.100330\t  0.100277\t  0.128327\t\tCURRENT LEARNING RATE: 0.14368280090629781\n",
      "previous_iter_valid_loss : 0.12016692757606506\n",
      "\n",
      "    124700\t  0.120401\t  0.120167\t  0.128034\t\tCURRENT LEARNING RATE: 0.14353918992285084\n",
      "previous_iter_valid_loss : 0.11817193031311035\n",
      "\n",
      "    124800\t  0.118370\t  0.118172\t  0.128278\t\tCURRENT LEARNING RATE: 0.1433957224786057\n",
      "previous_iter_valid_loss : 0.20388802886009216\n",
      "\n",
      "    124900\t  0.204419\t  0.203888\t  0.128467\t\tCURRENT LEARNING RATE: 0.14325239843009505\n",
      "previous_iter_valid_loss : 0.0929480567574501\n",
      "\n",
      "    125000\t  0.093004\t  0.092948\t  0.128286\t\tCURRENT LEARNING RATE: 0.14310921763399476\n",
      "previous_iter_valid_loss : 0.1674785614013672\n",
      "\n",
      "    125100\t  0.167878\t  0.167479\t  0.128835\t\tCURRENT LEARNING RATE: 0.142966179947124\n",
      "previous_iter_valid_loss : 0.12168639898300171\n",
      "\n",
      "    125200\t  0.121882\t  0.121686\t  0.129074\t\tCURRENT LEARNING RATE: 0.1428232852264451\n",
      "previous_iter_valid_loss : 0.14929400384426117\n",
      "\n",
      "    125300\t  0.149697\t  0.149294\t  0.126518\t\tCURRENT LEARNING RATE: 0.14268053332906333\n",
      "previous_iter_valid_loss : 0.14704987406730652\n",
      "\n",
      "    125400\t  0.147423\t  0.147050\t  0.126358\t\tCURRENT LEARNING RATE: 0.1425379241122268\n",
      "previous_iter_valid_loss : 0.1269991397857666\n",
      "\n",
      "    125500\t  0.127262\t  0.126999\t  0.126556\t\tCURRENT LEARNING RATE: 0.14239545743332624\n",
      "previous_iter_valid_loss : 0.11331004649400711\n",
      "\n",
      "    125600\t  0.113418\t  0.113310\t  0.125930\t\tCURRENT LEARNING RATE: 0.142253133149895\n",
      "previous_iter_valid_loss : 0.12142812460660934\n",
      "\n",
      "    125700\t  0.121657\t  0.121428\t  0.125918\t\tCURRENT LEARNING RATE: 0.14211095111960872\n",
      "previous_iter_valid_loss : 0.13337746262550354\n",
      "\n",
      "    125800\t  0.133658\t  0.133377\t  0.126247\t\tCURRENT LEARNING RATE: 0.14196891120028546\n",
      "previous_iter_valid_loss : 0.1083306297659874\n",
      "\n",
      "    125900\t  0.108463\t  0.108331\t  0.126145\t\tCURRENT LEARNING RATE: 0.1418270132498852\n",
      "previous_iter_valid_loss : 0.11256500333547592\n",
      "\n",
      "    126000\t  0.112761\t  0.112565\t  0.125402\t\tCURRENT LEARNING RATE: 0.14168525712651\n",
      "previous_iter_valid_loss : 0.1209566742181778\n",
      "\n",
      "    126100\t  0.121222\t  0.120957\t  0.125477\t\tCURRENT LEARNING RATE: 0.14154364268840375\n",
      "previous_iter_valid_loss : 0.11984950304031372\n",
      "\n",
      "    126200\t  0.120115\t  0.119850\t  0.125740\t\tCURRENT LEARNING RATE: 0.14140216979395198\n",
      "previous_iter_valid_loss : 0.09381544589996338\n",
      "\n",
      "    126300\t  0.093831\t  0.093815\t  0.125699\t\tCURRENT LEARNING RATE: 0.1412608383016818\n",
      "previous_iter_valid_loss : 0.12453900277614594\n",
      "\n",
      "    126400\t  0.124800\t  0.124539\t  0.125970\t\tCURRENT LEARNING RATE: 0.14111964807026167\n",
      "previous_iter_valid_loss : 0.14950169622898102\n",
      "\n",
      "    126500\t  0.149896\t  0.149502\t  0.126201\t\tCURRENT LEARNING RATE: 0.14097859895850137\n",
      "previous_iter_valid_loss : 0.16216044127941132\n",
      "\n",
      "    126600\t  0.162618\t  0.162160\t  0.126561\t\tCURRENT LEARNING RATE: 0.1408376908253518\n",
      "previous_iter_valid_loss : 0.11735494434833527\n",
      "\n",
      "    126700\t  0.117544\t  0.117355\t  0.126730\t\tCURRENT LEARNING RATE: 0.14069692352990476\n",
      "previous_iter_valid_loss : 0.10747639089822769\n",
      "\n",
      "    126800\t  0.107626\t  0.107476\t  0.126956\t\tCURRENT LEARNING RATE: 0.14055629693139302\n",
      "previous_iter_valid_loss : 0.09776758402585983\n",
      "\n",
      "    126900\t  0.097778\t  0.097768\t  0.126513\t\tCURRENT LEARNING RATE: 0.1404158108891899\n",
      "previous_iter_valid_loss : 0.13152340054512024\n",
      "\n",
      "    127000\t  0.131807\t  0.131523\t  0.126907\t\tCURRENT LEARNING RATE: 0.14027546526280937\n",
      "previous_iter_valid_loss : 0.13885143399238586\n",
      "\n",
      "    127100\t  0.139205\t  0.138851\t  0.127303\t\tCURRENT LEARNING RATE: 0.14013525991190579\n",
      "previous_iter_valid_loss : 0.14944683015346527\n",
      "\n",
      "    127200\t  0.150008\t  0.149447\t  0.127713\t\tCURRENT LEARNING RATE: 0.1399951946962738\n",
      "previous_iter_valid_loss : 0.09993390738964081\n",
      "\n",
      "    127300\t  0.100045\t  0.099934\t  0.127778\t\tCURRENT LEARNING RATE: 0.13985526947584817\n",
      "previous_iter_valid_loss : 0.09429573267698288\n",
      "\n",
      "    127400\t  0.094375\t  0.094296\t  0.127362\t\tCURRENT LEARNING RATE: 0.13971548411070367\n",
      "previous_iter_valid_loss : 0.11798711121082306\n",
      "\n",
      "    127500\t  0.118219\t  0.117987\t  0.127174\t\tCURRENT LEARNING RATE: 0.13957583846105492\n",
      "previous_iter_valid_loss : 0.12872964143753052\n",
      "\n",
      "    127600\t  0.129088\t  0.128730\t  0.127372\t\tCURRENT LEARNING RATE: 0.13943633238725628\n",
      "previous_iter_valid_loss : 0.11751227080821991\n",
      "\n",
      "    127700\t  0.117762\t  0.117512\t  0.127320\t\tCURRENT LEARNING RATE: 0.13929696574980163\n",
      "previous_iter_valid_loss : 0.11576514691114426\n",
      "\n",
      "    127800\t  0.115953\t  0.115765\t  0.127244\t\tCURRENT LEARNING RATE: 0.13915773840932436\n",
      "previous_iter_valid_loss : 0.10640173405408859\n",
      "\n",
      "    127900\t  0.106542\t  0.106402\t  0.127065\t\tCURRENT LEARNING RATE: 0.13901865022659707\n",
      "previous_iter_valid_loss : 0.11581845581531525\n",
      "\n",
      "    128000\t  0.116034\t  0.115818\t  0.126841\t\tCURRENT LEARNING RATE: 0.1388797010625316\n",
      "previous_iter_valid_loss : 0.12186022102832794\n",
      "\n",
      "    128100\t  0.122093\t  0.121860\t  0.126775\t\tCURRENT LEARNING RATE: 0.13874089077817875\n",
      "previous_iter_valid_loss : 0.13527631759643555\n",
      "\n",
      "    128200\t  0.135615\t  0.135276\t  0.126857\t\tCURRENT LEARNING RATE: 0.1386022192347283\n",
      "previous_iter_valid_loss : 0.18178890645503998\n",
      "\n",
      "    128300\t  0.182380\t  0.181789\t  0.126795\t\tCURRENT LEARNING RATE: 0.13846368629350855\n",
      "previous_iter_valid_loss : 0.1036216989159584\n",
      "\n",
      "    128400\t  0.103767\t  0.103622\t  0.126621\t\tCURRENT LEARNING RATE: 0.1383252918159867\n",
      "previous_iter_valid_loss : 0.10909412801265717\n",
      "\n",
      "    128500\t  0.109329\t  0.109094\t  0.126446\t\tCURRENT LEARNING RATE: 0.13818703566376817\n",
      "previous_iter_valid_loss : 0.09752624481916428\n",
      "\n",
      "    128600\t  0.097644\t  0.097526\t  0.126319\t\tCURRENT LEARNING RATE: 0.1380489176985968\n",
      "previous_iter_valid_loss : 0.09491732716560364\n",
      "\n",
      "    128700\t  0.094965\t  0.094917\t  0.125889\t\tCURRENT LEARNING RATE: 0.13791093778235466\n",
      "previous_iter_valid_loss : 0.11889542639255524\n",
      "\n",
      "    128800\t  0.119109\t  0.118895\t  0.125073\t\tCURRENT LEARNING RATE: 0.1377730957770618\n",
      "previous_iter_valid_loss : 0.1274736225605011\n",
      "\n",
      "    128900\t  0.127699\t  0.127474\t  0.125341\t\tCURRENT LEARNING RATE: 0.13763539154487617\n",
      "previous_iter_valid_loss : 0.10552455484867096\n",
      "\n",
      "    129000\t  0.105657\t  0.105525\t  0.125292\t\tCURRENT LEARNING RATE: 0.13749782494809357\n",
      "previous_iter_valid_loss : 0.1351998746395111\n",
      "\n",
      "    129100\t  0.135440\t  0.135200\t  0.125324\t\tCURRENT LEARNING RATE: 0.13736039584914736\n",
      "previous_iter_valid_loss : 0.09738190472126007\n",
      "\n",
      "    129200\t  0.097507\t  0.097382\t  0.125026\t\tCURRENT LEARNING RATE: 0.13722310411060848\n",
      "previous_iter_valid_loss : 0.20272767543792725\n",
      "\n",
      "    129300\t  0.203368\t  0.202728\t  0.125206\t\tCURRENT LEARNING RATE: 0.1370859495951851\n",
      "previous_iter_valid_loss : 0.12489543110132217\n",
      "\n",
      "    129400\t  0.125150\t  0.124895\t  0.125342\t\tCURRENT LEARNING RATE: 0.1369489321657228\n",
      "previous_iter_valid_loss : 0.11901169270277023\n",
      "\n",
      "    129500\t  0.119263\t  0.119012\t  0.124877\t\tCURRENT LEARNING RATE: 0.13681205168520402\n",
      "previous_iter_valid_loss : 0.095335453748703\n",
      "\n",
      "    129600\t  0.095472\t  0.095335\t  0.124972\t\tCURRENT LEARNING RATE: 0.13667530801674838\n",
      "previous_iter_valid_loss : 0.13446971774101257\n",
      "\n",
      "    129700\t  0.134795\t  0.134470\t  0.125256\t\tCURRENT LEARNING RATE: 0.1365387010236121\n",
      "previous_iter_valid_loss : 0.22764258086681366\n",
      "\n",
      "    129800\t  0.228192\t  0.227643\t  0.126413\t\tCURRENT LEARNING RATE: 0.13640223056918824\n",
      "previous_iter_valid_loss : 0.15818698704242706\n",
      "\n",
      "    129900\t  0.158636\t  0.158187\t  0.126522\t\tCURRENT LEARNING RATE: 0.1362658965170063\n",
      "previous_iter_valid_loss : 0.12914998829364777\n",
      "\n",
      "    130000\t  0.129478\t  0.129150\t  0.126155\t\tCURRENT LEARNING RATE: 0.13612969873073225\n",
      "previous_iter_valid_loss : 0.13072934746742249\n",
      "\n",
      "    130100\t  0.131085\t  0.130729\t  0.125708\t\tCURRENT LEARNING RATE: 0.13599363707416826\n",
      "previous_iter_valid_loss : 0.1509305089712143\n",
      "\n",
      "    130200\t  0.151305\t  0.150931\t  0.126010\t\tCURRENT LEARNING RATE: 0.13585771141125272\n",
      "previous_iter_valid_loss : 0.09803703427314758\n",
      "\n",
      "    130300\t  0.098147\t  0.098037\t  0.126129\t\tCURRENT LEARNING RATE: 0.13572192160605986\n",
      "previous_iter_valid_loss : 0.12436570227146149\n",
      "\n",
      "    130400\t  0.124598\t  0.124366\t  0.126349\t\tCURRENT LEARNING RATE: 0.13558626752279995\n",
      "previous_iter_valid_loss : 0.14748430252075195\n",
      "\n",
      "    130500\t  0.147856\t  0.147484\t  0.126719\t\tCURRENT LEARNING RATE: 0.13545074902581883\n",
      "previous_iter_valid_loss : 0.09961345791816711\n",
      "\n",
      "    130600\t  0.099706\t  0.099613\t  0.126215\t\tCURRENT LEARNING RATE: 0.13531536597959806\n",
      "previous_iter_valid_loss : 0.15794123709201813\n",
      "\n",
      "    130700\t  0.158397\t  0.157941\t  0.126602\t\tCURRENT LEARNING RATE: 0.1351801182487545\n",
      "previous_iter_valid_loss : 0.12433898448944092\n",
      "\n",
      "    130800\t  0.124665\t  0.124339\t  0.126726\t\tCURRENT LEARNING RATE: 0.1350450056980405\n",
      "previous_iter_valid_loss : 0.11214813590049744\n",
      "\n",
      "    130900\t  0.112348\t  0.112148\t  0.125949\t\tCURRENT LEARNING RATE: 0.1349100281923434\n",
      "previous_iter_valid_loss : 0.13372854888439178\n",
      "\n",
      "    131000\t  0.134016\t  0.133729\t  0.125985\t\tCURRENT LEARNING RATE: 0.1347751855966858\n",
      "previous_iter_valid_loss : 0.11950695514678955\n",
      "\n",
      "    131100\t  0.119738\t  0.119507\t  0.125942\t\tCURRENT LEARNING RATE: 0.13464047777622498\n",
      "previous_iter_valid_loss : 0.12724918127059937\n",
      "\n",
      "    131200\t  0.127495\t  0.127249\t  0.125990\t\tCURRENT LEARNING RATE: 0.1345059045962532\n",
      "previous_iter_valid_loss : 0.10320974141359329\n",
      "\n",
      "    131300\t  0.103379\t  0.103210\t  0.125225\t\tCURRENT LEARNING RATE: 0.13437146592219718\n",
      "previous_iter_valid_loss : 0.11426509916782379\n",
      "\n",
      "    131400\t  0.114517\t  0.114265\t  0.125153\t\tCURRENT LEARNING RATE: 0.1342371616196183\n",
      "previous_iter_valid_loss : 0.08872941881418228\n",
      "\n",
      "    131500\t  0.088760\t  0.088729\t  0.124830\t\tCURRENT LEARNING RATE: 0.1341029915542122\n",
      "previous_iter_valid_loss : 0.13377238810062408\n",
      "\n",
      "    131600\t  0.134069\t  0.133772\t  0.125167\t\tCURRENT LEARNING RATE: 0.13396895559180888\n",
      "previous_iter_valid_loss : 0.09000800549983978\n",
      "\n",
      "    131700\t  0.090134\t  0.090008\t  0.124706\t\tCURRENT LEARNING RATE: 0.13383505359837228\n",
      "previous_iter_valid_loss : 0.14114631712436676\n",
      "\n",
      "    131800\t  0.141498\t  0.141146\t  0.124726\t\tCURRENT LEARNING RATE: 0.13370128544000046\n",
      "previous_iter_valid_loss : 0.11897598206996918\n",
      "\n",
      "    131900\t  0.119309\t  0.118976\t  0.124410\t\tCURRENT LEARNING RATE: 0.13356765098292517\n",
      "previous_iter_valid_loss : 0.11453618854284286\n",
      "\n",
      "    132000\t  0.114737\t  0.114536\t  0.124630\t\tCURRENT LEARNING RATE: 0.13343415009351206\n",
      "previous_iter_valid_loss : 0.1331833302974701\n",
      "\n",
      "    132100\t  0.133518\t  0.133183\t  0.124853\t\tCURRENT LEARNING RATE: 0.1333007826382601\n",
      "previous_iter_valid_loss : 0.1503438502550125\n",
      "\n",
      "    132200\t  0.150729\t  0.150344\t  0.125314\t\tCURRENT LEARNING RATE: 0.13316754848380194\n",
      "previous_iter_valid_loss : 0.1444435864686966\n",
      "\n",
      "    132300\t  0.144810\t  0.144444\t  0.125664\t\tCURRENT LEARNING RATE: 0.13303444749690332\n",
      "previous_iter_valid_loss : 0.08754622936248779\n",
      "\n",
      "    132400\t  0.087586\t  0.087546\t  0.124987\t\tCURRENT LEARNING RATE: 0.1329014795444633\n",
      "previous_iter_valid_loss : 0.11684447526931763\n",
      "\n",
      "    132500\t  0.117016\t  0.116844\t  0.125071\t\tCURRENT LEARNING RATE: 0.1327686444935139\n",
      "previous_iter_valid_loss : 0.1337926834821701\n",
      "\n",
      "    132600\t  0.134070\t  0.133793\t  0.125256\t\tCURRENT LEARNING RATE: 0.13263594221122005\n",
      "previous_iter_valid_loss : 0.10969306528568268\n",
      "\n",
      "    132700\t  0.109874\t  0.109693\t  0.124594\t\tCURRENT LEARNING RATE: 0.13250337256487946\n",
      "previous_iter_valid_loss : 0.08944666385650635\n",
      "\n",
      "    132800\t  0.089474\t  0.089447\t  0.124272\t\tCURRENT LEARNING RATE: 0.13237093542192252\n",
      "previous_iter_valid_loss : 0.11679325252771378\n",
      "\n",
      "    132900\t  0.117037\t  0.116793\t  0.124157\t\tCURRENT LEARNING RATE: 0.13223863064991198\n",
      "previous_iter_valid_loss : 0.1371849626302719\n",
      "\n",
      "    133000\t  0.137554\t  0.137185\t  0.124239\t\tCURRENT LEARNING RATE: 0.13210645811654315\n",
      "previous_iter_valid_loss : 0.11895185708999634\n",
      "\n",
      "    133100\t  0.119141\t  0.118952\t  0.124070\t\tCURRENT LEARNING RATE: 0.1319744176896434\n",
      "previous_iter_valid_loss : 0.12441588938236237\n",
      "\n",
      "    133200\t  0.124647\t  0.124416\t  0.123749\t\tCURRENT LEARNING RATE: 0.1318425092371724\n",
      "previous_iter_valid_loss : 0.14736667275428772\n",
      "\n",
      "    133300\t  0.147709\t  0.147367\t  0.124076\t\tCURRENT LEARNING RATE: 0.13171073262722155\n",
      "previous_iter_valid_loss : 0.10877512395381927\n",
      "\n",
      "    133400\t  0.108954\t  0.108775\t  0.123681\t\tCURRENT LEARNING RATE: 0.13157908772801435\n",
      "previous_iter_valid_loss : 0.13728725910186768\n",
      "\n",
      "    133500\t  0.137612\t  0.137287\t  0.123990\t\tCURRENT LEARNING RATE: 0.13144757440790583\n",
      "previous_iter_valid_loss : 0.18551090359687805\n",
      "\n",
      "    133600\t  0.186051\t  0.185511\t  0.124868\t\tCURRENT LEARNING RATE: 0.13131619253538268\n",
      "previous_iter_valid_loss : 0.0984216034412384\n",
      "\n",
      "    133700\t  0.098621\t  0.098422\t  0.124841\t\tCURRENT LEARNING RATE: 0.131184941979063\n",
      "previous_iter_valid_loss : 0.10742484033107758\n",
      "\n",
      "    133800\t  0.107609\t  0.107425\t  0.124904\t\tCURRENT LEARNING RATE: 0.13105382260769624\n",
      "previous_iter_valid_loss : 0.11039259284734726\n",
      "\n",
      "    133900\t  0.110631\t  0.110393\t  0.124828\t\tCURRENT LEARNING RATE: 0.130922834290163\n",
      "previous_iter_valid_loss : 0.11574549227952957\n",
      "\n",
      "    134000\t  0.115985\t  0.115745\t  0.124467\t\tCURRENT LEARNING RATE: 0.13079197689547498\n",
      "previous_iter_valid_loss : 0.09678581357002258\n",
      "\n",
      "    134100\t  0.096885\t  0.096786\t  0.124430\t\tCURRENT LEARNING RATE: 0.1306612502927747\n",
      "previous_iter_valid_loss : 0.0971696749329567\n",
      "\n",
      "    134200\t  0.097274\t  0.097170\t  0.123994\t\tCURRENT LEARNING RATE: 0.13053065435133565\n",
      "previous_iter_valid_loss : 0.14664499461650848\n",
      "\n",
      "    134300\t  0.147079\t  0.146645\t  0.124415\t\tCURRENT LEARNING RATE: 0.13040018894056182\n",
      "previous_iter_valid_loss : 0.19236670434474945\n",
      "\n",
      "    134400\t  0.192903\t  0.192367\t  0.125151\t\tCURRENT LEARNING RATE: 0.1302698539299878\n",
      "previous_iter_valid_loss : 0.11799095571041107\n",
      "\n",
      "    134500\t  0.118266\t  0.117991\t  0.125219\t\tCURRENT LEARNING RATE: 0.13013964918927856\n",
      "previous_iter_valid_loss : 0.12915198504924774\n",
      "\n",
      "    134600\t  0.129405\t  0.129152\t  0.125507\t\tCURRENT LEARNING RATE: 0.13000957458822937\n",
      "previous_iter_valid_loss : 0.09844539314508438\n",
      "\n",
      "    134700\t  0.098561\t  0.098445\t  0.125290\t\tCURRENT LEARNING RATE: 0.12987962999676556\n",
      "previous_iter_valid_loss : 0.14158256351947784\n",
      "\n",
      "    134800\t  0.141978\t  0.141583\t  0.125524\t\tCURRENT LEARNING RATE: 0.12974981528494262\n",
      "previous_iter_valid_loss : 0.1236167624592781\n",
      "\n",
      "    134900\t  0.123843\t  0.123617\t  0.124722\t\tCURRENT LEARNING RATE: 0.12962013032294575\n",
      "previous_iter_valid_loss : 0.15824484825134277\n",
      "\n",
      "    135000\t  0.158671\t  0.158245\t  0.125375\t\tCURRENT LEARNING RATE: 0.12949057498109\n",
      "previous_iter_valid_loss : 0.12488722801208496\n",
      "\n",
      "    135100\t  0.125083\t  0.124887\t  0.124949\t\tCURRENT LEARNING RATE: 0.12936114912982002\n",
      "previous_iter_valid_loss : 0.09002815186977386\n",
      "\n",
      "    135200\t  0.090108\t  0.090028\t  0.124632\t\tCURRENT LEARNING RATE: 0.12923185263971\n",
      "previous_iter_valid_loss : 0.10473967343568802\n",
      "\n",
      "    135300\t  0.104897\t  0.104740\t  0.124187\t\tCURRENT LEARNING RATE: 0.12910268538146333\n",
      "previous_iter_valid_loss : 0.1026744470000267\n",
      "\n",
      "    135400\t  0.102820\t  0.102674\t  0.123743\t\tCURRENT LEARNING RATE: 0.12897364722591284\n",
      "previous_iter_valid_loss : 0.11494522541761398\n",
      "\n",
      "    135500\t  0.115122\t  0.114945\t  0.123622\t\tCURRENT LEARNING RATE: 0.12884473804402027\n",
      "previous_iter_valid_loss : 0.11642986536026001\n",
      "\n",
      "    135600\t  0.116664\t  0.116430\t  0.123653\t\tCURRENT LEARNING RATE: 0.12871595770687655\n",
      "previous_iter_valid_loss : 0.12522611021995544\n",
      "\n",
      "    135700\t  0.125491\t  0.125226\t  0.123691\t\tCURRENT LEARNING RATE: 0.1285873060857012\n",
      "previous_iter_valid_loss : 0.10471422970294952\n",
      "\n",
      "    135800\t  0.104864\t  0.104714\t  0.123405\t\tCURRENT LEARNING RATE: 0.12845878305184272\n",
      "previous_iter_valid_loss : 0.14860516786575317\n",
      "\n",
      "    135900\t  0.149009\t  0.148605\t  0.123808\t\tCURRENT LEARNING RATE: 0.12833038847677794\n",
      "previous_iter_valid_loss : 0.1449357569217682\n",
      "\n",
      "    136000\t  0.145287\t  0.144936\t  0.124131\t\tCURRENT LEARNING RATE: 0.12820212223211236\n",
      "previous_iter_valid_loss : 0.11832477897405624\n",
      "\n",
      "    136100\t  0.118657\t  0.118325\t  0.124105\t\tCURRENT LEARNING RATE: 0.12807398418957966\n",
      "previous_iter_valid_loss : 0.107134610414505\n",
      "\n",
      "    136200\t  0.107316\t  0.107135\t  0.123978\t\tCURRENT LEARNING RATE: 0.12794597422104187\n",
      "previous_iter_valid_loss : 0.12187795341014862\n",
      "\n",
      "    136300\t  0.122118\t  0.121878\t  0.124258\t\tCURRENT LEARNING RATE: 0.12781809219848891\n",
      "previous_iter_valid_loss : 0.12066608667373657\n",
      "\n",
      "    136400\t  0.120922\t  0.120666\t  0.124220\t\tCURRENT LEARNING RATE: 0.12769033799403884\n",
      "previous_iter_valid_loss : 0.1259130984544754\n",
      "\n",
      "    136500\t  0.126174\t  0.125913\t  0.123984\t\tCURRENT LEARNING RATE: 0.1275627114799374\n",
      "previous_iter_valid_loss : 0.16262377798557281\n",
      "\n",
      "    136600\t  0.162982\t  0.162624\t  0.123988\t\tCURRENT LEARNING RATE: 0.12743521252855808\n",
      "previous_iter_valid_loss : 0.11461346596479416\n",
      "\n",
      "    136700\t  0.114836\t  0.114613\t  0.123961\t\tCURRENT LEARNING RATE: 0.12730784101240186\n",
      "previous_iter_valid_loss : 0.15370459854602814\n",
      "\n",
      "    136800\t  0.154048\t  0.153705\t  0.124423\t\tCURRENT LEARNING RATE: 0.12718059680409732\n",
      "previous_iter_valid_loss : 0.15429359674453735\n",
      "\n",
      "    136900\t  0.154678\t  0.154294\t  0.124989\t\tCURRENT LEARNING RATE: 0.12705347977640014\n",
      "previous_iter_valid_loss : 0.14920352399349213\n",
      "\n",
      "    137000\t  0.149587\t  0.149204\t  0.125165\t\tCURRENT LEARNING RATE: 0.12692648980219334\n",
      "previous_iter_valid_loss : 0.16473937034606934\n",
      "\n",
      "    137100\t  0.165152\t  0.164739\t  0.125424\t\tCURRENT LEARNING RATE: 0.12679962675448692\n",
      "previous_iter_valid_loss : 0.10652052611112595\n",
      "\n",
      "    137200\t  0.106677\t  0.106521\t  0.124995\t\tCURRENT LEARNING RATE: 0.12667289050641783\n",
      "previous_iter_valid_loss : 0.1124633401632309\n",
      "\n",
      "    137300\t  0.112673\t  0.112463\t  0.125120\t\tCURRENT LEARNING RATE: 0.12654628093124978\n",
      "previous_iter_valid_loss : 0.12246332317590714\n",
      "\n",
      "    137400\t  0.122776\t  0.122463\t  0.125402\t\tCURRENT LEARNING RATE: 0.12641979790237323\n",
      "previous_iter_valid_loss : 0.15429328382015228\n",
      "\n",
      "    137500\t  0.154787\t  0.154293\t  0.125765\t\tCURRENT LEARNING RATE: 0.12629344129330514\n",
      "previous_iter_valid_loss : 0.11176881194114685\n",
      "\n",
      "    137600\t  0.111948\t  0.111769\t  0.125595\t\tCURRENT LEARNING RATE: 0.12616721097768882\n",
      "previous_iter_valid_loss : 0.1118231862783432\n",
      "\n",
      "    137700\t  0.112061\t  0.111823\t  0.125538\t\tCURRENT LEARNING RATE: 0.126041106829294\n",
      "previous_iter_valid_loss : 0.10773737728595734\n",
      "\n",
      "    137800\t  0.107885\t  0.107737\t  0.125458\t\tCURRENT LEARNING RATE: 0.12591512872201652\n",
      "previous_iter_valid_loss : 0.09550856798887253\n",
      "\n",
      "    137900\t  0.095584\t  0.095509\t  0.125349\t\tCURRENT LEARNING RATE: 0.12578927652987826\n",
      "previous_iter_valid_loss : 0.1274791806936264\n",
      "\n",
      "    138000\t  0.127824\t  0.127479\t  0.125466\t\tCURRENT LEARNING RATE: 0.125663550127027\n",
      "previous_iter_valid_loss : 0.14347496628761292\n",
      "\n",
      "    138100\t  0.143882\t  0.143475\t  0.125682\t\tCURRENT LEARNING RATE: 0.12553794938773635\n",
      "previous_iter_valid_loss : 0.0946011021733284\n",
      "\n",
      "    138200\t  0.094720\t  0.094601\t  0.125275\t\tCURRENT LEARNING RATE: 0.12541247418640555\n",
      "previous_iter_valid_loss : 0.1472020000219345\n",
      "\n",
      "    138300\t  0.147628\t  0.147202\t  0.124929\t\tCURRENT LEARNING RATE: 0.1252871243975594\n",
      "previous_iter_valid_loss : 0.11627061665058136\n",
      "\n",
      "    138400\t  0.116480\t  0.116271\t  0.125056\t\tCURRENT LEARNING RATE: 0.12516189989584806\n",
      "previous_iter_valid_loss : 0.12240979820489883\n",
      "\n",
      "    138500\t  0.122656\t  0.122410\t  0.125189\t\tCURRENT LEARNING RATE: 0.12503680055604707\n",
      "previous_iter_valid_loss : 0.10308016836643219\n",
      "\n",
      "    138600\t  0.103276\t  0.103080\t  0.125245\t\tCURRENT LEARNING RATE: 0.12491182625305702\n",
      "previous_iter_valid_loss : 0.1570909023284912\n",
      "\n",
      "    138700\t  0.157603\t  0.157091\t  0.125866\t\tCURRENT LEARNING RATE: 0.12478697686190367\n",
      "previous_iter_valid_loss : 0.12411821633577347\n",
      "\n",
      "    138800\t  0.124437\t  0.124118\t  0.125919\t\tCURRENT LEARNING RATE: 0.12466225225773755\n",
      "previous_iter_valid_loss : 0.0921974629163742\n",
      "\n",
      "    138900\t  0.092296\t  0.092197\t  0.125566\t\tCURRENT LEARNING RATE: 0.12453765231583411\n",
      "previous_iter_valid_loss : 0.16097724437713623\n",
      "\n",
      "    139000\t  0.161493\t  0.160977\t  0.126120\t\tCURRENT LEARNING RATE: 0.12441317691159333\n",
      "previous_iter_valid_loss : 0.15973006188869476\n",
      "\n",
      "    139100\t  0.160200\t  0.159730\t  0.126366\t\tCURRENT LEARNING RATE: 0.12428882592053986\n",
      "previous_iter_valid_loss : 0.10731978714466095\n",
      "\n",
      "    139200\t  0.107540\t  0.107320\t  0.126465\t\tCURRENT LEARNING RATE: 0.12416459921832264\n",
      "previous_iter_valid_loss : 0.09831668436527252\n",
      "\n",
      "    139300\t  0.098539\t  0.098317\t  0.125421\t\tCURRENT LEARNING RATE: 0.12404049668071501\n",
      "previous_iter_valid_loss : 0.12353783845901489\n",
      "\n",
      "    139400\t  0.123854\t  0.123538\t  0.125407\t\tCURRENT LEARNING RATE: 0.12391651818361438\n",
      "previous_iter_valid_loss : 0.1312965601682663\n",
      "\n",
      "    139500\t  0.131703\t  0.131297\t  0.125530\t\tCURRENT LEARNING RATE: 0.12379266360304228\n",
      "previous_iter_valid_loss : 0.10355023294687271\n",
      "\n",
      "    139600\t  0.103746\t  0.103550\t  0.125612\t\tCURRENT LEARNING RATE: 0.12366893281514406\n",
      "previous_iter_valid_loss : 0.1177544966340065\n",
      "\n",
      "    139700\t  0.118021\t  0.117754\t  0.125445\t\tCURRENT LEARNING RATE: 0.123545325696189\n",
      "previous_iter_valid_loss : 0.13641013205051422\n",
      "\n",
      "    139800\t  0.136826\t  0.136410\t  0.124533\t\tCURRENT LEARNING RATE: 0.12342184212256992\n",
      "previous_iter_valid_loss : 0.1059710904955864\n",
      "\n",
      "    139900\t  0.106123\t  0.105971\t  0.124011\t\tCURRENT LEARNING RATE: 0.12329848197080324\n",
      "previous_iter_valid_loss : 0.16503693163394928\n",
      "\n",
      "    140000\t  0.165533\t  0.165037\t  0.124370\t\tCURRENT LEARNING RATE: 0.12317524511752881\n",
      "previous_iter_valid_loss : 0.11394104361534119\n",
      "\n",
      "    140100\t  0.114140\t  0.113941\t  0.124202\t\tCURRENT LEARNING RATE: 0.12305213143950977\n",
      "previous_iter_valid_loss : 0.11694588512182236\n",
      "\n",
      "    140200\t  0.117180\t  0.116946\t  0.123862\t\tCURRENT LEARNING RATE: 0.1229291408136324\n",
      "previous_iter_valid_loss : 0.09063531458377838\n",
      "\n",
      "    140300\t  0.090706\t  0.090635\t  0.123788\t\tCURRENT LEARNING RATE: 0.12280627311690613\n",
      "previous_iter_valid_loss : 0.11262853443622589\n",
      "\n",
      "    140400\t  0.112839\t  0.112629\t  0.123670\t\tCURRENT LEARNING RATE: 0.12268352822646317\n",
      "previous_iter_valid_loss : 0.08501824736595154\n",
      "\n",
      "    140500\t  0.085042\t  0.085018\t  0.123046\t\tCURRENT LEARNING RATE: 0.12256090601955869\n",
      "previous_iter_valid_loss : 0.15935268998146057\n",
      "\n",
      "    140600\t  0.159774\t  0.159353\t  0.123643\t\tCURRENT LEARNING RATE: 0.12243840637357041\n",
      "previous_iter_valid_loss : 0.09626463055610657\n",
      "\n",
      "    140700\t  0.096410\t  0.096265\t  0.123026\t\tCURRENT LEARNING RATE: 0.12231602916599875\n",
      "previous_iter_valid_loss : 0.08415491878986359\n",
      "\n",
      "    140800\t  0.084208\t  0.084155\t  0.122625\t\tCURRENT LEARNING RATE: 0.1221937742744664\n",
      "previous_iter_valid_loss : 0.09606083482503891\n",
      "\n",
      "    140900\t  0.096222\t  0.096061\t  0.122464\t\tCURRENT LEARNING RATE: 0.12207164157671856\n",
      "previous_iter_valid_loss : 0.23750562965869904\n",
      "\n",
      "    141000\t  0.238123\t  0.237506\t  0.123501\t\tCURRENT LEARNING RATE: 0.12194963095062242\n",
      "previous_iter_valid_loss : 0.13232780992984772\n",
      "\n",
      "    141100\t  0.132675\t  0.132328\t  0.123630\t\tCURRENT LEARNING RATE: 0.12182774227416743\n",
      "previous_iter_valid_loss : 0.12879377603530884\n",
      "\n",
      "    141200\t  0.129144\t  0.128794\t  0.123645\t\tCURRENT LEARNING RATE: 0.12170597542546484\n",
      "previous_iter_valid_loss : 0.08947395533323288\n",
      "\n",
      "    141300\t  0.089490\t  0.089474\t  0.123508\t\tCURRENT LEARNING RATE: 0.12158433028274783\n",
      "previous_iter_valid_loss : 0.10197246819734573\n",
      "\n",
      "    141400\t  0.101786\t  0.101972\t  0.123385\t\tCURRENT LEARNING RATE: 0.12146280672437122\n",
      "previous_iter_valid_loss : 0.12799154222011566\n",
      "\n",
      "    141500\t  0.127773\t  0.127992\t  0.123777\t\tCURRENT LEARNING RATE: 0.12134140462881149\n",
      "previous_iter_valid_loss : 0.08643782138824463\n",
      "\n",
      "    141600\t  0.086359\t  0.086438\t  0.123304\t\tCURRENT LEARNING RATE: 0.12122012387466646\n",
      "previous_iter_valid_loss : 0.10454250872135162\n",
      "\n",
      "    141700\t  0.104332\t  0.104543\t  0.123449\t\tCURRENT LEARNING RATE: 0.12109896434065545\n",
      "previous_iter_valid_loss : 0.16221565008163452\n",
      "\n",
      "    141800\t  0.162057\t  0.162216\t  0.123660\t\tCURRENT LEARNING RATE: 0.12097792590561883\n",
      "previous_iter_valid_loss : 0.09139695018529892\n",
      "\n",
      "    141900\t  0.091342\t  0.091397\t  0.123384\t\tCURRENT LEARNING RATE: 0.12085700844851822\n",
      "previous_iter_valid_loss : 0.10486498475074768\n",
      "\n",
      "    142000\t  0.104659\t  0.104865\t  0.123288\t\tCURRENT LEARNING RATE: 0.12073621184843612\n",
      "previous_iter_valid_loss : 0.08737251907587051\n",
      "\n",
      "    142100\t  0.087374\t  0.087373\t  0.122830\t\tCURRENT LEARNING RATE: 0.12061553598457596\n",
      "previous_iter_valid_loss : 0.09833559393882751\n",
      "\n",
      "    142200\t  0.098164\t  0.098336\t  0.122309\t\tCURRENT LEARNING RATE: 0.12049498073626179\n",
      "previous_iter_valid_loss : 0.08820778876543045\n",
      "\n",
      "    142300\t  0.088257\t  0.088208\t  0.121747\t\tCURRENT LEARNING RATE: 0.12037454598293844\n",
      "previous_iter_valid_loss : 0.08547418564558029\n",
      "\n",
      "    142400\t  0.085390\t  0.085474\t  0.121726\t\tCURRENT LEARNING RATE: 0.12025423160417106\n",
      "previous_iter_valid_loss : 0.14934252202510834\n",
      "\n",
      "    142500\t  0.149126\t  0.149343\t  0.122051\t\tCURRENT LEARNING RATE: 0.12013403747964535\n",
      "previous_iter_valid_loss : 0.08923865854740143\n",
      "\n",
      "    142600\t  0.089273\t  0.089239\t  0.121606\t\tCURRENT LEARNING RATE: 0.1200139634891671\n",
      "previous_iter_valid_loss : 0.1025155633687973\n",
      "\n",
      "    142700\t  0.102291\t  0.102516\t  0.121534\t\tCURRENT LEARNING RATE: 0.11989400951266235\n",
      "previous_iter_valid_loss : 0.08373482525348663\n",
      "\n",
      "    142800\t  0.083828\t  0.083735\t  0.121477\t\tCURRENT LEARNING RATE: 0.1197741754301771\n",
      "previous_iter_valid_loss : 0.09165867418050766\n",
      "\n",
      "    142900\t  0.091572\t  0.091659\t  0.121226\t\tCURRENT LEARNING RATE: 0.11965446112187728\n",
      "previous_iter_valid_loss : 0.09112351387739182\n",
      "\n",
      "    143000\t  0.091004\t  0.091124\t  0.120765\t\tCURRENT LEARNING RATE: 0.11953486646804852\n",
      "previous_iter_valid_loss : 0.09556093066930771\n",
      "\n",
      "    143100\t  0.095537\t  0.095561\t  0.120531\t\tCURRENT LEARNING RATE: 0.11941539134909622\n",
      "previous_iter_valid_loss : 0.08770862221717834\n",
      "\n",
      "    143200\t  0.087792\t  0.087709\t  0.120164\t\tCURRENT LEARNING RATE: 0.1192960356455452\n",
      "previous_iter_valid_loss : 0.09581848233938217\n",
      "\n",
      "    143300\t  0.095770\t  0.095818\t  0.119649\t\tCURRENT LEARNING RATE: 0.11917679923803978\n",
      "previous_iter_valid_loss : 0.09591701626777649\n",
      "\n",
      "    143400\t  0.095723\t  0.095917\t  0.119520\t\tCURRENT LEARNING RATE: 0.11905768200734351\n",
      "previous_iter_valid_loss : 0.08180846273899078\n",
      "\n",
      "    143500\t  0.081782\t  0.081808\t  0.118965\t\tCURRENT LEARNING RATE: 0.1189386838343392\n",
      "previous_iter_valid_loss : 0.11009114235639572\n",
      "\n",
      "    143600\t  0.109834\t  0.110091\t  0.118211\t\tCURRENT LEARNING RATE: 0.1188198046000286\n",
      "previous_iter_valid_loss : 0.09583456069231033\n",
      "\n",
      "    143700\t  0.095690\t  0.095835\t  0.118185\t\tCURRENT LEARNING RATE: 0.11870104418553254\n",
      "previous_iter_valid_loss : 0.08430715650320053\n",
      "\n",
      "    143800\t  0.084377\t  0.084307\t  0.117954\t\tCURRENT LEARNING RATE: 0.11858240247209052\n",
      "previous_iter_valid_loss : 0.19726969301700592\n",
      "\n",
      "    143900\t  0.197089\t  0.197270\t  0.118823\t\tCURRENT LEARNING RATE: 0.11846387934106088\n",
      "previous_iter_valid_loss : 0.08914252370595932\n",
      "\n",
      "    144000\t  0.089025\t  0.089143\t  0.118557\t\tCURRENT LEARNING RATE: 0.11834547467392044\n",
      "previous_iter_valid_loss : 0.16447901725769043\n",
      "\n",
      "    144100\t  0.164962\t  0.164479\t  0.119234\t\tCURRENT LEARNING RATE: 0.11822718835226455\n",
      "previous_iter_valid_loss : 0.13732127845287323\n",
      "\n",
      "    144200\t  0.137668\t  0.137321\t  0.119635\t\tCURRENT LEARNING RATE: 0.11810902025780684\n",
      "previous_iter_valid_loss : 0.11403937637805939\n",
      "\n",
      "    144300\t  0.114228\t  0.114039\t  0.119309\t\tCURRENT LEARNING RATE: 0.11799097027237926\n",
      "previous_iter_valid_loss : 0.09943033754825592\n",
      "\n",
      "    144400\t  0.099458\t  0.099430\t  0.118380\t\tCURRENT LEARNING RATE: 0.11787303827793176\n",
      "previous_iter_valid_loss : 0.1133950874209404\n",
      "\n",
      "    144500\t  0.113565\t  0.113395\t  0.118334\t\tCURRENT LEARNING RATE: 0.11775522415653238\n",
      "previous_iter_valid_loss : 0.12129025906324387\n",
      "\n",
      "    144600\t  0.121498\t  0.121290\t  0.118255\t\tCURRENT LEARNING RATE: 0.11763752779036694\n",
      "previous_iter_valid_loss : 0.09019535779953003\n",
      "\n",
      "    144700\t  0.090271\t  0.090195\t  0.118173\t\tCURRENT LEARNING RATE: 0.11751994906173914\n",
      "previous_iter_valid_loss : 0.11088807880878448\n",
      "\n",
      "    144800\t  0.111068\t  0.110888\t  0.117866\t\tCURRENT LEARNING RATE: 0.11740248785307016\n",
      "previous_iter_valid_loss : 0.09040156751871109\n",
      "\n",
      "    144900\t  0.090450\t  0.090402\t  0.117533\t\tCURRENT LEARNING RATE: 0.11728514404689883\n",
      "previous_iter_valid_loss : 0.08840945363044739\n",
      "\n",
      "    145000\t  0.088324\t  0.088409\t  0.116835\t\tCURRENT LEARNING RATE: 0.11716791752588131\n",
      "previous_iter_valid_loss : 0.08461945503950119\n",
      "\n",
      "    145100\t  0.084690\t  0.084619\t  0.116432\t\tCURRENT LEARNING RATE: 0.1170508081727911\n",
      "previous_iter_valid_loss : 0.08848225325345993\n",
      "\n",
      "    145200\t  0.088466\t  0.088482\t  0.116417\t\tCURRENT LEARNING RATE: 0.11693381587051878\n",
      "previous_iter_valid_loss : 0.0851084515452385\n",
      "\n",
      "    145300\t  0.085167\t  0.085108\t  0.116221\t\tCURRENT LEARNING RATE: 0.11681694050207211\n",
      "previous_iter_valid_loss : 0.0912134125828743\n",
      "\n",
      "    145400\t  0.091186\t  0.091213\t  0.116106\t\tCURRENT LEARNING RATE: 0.11670018195057566\n",
      "previous_iter_valid_loss : 0.11001919209957123\n",
      "\n",
      "    145500\t  0.109820\t  0.110019\t  0.116057\t\tCURRENT LEARNING RATE: 0.1165835400992709\n",
      "previous_iter_valid_loss : 0.08225912600755692\n",
      "\n",
      "    145600\t  0.082248\t  0.082259\t  0.115715\t\tCURRENT LEARNING RATE: 0.11646701483151593\n",
      "previous_iter_valid_loss : 0.08582740277051926\n",
      "\n",
      "    145700\t  0.085808\t  0.085827\t  0.115321\t\tCURRENT LEARNING RATE: 0.11635060603078554\n",
      "previous_iter_valid_loss : 0.10992690920829773\n",
      "\n",
      "    145800\t  0.109797\t  0.109927\t  0.115373\t\tCURRENT LEARNING RATE: 0.11623431358067082\n",
      "previous_iter_valid_loss : 0.1314055621623993\n",
      "\n",
      "    145900\t  0.131227\t  0.131406\t  0.115201\t\tCURRENT LEARNING RATE: 0.11611813736487941\n",
      "previous_iter_valid_loss : 0.09484973549842834\n",
      "\n",
      "    146000\t  0.094729\t  0.094850\t  0.114700\t\tCURRENT LEARNING RATE: 0.11600207726723502\n",
      "previous_iter_valid_loss : 0.09922541677951813\n",
      "\n",
      "    146100\t  0.099523\t  0.099225\t  0.114509\t\tCURRENT LEARNING RATE: 0.11588613317167758\n",
      "previous_iter_valid_loss : 0.08551887422800064\n",
      "\n",
      "    146200\t  0.085514\t  0.085519\t  0.114293\t\tCURRENT LEARNING RATE: 0.11577030496226295\n",
      "previous_iter_valid_loss : 0.09004718065261841\n",
      "\n",
      "    146300\t  0.090169\t  0.090047\t  0.113975\t\tCURRENT LEARNING RATE: 0.11565459252316296\n",
      "previous_iter_valid_loss : 0.09590750932693481\n",
      "\n",
      "    146400\t  0.095716\t  0.095908\t  0.113727\t\tCURRENT LEARNING RATE: 0.11553899573866509\n",
      "previous_iter_valid_loss : 0.10432673990726471\n",
      "\n",
      "    146500\t  0.104172\t  0.104327\t  0.113511\t\tCURRENT LEARNING RATE: 0.11542351449317262\n",
      "previous_iter_valid_loss : 0.12857428193092346\n",
      "\n",
      "    146600\t  0.128548\t  0.128574\t  0.113171\t\tCURRENT LEARNING RATE: 0.11530814867120424\n",
      "previous_iter_valid_loss : 0.09582691639661789\n",
      "\n",
      "    146700\t  0.095717\t  0.095827\t  0.112983\t\tCURRENT LEARNING RATE: 0.11519289815739417\n",
      "previous_iter_valid_loss : 0.11235892027616501\n",
      "\n",
      "    146800\t  0.112183\t  0.112359\t  0.112570\t\tCURRENT LEARNING RATE: 0.11507776283649182\n",
      "previous_iter_valid_loss : 0.09416119754314423\n",
      "\n",
      "    146900\t  0.094217\t  0.094161\t  0.111968\t\tCURRENT LEARNING RATE: 0.11496274259336192\n",
      "previous_iter_valid_loss : 0.09120923280715942\n",
      "\n",
      "    147000\t  0.091300\t  0.091209\t  0.111388\t\tCURRENT LEARNING RATE: 0.11484783731298417\n",
      "previous_iter_valid_loss : 0.09344238042831421\n",
      "\n",
      "    147100\t  0.093548\t  0.093442\t  0.110675\t\tCURRENT LEARNING RATE: 0.11473304688045334\n",
      "previous_iter_valid_loss : 0.12091474235057831\n",
      "\n",
      "    147200\t  0.121104\t  0.120915\t  0.110819\t\tCURRENT LEARNING RATE: 0.11461837118097892\n",
      "previous_iter_valid_loss : 0.16979970037937164\n",
      "\n",
      "    147300\t  0.170193\t  0.169800\t  0.111393\t\tCURRENT LEARNING RATE: 0.11450381009988525\n",
      "previous_iter_valid_loss : 0.0986563041806221\n",
      "\n",
      "    147400\t  0.098808\t  0.098656\t  0.111155\t\tCURRENT LEARNING RATE: 0.11438936352261121\n",
      "previous_iter_valid_loss : 0.22236423194408417\n",
      "\n",
      "    147500\t  0.222033\t  0.222364\t  0.111835\t\tCURRENT LEARNING RATE: 0.11427503133471024\n",
      "previous_iter_valid_loss : 0.20693722367286682\n",
      "\n",
      "    147600\t  0.207598\t  0.206937\t  0.112787\t\tCURRENT LEARNING RATE: 0.11416081342185011\n",
      "previous_iter_valid_loss : 0.0933041125535965\n",
      "\n",
      "    147700\t  0.093510\t  0.093304\t  0.112602\t\tCURRENT LEARNING RATE: 0.11404670966981294\n",
      "previous_iter_valid_loss : 0.14079980552196503\n",
      "\n",
      "    147800\t  0.140586\t  0.140800\t  0.112932\t\tCURRENT LEARNING RATE: 0.11393271996449492\n",
      "previous_iter_valid_loss : 0.09412413835525513\n",
      "\n",
      "    147900\t  0.094197\t  0.094124\t  0.112919\t\tCURRENT LEARNING RATE: 0.11381884419190637\n",
      "previous_iter_valid_loss : 0.1315280646085739\n",
      "\n",
      "    148000\t  0.131714\t  0.131528\t  0.112959\t\tCURRENT LEARNING RATE: 0.11370508223817148\n",
      "previous_iter_valid_loss : 0.10652683675289154\n",
      "\n",
      "    148100\t  0.106442\t  0.106527\t  0.112590\t\tCURRENT LEARNING RATE: 0.11359143398952833\n",
      "previous_iter_valid_loss : 0.08881016820669174\n",
      "\n",
      "    148200\t  0.088832\t  0.088810\t  0.112532\t\tCURRENT LEARNING RATE: 0.11347789933232862\n",
      "previous_iter_valid_loss : 0.11326546967029572\n",
      "\n",
      "    148300\t  0.113506\t  0.113265\t  0.112192\t\tCURRENT LEARNING RATE: 0.11336447815303771\n",
      "previous_iter_valid_loss : 0.24519893527030945\n",
      "\n",
      "    148400\t  0.246134\t  0.245199\t  0.113482\t\tCURRENT LEARNING RATE: 0.11325117033823437\n",
      "previous_iter_valid_loss : 0.08506371080875397\n",
      "\n",
      "    148500\t  0.085118\t  0.085064\t  0.113108\t\tCURRENT LEARNING RATE: 0.11313797577461085\n",
      "previous_iter_valid_loss : 0.1475725620985031\n",
      "\n",
      "    148600\t  0.147897\t  0.147573\t  0.113553\t\tCURRENT LEARNING RATE: 0.11302489434897249\n",
      "previous_iter_valid_loss : 0.2661498188972473\n",
      "\n",
      "    148700\t  0.266867\t  0.266150\t  0.114644\t\tCURRENT LEARNING RATE: 0.11291192594823793\n",
      "previous_iter_valid_loss : 0.12947013974189758\n",
      "\n",
      "    148800\t  0.129188\t  0.129470\t  0.114697\t\tCURRENT LEARNING RATE: 0.11279907045943871\n",
      "previous_iter_valid_loss : 0.11598459631204605\n",
      "\n",
      "    148900\t  0.115753\t  0.115985\t  0.114935\t\tCURRENT LEARNING RATE: 0.11268632776971936\n",
      "previous_iter_valid_loss : 0.12843574583530426\n",
      "\n",
      "    149000\t  0.128271\t  0.128436\t  0.114610\t\tCURRENT LEARNING RATE: 0.11257369776633716\n",
      "previous_iter_valid_loss : 0.11029540747404099\n",
      "\n",
      "    149100\t  0.110419\t  0.110295\t  0.114115\t\tCURRENT LEARNING RATE: 0.11246118033666212\n",
      "previous_iter_valid_loss : 0.149470254778862\n",
      "\n",
      "    149200\t  0.149838\t  0.149470\t  0.114537\t\tCURRENT LEARNING RATE: 0.11234877536817676\n",
      "previous_iter_valid_loss : 0.10323433578014374\n",
      "\n",
      "    149300\t  0.103274\t  0.103234\t  0.114586\t\tCURRENT LEARNING RATE: 0.11223648274847617\n",
      "previous_iter_valid_loss : 0.09673624485731125\n",
      "\n",
      "    149400\t  0.096668\t  0.096736\t  0.114318\t\tCURRENT LEARNING RATE: 0.11212430236526766\n",
      "previous_iter_valid_loss : 0.1014247015118599\n",
      "\n",
      "    149500\t  0.101120\t  0.101425\t  0.114019\t\tCURRENT LEARNING RATE: 0.11201223410637087\n",
      "previous_iter_valid_loss : 0.12319118529558182\n",
      "\n",
      "    149600\t  0.123457\t  0.123191\t  0.114216\t\tCURRENT LEARNING RATE: 0.1119002778597175\n",
      "previous_iter_valid_loss : 0.21002322435379028\n",
      "\n",
      "    149700\t  0.210500\t  0.210023\t  0.115138\t\tCURRENT LEARNING RATE: 0.11178843351335134\n",
      "previous_iter_valid_loss : 0.12226900458335876\n",
      "\n",
      "    149800\t  0.122526\t  0.122269\t  0.114997\t\tCURRENT LEARNING RATE: 0.11167670095542799\n",
      "previous_iter_valid_loss : 0.08380751311779022\n",
      "\n",
      "    149900\t  0.083717\t  0.083808\t  0.114775\t\tCURRENT LEARNING RATE: 0.11156508007421491\n",
      "previous_iter_valid_loss : 0.14048217236995697\n",
      "\n",
      "    150000\t  0.140919\t  0.140482\t  0.114530\t\tCURRENT LEARNING RATE: 0.11145357075809122\n",
      "previous_iter_valid_loss : 0.1123344823718071\n",
      "\n",
      "    150100\t  0.112071\t  0.112334\t  0.114514\t\tCURRENT LEARNING RATE: 0.11134217289554754\n",
      "previous_iter_valid_loss : 0.10981947183609009\n",
      "\n",
      "    150200\t  0.110014\t  0.109819\t  0.114442\t\tCURRENT LEARNING RATE: 0.11123088637518606\n",
      "previous_iter_valid_loss : 0.15047071874141693\n",
      "\n",
      "    150300\t  0.150895\t  0.150471\t  0.115041\t\tCURRENT LEARNING RATE: 0.1111197110857202\n",
      "previous_iter_valid_loss : 0.08529787510633469\n",
      "\n",
      "    150400\t  0.085214\t  0.085298\t  0.114768\t\tCURRENT LEARNING RATE: 0.11100864691597472\n",
      "previous_iter_valid_loss : 0.15572437644004822\n",
      "\n",
      "    150500\t  0.156121\t  0.155724\t  0.115475\t\tCURRENT LEARNING RATE: 0.11089769375488537\n",
      "previous_iter_valid_loss : 0.11858388036489487\n",
      "\n",
      "    150600\t  0.118824\t  0.118584\t  0.115067\t\tCURRENT LEARNING RATE: 0.11078685149149904\n",
      "previous_iter_valid_loss : 0.2800901234149933\n",
      "\n",
      "    150700\t  0.280595\t  0.280090\t  0.116905\t\tCURRENT LEARNING RATE: 0.11067612001497341\n",
      "previous_iter_valid_loss : 0.08897099643945694\n",
      "\n",
      "    150800\t  0.089117\t  0.088971\t  0.116953\t\tCURRENT LEARNING RATE: 0.11056549921457706\n",
      "previous_iter_valid_loss : 0.15232263505458832\n",
      "\n",
      "    150900\t  0.152937\t  0.152323\t  0.117516\t\tCURRENT LEARNING RATE: 0.1104549889796891\n",
      "previous_iter_valid_loss : 0.12456465512514114\n",
      "\n",
      "    151000\t  0.125099\t  0.124565\t  0.116387\t\tCURRENT LEARNING RATE: 0.11034458919979935\n",
      "previous_iter_valid_loss : 0.2588430345058441\n",
      "\n",
      "    151100\t  0.259847\t  0.258843\t  0.117652\t\tCURRENT LEARNING RATE: 0.11023429976450796\n",
      "previous_iter_valid_loss : 0.10891517251729965\n",
      "\n",
      "    151200\t  0.108675\t  0.108915\t  0.117453\t\tCURRENT LEARNING RATE: 0.11012412056352557\n",
      "previous_iter_valid_loss : 0.11230426281690598\n",
      "\n",
      "    151300\t  0.112152\t  0.112304\t  0.117681\t\tCURRENT LEARNING RATE: 0.11001405148667287\n",
      "previous_iter_valid_loss : 0.16604594886302948\n",
      "\n",
      "    151400\t  0.166640\t  0.166046\t  0.118322\t\tCURRENT LEARNING RATE: 0.10990409242388087\n",
      "previous_iter_valid_loss : 0.14911086857318878\n",
      "\n",
      "    151500\t  0.149637\t  0.149111\t  0.118533\t\tCURRENT LEARNING RATE: 0.10979424326519041\n",
      "previous_iter_valid_loss : 0.08255674690008163\n",
      "\n",
      "    151600\t  0.082665\t  0.082557\t  0.118494\t\tCURRENT LEARNING RATE: 0.1096845039007524\n",
      "previous_iter_valid_loss : 0.12365198135375977\n",
      "\n",
      "    151700\t  0.124003\t  0.123652\t  0.118685\t\tCURRENT LEARNING RATE: 0.1095748742208274\n",
      "previous_iter_valid_loss : 0.0872003510594368\n",
      "\n",
      "    151800\t  0.087160\t  0.087200\t  0.117935\t\tCURRENT LEARNING RATE: 0.10946535411578578\n",
      "previous_iter_valid_loss : 0.08622368425130844\n",
      "\n",
      "    151900\t  0.086238\t  0.086224\t  0.117884\t\tCURRENT LEARNING RATE: 0.10935594347610737\n",
      "previous_iter_valid_loss : 0.09846164286136627\n",
      "\n",
      "    152000\t  0.098334\t  0.098462\t  0.117819\t\tCURRENT LEARNING RATE: 0.10924664219238159\n",
      "previous_iter_valid_loss : 0.09731370955705643\n",
      "\n",
      "    152100\t  0.097665\t  0.097314\t  0.117919\t\tCURRENT LEARNING RATE: 0.10913745015530707\n",
      "previous_iter_valid_loss : 0.17211675643920898\n",
      "\n",
      "    152200\t  0.172685\t  0.172117\t  0.118657\t\tCURRENT LEARNING RATE: 0.10902836725569182\n",
      "previous_iter_valid_loss : 0.22999247908592224\n",
      "\n",
      "    152300\t  0.229940\t  0.229992\t  0.120075\t\tCURRENT LEARNING RATE: 0.10891939338445289\n",
      "previous_iter_valid_loss : 0.09108807891607285\n",
      "\n",
      "    152400\t  0.091037\t  0.091088\t  0.120131\t\tCURRENT LEARNING RATE: 0.10881052843261645\n",
      "previous_iter_valid_loss : 0.08284451812505722\n",
      "\n",
      "    152500\t  0.082883\t  0.082845\t  0.119466\t\tCURRENT LEARNING RATE: 0.10870177229131749\n",
      "previous_iter_valid_loss : 0.1160011887550354\n",
      "\n",
      "    152600\t  0.115851\t  0.116001\t  0.119733\t\tCURRENT LEARNING RATE: 0.10859312485179988\n",
      "previous_iter_valid_loss : 0.08808859437704086\n",
      "\n",
      "    152700\t  0.088074\t  0.088089\t  0.119589\t\tCURRENT LEARNING RATE: 0.10848458600541618\n",
      "previous_iter_valid_loss : 0.08730851858854294\n",
      "\n",
      "    152800\t  0.087342\t  0.087309\t  0.119625\t\tCURRENT LEARNING RATE: 0.10837615564362753\n",
      "previous_iter_valid_loss : 0.08525600284337997\n",
      "\n",
      "    152900\t  0.085270\t  0.085256\t  0.119561\t\tCURRENT LEARNING RATE: 0.10826783365800353\n",
      "previous_iter_valid_loss : 0.08695637434720993\n",
      "\n",
      "    153000\t  0.087089\t  0.086956\t  0.119519\t\tCURRENT LEARNING RATE: 0.10815961994022223\n",
      "previous_iter_valid_loss : 0.17436575889587402\n",
      "\n",
      "    153100\t  0.174445\t  0.174366\t  0.120307\t\tCURRENT LEARNING RATE: 0.10805151438206988\n",
      "previous_iter_valid_loss : 0.09543696790933609\n",
      "\n",
      "    153200\t  0.095246\t  0.095437\t  0.120384\t\tCURRENT LEARNING RATE: 0.10794351687544092\n",
      "previous_iter_valid_loss : 0.0871506854891777\n",
      "\n",
      "    153300\t  0.087205\t  0.087151\t  0.120298\t\tCURRENT LEARNING RATE: 0.10783562731233783\n",
      "previous_iter_valid_loss : 0.13499397039413452\n",
      "\n",
      "    153400\t  0.134903\t  0.134994\t  0.120689\t\tCURRENT LEARNING RATE: 0.10772784558487104\n",
      "previous_iter_valid_loss : 0.16478557884693146\n",
      "\n",
      "    153500\t  0.165260\t  0.164786\t  0.121518\t\tCURRENT LEARNING RATE: 0.10762017158525879\n",
      "previous_iter_valid_loss : 0.08318842202425003\n",
      "\n",
      "    153600\t  0.083250\t  0.083188\t  0.121249\t\tCURRENT LEARNING RATE: 0.10751260520582713\n",
      "previous_iter_valid_loss : 0.1651606559753418\n",
      "\n",
      "    153700\t  0.164969\t  0.165161\t  0.121943\t\tCURRENT LEARNING RATE: 0.1074051463390096\n",
      "previous_iter_valid_loss : 0.09857932478189468\n",
      "\n",
      "    153800\t  0.098767\t  0.098579\t  0.122085\t\tCURRENT LEARNING RATE: 0.10729779487734739\n",
      "previous_iter_valid_loss : 0.1373634934425354\n",
      "\n",
      "    153900\t  0.137750\t  0.137363\t  0.121486\t\tCURRENT LEARNING RATE: 0.10719055071348897\n",
      "previous_iter_valid_loss : 0.10770989209413528\n",
      "\n",
      "    154000\t  0.107538\t  0.107710\t  0.121672\t\tCURRENT LEARNING RATE: 0.10708341374019023\n",
      "previous_iter_valid_loss : 0.08059181272983551\n",
      "\n",
      "    154100\t  0.080682\t  0.080592\t  0.120833\t\tCURRENT LEARNING RATE: 0.10697638385031412\n",
      "previous_iter_valid_loss : 0.08908621966838837\n",
      "\n",
      "    154200\t  0.089148\t  0.089086\t  0.120351\t\tCURRENT LEARNING RATE: 0.1068694609368308\n",
      "previous_iter_valid_loss : 0.18177972733974457\n",
      "\n",
      "    154300\t  0.182335\t  0.181780\t  0.121028\t\tCURRENT LEARNING RATE: 0.1067626448928173\n",
      "previous_iter_valid_loss : 0.09782807528972626\n",
      "\n",
      "    154400\t  0.097639\t  0.097828\t  0.121012\t\tCURRENT LEARNING RATE: 0.10665593561145761\n",
      "previous_iter_valid_loss : 0.23594707250595093\n",
      "\n",
      "    154500\t  0.235687\t  0.235947\t  0.122238\t\tCURRENT LEARNING RATE: 0.10654933298604241\n",
      "previous_iter_valid_loss : 0.09324759989976883\n",
      "\n",
      "    154600\t  0.093184\t  0.093248\t  0.121957\t\tCURRENT LEARNING RATE: 0.10644283690996909\n",
      "previous_iter_valid_loss : 0.12700283527374268\n",
      "\n",
      "    154700\t  0.127303\t  0.127003\t  0.122325\t\tCURRENT LEARNING RATE: 0.10633644727674152\n",
      "previous_iter_valid_loss : 0.09504729509353638\n",
      "\n",
      "    154800\t  0.095114\t  0.095047\t  0.122167\t\tCURRENT LEARNING RATE: 0.10623016397997012\n",
      "previous_iter_valid_loss : 0.1308911144733429\n",
      "\n",
      "    154900\t  0.131297\t  0.130891\t  0.122572\t\tCURRENT LEARNING RATE: 0.10612398691337152\n",
      "previous_iter_valid_loss : 0.2716584801673889\n",
      "\n",
      "    155000\t  0.271414\t  0.271658\t  0.124404\t\tCURRENT LEARNING RATE: 0.1060179159707687\n",
      "previous_iter_valid_loss : 0.11631101369857788\n",
      "\n",
      "    155100\t  0.116672\t  0.116311\t  0.124721\t\tCURRENT LEARNING RATE: 0.10591195104609068\n",
      "previous_iter_valid_loss : 0.14510098099708557\n",
      "\n",
      "    155200\t  0.144930\t  0.145101\t  0.125287\t\tCURRENT LEARNING RATE: 0.10580609203337255\n",
      "previous_iter_valid_loss : 0.0841171070933342\n",
      "\n",
      "    155300\t  0.084130\t  0.084117\t  0.125277\t\tCURRENT LEARNING RATE: 0.10570033882675524\n",
      "previous_iter_valid_loss : 0.149812713265419\n",
      "\n",
      "    155400\t  0.149674\t  0.149813\t  0.125863\t\tCURRENT LEARNING RATE: 0.10559469132048559\n",
      "previous_iter_valid_loss : 0.08853945136070251\n",
      "\n",
      "    155500\t  0.088424\t  0.088539\t  0.125649\t\tCURRENT LEARNING RATE: 0.10548914940891603\n",
      "previous_iter_valid_loss : 0.10698738694190979\n",
      "\n",
      "    155600\t  0.106745\t  0.106987\t  0.125896\t\tCURRENT LEARNING RATE: 0.1053837129865047\n",
      "previous_iter_valid_loss : 0.09353005886077881\n",
      "\n",
      "    155700\t  0.093360\t  0.093530\t  0.125973\t\tCURRENT LEARNING RATE: 0.10527838194781512\n",
      "previous_iter_valid_loss : 0.09697830677032471\n",
      "\n",
      "    155800\t  0.096774\t  0.096978\t  0.125843\t\tCURRENT LEARNING RATE: 0.10517315618751627\n",
      "previous_iter_valid_loss : 0.08615314215421677\n",
      "\n",
      "    155900\t  0.086023\t  0.086153\t  0.125391\t\tCURRENT LEARNING RATE: 0.10506803560038236\n",
      "previous_iter_valid_loss : 0.10658375173807144\n",
      "\n",
      "    156000\t  0.106765\t  0.106584\t  0.125508\t\tCURRENT LEARNING RATE: 0.10496302008129282\n",
      "previous_iter_valid_loss : 0.10257799923419952\n",
      "\n",
      "    156100\t  0.102474\t  0.102578\t  0.125542\t\tCURRENT LEARNING RATE: 0.1048581095252321\n",
      "previous_iter_valid_loss : 0.08803229033946991\n",
      "\n",
      "    156200\t  0.087881\t  0.088032\t  0.125567\t\tCURRENT LEARNING RATE: 0.10475330382728966\n",
      "previous_iter_valid_loss : 0.12280551344156265\n",
      "\n",
      "    156300\t  0.122978\t  0.122806\t  0.125894\t\tCURRENT LEARNING RATE: 0.10464860288265976\n",
      "previous_iter_valid_loss : 0.0882999449968338\n",
      "\n",
      "    156400\t  0.088151\t  0.088300\t  0.125818\t\tCURRENT LEARNING RATE: 0.10454400658664147\n",
      "previous_iter_valid_loss : 0.08244603127241135\n",
      "\n",
      "    156500\t  0.082323\t  0.082446\t  0.125600\t\tCURRENT LEARNING RATE: 0.10443951483463847\n",
      "previous_iter_valid_loss : 0.09027230739593506\n",
      "\n",
      "    156600\t  0.090041\t  0.090272\t  0.125216\t\tCURRENT LEARNING RATE: 0.10433512752215902\n",
      "previous_iter_valid_loss : 0.0876707062125206\n",
      "\n",
      "    156700\t  0.087642\t  0.087671\t  0.125135\t\tCURRENT LEARNING RATE: 0.10423084454481576\n",
      "previous_iter_valid_loss : 0.08839919418096542\n",
      "\n",
      "    156800\t  0.088363\t  0.088399\t  0.124895\t\tCURRENT LEARNING RATE: 0.10412666579832577\n",
      "previous_iter_valid_loss : 0.102012999355793\n",
      "\n",
      "    156900\t  0.102057\t  0.102013\t  0.124974\t\tCURRENT LEARNING RATE: 0.10402259117851023\n",
      "previous_iter_valid_loss : 0.09658269584178925\n",
      "\n",
      "    157000\t  0.096610\t  0.096583\t  0.125028\t\tCURRENT LEARNING RATE: 0.10391862058129456\n",
      "previous_iter_valid_loss : 0.14597737789154053\n",
      "\n",
      "    157100\t  0.146250\t  0.145977\t  0.125553\t\tCURRENT LEARNING RATE: 0.1038147539027081\n",
      "previous_iter_valid_loss : 0.12590375542640686\n",
      "\n",
      "    157200\t  0.125985\t  0.125904\t  0.125603\t\tCURRENT LEARNING RATE: 0.10371099103888422\n",
      "previous_iter_valid_loss : 0.1264515072107315\n",
      "\n",
      "    157300\t  0.126634\t  0.126452\t  0.125169\t\tCURRENT LEARNING RATE: 0.10360733188606\n",
      "previous_iter_valid_loss : 0.08591274172067642\n",
      "\n",
      "    157400\t  0.085518\t  0.085913\t  0.125042\t\tCURRENT LEARNING RATE: 0.10350377634057632\n",
      "previous_iter_valid_loss : 0.08845323324203491\n",
      "\n",
      "    157500\t  0.088334\t  0.088453\t  0.123703\t\tCURRENT LEARNING RATE: 0.10340032429887758\n",
      "previous_iter_valid_loss : 0.09014295786619186\n",
      "\n",
      "    157600\t  0.089952\t  0.090143\t  0.122535\t\tCURRENT LEARNING RATE: 0.10329697565751178\n",
      "previous_iter_valid_loss : 0.0838107094168663\n",
      "\n",
      "    157700\t  0.083593\t  0.083811\t  0.122440\t\tCURRENT LEARNING RATE: 0.10319373031313023\n",
      "previous_iter_valid_loss : 0.096425361931324\n",
      "\n",
      "    157800\t  0.096397\t  0.096425\t  0.121996\t\tCURRENT LEARNING RATE: 0.10309058816248762\n",
      "previous_iter_valid_loss : 0.11493300646543503\n",
      "\n",
      "    157900\t  0.114940\t  0.114933\t  0.122204\t\tCURRENT LEARNING RATE: 0.10298754910244172\n",
      "previous_iter_valid_loss : 0.1691078096628189\n",
      "\n",
      "    158000\t  0.169640\t  0.169108\t  0.122580\t\tCURRENT LEARNING RATE: 0.10288461302995354\n",
      "previous_iter_valid_loss : 0.11997487396001816\n",
      "\n",
      "    158100\t  0.120150\t  0.119975\t  0.122714\t\tCURRENT LEARNING RATE: 0.10278177984208695\n",
      "previous_iter_valid_loss : 0.08087614178657532\n",
      "\n",
      "    158200\t  0.080682\t  0.080876\t  0.122635\t\tCURRENT LEARNING RATE: 0.10267904943600878\n",
      "previous_iter_valid_loss : 0.11035093665122986\n",
      "\n",
      "    158300\t  0.110529\t  0.110351\t  0.122606\t\tCURRENT LEARNING RATE: 0.10257642170898858\n",
      "previous_iter_valid_loss : 0.08823179453611374\n",
      "\n",
      "    158400\t  0.088231\t  0.088232\t  0.121036\t\tCURRENT LEARNING RATE: 0.10247389655839866\n",
      "previous_iter_valid_loss : 0.13512203097343445\n",
      "\n",
      "    158500\t  0.135443\t  0.135122\t  0.121537\t\tCURRENT LEARNING RATE: 0.10237147388171382\n",
      "previous_iter_valid_loss : 0.1269206404685974\n",
      "\n",
      "    158600\t  0.127290\t  0.126921\t  0.121330\t\tCURRENT LEARNING RATE: 0.1022691535765114\n",
      "previous_iter_valid_loss : 0.08261453360319138\n",
      "\n",
      "    158700\t  0.082590\t  0.082615\t  0.119495\t\tCURRENT LEARNING RATE: 0.10216693554047107\n",
      "previous_iter_valid_loss : 0.10506347566843033\n",
      "\n",
      "    158800\t  0.104972\t  0.105063\t  0.119251\t\tCURRENT LEARNING RATE: 0.10206481967137482\n",
      "previous_iter_valid_loss : 0.10831105709075928\n",
      "\n",
      "    158900\t  0.108197\t  0.108311\t  0.119174\t\tCURRENT LEARNING RATE: 0.10196280586710671\n",
      "previous_iter_valid_loss : 0.09328273683786392\n",
      "\n",
      "    159000\t  0.093125\t  0.093283\t  0.118823\t\tCURRENT LEARNING RATE: 0.101860894025653\n",
      "previous_iter_valid_loss : 0.09101281315088272\n",
      "\n",
      "    159100\t  0.090976\t  0.091013\t  0.118630\t\tCURRENT LEARNING RATE: 0.10175908404510177\n",
      "previous_iter_valid_loss : 0.1126038059592247\n",
      "\n",
      "    159200\t  0.112458\t  0.112604\t  0.118261\t\tCURRENT LEARNING RATE: 0.10165737582364309\n",
      "previous_iter_valid_loss : 0.08572274446487427\n",
      "\n",
      "    159300\t  0.085742\t  0.085723\t  0.118086\t\tCURRENT LEARNING RATE: 0.10155576925956869\n",
      "previous_iter_valid_loss : 0.10994471609592438\n",
      "\n",
      "    159400\t  0.109681\t  0.109945\t  0.118218\t\tCURRENT LEARNING RATE: 0.10145426425127203\n",
      "previous_iter_valid_loss : 0.1280299723148346\n",
      "\n",
      "    159500\t  0.128023\t  0.128030\t  0.118484\t\tCURRENT LEARNING RATE: 0.10135286069724805\n",
      "previous_iter_valid_loss : 0.09589796513319016\n",
      "\n",
      "    159600\t  0.095818\t  0.095898\t  0.118211\t\tCURRENT LEARNING RATE: 0.10125155849609324\n",
      "previous_iter_valid_loss : 0.09265103191137314\n",
      "\n",
      "    159700\t  0.092474\t  0.092651\t  0.117038\t\tCURRENT LEARNING RATE: 0.10115035754650535\n",
      "previous_iter_valid_loss : 0.09650243073701859\n",
      "\n",
      "    159800\t  0.096698\t  0.096502\t  0.116780\t\tCURRENT LEARNING RATE: 0.10104925774728345\n",
      "previous_iter_valid_loss : 0.09265582263469696\n",
      "\n",
      "    159900\t  0.092784\t  0.092656\t  0.116868\t\tCURRENT LEARNING RATE: 0.10094825899732769\n",
      "previous_iter_valid_loss : 0.10133204609155655\n",
      "\n",
      "    160000\t  0.101202\t  0.101332\t  0.116477\t\tCURRENT LEARNING RATE: 0.10084736119563938\n",
      "previous_iter_valid_loss : 0.12697084248065948\n",
      "\n",
      "    160100\t  0.126812\t  0.126971\t  0.116623\t\tCURRENT LEARNING RATE: 0.10074656424132063\n",
      "previous_iter_valid_loss : 0.10041065514087677\n",
      "\n",
      "    160200\t  0.100322\t  0.100411\t  0.116529\t\tCURRENT LEARNING RATE: 0.10064586803357455\n",
      "previous_iter_valid_loss : 0.10935816168785095\n",
      "\n",
      "    160300\t  0.109309\t  0.109358\t  0.116118\t\tCURRENT LEARNING RATE: 0.10054527247170486\n",
      "previous_iter_valid_loss : 0.10754779726266861\n",
      "\n",
      "    160400\t  0.107467\t  0.107548\t  0.116341\t\tCURRENT LEARNING RATE: 0.10044477745511604\n",
      "previous_iter_valid_loss : 0.08353575319051743\n",
      "\n",
      "    160500\t  0.083534\t  0.083536\t  0.115619\t\tCURRENT LEARNING RATE: 0.10034438288331303\n",
      "previous_iter_valid_loss : 0.08920671045780182\n",
      "\n",
      "    160600\t  0.089092\t  0.089207\t  0.115325\t\tCURRENT LEARNING RATE: 0.10024408865590129\n",
      "previous_iter_valid_loss : 0.09820961207151413\n",
      "\n",
      "    160700\t  0.098150\t  0.098210\t  0.113506\t\tCURRENT LEARNING RATE: 0.10014389467258653\n",
      "previous_iter_valid_loss : 0.0941435694694519\n",
      "\n",
      "    160800\t  0.094059\t  0.094144\t  0.113558\t\tCURRENT LEARNING RATE: 0.10004380083317481\n",
      "previous_iter_valid_loss : 0.10101836174726486\n",
      "\n",
      "    160900\t  0.101200\t  0.101018\t  0.113045\t\tCURRENT LEARNING RATE: 0.09994380703757225\n",
      "previous_iter_valid_loss : 0.08455807715654373\n",
      "\n",
      "    161000\t  0.084702\t  0.084558\t  0.112645\t\tCURRENT LEARNING RATE: 0.09984391318578506\n",
      "previous_iter_valid_loss : 0.08875805884599686\n",
      "\n",
      "    161100\t  0.088895\t  0.088758\t  0.110944\t\tCURRENT LEARNING RATE: 0.09974411917791937\n",
      "previous_iter_valid_loss : 0.08845040947198868\n",
      "\n",
      "    161200\t  0.088533\t  0.088450\t  0.110739\t\tCURRENT LEARNING RATE: 0.09964442491418118\n",
      "previous_iter_valid_loss : 0.12277276813983917\n",
      "\n",
      "    161300\t  0.122758\t  0.122773\t  0.110844\t\tCURRENT LEARNING RATE: 0.0995448302948762\n",
      "previous_iter_valid_loss : 0.08183806389570236\n",
      "\n",
      "    161400\t  0.081831\t  0.081838\t  0.110002\t\tCURRENT LEARNING RATE: 0.09944533522040981\n",
      "previous_iter_valid_loss : 0.10133668780326843\n",
      "\n",
      "    161500\t  0.101291\t  0.101337\t  0.109524\t\tCURRENT LEARNING RATE: 0.09934593959128693\n",
      "previous_iter_valid_loss : 0.08149620145559311\n",
      "\n",
      "    161600\t  0.081547\t  0.081496\t  0.109513\t\tCURRENT LEARNING RATE: 0.09924664330811193\n",
      "previous_iter_valid_loss : 0.09670176357030869\n",
      "\n",
      "    161700\t  0.096918\t  0.096702\t  0.109244\t\tCURRENT LEARNING RATE: 0.09914744627158849\n",
      "previous_iter_valid_loss : 0.10477890074253082\n",
      "\n",
      "    161800\t  0.105053\t  0.104779\t  0.109420\t\tCURRENT LEARNING RATE: 0.09904834838251961\n",
      "previous_iter_valid_loss : 0.11241721361875534\n",
      "\n",
      "    161900\t  0.112769\t  0.112417\t  0.109682\t\tCURRENT LEARNING RATE: 0.09894934954180733\n",
      "previous_iter_valid_loss : 0.09354593604803085\n",
      "\n",
      "    162000\t  0.093709\t  0.093546\t  0.109633\t\tCURRENT LEARNING RATE: 0.09885044965045287\n",
      "previous_iter_valid_loss : 0.08475248515605927\n",
      "\n",
      "    162100\t  0.084983\t  0.084752\t  0.109507\t\tCURRENT LEARNING RATE: 0.09875164860955628\n",
      "previous_iter_valid_loss : 0.09547307342290878\n",
      "\n",
      "    162200\t  0.095667\t  0.095473\t  0.108740\t\tCURRENT LEARNING RATE: 0.09865294632031654\n",
      "previous_iter_valid_loss : 0.08555681258440018\n",
      "\n",
      "    162300\t  0.085649\t  0.085557\t  0.107296\t\tCURRENT LEARNING RATE: 0.09855434268403132\n",
      "previous_iter_valid_loss : 0.11295263469219208\n",
      "\n",
      "    162400\t  0.113247\t  0.112953\t  0.107515\t\tCURRENT LEARNING RATE: 0.09845583760209703\n",
      "previous_iter_valid_loss : 0.10134662687778473\n",
      "\n",
      "    162500\t  0.101637\t  0.101347\t  0.107700\t\tCURRENT LEARNING RATE: 0.09835743097600853\n",
      "previous_iter_valid_loss : 0.11601578444242477\n",
      "\n",
      "    162600\t  0.116313\t  0.116016\t  0.107700\t\tCURRENT LEARNING RATE: 0.09825912270735919\n",
      "previous_iter_valid_loss : 0.10050641745328903\n",
      "\n",
      "    162700\t  0.100449\t  0.100506\t  0.107824\t\tCURRENT LEARNING RATE: 0.09816091269784077\n",
      "previous_iter_valid_loss : 0.09439267218112946\n",
      "\n",
      "    162800\t  0.094385\t  0.094393\t  0.107895\t\tCURRENT LEARNING RATE: 0.09806280084924321\n",
      "previous_iter_valid_loss : 0.1214621439576149\n",
      "\n",
      "    162900\t  0.121651\t  0.121462\t  0.108257\t\tCURRENT LEARNING RATE: 0.09796478706345468\n",
      "previous_iter_valid_loss : 0.12801393866539001\n",
      "\n",
      "    163000\t  0.127941\t  0.128014\t  0.108668\t\tCURRENT LEARNING RATE: 0.09786687124246136\n",
      "previous_iter_valid_loss : 0.2408299744129181\n",
      "\n",
      "    163100\t  0.241432\t  0.240830\t  0.109332\t\tCURRENT LEARNING RATE: 0.09776905328834747\n",
      "previous_iter_valid_loss : 0.13830506801605225\n",
      "\n",
      "    163200\t  0.138648\t  0.138305\t  0.109761\t\tCURRENT LEARNING RATE: 0.09767133310329498\n",
      "previous_iter_valid_loss : 0.11773045361042023\n",
      "\n",
      "    163300\t  0.117976\t  0.117730\t  0.110067\t\tCURRENT LEARNING RATE: 0.09757371058958376\n",
      "previous_iter_valid_loss : 0.10844181478023529\n",
      "\n",
      "    163400\t  0.108605\t  0.108442\t  0.109801\t\tCURRENT LEARNING RATE: 0.09747618564959125\n",
      "previous_iter_valid_loss : 0.13743944466114044\n",
      "\n",
      "    163500\t  0.137668\t  0.137439\t  0.109528\t\tCURRENT LEARNING RATE: 0.09737875818579252\n",
      "previous_iter_valid_loss : 0.08801046758890152\n",
      "\n",
      "    163600\t  0.088022\t  0.088010\t  0.109576\t\tCURRENT LEARNING RATE: 0.09728142810076007\n",
      "previous_iter_valid_loss : 0.19262906908988953\n",
      "\n",
      "    163700\t  0.192505\t  0.192629\t  0.109851\t\tCURRENT LEARNING RATE: 0.09718419529716385\n",
      "previous_iter_valid_loss : 0.09963449835777283\n",
      "\n",
      "    163800\t  0.099549\t  0.099634\t  0.109861\t\tCURRENT LEARNING RATE: 0.09708705967777101\n",
      "previous_iter_valid_loss : 0.08366835862398148\n",
      "\n",
      "    163900\t  0.083666\t  0.083668\t  0.109324\t\tCURRENT LEARNING RATE: 0.09699002114544596\n",
      "previous_iter_valid_loss : 0.08733072876930237\n",
      "\n",
      "    164000\t  0.087385\t  0.087331\t  0.109120\t\tCURRENT LEARNING RATE: 0.0968930796031501\n",
      "previous_iter_valid_loss : 0.11323749274015427\n",
      "\n",
      "    164100\t  0.113110\t  0.113237\t  0.109447\t\tCURRENT LEARNING RATE: 0.09679623495394196\n",
      "previous_iter_valid_loss : 0.09179005771875381\n",
      "\n",
      "    164200\t  0.091727\t  0.091790\t  0.109474\t\tCURRENT LEARNING RATE: 0.09669948710097681\n",
      "previous_iter_valid_loss : 0.1483718752861023\n",
      "\n",
      "    164300\t  0.148680\t  0.148372\t  0.109140\t\tCURRENT LEARNING RATE: 0.09660283594750685\n",
      "previous_iter_valid_loss : 0.14300814270973206\n",
      "\n",
      "    164400\t  0.143200\t  0.143008\t  0.109592\t\tCURRENT LEARNING RATE: 0.09650628139688086\n",
      "previous_iter_valid_loss : 0.09190387278795242\n",
      "\n",
      "    164500\t  0.091921\t  0.091904\t  0.108151\t\tCURRENT LEARNING RATE: 0.09640982335254432\n",
      "previous_iter_valid_loss : 0.14777033030986786\n",
      "\n",
      "    164600\t  0.147608\t  0.147770\t  0.108696\t\tCURRENT LEARNING RATE: 0.09631346171803916\n",
      "previous_iter_valid_loss : 0.10594283044338226\n",
      "\n",
      "    164700\t  0.105806\t  0.105943\t  0.108486\t\tCURRENT LEARNING RATE: 0.09621719639700375\n",
      "previous_iter_valid_loss : 0.11392683535814285\n",
      "\n",
      "    164800\t  0.114284\t  0.113927\t  0.108675\t\tCURRENT LEARNING RATE: 0.09612102729317275\n",
      "previous_iter_valid_loss : 0.11803457140922546\n",
      "\n",
      "    164900\t  0.118165\t  0.118035\t  0.108546\t\tCURRENT LEARNING RATE: 0.09602495431037707\n",
      "previous_iter_valid_loss : 0.11908454447984695\n",
      "\n",
      "    165000\t  0.119130\t  0.119085\t  0.107020\t\tCURRENT LEARNING RATE: 0.09592897735254367\n",
      "previous_iter_valid_loss : 0.09288768470287323\n",
      "\n",
      "    165100\t  0.092988\t  0.092888\t  0.106786\t\tCURRENT LEARNING RATE: 0.09583309632369565\n",
      "previous_iter_valid_loss : 0.0863887369632721\n",
      "\n",
      "    165200\t  0.086285\t  0.086389\t  0.106199\t\tCURRENT LEARNING RATE: 0.09573731112795192\n",
      "previous_iter_valid_loss : 0.15142960846424103\n",
      "\n",
      "    165300\t  0.151175\t  0.151430\t  0.106872\t\tCURRENT LEARNING RATE: 0.0956416216695273\n",
      "previous_iter_valid_loss : 0.10027635842561722\n",
      "\n",
      "    165400\t  0.099889\t  0.100276\t  0.106377\t\tCURRENT LEARNING RATE: 0.09554602785273232\n",
      "previous_iter_valid_loss : 0.08600122481584549\n",
      "\n",
      "    165500\t  0.085995\t  0.086001\t  0.106351\t\tCURRENT LEARNING RATE: 0.09545052958197317\n",
      "previous_iter_valid_loss : 0.2600080668926239\n",
      "\n",
      "    165600\t  0.260525\t  0.260008\t  0.107882\t\tCURRENT LEARNING RATE: 0.09535512676175152\n",
      "previous_iter_valid_loss : 0.09683113545179367\n",
      "\n",
      "    165700\t  0.096866\t  0.096831\t  0.107915\t\tCURRENT LEARNING RATE: 0.09525981929666462\n",
      "previous_iter_valid_loss : 0.08652040362358093\n",
      "\n",
      "    165800\t  0.086367\t  0.086520\t  0.107810\t\tCURRENT LEARNING RATE: 0.09516460709140492\n",
      "previous_iter_valid_loss : 0.11995679885149002\n",
      "\n",
      "    165900\t  0.119818\t  0.119957\t  0.108148\t\tCURRENT LEARNING RATE: 0.09506949005076028\n",
      "previous_iter_valid_loss : 0.08973594009876251\n",
      "\n",
      "    166000\t  0.089886\t  0.089736\t  0.107980\t\tCURRENT LEARNING RATE: 0.09497446807961357\n",
      "previous_iter_valid_loss : 0.08182855695486069\n",
      "\n",
      "    166100\t  0.081856\t  0.081829\t  0.107772\t\tCURRENT LEARNING RATE: 0.09487954108294289\n",
      "previous_iter_valid_loss : 0.10667947679758072\n",
      "\n",
      "    166200\t  0.106571\t  0.106679\t  0.107959\t\tCURRENT LEARNING RATE: 0.09478470896582117\n",
      "previous_iter_valid_loss : 0.09705906361341476\n",
      "\n",
      "    166300\t  0.097075\t  0.097059\t  0.107701\t\tCURRENT LEARNING RATE: 0.09468997163341634\n",
      "previous_iter_valid_loss : 0.10261182487010956\n",
      "\n",
      "    166400\t  0.102769\t  0.102612\t  0.107844\t\tCURRENT LEARNING RATE: 0.09459532899099102\n",
      "previous_iter_valid_loss : 0.12595660984516144\n",
      "\n",
      "    166500\t  0.125775\t  0.125957\t  0.108279\t\tCURRENT LEARNING RATE: 0.09450078094390257\n",
      "previous_iter_valid_loss : 0.08232251554727554\n",
      "\n",
      "    166600\t  0.082286\t  0.082323\t  0.108200\t\tCURRENT LEARNING RATE: 0.09440632739760295\n",
      "previous_iter_valid_loss : 0.08625004440546036\n",
      "\n",
      "    166700\t  0.086290\t  0.086250\t  0.108186\t\tCURRENT LEARNING RATE: 0.0943119682576386\n",
      "previous_iter_valid_loss : 0.09264685958623886\n",
      "\n",
      "    166800\t  0.092496\t  0.092647\t  0.108228\t\tCURRENT LEARNING RATE: 0.09421770342965034\n",
      "previous_iter_valid_loss : 0.11875782907009125\n",
      "\n",
      "    166900\t  0.118884\t  0.118758\t  0.108396\t\tCURRENT LEARNING RATE: 0.0941235328193734\n",
      "previous_iter_valid_loss : 0.08651754260063171\n",
      "\n",
      "    167000\t  0.086353\t  0.086518\t  0.108295\t\tCURRENT LEARNING RATE: 0.09402945633263708\n",
      "previous_iter_valid_loss : 0.08289232105016708\n",
      "\n",
      "    167100\t  0.082782\t  0.082892\t  0.107664\t\tCURRENT LEARNING RATE: 0.09393547387536497\n",
      "previous_iter_valid_loss : 0.08357355743646622\n",
      "\n",
      "    167200\t  0.083530\t  0.083574\t  0.107241\t\tCURRENT LEARNING RATE: 0.09384158535357452\n",
      "previous_iter_valid_loss : 0.11065714061260223\n",
      "\n",
      "    167300\t  0.110833\t  0.110657\t  0.107083\t\tCURRENT LEARNING RATE: 0.09374779067337728\n",
      "previous_iter_valid_loss : 0.11162169277667999\n",
      "\n",
      "    167400\t  0.111791\t  0.111622\t  0.107340\t\tCURRENT LEARNING RATE: 0.09365408974097851\n",
      "previous_iter_valid_loss : 0.12419772148132324\n",
      "\n",
      "    167500\t  0.124441\t  0.124198\t  0.107697\t\tCURRENT LEARNING RATE: 0.0935604824626773\n",
      "previous_iter_valid_loss : 0.1031513437628746\n",
      "\n",
      "    167600\t  0.103235\t  0.103151\t  0.107827\t\tCURRENT LEARNING RATE: 0.09346696874486632\n",
      "previous_iter_valid_loss : 0.10168562084436417\n",
      "\n",
      "    167700\t  0.101546\t  0.101686\t  0.108006\t\tCURRENT LEARNING RATE: 0.0933735484940319\n",
      "previous_iter_valid_loss : 0.08304360508918762\n",
      "\n",
      "    167800\t  0.083065\t  0.083044\t  0.107872\t\tCURRENT LEARNING RATE: 0.09328022161675374\n",
      "previous_iter_valid_loss : 0.09272635728120804\n",
      "\n",
      "    167900\t  0.092811\t  0.092726\t  0.107650\t\tCURRENT LEARNING RATE: 0.09318698801970499\n",
      "previous_iter_valid_loss : 0.1232002004981041\n",
      "\n",
      "    168000\t  0.123446\t  0.123200\t  0.107191\t\tCURRENT LEARNING RATE: 0.093093847609652\n",
      "previous_iter_valid_loss : 0.08785154670476913\n",
      "\n",
      "    168100\t  0.087774\t  0.087852\t  0.106870\t\tCURRENT LEARNING RATE: 0.0930008002934544\n",
      "previous_iter_valid_loss : 0.09284190088510513\n",
      "\n",
      "    168200\t  0.092763\t  0.092842\t  0.106990\t\tCURRENT LEARNING RATE: 0.09290784597806483\n",
      "previous_iter_valid_loss : 0.08157827705144882\n",
      "\n",
      "    168300\t  0.081573\t  0.081578\t  0.106702\t\tCURRENT LEARNING RATE: 0.09281498457052899\n",
      "previous_iter_valid_loss : 0.0957726389169693\n",
      "\n",
      "    168400\t  0.095915\t  0.095773\t  0.106777\t\tCURRENT LEARNING RATE: 0.09272221597798544\n",
      "previous_iter_valid_loss : 0.2201520949602127\n",
      "\n",
      "    168500\t  0.220673\t  0.220152\t  0.107628\t\tCURRENT LEARNING RATE: 0.09262954010766561\n",
      "previous_iter_valid_loss : 0.09072092920541763\n",
      "\n",
      "    168600\t  0.090851\t  0.090721\t  0.107266\t\tCURRENT LEARNING RATE: 0.09253695686689359\n",
      "previous_iter_valid_loss : 0.1207776740193367\n",
      "\n",
      "    168700\t  0.120681\t  0.120778\t  0.107647\t\tCURRENT LEARNING RATE: 0.09244446616308617\n",
      "previous_iter_valid_loss : 0.13521887362003326\n",
      "\n",
      "    168800\t  0.135537\t  0.135219\t  0.107949\t\tCURRENT LEARNING RATE: 0.0923520679037526\n",
      "previous_iter_valid_loss : 0.11318174004554749\n",
      "\n",
      "    168900\t  0.113218\t  0.113182\t  0.107997\t\tCURRENT LEARNING RATE: 0.09225976199649463\n",
      "previous_iter_valid_loss : 0.11376740038394928\n",
      "\n",
      "    169000\t  0.113846\t  0.113767\t  0.108202\t\tCURRENT LEARNING RATE: 0.09216754834900635\n",
      "previous_iter_valid_loss : 0.0961410328745842\n",
      "\n",
      "    169100\t  0.096111\t  0.096141\t  0.108254\t\tCURRENT LEARNING RATE: 0.0920754268690741\n",
      "previous_iter_valid_loss : 0.09772796928882599\n",
      "\n",
      "    169200\t  0.097949\t  0.097728\t  0.108105\t\tCURRENT LEARNING RATE: 0.09198339746457639\n",
      "previous_iter_valid_loss : 0.1692209392786026\n",
      "\n",
      "    169300\t  0.169703\t  0.169221\t  0.108940\t\tCURRENT LEARNING RATE: 0.09189146004348382\n",
      "previous_iter_valid_loss : 0.08560853451490402\n",
      "\n",
      "    169400\t  0.085634\t  0.085609\t  0.108696\t\tCURRENT LEARNING RATE: 0.09179961451385893\n",
      "previous_iter_valid_loss : 0.0809313952922821\n",
      "\n",
      "    169500\t  0.080877\t  0.080931\t  0.108225\t\tCURRENT LEARNING RATE: 0.09170786078385623\n",
      "previous_iter_valid_loss : 0.1281690001487732\n",
      "\n",
      "    169600\t  0.128521\t  0.128169\t  0.108548\t\tCURRENT LEARNING RATE: 0.09161619876172193\n",
      "previous_iter_valid_loss : 0.10664200037717819\n",
      "\n",
      "    169700\t  0.106897\t  0.106642\t  0.108688\t\tCURRENT LEARNING RATE: 0.09152462835579406\n",
      "previous_iter_valid_loss : 0.08374462276697159\n",
      "\n",
      "    169800\t  0.083741\t  0.083745\t  0.108561\t\tCURRENT LEARNING RATE: 0.09143314947450214\n",
      "previous_iter_valid_loss : 0.07965992391109467\n",
      "\n",
      "    169900\t  0.079548\t  0.079660\t  0.108431\t\tCURRENT LEARNING RATE: 0.09134176202636733\n",
      "previous_iter_valid_loss : 0.09758549928665161\n",
      "\n",
      "    170000\t  0.097339\t  0.097585\t  0.108393\t\tCURRENT LEARNING RATE: 0.09125046592000215\n",
      "previous_iter_valid_loss : 0.08603276312351227\n",
      "\n",
      "    170100\t  0.086034\t  0.086033\t  0.107984\t\tCURRENT LEARNING RATE: 0.0911592610641105\n",
      "previous_iter_valid_loss : 0.08834880590438843\n",
      "\n",
      "    170200\t  0.088389\t  0.088349\t  0.107863\t\tCURRENT LEARNING RATE: 0.0910681473674875\n",
      "previous_iter_valid_loss : 0.13455811142921448\n",
      "\n",
      "    170300\t  0.134305\t  0.134558\t  0.108115\t\tCURRENT LEARNING RATE: 0.09097712473901948\n",
      "previous_iter_valid_loss : 0.08553336560726166\n",
      "\n",
      "    170400\t  0.085483\t  0.085533\t  0.107895\t\tCURRENT LEARNING RATE: 0.09088619308768375\n",
      "previous_iter_valid_loss : 0.08594456315040588\n",
      "\n",
      "    170500\t  0.085915\t  0.085945\t  0.107919\t\tCURRENT LEARNING RATE: 0.0907953523225487\n",
      "previous_iter_valid_loss : 0.10596061497926712\n",
      "\n",
      "    170600\t  0.106186\t  0.105961\t  0.108087\t\tCURRENT LEARNING RATE: 0.09070460235277353\n",
      "previous_iter_valid_loss : 0.10096340626478195\n",
      "\n",
      "    170700\t  0.100720\t  0.100963\t  0.108114\t\tCURRENT LEARNING RATE: 0.0906139430876083\n",
      "previous_iter_valid_loss : 0.08952803909778595\n",
      "\n",
      "    170800\t  0.089313\t  0.089528\t  0.108068\t\tCURRENT LEARNING RATE: 0.09052337443639367\n",
      "previous_iter_valid_loss : 0.08238622546195984\n",
      "\n",
      "    170900\t  0.082331\t  0.082386\t  0.107882\t\tCURRENT LEARNING RATE: 0.09043289630856105\n",
      "previous_iter_valid_loss : 0.09048157185316086\n",
      "\n",
      "    171000\t  0.090505\t  0.090482\t  0.107941\t\tCURRENT LEARNING RATE: 0.09034250861363224\n",
      "previous_iter_valid_loss : 0.0909939557313919\n",
      "\n",
      "    171100\t  0.090836\t  0.090994\t  0.107963\t\tCURRENT LEARNING RATE: 0.09025221126121961\n",
      "previous_iter_valid_loss : 0.15894752740859985\n",
      "\n",
      "    171200\t  0.159479\t  0.158948\t  0.108668\t\tCURRENT LEARNING RATE: 0.09016200416102574\n",
      "previous_iter_valid_loss : 0.09693032503128052\n",
      "\n",
      "    171300\t  0.096786\t  0.096930\t  0.108410\t\tCURRENT LEARNING RATE: 0.09007188722284355\n",
      "previous_iter_valid_loss : 0.11467205733060837\n",
      "\n",
      "    171400\t  0.114520\t  0.114672\t  0.108738\t\tCURRENT LEARNING RATE: 0.08998186035655609\n",
      "previous_iter_valid_loss : 0.09816896170377731\n",
      "\n",
      "    171500\t  0.098289\t  0.098169\t  0.108706\t\tCURRENT LEARNING RATE: 0.08989192347213648\n",
      "previous_iter_valid_loss : 0.10263942182064056\n",
      "\n",
      "    171600\t  0.102733\t  0.102639\t  0.108918\t\tCURRENT LEARNING RATE: 0.08980207647964783\n",
      "previous_iter_valid_loss : 0.09470390528440475\n",
      "\n",
      "    171700\t  0.095099\t  0.094704\t  0.108898\t\tCURRENT LEARNING RATE: 0.08971231928924317\n",
      "previous_iter_valid_loss : 0.1537085920572281\n",
      "\n",
      "    171800\t  0.153653\t  0.153709\t  0.109387\t\tCURRENT LEARNING RATE: 0.08962265181116524\n",
      "previous_iter_valid_loss : 0.09343093633651733\n",
      "\n",
      "    171900\t  0.093586\t  0.093431\t  0.109197\t\tCURRENT LEARNING RATE: 0.08953307395574661\n",
      "previous_iter_valid_loss : 0.1082405298948288\n",
      "\n",
      "    172000\t  0.108621\t  0.108241\t  0.109344\t\tCURRENT LEARNING RATE: 0.08944358563340939\n",
      "previous_iter_valid_loss : 0.11085668951272964\n",
      "\n",
      "    172100\t  0.110842\t  0.110857\t  0.109605\t\tCURRENT LEARNING RATE: 0.08935418675466526\n",
      "previous_iter_valid_loss : 0.08700603246688843\n",
      "\n",
      "    172200\t  0.087262\t  0.087006\t  0.109521\t\tCURRENT LEARNING RATE: 0.08926487723011532\n",
      "previous_iter_valid_loss : 0.09673888236284256\n",
      "\n",
      "    172300\t  0.096703\t  0.096739\t  0.109632\t\tCURRENT LEARNING RATE: 0.08917565697045007\n",
      "previous_iter_valid_loss : 0.08020071685314178\n",
      "\n",
      "    172400\t  0.080260\t  0.080201\t  0.109305\t\tCURRENT LEARNING RATE: 0.0890865258864492\n",
      "previous_iter_valid_loss : 0.09765898436307907\n",
      "\n",
      "    172500\t  0.097864\t  0.097659\t  0.109268\t\tCURRENT LEARNING RATE: 0.08899748388898167\n",
      "previous_iter_valid_loss : 0.08433626592159271\n",
      "\n",
      "    172600\t  0.084371\t  0.084336\t  0.108951\t\tCURRENT LEARNING RATE: 0.08890853088900541\n",
      "previous_iter_valid_loss : 0.09518732875585556\n",
      "\n",
      "    172700\t  0.095189\t  0.095187\t  0.108898\t\tCURRENT LEARNING RATE: 0.08881966679756748\n",
      "previous_iter_valid_loss : 0.0896119549870491\n",
      "\n",
      "    172800\t  0.089534\t  0.089612\t  0.108850\t\tCURRENT LEARNING RATE: 0.08873089152580373\n",
      "previous_iter_valid_loss : 0.08771137148141861\n",
      "\n",
      "    172900\t  0.087627\t  0.087711\t  0.108513\t\tCURRENT LEARNING RATE: 0.08864220498493891\n",
      "previous_iter_valid_loss : 0.10375312715768814\n",
      "\n",
      "    173000\t  0.103650\t  0.103753\t  0.108270\t\tCURRENT LEARNING RATE: 0.08855360708628644\n",
      "previous_iter_valid_loss : 0.0807587057352066\n",
      "\n",
      "    173100\t  0.080784\t  0.080759\t  0.106669\t\tCURRENT LEARNING RATE: 0.08846509774124846\n",
      "previous_iter_valid_loss : 0.10370375216007233\n",
      "\n",
      "    173200\t  0.104167\t  0.103704\t  0.106323\t\tCURRENT LEARNING RATE: 0.08837667686131558\n",
      "previous_iter_valid_loss : 0.08193803578615189\n",
      "\n",
      "    173300\t  0.082252\t  0.081938\t  0.105966\t\tCURRENT LEARNING RATE: 0.08828834435806694\n",
      "previous_iter_valid_loss : 0.09100315719842911\n",
      "\n",
      "    173400\t  0.091277\t  0.091003\t  0.105791\t\tCURRENT LEARNING RATE: 0.08820010014317\n",
      "previous_iter_valid_loss : 0.10586278885602951\n",
      "\n",
      "    173500\t  0.106205\t  0.105863\t  0.105475\t\tCURRENT LEARNING RATE: 0.08811194412838055\n",
      "previous_iter_valid_loss : 0.08396244049072266\n",
      "\n",
      "    173600\t  0.084154\t  0.083962\t  0.105435\t\tCURRENT LEARNING RATE: 0.08802387622554259\n",
      "previous_iter_valid_loss : 0.09509482979774475\n",
      "\n",
      "    173700\t  0.095324\t  0.095095\t  0.104460\t\tCURRENT LEARNING RATE: 0.08793589634658819\n",
      "previous_iter_valid_loss : 0.10304877907037735\n",
      "\n",
      "    173800\t  0.103239\t  0.103049\t  0.104494\t\tCURRENT LEARNING RATE: 0.08784800440353743\n",
      "previous_iter_valid_loss : 0.09564857929944992\n",
      "\n",
      "    173900\t  0.095792\t  0.095649\t  0.104613\t\tCURRENT LEARNING RATE: 0.08776020030849843\n",
      "previous_iter_valid_loss : 0.10510026663541794\n",
      "\n",
      "    174000\t  0.105432\t  0.105100\t  0.104791\t\tCURRENT LEARNING RATE: 0.08767248397366705\n",
      "previous_iter_valid_loss : 0.08061641454696655\n",
      "\n",
      "    174100\t  0.080620\t  0.080616\t  0.104465\t\tCURRENT LEARNING RATE: 0.08758485531132694\n",
      "previous_iter_valid_loss : 0.10597103089094162\n",
      "\n",
      "    174200\t  0.105814\t  0.105971\t  0.104607\t\tCURRENT LEARNING RATE: 0.08749731423384943\n",
      "previous_iter_valid_loss : 0.08121374249458313\n",
      "\n",
      "    174300\t  0.081189\t  0.081214\t  0.103935\t\tCURRENT LEARNING RATE: 0.08740986065369347\n",
      "previous_iter_valid_loss : 0.09472553431987762\n",
      "\n",
      "    174400\t  0.094741\t  0.094726\t  0.103452\t\tCURRENT LEARNING RATE: 0.08732249448340543\n",
      "previous_iter_valid_loss : 0.11377710849046707\n",
      "\n",
      "    174500\t  0.113718\t  0.113777\t  0.103671\t\tCURRENT LEARNING RATE: 0.08723521563561916\n",
      "previous_iter_valid_loss : 0.08761827647686005\n",
      "\n",
      "    174600\t  0.087518\t  0.087618\t  0.103070\t\tCURRENT LEARNING RATE: 0.08714802402305578\n",
      "previous_iter_valid_loss : 0.10441979765892029\n",
      "\n",
      "    174700\t  0.104304\t  0.104420\t  0.103054\t\tCURRENT LEARNING RATE: 0.0870609195585237\n",
      "previous_iter_valid_loss : 0.1180119514465332\n",
      "\n",
      "    174800\t  0.117895\t  0.118012\t  0.103095\t\tCURRENT LEARNING RATE: 0.08697390215491842\n",
      "previous_iter_valid_loss : 0.08936702460050583\n",
      "\n",
      "    174900\t  0.089322\t  0.089367\t  0.102809\t\tCURRENT LEARNING RATE: 0.08688697172522257\n",
      "previous_iter_valid_loss : 0.1102055087685585\n",
      "\n",
      "    175000\t  0.110174\t  0.110206\t  0.102720\t\tCURRENT LEARNING RATE: 0.08680012818250567\n",
      "previous_iter_valid_loss : 0.09321737289428711\n",
      "\n",
      "    175100\t  0.093153\t  0.093217\t  0.102723\t\tCURRENT LEARNING RATE: 0.08671337143992418\n",
      "previous_iter_valid_loss : 0.1037534549832344\n",
      "\n",
      "    175200\t  0.103663\t  0.103753\t  0.102897\t\tCURRENT LEARNING RATE: 0.08662670141072136\n",
      "previous_iter_valid_loss : 0.16882428526878357\n",
      "\n",
      "    175300\t  0.168629\t  0.168824\t  0.103071\t\tCURRENT LEARNING RATE: 0.08654011800822717\n",
      "previous_iter_valid_loss : 0.10119938105344772\n",
      "\n",
      "    175400\t  0.100991\t  0.101199\t  0.103080\t\tCURRENT LEARNING RATE: 0.0864536211458582\n",
      "previous_iter_valid_loss : 0.15682919323444366\n",
      "\n",
      "    175500\t  0.156691\t  0.156829\t  0.103788\t\tCURRENT LEARNING RATE: 0.08636721073711758\n",
      "previous_iter_valid_loss : 0.09369933605194092\n",
      "\n",
      "    175600\t  0.093538\t  0.093699\t  0.102125\t\tCURRENT LEARNING RATE: 0.08628088669559489\n",
      "previous_iter_valid_loss : 0.14318056404590607\n",
      "\n",
      "    175700\t  0.143051\t  0.143181\t  0.102589\t\tCURRENT LEARNING RATE: 0.08619464893496609\n",
      "previous_iter_valid_loss : 0.0850762203335762\n",
      "\n",
      "    175800\t  0.084984\t  0.085076\t  0.102574\t\tCURRENT LEARNING RATE: 0.08610849736899341\n",
      "previous_iter_valid_loss : 0.09040902554988861\n",
      "\n",
      "    175900\t  0.090326\t  0.090409\t  0.102279\t\tCURRENT LEARNING RATE: 0.08602243191152527\n",
      "previous_iter_valid_loss : 0.11560890823602676\n",
      "\n",
      "    176000\t  0.115445\t  0.115609\t  0.102537\t\tCURRENT LEARNING RATE: 0.08593645247649621\n",
      "previous_iter_valid_loss : 0.10518898069858551\n",
      "\n",
      "    176100\t  0.105460\t  0.105189\t  0.102771\t\tCURRENT LEARNING RATE: 0.08585055897792679\n",
      "previous_iter_valid_loss : 0.1696336418390274\n",
      "\n",
      "    176200\t  0.170382\t  0.169634\t  0.103401\t\tCURRENT LEARNING RATE: 0.0857647513299235\n",
      "previous_iter_valid_loss : 0.09504613280296326\n",
      "\n",
      "    176300\t  0.095311\t  0.095046\t  0.103380\t\tCURRENT LEARNING RATE: 0.08567902944667868\n",
      "previous_iter_valid_loss : 0.11022690683603287\n",
      "\n",
      "    176400\t  0.110572\t  0.110227\t  0.103457\t\tCURRENT LEARNING RATE: 0.08559339324247048\n",
      "previous_iter_valid_loss : 0.08225821703672409\n",
      "\n",
      "    176500\t  0.082305\t  0.082258\t  0.103020\t\tCURRENT LEARNING RATE: 0.08550784263166261\n",
      "previous_iter_valid_loss : 0.08578445017337799\n",
      "\n",
      "    176600\t  0.085773\t  0.085784\t  0.103054\t\tCURRENT LEARNING RATE: 0.08542237752870453\n",
      "previous_iter_valid_loss : 0.09913145005702972\n",
      "\n",
      "    176700\t  0.099055\t  0.099131\t  0.103183\t\tCURRENT LEARNING RATE: 0.08533699784813108\n",
      "previous_iter_valid_loss : 0.1472228765487671\n",
      "\n",
      "    176800\t  0.147057\t  0.147223\t  0.103729\t\tCURRENT LEARNING RATE: 0.0852517035045626\n",
      "previous_iter_valid_loss : 0.11716591566801071\n",
      "\n",
      "    176900\t  0.116987\t  0.117166\t  0.103713\t\tCURRENT LEARNING RATE: 0.08516649441270471\n",
      "previous_iter_valid_loss : 0.0860714390873909\n",
      "\n",
      "    177000\t  0.085977\t  0.086071\t  0.103708\t\tCURRENT LEARNING RATE: 0.08508137048734836\n",
      "previous_iter_valid_loss : 0.09653481096029282\n",
      "\n",
      "    177100\t  0.096525\t  0.096535\t  0.103845\t\tCURRENT LEARNING RATE: 0.08499633164336956\n",
      "previous_iter_valid_loss : 0.09672239422798157\n",
      "\n",
      "    177200\t  0.096593\t  0.096722\t  0.103976\t\tCURRENT LEARNING RATE: 0.0849113777957295\n",
      "previous_iter_valid_loss : 0.09095855057239532\n",
      "\n",
      "    177300\t  0.090994\t  0.090959\t  0.103779\t\tCURRENT LEARNING RATE: 0.0848265088594743\n",
      "previous_iter_valid_loss : 0.12244617193937302\n",
      "\n",
      "    177400\t  0.122985\t  0.122446\t  0.103888\t\tCURRENT LEARNING RATE: 0.08474172474973506\n",
      "previous_iter_valid_loss : 0.08998515456914902\n",
      "\n",
      "    177500\t  0.090225\t  0.089985\t  0.103545\t\tCURRENT LEARNING RATE: 0.08465702538172759\n",
      "previous_iter_valid_loss : 0.11227347701787949\n",
      "\n",
      "    177600\t  0.112543\t  0.112273\t  0.103637\t\tCURRENT LEARNING RATE: 0.08457241067075259\n",
      "previous_iter_valid_loss : 0.08666235953569412\n",
      "\n",
      "    177700\t  0.086864\t  0.086662\t  0.103486\t\tCURRENT LEARNING RATE: 0.08448788053219529\n",
      "previous_iter_valid_loss : 0.16002537310123444\n",
      "\n",
      "    177800\t  0.160575\t  0.160025\t  0.104256\t\tCURRENT LEARNING RATE: 0.08440343488152557\n",
      "previous_iter_valid_loss : 0.09885827451944351\n",
      "\n",
      "    177900\t  0.099084\t  0.098858\t  0.104318\t\tCURRENT LEARNING RATE: 0.08431907363429775\n",
      "previous_iter_valid_loss : 0.08092120289802551\n",
      "\n",
      "    178000\t  0.081016\t  0.080921\t  0.103895\t\tCURRENT LEARNING RATE: 0.08423479670615061\n",
      "previous_iter_valid_loss : 0.09673084318637848\n",
      "\n",
      "    178100\t  0.096937\t  0.096731\t  0.103984\t\tCURRENT LEARNING RATE: 0.08415060401280719\n",
      "previous_iter_valid_loss : 0.15216393768787384\n",
      "\n",
      "    178200\t  0.152560\t  0.152164\t  0.104577\t\tCURRENT LEARNING RATE: 0.0840664954700748\n",
      "previous_iter_valid_loss : 0.11462412029504776\n",
      "\n",
      "    178300\t  0.114943\t  0.114624\t  0.104907\t\tCURRENT LEARNING RATE: 0.08398247099384487\n",
      "previous_iter_valid_loss : 0.09016415476799011\n",
      "\n",
      "    178400\t  0.090367\t  0.090164\t  0.104851\t\tCURRENT LEARNING RATE: 0.08389853050009295\n",
      "previous_iter_valid_loss : 0.08287128061056137\n",
      "\n",
      "    178500\t  0.082947\t  0.082871\t  0.103478\t\tCURRENT LEARNING RATE: 0.0838146739048785\n",
      "previous_iter_valid_loss : 0.08507148176431656\n",
      "\n",
      "    178600\t  0.085205\t  0.085071\t  0.103422\t\tCURRENT LEARNING RATE: 0.08373090112434496\n",
      "previous_iter_valid_loss : 0.1146470308303833\n",
      "\n",
      "    178700\t  0.114900\t  0.114647\t  0.103361\t\tCURRENT LEARNING RATE: 0.0836472120747195\n",
      "previous_iter_valid_loss : 0.12000353634357452\n",
      "\n",
      "    178800\t  0.119829\t  0.120004\t  0.103208\t\tCURRENT LEARNING RATE: 0.08356360667231312\n",
      "previous_iter_valid_loss : 0.08479928225278854\n",
      "\n",
      "    178900\t  0.084750\t  0.084799\t  0.102925\t\tCURRENT LEARNING RATE: 0.08348008483352035\n",
      "previous_iter_valid_loss : 0.09208356589078903\n",
      "\n",
      "    179000\t  0.091895\t  0.092084\t  0.102708\t\tCURRENT LEARNING RATE: 0.08339664647481938\n",
      "previous_iter_valid_loss : 0.08232483267784119\n",
      "\n",
      "    179100\t  0.082323\t  0.082325\t  0.102570\t\tCURRENT LEARNING RATE: 0.08331329151277182\n",
      "previous_iter_valid_loss : 0.08081380277872086\n",
      "\n",
      "    179200\t  0.080793\t  0.080814\t  0.102400\t\tCURRENT LEARNING RATE: 0.08323001986402274\n",
      "previous_iter_valid_loss : 0.09064361453056335\n",
      "\n",
      "    179300\t  0.090733\t  0.090644\t  0.101615\t\tCURRENT LEARNING RATE: 0.08314683144530044\n",
      "previous_iter_valid_loss : 0.08713028579950333\n",
      "\n",
      "    179400\t  0.087258\t  0.087130\t  0.101630\t\tCURRENT LEARNING RATE: 0.08306372617341654\n",
      "previous_iter_valid_loss : 0.08062487840652466\n",
      "\n",
      "    179500\t  0.080711\t  0.080625\t  0.101627\t\tCURRENT LEARNING RATE: 0.08298070396526569\n",
      "previous_iter_valid_loss : 0.08857636898756027\n",
      "\n",
      "    179600\t  0.088730\t  0.088576\t  0.101231\t\tCURRENT LEARNING RATE: 0.08289776473782576\n",
      "previous_iter_valid_loss : 0.11067993938922882\n",
      "\n",
      "    179700\t  0.111021\t  0.110680\t  0.101271\t\tCURRENT LEARNING RATE: 0.08281490840815746\n",
      "previous_iter_valid_loss : 0.1144636869430542\n",
      "\n",
      "    179800\t  0.114741\t  0.114464\t  0.101578\t\tCURRENT LEARNING RATE: 0.08273213489340447\n",
      "previous_iter_valid_loss : 0.13535715639591217\n",
      "\n",
      "    179900\t  0.135772\t  0.135357\t  0.102135\t\tCURRENT LEARNING RATE: 0.08264944411079327\n",
      "previous_iter_valid_loss : 0.13404609262943268\n",
      "\n",
      "    180000\t  0.134468\t  0.134046\t  0.102500\t\tCURRENT LEARNING RATE: 0.08256683597763308\n",
      "previous_iter_valid_loss : 0.10839096456766129\n",
      "\n",
      "    180100\t  0.108138\t  0.108391\t  0.102724\t\tCURRENT LEARNING RATE: 0.08248431041131572\n",
      "previous_iter_valid_loss : 0.09285465627908707\n",
      "\n",
      "    180200\t  0.092954\t  0.092855\t  0.102769\t\tCURRENT LEARNING RATE: 0.08240186732931568\n",
      "previous_iter_valid_loss : 0.10201144963502884\n",
      "\n",
      "    180300\t  0.102186\t  0.102011\t  0.102443\t\tCURRENT LEARNING RATE: 0.0823195066491898\n",
      "previous_iter_valid_loss : 0.10455251485109329\n",
      "\n",
      "    180400\t  0.104400\t  0.104553\t  0.102633\t\tCURRENT LEARNING RATE: 0.08223722828857745\n",
      "previous_iter_valid_loss : 0.09579096734523773\n",
      "\n",
      "    180500\t  0.095888\t  0.095791\t  0.102732\t\tCURRENT LEARNING RATE: 0.08215503216520023\n",
      "previous_iter_valid_loss : 0.1284041553735733\n",
      "\n",
      "    180600\t  0.128799\t  0.128404\t  0.102956\t\tCURRENT LEARNING RATE: 0.08207291819686204\n",
      "previous_iter_valid_loss : 0.07887069880962372\n",
      "\n",
      "    180700\t  0.078883\t  0.078871\t  0.102735\t\tCURRENT LEARNING RATE: 0.08199088630144886\n",
      "previous_iter_valid_loss : 0.08425411581993103\n",
      "\n",
      "    180800\t  0.084149\t  0.084254\t  0.102683\t\tCURRENT LEARNING RATE: 0.08190893639692884\n",
      "previous_iter_valid_loss : 0.07788792252540588\n",
      "\n",
      "\n",
      "Current valid loss: 0.07788792252540588;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "    180900\t  0.077847\t  0.077888\t  0.102638\t\tCURRENT LEARNING RATE: 0.08182706840135202\n",
      "previous_iter_valid_loss : 0.09919007867574692\n",
      "\n",
      "    181000\t  0.099397\t  0.099190\t  0.102725\t\tCURRENT LEARNING RATE: 0.08174528223285045\n",
      "previous_iter_valid_loss : 0.13060416281223297\n",
      "\n",
      "    181100\t  0.130994\t  0.130604\t  0.103121\t\tCURRENT LEARNING RATE: 0.0816635778096379\n",
      "previous_iter_valid_loss : 0.08629899471998215\n",
      "\n",
      "    181200\t  0.086462\t  0.086299\t  0.102394\t\tCURRENT LEARNING RATE: 0.08158195505000998\n",
      "previous_iter_valid_loss : 0.10331233590841293\n",
      "\n",
      "    181300\t  0.103520\t  0.103312\t  0.102458\t\tCURRENT LEARNING RATE: 0.08150041387234389\n",
      "previous_iter_valid_loss : 0.11690862476825714\n",
      "\n",
      "    181400\t  0.117108\t  0.116909\t  0.102481\t\tCURRENT LEARNING RATE: 0.08141895419509848\n",
      "previous_iter_valid_loss : 0.09724918752908707\n",
      "\n",
      "    181500\t  0.097442\t  0.097249\t  0.102471\t\tCURRENT LEARNING RATE: 0.08133757593681404\n",
      "previous_iter_valid_loss : 0.10648007690906525\n",
      "\n",
      "    181600\t  0.106592\t  0.106480\t  0.102510\t\tCURRENT LEARNING RATE: 0.08125627901611233\n",
      "previous_iter_valid_loss : 0.08083279430866241\n",
      "\n",
      "    181700\t  0.080819\t  0.080833\t  0.102371\t\tCURRENT LEARNING RATE: 0.08117506335169639\n",
      "previous_iter_valid_loss : 0.10818745195865631\n",
      "\n",
      "    181800\t  0.108434\t  0.108187\t  0.101916\t\tCURRENT LEARNING RATE: 0.08109392886235059\n",
      "previous_iter_valid_loss : 0.09055014699697495\n",
      "\n",
      "    181900\t  0.090281\t  0.090550\t  0.101887\t\tCURRENT LEARNING RATE: 0.08101287546694037\n",
      "previous_iter_valid_loss : 0.08061656355857849\n",
      "\n",
      "    182000\t  0.080528\t  0.080617\t  0.101611\t\tCURRENT LEARNING RATE: 0.08093190308441241\n",
      "previous_iter_valid_loss : 0.10545754432678223\n",
      "\n",
      "    182100\t  0.105689\t  0.105458\t  0.101557\t\tCURRENT LEARNING RATE: 0.08085101163379425\n",
      "previous_iter_valid_loss : 0.08277921378612518\n",
      "\n",
      "    182200\t  0.082691\t  0.082779\t  0.101515\t\tCURRENT LEARNING RATE: 0.08077020103419448\n",
      "previous_iter_valid_loss : 0.08663704991340637\n",
      "\n",
      "    182300\t  0.086679\t  0.086637\t  0.101414\t\tCURRENT LEARNING RATE: 0.08068947120480247\n",
      "previous_iter_valid_loss : 0.08341673016548157\n",
      "\n",
      "    182400\t  0.083445\t  0.083417\t  0.101446\t\tCURRENT LEARNING RATE: 0.08060882206488838\n",
      "previous_iter_valid_loss : 0.08612506091594696\n",
      "\n",
      "    182500\t  0.086213\t  0.086125\t  0.101330\t\tCURRENT LEARNING RATE: 0.08052825353380308\n",
      "previous_iter_valid_loss : 0.110481396317482\n",
      "\n",
      "    182600\t  0.110711\t  0.110481\t  0.101592\t\tCURRENT LEARNING RATE: 0.08044776553097803\n",
      "previous_iter_valid_loss : 0.09910567849874496\n",
      "\n",
      "    182700\t  0.099367\t  0.099106\t  0.101631\t\tCURRENT LEARNING RATE: 0.08036735797592519\n",
      "previous_iter_valid_loss : 0.08106720447540283\n",
      "\n",
      "    182800\t  0.080997\t  0.081067\t  0.101546\t\tCURRENT LEARNING RATE: 0.08028703078823705\n",
      "previous_iter_valid_loss : 0.10203859955072403\n",
      "\n",
      "    182900\t  0.102215\t  0.102039\t  0.101689\t\tCURRENT LEARNING RATE: 0.08020678388758637\n",
      "previous_iter_valid_loss : 0.08183819055557251\n",
      "\n",
      "    183000\t  0.081834\t  0.081838\t  0.101470\t\tCURRENT LEARNING RATE: 0.08012661719372628\n",
      "previous_iter_valid_loss : 0.09559761732816696\n",
      "\n",
      "    183100\t  0.095700\t  0.095598\t  0.101618\t\tCURRENT LEARNING RATE: 0.08004653062649005\n",
      "previous_iter_valid_loss : 0.07834174484014511\n",
      "\n",
      "    183200\t  0.078311\t  0.078342\t  0.101364\t\tCURRENT LEARNING RATE: 0.07996652410579112\n",
      "previous_iter_valid_loss : 0.13370059430599213\n",
      "\n",
      "    183300\t  0.134042\t  0.133701\t  0.101882\t\tCURRENT LEARNING RATE: 0.07988659755162296\n",
      "previous_iter_valid_loss : 0.07908200472593307\n",
      "\n",
      "    183400\t  0.078969\t  0.079082\t  0.101763\t\tCURRENT LEARNING RATE: 0.07980675088405902\n",
      "previous_iter_valid_loss : 0.07845713198184967\n",
      "\n",
      "    183500\t  0.078461\t  0.078457\t  0.101489\t\tCURRENT LEARNING RATE: 0.07972698402325258\n",
      "previous_iter_valid_loss : 0.11013233661651611\n",
      "\n",
      "    183600\t  0.110412\t  0.110132\t  0.101750\t\tCURRENT LEARNING RATE: 0.07964729688943685\n",
      "previous_iter_valid_loss : 0.0966886430978775\n",
      "\n",
      "    183700\t  0.096779\t  0.096689\t  0.101766\t\tCURRENT LEARNING RATE: 0.07956768940292461\n",
      "previous_iter_valid_loss : 0.08431614190340042\n",
      "\n",
      "    183800\t  0.084105\t  0.084316\t  0.101579\t\tCURRENT LEARNING RATE: 0.07948816148410844\n",
      "previous_iter_valid_loss : 0.08537601679563522\n",
      "\n",
      "    183900\t  0.085193\t  0.085376\t  0.101476\t\tCURRENT LEARNING RATE: 0.07940871305346034\n",
      "previous_iter_valid_loss : 0.08157362788915634\n",
      "\n",
      "    184000\t  0.081436\t  0.081574\t  0.101241\t\tCURRENT LEARNING RATE: 0.07932934403153194\n",
      "previous_iter_valid_loss : 0.10058989375829697\n",
      "\n",
      "    184100\t  0.100774\t  0.100590\t  0.101441\t\tCURRENT LEARNING RATE: 0.07925005433895416\n",
      "previous_iter_valid_loss : 0.08346923440694809\n",
      "\n",
      "    184200\t  0.083435\t  0.083469\t  0.101216\t\tCURRENT LEARNING RATE: 0.07917084389643735\n",
      "previous_iter_valid_loss : 0.11474397033452988\n",
      "\n",
      "    184300\t  0.114961\t  0.114744\t  0.101551\t\tCURRENT LEARNING RATE: 0.07909171262477101\n",
      "previous_iter_valid_loss : 0.08425068855285645\n",
      "\n",
      "    184400\t  0.084273\t  0.084251\t  0.101446\t\tCURRENT LEARNING RATE: 0.0790126604448239\n",
      "previous_iter_valid_loss : 0.0834708884358406\n",
      "\n",
      "    184500\t  0.083443\t  0.083471\t  0.101143\t\tCURRENT LEARNING RATE: 0.0789336872775438\n",
      "previous_iter_valid_loss : 0.10327157378196716\n",
      "\n",
      "    184600\t  0.103038\t  0.103272\t  0.101300\t\tCURRENT LEARNING RATE: 0.07885479304395758\n",
      "previous_iter_valid_loss : 0.11026665568351746\n",
      "\n",
      "    184700\t  0.110020\t  0.110267\t  0.101358\t\tCURRENT LEARNING RATE: 0.07877597766517096\n",
      "previous_iter_valid_loss : 0.1252269744873047\n",
      "\n",
      "    184800\t  0.125161\t  0.125227\t  0.101430\t\tCURRENT LEARNING RATE: 0.07869724106236857\n",
      "previous_iter_valid_loss : 0.10943280160427094\n",
      "\n",
      "    184900\t  0.109665\t  0.109433\t  0.101631\t\tCURRENT LEARNING RATE: 0.0786185831568138\n",
      "previous_iter_valid_loss : 0.11507637798786163\n",
      "\n",
      "    185000\t  0.115226\t  0.115076\t  0.101680\t\tCURRENT LEARNING RATE: 0.07854000386984875\n",
      "previous_iter_valid_loss : 0.08412464708089828\n",
      "\n",
      "    185100\t  0.083913\t  0.084125\t  0.101589\t\tCURRENT LEARNING RATE: 0.0784615031228941\n",
      "previous_iter_valid_loss : 0.09037665277719498\n",
      "\n",
      "    185200\t  0.090452\t  0.090377\t  0.101455\t\tCURRENT LEARNING RATE: 0.07838308083744913\n",
      "previous_iter_valid_loss : 0.08031155914068222\n",
      "\n",
      "    185300\t  0.080330\t  0.080312\t  0.100570\t\tCURRENT LEARNING RATE: 0.0783047369350915\n",
      "previous_iter_valid_loss : 0.09586640447378159\n",
      "\n",
      "    185400\t  0.095971\t  0.095866\t  0.100517\t\tCURRENT LEARNING RATE: 0.07822647133747737\n",
      "previous_iter_valid_loss : 0.08036307990550995\n",
      "\n",
      "    185500\t  0.080306\t  0.080363\t  0.099752\t\tCURRENT LEARNING RATE: 0.07814828396634106\n",
      "previous_iter_valid_loss : 0.08191700279712677\n",
      "\n",
      "    185600\t  0.081980\t  0.081917\t  0.099634\t\tCURRENT LEARNING RATE: 0.07807017474349526\n",
      "previous_iter_valid_loss : 0.08281931281089783\n",
      "\n",
      "    185700\t  0.082860\t  0.082819\t  0.099031\t\tCURRENT LEARNING RATE: 0.07799214359083068\n",
      "previous_iter_valid_loss : 0.08722512423992157\n",
      "\n",
      "    185800\t  0.087089\t  0.087225\t  0.099052\t\tCURRENT LEARNING RATE: 0.07791419043031621\n",
      "previous_iter_valid_loss : 0.08532340824604034\n",
      "\n",
      "    185900\t  0.085489\t  0.085323\t  0.099001\t\tCURRENT LEARNING RATE: 0.07783631518399865\n",
      "previous_iter_valid_loss : 0.09140768647193909\n",
      "\n",
      "    186000\t  0.091469\t  0.091408\t  0.098759\t\tCURRENT LEARNING RATE: 0.07775851777400278\n",
      "previous_iter_valid_loss : 0.12103714048862457\n",
      "\n",
      "    186100\t  0.121293\t  0.121037\t  0.098918\t\tCURRENT LEARNING RATE: 0.07768079812253113\n",
      "previous_iter_valid_loss : 0.08490876853466034\n",
      "\n",
      "    186200\t  0.084944\t  0.084909\t  0.098070\t\tCURRENT LEARNING RATE: 0.07760315615186411\n",
      "previous_iter_valid_loss : 0.09120608121156693\n",
      "\n",
      "    186300\t  0.091243\t  0.091206\t  0.098032\t\tCURRENT LEARNING RATE: 0.07752559178435968\n",
      "previous_iter_valid_loss : 0.0940374955534935\n",
      "\n",
      "    186400\t  0.094158\t  0.094037\t  0.097870\t\tCURRENT LEARNING RATE: 0.07744810494245352\n",
      "previous_iter_valid_loss : 0.09270087629556656\n",
      "\n",
      "    186500\t  0.092746\t  0.092701\t  0.097975\t\tCURRENT LEARNING RATE: 0.07737069554865875\n",
      "previous_iter_valid_loss : 0.09992551803588867\n",
      "\n",
      "    186600\t  0.100112\t  0.099926\t  0.098116\t\tCURRENT LEARNING RATE: 0.07729336352556597\n",
      "previous_iter_valid_loss : 0.09258153289556503\n",
      "\n",
      "    186700\t  0.092629\t  0.092582\t  0.098050\t\tCURRENT LEARNING RATE: 0.07721610879584316\n",
      "previous_iter_valid_loss : 0.08832195401191711\n",
      "\n",
      "    186800\t  0.088409\t  0.088322\t  0.097461\t\tCURRENT LEARNING RATE: 0.07713893128223558\n",
      "previous_iter_valid_loss : 0.09862414002418518\n",
      "\n",
      "    186900\t  0.098428\t  0.098624\t  0.097276\t\tCURRENT LEARNING RATE: 0.0770618309075657\n",
      "previous_iter_valid_loss : 0.11133775860071182\n",
      "\n",
      "    187000\t  0.111595\t  0.111338\t  0.097529\t\tCURRENT LEARNING RATE: 0.07698480759473317\n",
      "previous_iter_valid_loss : 0.07883700728416443\n",
      "\n",
      "    187100\t  0.078731\t  0.078837\t  0.097352\t\tCURRENT LEARNING RATE: 0.07690786126671463\n",
      "previous_iter_valid_loss : 0.07848397642374039\n",
      "\n",
      "    187200\t  0.078418\t  0.078484\t  0.097169\t\tCURRENT LEARNING RATE: 0.07683099184656379\n",
      "previous_iter_valid_loss : 0.0837012529373169\n",
      "\n",
      "    187300\t  0.083626\t  0.083701\t  0.097097\t\tCURRENT LEARNING RATE: 0.07675419925741117\n",
      "previous_iter_valid_loss : 0.07965343445539474\n",
      "\n",
      "    187400\t  0.079634\t  0.079653\t  0.096669\t\tCURRENT LEARNING RATE: 0.07667748342246423\n",
      "previous_iter_valid_loss : 0.0797044038772583\n",
      "\n",
      "    187500\t  0.079639\t  0.079704\t  0.096566\t\tCURRENT LEARNING RATE: 0.0766008442650071\n",
      "previous_iter_valid_loss : 0.07953469455242157\n",
      "\n",
      "    187600\t  0.079534\t  0.079535\t  0.096239\t\tCURRENT LEARNING RATE: 0.0765242817084006\n",
      "previous_iter_valid_loss : 0.1131562739610672\n",
      "\n",
      "    187700\t  0.113330\t  0.113156\t  0.096504\t\tCURRENT LEARNING RATE: 0.0764477956760822\n",
      "previous_iter_valid_loss : 0.09782677888870239\n",
      "\n",
      "    187800\t  0.097914\t  0.097827\t  0.095882\t\tCURRENT LEARNING RATE: 0.07637138609156584\n",
      "previous_iter_valid_loss : 0.07805415987968445\n",
      "\n",
      "    187900\t  0.077954\t  0.078054\t  0.095674\t\tCURRENT LEARNING RATE: 0.07629505287844195\n",
      "previous_iter_valid_loss : 0.10259454697370529\n",
      "\n",
      "    188000\t  0.102359\t  0.102595\t  0.095890\t\tCURRENT LEARNING RATE: 0.07621879596037727\n",
      "previous_iter_valid_loss : 0.08906061947345734\n",
      "\n",
      "    188100\t  0.089190\t  0.089061\t  0.095814\t\tCURRENT LEARNING RATE: 0.07614261526111492\n",
      "previous_iter_valid_loss : 0.08747168630361557\n",
      "\n",
      "    188200\t  0.087304\t  0.087472\t  0.095167\t\tCURRENT LEARNING RATE: 0.07606651070447416\n",
      "previous_iter_valid_loss : 0.08066199719905853\n",
      "\n",
      "    188300\t  0.080526\t  0.080662\t  0.094827\t\tCURRENT LEARNING RATE: 0.07599048221435047\n",
      "previous_iter_valid_loss : 0.11097214370965958\n",
      "\n",
      "    188400\t  0.110800\t  0.110972\t  0.095035\t\tCURRENT LEARNING RATE: 0.0759145297147153\n",
      "previous_iter_valid_loss : 0.08609860390424728\n",
      "\n",
      "    188500\t  0.085948\t  0.086099\t  0.095067\t\tCURRENT LEARNING RATE: 0.0758386531296162\n",
      "previous_iter_valid_loss : 0.09627453982830048\n",
      "\n",
      "    188600\t  0.096455\t  0.096275\t  0.095179\t\tCURRENT LEARNING RATE: 0.07576285238317651\n",
      "previous_iter_valid_loss : 0.08442562818527222\n",
      "\n",
      "    188700\t  0.084500\t  0.084426\t  0.094877\t\tCURRENT LEARNING RATE: 0.07568712739959556\n",
      "previous_iter_valid_loss : 0.11666478961706161\n",
      "\n",
      "    188800\t  0.116884\t  0.116665\t  0.094844\t\tCURRENT LEARNING RATE: 0.07561147810314828\n",
      "previous_iter_valid_loss : 0.08437921851873398\n",
      "\n",
      "    188900\t  0.084376\t  0.084379\t  0.094840\t\tCURRENT LEARNING RATE: 0.07553590441818543\n",
      "previous_iter_valid_loss : 0.10261519998311996\n",
      "\n",
      "    189000\t  0.102817\t  0.102615\t  0.094945\t\tCURRENT LEARNING RATE: 0.07546040626913328\n",
      "previous_iter_valid_loss : 0.07995687425136566\n",
      "\n",
      "    189100\t  0.079815\t  0.079957\t  0.094921\t\tCURRENT LEARNING RATE: 0.0753849835804937\n",
      "previous_iter_valid_loss : 0.08760948479175568\n",
      "\n",
      "    189200\t  0.087531\t  0.087609\t  0.094989\t\tCURRENT LEARNING RATE: 0.07530963627684396\n",
      "previous_iter_valid_loss : 0.08804550021886826\n",
      "\n",
      "    189300\t  0.088077\t  0.088046\t  0.094963\t\tCURRENT LEARNING RATE: 0.0752343642828368\n",
      "previous_iter_valid_loss : 0.11986097693443298\n",
      "\n",
      "    189400\t  0.120100\t  0.119861\t  0.095291\t\tCURRENT LEARNING RATE: 0.07515916752320016\n",
      "previous_iter_valid_loss : 0.08266495168209076\n",
      "\n",
      "    189500\t  0.082578\t  0.082665\t  0.095311\t\tCURRENT LEARNING RATE: 0.07508404592273733\n",
      "previous_iter_valid_loss : 0.08629106730222702\n",
      "\n",
      "    189600\t  0.086314\t  0.086291\t  0.095288\t\tCURRENT LEARNING RATE: 0.07500899940632667\n",
      "previous_iter_valid_loss : 0.0794294998049736\n",
      "\n",
      "    189700\t  0.079416\t  0.079429\t  0.094976\t\tCURRENT LEARNING RATE: 0.07493402789892167\n",
      "previous_iter_valid_loss : 0.09980794787406921\n",
      "\n",
      "    189800\t  0.099622\t  0.099808\t  0.094829\t\tCURRENT LEARNING RATE: 0.07485913132555082\n",
      "previous_iter_valid_loss : 0.10031206905841827\n",
      "\n",
      "    189900\t  0.100121\t  0.100312\t  0.094479\t\tCURRENT LEARNING RATE: 0.07478430961131753\n",
      "previous_iter_valid_loss : 0.08719000965356827\n",
      "\n",
      "    190000\t  0.087033\t  0.087190\t  0.094010\t\tCURRENT LEARNING RATE: 0.07470956268140008\n",
      "previous_iter_valid_loss : 0.08426442742347717\n",
      "\n",
      "    190100\t  0.084209\t  0.084264\t  0.093769\t\tCURRENT LEARNING RATE: 0.07463489046105154\n",
      "previous_iter_valid_loss : 0.07952212542295456\n",
      "\n",
      "    190200\t  0.079521\t  0.079522\t  0.093635\t\tCURRENT LEARNING RATE: 0.07456029287559968\n",
      "previous_iter_valid_loss : 0.07850436866283417\n",
      "\n",
      "    190300\t  0.078544\t  0.078504\t  0.093400\t\tCURRENT LEARNING RATE: 0.07448576985044691\n",
      "previous_iter_valid_loss : 0.09993443638086319\n",
      "\n",
      "    190400\t  0.100136\t  0.099934\t  0.093354\t\tCURRENT LEARNING RATE: 0.07441132131107019\n",
      "previous_iter_valid_loss : 0.08413168787956238\n",
      "\n",
      "    190500\t  0.083968\t  0.084132\t  0.093238\t\tCURRENT LEARNING RATE: 0.074336947183021\n",
      "previous_iter_valid_loss : 0.08003424853086472\n",
      "\n",
      "    190600\t  0.079925\t  0.080034\t  0.092754\t\tCURRENT LEARNING RATE: 0.07426264739192516\n",
      "previous_iter_valid_loss : 0.0812431052327156\n",
      "\n",
      "    190700\t  0.081184\t  0.081243\t  0.092778\t\tCURRENT LEARNING RATE: 0.07418842186348293\n",
      "previous_iter_valid_loss : 0.11631444096565247\n",
      "\n",
      "    190800\t  0.116107\t  0.116314\t  0.093098\t\tCURRENT LEARNING RATE: 0.07411427052346872\n",
      "previous_iter_valid_loss : 0.08251935988664627\n",
      "\n",
      "    190900\t  0.082460\t  0.082519\t  0.093145\t\tCURRENT LEARNING RATE: 0.07404019329773123\n",
      "previous_iter_valid_loss : 0.12334905564785004\n",
      "\n",
      "    191000\t  0.123691\t  0.123349\t  0.093386\t\tCURRENT LEARNING RATE: 0.0739661901121932\n",
      "previous_iter_valid_loss : 0.1037462055683136\n",
      "\n",
      "    191100\t  0.103935\t  0.103746\t  0.093118\t\tCURRENT LEARNING RATE: 0.07389226089285145\n",
      "previous_iter_valid_loss : 0.08054345846176147\n",
      "\n",
      "    191200\t  0.080508\t  0.080543\t  0.093060\t\tCURRENT LEARNING RATE: 0.07381840556577673\n",
      "previous_iter_valid_loss : 0.08040379732847214\n",
      "\n",
      "    191300\t  0.080432\t  0.080404\t  0.092831\t\tCURRENT LEARNING RATE: 0.07374462405711375\n",
      "previous_iter_valid_loss : 0.10670989751815796\n",
      "\n",
      "    191400\t  0.106905\t  0.106710\t  0.092729\t\tCURRENT LEARNING RATE: 0.07367091629308097\n",
      "previous_iter_valid_loss : 0.08472487330436707\n",
      "\n",
      "    191500\t  0.084777\t  0.084725\t  0.092604\t\tCURRENT LEARNING RATE: 0.07359728219997062\n",
      "previous_iter_valid_loss : 0.08273709565401077\n",
      "\n",
      "    191600\t  0.082735\t  0.082737\t  0.092366\t\tCURRENT LEARNING RATE: 0.0735237217041486\n",
      "previous_iter_valid_loss : 0.07927471399307251\n",
      "\n",
      "    191700\t  0.079234\t  0.079275\t  0.092351\t\tCURRENT LEARNING RATE: 0.07345023473205442\n",
      "previous_iter_valid_loss : 0.14051303267478943\n",
      "\n",
      "    191800\t  0.140292\t  0.140513\t  0.092674\t\tCURRENT LEARNING RATE: 0.07337682121020107\n",
      "previous_iter_valid_loss : 0.07882020622491837\n",
      "\n",
      "    191900\t  0.078746\t  0.078820\t  0.092557\t\tCURRENT LEARNING RATE: 0.07330348106517508\n",
      "previous_iter_valid_loss : 0.10034559667110443\n",
      "\n",
      "    192000\t  0.100096\t  0.100346\t  0.092754\t\tCURRENT LEARNING RATE: 0.07323021422363624\n",
      "previous_iter_valid_loss : 0.10330042988061905\n",
      "\n",
      "    192100\t  0.103111\t  0.103300\t  0.092732\t\tCURRENT LEARNING RATE: 0.07315702061231773\n",
      "previous_iter_valid_loss : 0.08590788394212723\n",
      "\n",
      "    192200\t  0.085882\t  0.085908\t  0.092764\t\tCURRENT LEARNING RATE: 0.07308390015802592\n",
      "previous_iter_valid_loss : 0.07823611795902252\n",
      "\n",
      "    192300\t  0.078137\t  0.078236\t  0.092680\t\tCURRENT LEARNING RATE: 0.07301085278764037\n",
      "previous_iter_valid_loss : 0.150675967335701\n",
      "\n",
      "    192400\t  0.150394\t  0.150676\t  0.093352\t\tCURRENT LEARNING RATE: 0.07293787842811368\n",
      "previous_iter_valid_loss : 0.09658904373645782\n",
      "\n",
      "    192500\t  0.096678\t  0.096589\t  0.093457\t\tCURRENT LEARNING RATE: 0.07286497700647152\n",
      "previous_iter_valid_loss : 0.07833452522754669\n",
      "\n",
      "    192600\t  0.078305\t  0.078335\t  0.093135\t\tCURRENT LEARNING RATE: 0.07279214844981241\n",
      "previous_iter_valid_loss : 0.0787518173456192\n",
      "\n",
      "    192700\t  0.078642\t  0.078752\t  0.092932\t\tCURRENT LEARNING RATE: 0.07271939268530785\n",
      "previous_iter_valid_loss : 0.07958769053220749\n",
      "\n",
      "    192800\t  0.079534\t  0.079588\t  0.092917\t\tCURRENT LEARNING RATE: 0.072646709640202\n",
      "previous_iter_valid_loss : 0.08522749692201614\n",
      "\n",
      "    192900\t  0.085182\t  0.085227\t  0.092749\t\tCURRENT LEARNING RATE: 0.07257409924181187\n",
      "previous_iter_valid_loss : 0.07976753264665604\n",
      "\n",
      "    193000\t  0.079753\t  0.079768\t  0.092728\t\tCURRENT LEARNING RATE: 0.072501561417527\n",
      "previous_iter_valid_loss : 0.09197210520505905\n",
      "\n",
      "    193100\t  0.092131\t  0.091972\t  0.092692\t\tCURRENT LEARNING RATE: 0.07242909609480963\n",
      "previous_iter_valid_loss : 0.07810351252555847\n",
      "\n",
      "    193200\t  0.078018\t  0.078104\t  0.092690\t\tCURRENT LEARNING RATE: 0.07235670320119436\n",
      "previous_iter_valid_loss : 0.08317279815673828\n",
      "\n",
      "    193300\t  0.083081\t  0.083173\t  0.092184\t\tCURRENT LEARNING RATE: 0.07228438266428834\n",
      "previous_iter_valid_loss : 0.08144351094961166\n",
      "\n",
      "    193400\t  0.081487\t  0.081444\t  0.092208\t\tCURRENT LEARNING RATE: 0.07221213441177099\n",
      "previous_iter_valid_loss : 0.08295293897390366\n",
      "\n",
      "    193500\t  0.082890\t  0.082953\t  0.092253\t\tCURRENT LEARNING RATE: 0.07213995837139409\n",
      "previous_iter_valid_loss : 0.08538206666707993\n",
      "\n",
      "    193600\t  0.085460\t  0.085382\t  0.092005\t\tCURRENT LEARNING RATE: 0.07206785447098155\n",
      "previous_iter_valid_loss : 0.11490361392498016\n",
      "\n",
      "    193700\t  0.115242\t  0.114904\t  0.092188\t\tCURRENT LEARNING RATE: 0.0719958226384295\n",
      "previous_iter_valid_loss : 0.1007634773850441\n",
      "\n",
      "    193800\t  0.100549\t  0.100763\t  0.092352\t\tCURRENT LEARNING RATE: 0.07192386280170608\n",
      "previous_iter_valid_loss : 0.08289758861064911\n",
      "\n",
      "    193900\t  0.082740\t  0.082898\t  0.092327\t\tCURRENT LEARNING RATE: 0.07185197488885146\n",
      "previous_iter_valid_loss : 0.0826195627450943\n",
      "\n",
      "    194000\t  0.082381\t  0.082620\t  0.092338\t\tCURRENT LEARNING RATE: 0.07178015882797771\n",
      "previous_iter_valid_loss : 0.08796754479408264\n",
      "\n",
      "    194100\t  0.088027\t  0.087968\t  0.092211\t\tCURRENT LEARNING RATE: 0.07170841454726878\n",
      "previous_iter_valid_loss : 0.07804097980260849\n",
      "\n",
      "    194200\t  0.077928\t  0.078041\t  0.092157\t\tCURRENT LEARNING RATE: 0.07163674197498036\n",
      "previous_iter_valid_loss : 0.07895559072494507\n",
      "\n",
      "    194300\t  0.078875\t  0.078956\t  0.091799\t\tCURRENT LEARNING RATE: 0.07156514103943991\n",
      "previous_iter_valid_loss : 0.07931586354970932\n",
      "\n",
      "    194400\t  0.079302\t  0.079316\t  0.091750\t\tCURRENT LEARNING RATE: 0.07149361166904644\n",
      "previous_iter_valid_loss : 0.10186745226383209\n",
      "\n",
      "    194500\t  0.101575\t  0.101867\t  0.091934\t\tCURRENT LEARNING RATE: 0.07142215379227061\n",
      "previous_iter_valid_loss : 0.07827957719564438\n",
      "\n",
      "    194600\t  0.078165\t  0.078280\t  0.091684\t\tCURRENT LEARNING RATE: 0.07135076733765451\n",
      "previous_iter_valid_loss : 0.08113455772399902\n",
      "\n",
      "    194700\t  0.081169\t  0.081135\t  0.091393\t\tCURRENT LEARNING RATE: 0.07127945223381171\n",
      "previous_iter_valid_loss : 0.08034910261631012\n",
      "\n",
      "    194800\t  0.080236\t  0.080349\t  0.090944\t\tCURRENT LEARNING RATE: 0.07120820840942707\n",
      "previous_iter_valid_loss : 0.08054440468549728\n",
      "\n",
      "    194900\t  0.080508\t  0.080544\t  0.090655\t\tCURRENT LEARNING RATE: 0.0711370357932568\n",
      "previous_iter_valid_loss : 0.08115947246551514\n",
      "\n",
      "    195000\t  0.081097\t  0.081159\t  0.090316\t\tCURRENT LEARNING RATE: 0.0710659343141282\n",
      "previous_iter_valid_loss : 0.08932904899120331\n",
      "\n",
      "    195100\t  0.089190\t  0.089329\t  0.090368\t\tCURRENT LEARNING RATE: 0.07099490390093989\n",
      "previous_iter_valid_loss : 0.07927410304546356\n",
      "\n",
      "    195200\t  0.079244\t  0.079274\t  0.090257\t\tCURRENT LEARNING RATE: 0.07092394448266136\n",
      "previous_iter_valid_loss : 0.1323622614145279\n",
      "\n",
      "    195300\t  0.132643\t  0.132362\t  0.090777\t\tCURRENT LEARNING RATE: 0.07085305598833325\n",
      "previous_iter_valid_loss : 0.08110713213682175\n",
      "\n",
      "    195400\t  0.080936\t  0.081107\t  0.090630\t\tCURRENT LEARNING RATE: 0.07078223834706701\n",
      "previous_iter_valid_loss : 0.08301644027233124\n",
      "\n",
      "    195500\t  0.083056\t  0.083016\t  0.090656\t\tCURRENT LEARNING RATE: 0.07071149148804504\n",
      "previous_iter_valid_loss : 0.07848838716745377\n",
      "\n",
      "    195600\t  0.078451\t  0.078488\t  0.090622\t\tCURRENT LEARNING RATE: 0.07064081534052043\n",
      "previous_iter_valid_loss : 0.09803926199674606\n",
      "\n",
      "    195700\t  0.097866\t  0.098039\t  0.090774\t\tCURRENT LEARNING RATE: 0.07057020983381705\n",
      "previous_iter_valid_loss : 0.10185898095369339\n",
      "\n",
      "    195800\t  0.102031\t  0.101859\t  0.090921\t\tCURRENT LEARNING RATE: 0.07049967489732938\n",
      "previous_iter_valid_loss : 0.09472634643316269\n",
      "\n",
      "    195900\t  0.094827\t  0.094726\t  0.091015\t\tCURRENT LEARNING RATE: 0.0704292104605225\n",
      "previous_iter_valid_loss : 0.09833947569131851\n",
      "\n",
      "    196000\t  0.098452\t  0.098339\t  0.091084\t\tCURRENT LEARNING RATE: 0.07035881645293193\n",
      "previous_iter_valid_loss : 0.08782390505075455\n",
      "\n",
      "    196100\t  0.087854\t  0.087824\t  0.090752\t\tCURRENT LEARNING RATE: 0.0702884928041637\n",
      "previous_iter_valid_loss : 0.11985252797603607\n",
      "\n",
      "    196200\t  0.119617\t  0.119853\t  0.091101\t\tCURRENT LEARNING RATE: 0.0702182394438941\n",
      "previous_iter_valid_loss : 0.09608282893896103\n",
      "\n",
      "    196300\t  0.096171\t  0.096083\t  0.091150\t\tCURRENT LEARNING RATE: 0.07014805630186982\n",
      "previous_iter_valid_loss : 0.08837869763374329\n",
      "\n",
      "    196400\t  0.088194\t  0.088379\t  0.091093\t\tCURRENT LEARNING RATE: 0.07007794330790768\n",
      "previous_iter_valid_loss : 0.08810367435216904\n",
      "\n",
      "    196500\t  0.088111\t  0.088104\t  0.091047\t\tCURRENT LEARNING RATE: 0.0700079003918947\n",
      "previous_iter_valid_loss : 0.07911376655101776\n",
      "\n",
      "    196600\t  0.078932\t  0.079114\t  0.090839\t\tCURRENT LEARNING RATE: 0.06993792748378792\n",
      "previous_iter_valid_loss : 0.13806632161140442\n",
      "\n",
      "    196700\t  0.138434\t  0.138066\t  0.091294\t\tCURRENT LEARNING RATE: 0.06986802451361447\n",
      "previous_iter_valid_loss : 0.13452699780464172\n",
      "\n",
      "    196800\t  0.134890\t  0.134527\t  0.091756\t\tCURRENT LEARNING RATE: 0.06979819141147135\n",
      "previous_iter_valid_loss : 0.08566898852586746\n",
      "\n",
      "    196900\t  0.085704\t  0.085669\t  0.091627\t\tCURRENT LEARNING RATE: 0.06972842810752547\n",
      "previous_iter_valid_loss : 0.07735144346952438\n",
      "\n",
      "\n",
      "Current valid loss: 0.07735144346952438;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "    197000\t  0.077261\t  0.077351\t  0.091287\t\tCURRENT LEARNING RATE: 0.06965873453201349\n",
      "previous_iter_valid_loss : 0.07821033149957657\n",
      "\n",
      "    197100\t  0.078180\t  0.078210\t  0.091280\t\tCURRENT LEARNING RATE: 0.06958911061524187\n",
      "previous_iter_valid_loss : 0.08170292526483536\n",
      "\n",
      "    197200\t  0.081706\t  0.081703\t  0.091313\t\tCURRENT LEARNING RATE: 0.06951955628758663\n",
      "previous_iter_valid_loss : 0.08815287053585052\n",
      "\n",
      "    197300\t  0.088232\t  0.088153\t  0.091357\t\tCURRENT LEARNING RATE: 0.0694500714794935\n",
      "previous_iter_valid_loss : 0.09354006499052048\n",
      "\n",
      "    197400\t  0.093387\t  0.093540\t  0.091496\t\tCURRENT LEARNING RATE: 0.06938065612147762\n",
      "previous_iter_valid_loss : 0.07975821942090988\n",
      "\n",
      "    197500\t  0.079740\t  0.079758\t  0.091497\t\tCURRENT LEARNING RATE: 0.06931131014412366\n",
      "previous_iter_valid_loss : 0.08509258180856705\n",
      "\n",
      "    197600\t  0.085148\t  0.085093\t  0.091552\t\tCURRENT LEARNING RATE: 0.06924203347808561\n",
      "previous_iter_valid_loss : 0.08533165603876114\n",
      "\n",
      "    197700\t  0.085345\t  0.085332\t  0.091274\t\tCURRENT LEARNING RATE: 0.06917282605408681\n",
      "previous_iter_valid_loss : 0.12344584614038467\n",
      "\n",
      "    197800\t  0.123352\t  0.123446\t  0.091530\t\tCURRENT LEARNING RATE: 0.06910368780291982\n",
      "previous_iter_valid_loss : 0.10942696034908295\n",
      "\n",
      "    197900\t  0.109264\t  0.109427\t  0.091844\t\tCURRENT LEARNING RATE: 0.06903461865544641\n",
      "previous_iter_valid_loss : 0.07875173538923264\n",
      "\n",
      "    198000\t  0.078712\t  0.078752\t  0.091605\t\tCURRENT LEARNING RATE: 0.06896561854259739\n",
      "previous_iter_valid_loss : 0.14173604547977448\n",
      "\n",
      "    198100\t  0.141518\t  0.141736\t  0.092132\t\tCURRENT LEARNING RATE: 0.06889668739537268\n",
      "previous_iter_valid_loss : 0.08032775670289993\n",
      "\n",
      "    198200\t  0.080353\t  0.080328\t  0.092061\t\tCURRENT LEARNING RATE: 0.06882782514484108\n",
      "previous_iter_valid_loss : 0.12902021408081055\n",
      "\n",
      "    198300\t  0.129245\t  0.129020\t  0.092544\t\tCURRENT LEARNING RATE: 0.06875903172214037\n",
      "previous_iter_valid_loss : 0.07850977778434753\n",
      "\n",
      "    198400\t  0.078426\t  0.078510\t  0.092220\t\tCURRENT LEARNING RATE: 0.06869030705847712\n",
      "previous_iter_valid_loss : 0.07749374955892563\n",
      "\n",
      "    198500\t  0.077446\t  0.077494\t  0.092134\t\tCURRENT LEARNING RATE: 0.06862165108512666\n",
      "previous_iter_valid_loss : 0.10927082598209381\n",
      "\n",
      "    198600\t  0.109015\t  0.109271\t  0.092264\t\tCURRENT LEARNING RATE: 0.06855306373343298\n",
      "previous_iter_valid_loss : 0.11301232874393463\n",
      "\n",
      "    198700\t  0.112774\t  0.113012\t  0.092549\t\tCURRENT LEARNING RATE: 0.06848454493480877\n",
      "previous_iter_valid_loss : 0.08526718616485596\n",
      "\n",
      "    198800\t  0.085085\t  0.085267\t  0.092236\t\tCURRENT LEARNING RATE: 0.06841609462073518\n",
      "previous_iter_valid_loss : 0.08087765425443649\n",
      "\n",
      "    198900\t  0.080816\t  0.080878\t  0.092200\t\tCURRENT LEARNING RATE: 0.06834771272276192\n",
      "previous_iter_valid_loss : 0.08164142817258835\n",
      "\n",
      "    199000\t  0.081511\t  0.081641\t  0.091991\t\tCURRENT LEARNING RATE: 0.06827939917250708\n",
      "previous_iter_valid_loss : 0.07855595648288727\n",
      "\n",
      "    199100\t  0.078541\t  0.078556\t  0.091977\t\tCURRENT LEARNING RATE: 0.06821115390165712\n",
      "previous_iter_valid_loss : 0.08040817826986313\n",
      "\n",
      "    199200\t  0.080390\t  0.080408\t  0.091905\t\tCURRENT LEARNING RATE: 0.06814297684196671\n",
      "previous_iter_valid_loss : 0.08782322704792023\n",
      "\n",
      "    199300\t  0.087688\t  0.087823\t  0.091903\t\tCURRENT LEARNING RATE: 0.06807486792525885\n",
      "previous_iter_valid_loss : 0.1017376035451889\n",
      "\n",
      "    199400\t  0.101925\t  0.101738\t  0.091721\t\tCURRENT LEARNING RATE: 0.06800682708342458\n",
      "previous_iter_valid_loss : 0.0903502032160759\n",
      "\n",
      "    199500\t  0.090351\t  0.090350\t  0.091798\t\tCURRENT LEARNING RATE: 0.06793885424842307\n",
      "previous_iter_valid_loss : 0.12029898911714554\n",
      "\n",
      "    199600\t  0.120142\t  0.120299\t  0.092138\t\tCURRENT LEARNING RATE: 0.06787094935228144\n",
      "previous_iter_valid_loss : 0.10972153395414352\n",
      "\n",
      "    199700\t  0.109800\t  0.109722\t  0.092441\t\tCURRENT LEARNING RATE: 0.06780311232709485\n",
      "previous_iter_valid_loss : 0.07752827554941177\n",
      "\n",
      "    199800\t  0.077474\t  0.077528\t  0.092218\t\tCURRENT LEARNING RATE: 0.06773534310502621\n",
      "previous_iter_valid_loss : 0.11011791974306107\n",
      "\n",
      "    199900\t  0.109929\t  0.110118\t  0.092316\t\tCURRENT LEARNING RATE: 0.06766764161830635\n",
      "previous_iter_valid_loss : 0.09821254760026932\n",
      "\n",
      "    200000\t  0.098334\t  0.098213\t  0.092427\t\tCURRENT LEARNING RATE: 0.06760000779923374\n",
      "previous_iter_valid_loss : 0.09731271862983704\n",
      "\n",
      "    200100\t  0.097379\t  0.097313\t  0.092557\t\tCURRENT LEARNING RATE: 0.06753244158017456\n",
      "previous_iter_valid_loss : 0.10247158259153366\n",
      "\n",
      "    200200\t  0.102145\t  0.102472\t  0.092787\t\tCURRENT LEARNING RATE: 0.06746494289356256\n",
      "previous_iter_valid_loss : 0.08308719098567963\n",
      "\n",
      "    200300\t  0.083072\t  0.083087\t  0.092832\t\tCURRENT LEARNING RATE: 0.0673975116718991\n",
      "previous_iter_valid_loss : 0.08096714317798615\n",
      "\n",
      "    200400\t  0.080749\t  0.080967\t  0.092643\t\tCURRENT LEARNING RATE: 0.06733014784775293\n",
      "previous_iter_valid_loss : 0.11981888860464096\n",
      "\n",
      "    200500\t  0.119581\t  0.119819\t  0.093000\t\tCURRENT LEARNING RATE: 0.06726285135376023\n",
      "previous_iter_valid_loss : 0.11924143880605698\n",
      "\n",
      "    200600\t  0.118944\t  0.119241\t  0.093392\t\tCURRENT LEARNING RATE: 0.06719562212262445\n",
      "previous_iter_valid_loss : 0.1122891828417778\n",
      "\n",
      "    200700\t  0.112151\t  0.112289\t  0.093702\t\tCURRENT LEARNING RATE: 0.06712846008711643\n",
      "previous_iter_valid_loss : 0.10719680041074753\n",
      "\n",
      "    200800\t  0.106972\t  0.107197\t  0.093611\t\tCURRENT LEARNING RATE: 0.06706136518007408\n",
      "previous_iter_valid_loss : 0.08011113852262497\n",
      "\n",
      "    200900\t  0.080074\t  0.080111\t  0.093587\t\tCURRENT LEARNING RATE: 0.06699433733440249\n",
      "previous_iter_valid_loss : 0.1116095706820488\n",
      "\n",
      "    201000\t  0.111785\t  0.111610\t  0.093469\t\tCURRENT LEARNING RATE: 0.06692737648307381\n",
      "previous_iter_valid_loss : 0.08282556384801865\n",
      "\n",
      "    201100\t  0.082782\t  0.082826\t  0.093260\t\tCURRENT LEARNING RATE: 0.0668604825591272\n",
      "previous_iter_valid_loss : 0.1305825561285019\n",
      "\n",
      "    201200\t  0.130389\t  0.130583\t  0.093761\t\tCURRENT LEARNING RATE: 0.06679365549566874\n",
      "previous_iter_valid_loss : 0.07826615869998932\n",
      "\n",
      "    201300\t  0.078222\t  0.078266\t  0.093739\t\tCURRENT LEARNING RATE: 0.06672689522587133\n",
      "previous_iter_valid_loss : 0.09652084857225418\n",
      "\n",
      "    201400\t  0.096293\t  0.096521\t  0.093637\t\tCURRENT LEARNING RATE: 0.06666020168297468\n",
      "previous_iter_valid_loss : 0.09231055527925491\n",
      "\n",
      "    201500\t  0.092450\t  0.092311\t  0.093713\t\tCURRENT LEARNING RATE: 0.0665935748002853\n",
      "previous_iter_valid_loss : 0.11988106369972229\n",
      "\n",
      "    201600\t  0.120137\t  0.119881\t  0.094085\t\tCURRENT LEARNING RATE: 0.06652701451117626\n",
      "previous_iter_valid_loss : 0.08464029431343079\n",
      "\n",
      "    201700\t  0.084507\t  0.084640\t  0.094138\t\tCURRENT LEARNING RATE: 0.06646052074908729\n",
      "previous_iter_valid_loss : 0.14391741156578064\n",
      "\n",
      "    201800\t  0.143753\t  0.143917\t  0.094172\t\tCURRENT LEARNING RATE: 0.06639409344752457\n",
      "previous_iter_valid_loss : 0.08412884920835495\n",
      "\n",
      "    201900\t  0.084128\t  0.084129\t  0.094225\t\tCURRENT LEARNING RATE: 0.06632773254006086\n",
      "previous_iter_valid_loss : 0.09417498111724854\n",
      "\n",
      "    202000\t  0.094310\t  0.094175\t  0.094164\t\tCURRENT LEARNING RATE: 0.06626143796033522\n",
      "previous_iter_valid_loss : 0.08293724805116653\n",
      "\n",
      "    202100\t  0.082971\t  0.082937\t  0.093960\t\tCURRENT LEARNING RATE: 0.06619520964205305\n",
      "previous_iter_valid_loss : 0.09035515785217285\n",
      "\n",
      "    202200\t  0.090384\t  0.090355\t  0.094005\t\tCURRENT LEARNING RATE: 0.06612904751898603\n",
      "previous_iter_valid_loss : 0.09475187212228775\n",
      "\n",
      "    202300\t  0.094581\t  0.094752\t  0.094170\t\tCURRENT LEARNING RATE: 0.06606295152497205\n",
      "previous_iter_valid_loss : 0.08065153658390045\n",
      "\n",
      "    202400\t  0.080494\t  0.080652\t  0.093470\t\tCURRENT LEARNING RATE: 0.06599692159391511\n",
      "previous_iter_valid_loss : 0.10449323803186417\n",
      "\n",
      "    202500\t  0.104312\t  0.104493\t  0.093549\t\tCURRENT LEARNING RATE: 0.06593095765978527\n",
      "previous_iter_valid_loss : 0.09289314597845078\n",
      "\n",
      "    202600\t  0.092759\t  0.092893\t  0.093694\t\tCURRENT LEARNING RATE: 0.06586505965661854\n",
      "previous_iter_valid_loss : 0.07811899483203888\n",
      "\n",
      "    202700\t  0.078033\t  0.078119\t  0.093688\t\tCURRENT LEARNING RATE: 0.065799227518517\n",
      "previous_iter_valid_loss : 0.08549037575721741\n",
      "\n",
      "    202800\t  0.085488\t  0.085490\t  0.093747\t\tCURRENT LEARNING RATE: 0.06573346117964844\n",
      "previous_iter_valid_loss : 0.10299881547689438\n",
      "\n",
      "    202900\t  0.103098\t  0.102999\t  0.093925\t\tCURRENT LEARNING RATE: 0.06566776057424656\n",
      "previous_iter_valid_loss : 0.08859290927648544\n",
      "\n",
      "    203000\t  0.088625\t  0.088593\t  0.094013\t\tCURRENT LEARNING RATE: 0.06560212563661068\n",
      "previous_iter_valid_loss : 0.07834828644990921\n",
      "\n",
      "    203100\t  0.078383\t  0.078348\t  0.093877\t\tCURRENT LEARNING RATE: 0.06553655630110594\n",
      "previous_iter_valid_loss : 0.07942502945661545\n",
      "\n",
      "    203200\t  0.079370\t  0.079425\t  0.093890\t\tCURRENT LEARNING RATE: 0.06547105250216297\n",
      "previous_iter_valid_loss : 0.09023217111825943\n",
      "\n",
      "    203300\t  0.090037\t  0.090232\t  0.093960\t\tCURRENT LEARNING RATE: 0.06540561417427794\n",
      "previous_iter_valid_loss : 0.08161704242229462\n",
      "\n",
      "    203400\t  0.081608\t  0.081617\t  0.093962\t\tCURRENT LEARNING RATE: 0.06534024125201252\n",
      "previous_iter_valid_loss : 0.10246302932500839\n",
      "\n",
      "    203500\t  0.102527\t  0.102463\t  0.094157\t\tCURRENT LEARNING RATE: 0.06527493366999382\n",
      "previous_iter_valid_loss : 0.14190618693828583\n",
      "\n",
      "    203600\t  0.142234\t  0.141906\t  0.094722\t\tCURRENT LEARNING RATE: 0.06520969136291424\n",
      "previous_iter_valid_loss : 0.09998682141304016\n",
      "\n",
      "    203700\t  0.100028\t  0.099987\t  0.094573\t\tCURRENT LEARNING RATE: 0.06514451426553144\n",
      "previous_iter_valid_loss : 0.10929286479949951\n",
      "\n",
      "    203800\t  0.109090\t  0.109293\t  0.094659\t\tCURRENT LEARNING RATE: 0.06507940231266832\n",
      "previous_iter_valid_loss : 0.11973249912261963\n",
      "\n",
      "    203900\t  0.119490\t  0.119732\t  0.095027\t\tCURRENT LEARNING RATE: 0.06501435543921295\n",
      "previous_iter_valid_loss : 0.11233581602573395\n",
      "\n",
      "    204000\t  0.112570\t  0.112336\t  0.095324\t\tCURRENT LEARNING RATE: 0.06494937358011846\n",
      "previous_iter_valid_loss : 0.07931052148342133\n",
      "\n",
      "    204100\t  0.079274\t  0.079311\t  0.095238\t\tCURRENT LEARNING RATE: 0.06488445667040293\n",
      "previous_iter_valid_loss : 0.08147945255041122\n",
      "\n",
      "    204200\t  0.081350\t  0.081479\t  0.095272\t\tCURRENT LEARNING RATE: 0.06481960464514948\n",
      "previous_iter_valid_loss : 0.09294494241476059\n",
      "\n",
      "    204300\t  0.093105\t  0.092945\t  0.095412\t\tCURRENT LEARNING RATE: 0.06475481743950609\n",
      "previous_iter_valid_loss : 0.08180416375398636\n",
      "\n",
      "    204400\t  0.081658\t  0.081804\t  0.095437\t\tCURRENT LEARNING RATE: 0.06469009498868554\n",
      "previous_iter_valid_loss : 0.08538109809160233\n",
      "\n",
      "    204500\t  0.085190\t  0.085381\t  0.095272\t\tCURRENT LEARNING RATE: 0.06462543722796536\n",
      "previous_iter_valid_loss : 0.09958750754594803\n",
      "\n",
      "    204600\t  0.099769\t  0.099588\t  0.095485\t\tCURRENT LEARNING RATE: 0.06456084409268778\n",
      "previous_iter_valid_loss : 0.08180664479732513\n",
      "\n",
      "    204700\t  0.081621\t  0.081807\t  0.095492\t\tCURRENT LEARNING RATE: 0.0644963155182597\n",
      "previous_iter_valid_loss : 0.08184697479009628\n",
      "\n",
      "    204800\t  0.081753\t  0.081847\t  0.095507\t\tCURRENT LEARNING RATE: 0.06443185144015251\n",
      "previous_iter_valid_loss : 0.0823550745844841\n",
      "\n",
      "    204900\t  0.082273\t  0.082355\t  0.095525\t\tCURRENT LEARNING RATE: 0.06436745179390212\n",
      "previous_iter_valid_loss : 0.09816402941942215\n",
      "\n",
      "    205000\t  0.098076\t  0.098164\t  0.095695\t\tCURRENT LEARNING RATE: 0.06430311651510887\n",
      "previous_iter_valid_loss : 0.08286157995462418\n",
      "\n",
      "    205100\t  0.082751\t  0.082862\t  0.095630\t\tCURRENT LEARNING RATE: 0.06423884553943751\n",
      "previous_iter_valid_loss : 0.09761149436235428\n",
      "\n",
      "    205200\t  0.097695\t  0.097611\t  0.095813\t\tCURRENT LEARNING RATE: 0.06417463880261706\n",
      "previous_iter_valid_loss : 0.09234079718589783\n",
      "\n",
      "    205300\t  0.092350\t  0.092341\t  0.095413\t\tCURRENT LEARNING RATE: 0.06411049624044075\n",
      "previous_iter_valid_loss : 0.08726654946804047\n",
      "\n",
      "    205400\t  0.087052\t  0.087267\t  0.095475\t\tCURRENT LEARNING RATE: 0.06404641778876599\n",
      "previous_iter_valid_loss : 0.11721225082874298\n",
      "\n",
      "    205500\t  0.117043\t  0.117212\t  0.095817\t\tCURRENT LEARNING RATE: 0.0639824033835144\n",
      "previous_iter_valid_loss : 0.10418713837862015\n",
      "\n",
      "    205600\t  0.104017\t  0.104187\t  0.096074\t\tCURRENT LEARNING RATE: 0.06391845296067152\n",
      "previous_iter_valid_loss : 0.08393832296133041\n",
      "\n",
      "    205700\t  0.083762\t  0.083938\t  0.095933\t\tCURRENT LEARNING RATE: 0.06385456645628691\n",
      "previous_iter_valid_loss : 0.13103561103343964\n",
      "\n",
      "    205800\t  0.131286\t  0.131036\t  0.096225\t\tCURRENT LEARNING RATE: 0.06379074380647407\n",
      "previous_iter_valid_loss : 0.11318153142929077\n",
      "\n",
      "    205900\t  0.113075\t  0.113182\t  0.096409\t\tCURRENT LEARNING RATE: 0.06372698494741037\n",
      "previous_iter_valid_loss : 0.0880703330039978\n",
      "\n",
      "    206000\t  0.087989\t  0.088070\t  0.096306\t\tCURRENT LEARNING RATE: 0.06366328981533693\n",
      "previous_iter_valid_loss : 0.08568888902664185\n",
      "\n",
      "    206100\t  0.085637\t  0.085689\t  0.096285\t\tCURRENT LEARNING RATE: 0.0635996583465586\n",
      "previous_iter_valid_loss : 0.09100520610809326\n",
      "\n",
      "    206200\t  0.091129\t  0.091005\t  0.095997\t\tCURRENT LEARNING RATE: 0.06353609047744391\n",
      "previous_iter_valid_loss : 0.08502674102783203\n",
      "\n",
      "    206300\t  0.085040\t  0.085027\t  0.095886\t\tCURRENT LEARNING RATE: 0.06347258614442501\n",
      "previous_iter_valid_loss : 0.09745042026042938\n",
      "\n",
      "    206400\t  0.097455\t  0.097450\t  0.095977\t\tCURRENT LEARNING RATE: 0.06340914528399755\n",
      "previous_iter_valid_loss : 0.1432010531425476\n",
      "\n",
      "    206500\t  0.143437\t  0.143201\t  0.096528\t\tCURRENT LEARNING RATE: 0.06334576783272065\n",
      "previous_iter_valid_loss : 0.10936010628938675\n",
      "\n",
      "    206600\t  0.109506\t  0.109360\t  0.096830\t\tCURRENT LEARNING RATE: 0.06328245372721683\n",
      "previous_iter_valid_loss : 0.10487381368875504\n",
      "\n",
      "    206700\t  0.104816\t  0.104874\t  0.096498\t\tCURRENT LEARNING RATE: 0.06321920290417204\n",
      "previous_iter_valid_loss : 0.09343129396438599\n",
      "\n",
      "    206800\t  0.093532\t  0.093431\t  0.096087\t\tCURRENT LEARNING RATE: 0.06315601530033543\n",
      "previous_iter_valid_loss : 0.08193118870258331\n",
      "\n",
      "    206900\t  0.082032\t  0.081931\t  0.096050\t\tCURRENT LEARNING RATE: 0.06309289085251939\n",
      "previous_iter_valid_loss : 0.11744965612888336\n",
      "\n",
      "    207000\t  0.117715\t  0.117450\t  0.096451\t\tCURRENT LEARNING RATE: 0.06302982949759942\n",
      "previous_iter_valid_loss : 0.09667842090129852\n",
      "\n",
      "    207100\t  0.096925\t  0.096678\t  0.096636\t\tCURRENT LEARNING RATE: 0.06296683117251423\n",
      "previous_iter_valid_loss : 0.08769463002681732\n",
      "\n",
      "    207200\t  0.087544\t  0.087695\t  0.096696\t\tCURRENT LEARNING RATE: 0.06290389581426546\n",
      "previous_iter_valid_loss : 0.09603876620531082\n",
      "\n",
      "    207300\t  0.095910\t  0.096039\t  0.096774\t\tCURRENT LEARNING RATE: 0.06284102335991774\n",
      "previous_iter_valid_loss : 0.10508479177951813\n",
      "\n",
      "    207400\t  0.105300\t  0.105085\t  0.096890\t\tCURRENT LEARNING RATE: 0.0627782137465986\n",
      "previous_iter_valid_loss : 0.11057288944721222\n",
      "\n",
      "    207500\t  0.110824\t  0.110573\t  0.097198\t\tCURRENT LEARNING RATE: 0.06271546691149846\n",
      "previous_iter_valid_loss : 0.08438918739557266\n",
      "\n",
      "    207600\t  0.084342\t  0.084389\t  0.097191\t\tCURRENT LEARNING RATE: 0.06265278279187046\n",
      "previous_iter_valid_loss : 0.09488523751497269\n",
      "\n",
      "    207700\t  0.094982\t  0.094885\t  0.097286\t\tCURRENT LEARNING RATE: 0.06259016132503047\n",
      "previous_iter_valid_loss : 0.12286985665559769\n",
      "\n",
      "    207800\t  0.122886\t  0.122870\t  0.097281\t\tCURRENT LEARNING RATE: 0.06252760244835699\n",
      "previous_iter_valid_loss : 0.09688801318407059\n",
      "\n",
      "    207900\t  0.096812\t  0.096888\t  0.097155\t\tCURRENT LEARNING RATE: 0.06246510609929121\n",
      "previous_iter_valid_loss : 0.138795405626297\n",
      "\n",
      "    208000\t  0.139085\t  0.138795\t  0.097756\t\tCURRENT LEARNING RATE: 0.06240267221533673\n",
      "previous_iter_valid_loss : 0.09619411081075668\n",
      "\n",
      "    208100\t  0.096259\t  0.096194\t  0.097300\t\tCURRENT LEARNING RATE: 0.062340300734059655\n",
      "previous_iter_valid_loss : 0.08861754089593887\n",
      "\n",
      "    208200\t  0.088695\t  0.088618\t  0.097383\t\tCURRENT LEARNING RATE: 0.06227799159308849\n",
      "previous_iter_valid_loss : 0.09496814012527466\n",
      "\n",
      "    208300\t  0.094915\t  0.094968\t  0.097043\t\tCURRENT LEARNING RATE: 0.06221574473011413\n",
      "previous_iter_valid_loss : 0.09229114651679993\n",
      "\n",
      "    208400\t  0.092098\t  0.092291\t  0.097181\t\tCURRENT LEARNING RATE: 0.06215356008288969\n",
      "previous_iter_valid_loss : 0.0843241736292839\n",
      "\n",
      "    208500\t  0.084296\t  0.084324\t  0.097249\t\tCURRENT LEARNING RATE: 0.06209143758923051\n",
      "previous_iter_valid_loss : 0.08455849438905716\n",
      "\n",
      "    208600\t  0.084619\t  0.084558\t  0.097002\t\tCURRENT LEARNING RATE: 0.06202937718701407\n",
      "previous_iter_valid_loss : 0.0972171425819397\n",
      "\n",
      "    208700\t  0.097275\t  0.097217\t  0.096844\t\tCURRENT LEARNING RATE: 0.06196737881418001\n",
      "previous_iter_valid_loss : 0.09403392672538757\n",
      "\n",
      "    208800\t  0.094175\t  0.094034\t  0.096931\t\tCURRENT LEARNING RATE: 0.06190544240872993\n",
      "previous_iter_valid_loss : 0.09559587389230728\n",
      "\n",
      "    208900\t  0.095449\t  0.095596\t  0.097079\t\tCURRENT LEARNING RATE: 0.061843567908727415\n",
      "previous_iter_valid_loss : 0.08747244626283646\n",
      "\n",
      "    209000\t  0.087378\t  0.087472\t  0.097137\t\tCURRENT LEARNING RATE: 0.06178175525229794\n",
      "previous_iter_valid_loss : 0.08182907849550247\n",
      "\n",
      "    209100\t  0.081802\t  0.081829\t  0.097170\t\tCURRENT LEARNING RATE: 0.06172000437762889\n",
      "previous_iter_valid_loss : 0.08709942549467087\n",
      "\n",
      "    209200\t  0.086945\t  0.087099\t  0.097237\t\tCURRENT LEARNING RATE: 0.061658315222969357\n",
      "previous_iter_valid_loss : 0.0801440179347992\n",
      "\n",
      "    209300\t  0.080096\t  0.080144\t  0.097160\t\tCURRENT LEARNING RATE: 0.06159668772663019\n",
      "previous_iter_valid_loss : 0.08729482442140579\n",
      "\n",
      "    209400\t  0.087164\t  0.087295\t  0.097015\t\tCURRENT LEARNING RATE: 0.061535121826983855\n",
      "previous_iter_valid_loss : 0.1311320662498474\n",
      "\n",
      "    209500\t  0.130981\t  0.131132\t  0.097423\t\tCURRENT LEARNING RATE: 0.0614736174624645\n",
      "previous_iter_valid_loss : 0.0808100551366806\n",
      "\n",
      "    209600\t  0.080726\t  0.080810\t  0.097028\t\tCURRENT LEARNING RATE: 0.06141217457156773\n",
      "previous_iter_valid_loss : 0.12426596879959106\n",
      "\n",
      "    209700\t  0.124073\t  0.124266\t  0.097174\t\tCURRENT LEARNING RATE: 0.06135079309285065\n",
      "previous_iter_valid_loss : 0.08749565482139587\n",
      "\n",
      "    209800\t  0.087238\t  0.087496\t  0.097273\t\tCURRENT LEARNING RATE: 0.06128947296493175\n",
      "previous_iter_valid_loss : 0.1210830956697464\n",
      "\n",
      "    209900\t  0.120860\t  0.121083\t  0.097383\t\tCURRENT LEARNING RATE: 0.06122821412649095\n",
      "previous_iter_valid_loss : 0.08306397497653961\n",
      "\n",
      "    210000\t  0.083016\t  0.083064\t  0.097232\t\tCURRENT LEARNING RATE: 0.06116701651626938\n",
      "previous_iter_valid_loss : 0.0811009332537651\n",
      "\n",
      "    210100\t  0.081140\t  0.081101\t  0.097069\t\tCURRENT LEARNING RATE: 0.06110588007306942\n",
      "previous_iter_valid_loss : 0.08029349893331528\n",
      "\n",
      "    210200\t  0.080283\t  0.080293\t  0.096848\t\tCURRENT LEARNING RATE: 0.0610448047357546\n",
      "previous_iter_valid_loss : 0.07950333505868912\n",
      "\n",
      "    210300\t  0.079457\t  0.079503\t  0.096812\t\tCURRENT LEARNING RATE: 0.06098379044324963\n",
      "previous_iter_valid_loss : 0.10337997227907181\n",
      "\n",
      "    210400\t  0.103165\t  0.103380\t  0.097036\t\tCURRENT LEARNING RATE: 0.06092283713454018\n",
      "previous_iter_valid_loss : 0.09803786873817444\n",
      "\n",
      "    210500\t  0.097932\t  0.098038\t  0.096818\t\tCURRENT LEARNING RATE: 0.060861944748672944\n",
      "previous_iter_valid_loss : 0.11623641103506088\n",
      "\n",
      "    210600\t  0.116475\t  0.116236\t  0.096788\t\tCURRENT LEARNING RATE: 0.0608011132247555\n",
      "previous_iter_valid_loss : 0.08450090140104294\n",
      "\n",
      "    210700\t  0.084513\t  0.084501\t  0.096510\t\tCURRENT LEARNING RATE: 0.06074034250195638\n",
      "previous_iter_valid_loss : 0.13973000645637512\n",
      "\n",
      "    210800\t  0.139508\t  0.139730\t  0.096836\t\tCURRENT LEARNING RATE: 0.060679632519504825\n",
      "previous_iter_valid_loss : 0.08656435459852219\n",
      "\n",
      "    210900\t  0.086574\t  0.086564\t  0.096900\t\tCURRENT LEARNING RATE: 0.06061898321669084\n",
      "previous_iter_valid_loss : 0.0900760367512703\n",
      "\n",
      "    211000\t  0.090035\t  0.090076\t  0.096685\t\tCURRENT LEARNING RATE: 0.0605583945328651\n",
      "previous_iter_valid_loss : 0.08635054528713226\n",
      "\n",
      "    211100\t  0.086358\t  0.086351\t  0.096720\t\tCURRENT LEARNING RATE: 0.06049786640743896\n",
      "previous_iter_valid_loss : 0.08458726853132248\n",
      "\n",
      "    211200\t  0.084552\t  0.084587\t  0.096260\t\tCURRENT LEARNING RATE: 0.06043739877988428\n",
      "previous_iter_valid_loss : 0.10353463888168335\n",
      "\n",
      "    211300\t  0.103841\t  0.103535\t  0.096513\t\tCURRENT LEARNING RATE: 0.060376991589733406\n",
      "previous_iter_valid_loss : 0.08585843443870544\n",
      "\n",
      "    211400\t  0.085799\t  0.085858\t  0.096406\t\tCURRENT LEARNING RATE: 0.06031664477657913\n",
      "previous_iter_valid_loss : 0.0836353525519371\n",
      "\n",
      "    211500\t  0.083635\t  0.083635\t  0.096319\t\tCURRENT LEARNING RATE: 0.06025635828007469\n",
      "previous_iter_valid_loss : 0.11638056486845016\n",
      "\n",
      "    211600\t  0.116539\t  0.116381\t  0.096284\t\tCURRENT LEARNING RATE: 0.06019613203993354\n",
      "previous_iter_valid_loss : 0.07986502349376678\n",
      "\n",
      "    211700\t  0.079749\t  0.079865\t  0.096237\t\tCURRENT LEARNING RATE: 0.060135965995929457\n",
      "previous_iter_valid_loss : 0.09804500639438629\n",
      "\n",
      "    211800\t  0.097814\t  0.098045\t  0.095778\t\tCURRENT LEARNING RATE: 0.060075860087896345\n",
      "previous_iter_valid_loss : 0.08752768486738205\n",
      "\n",
      "    211900\t  0.087613\t  0.087528\t  0.095812\t\tCURRENT LEARNING RATE: 0.06001581425572836\n",
      "previous_iter_valid_loss : 0.08995941281318665\n",
      "\n",
      "    212000\t  0.089667\t  0.089959\t  0.095770\t\tCURRENT LEARNING RATE: 0.05995582843937963\n",
      "previous_iter_valid_loss : 0.08020278066396713\n",
      "\n",
      "    212100\t  0.080206\t  0.080203\t  0.095742\t\tCURRENT LEARNING RATE: 0.05989590257886434\n",
      "previous_iter_valid_loss : 0.12400154769420624\n",
      "\n",
      "    212200\t  0.123808\t  0.124002\t  0.096079\t\tCURRENT LEARNING RATE: 0.059836036614256585\n",
      "previous_iter_valid_loss : 0.08606947213411331\n",
      "\n",
      "    212300\t  0.085856\t  0.086069\t  0.095992\t\tCURRENT LEARNING RATE: 0.05977623048569047\n",
      "previous_iter_valid_loss : 0.10363548249006271\n",
      "\n",
      "    212400\t  0.103459\t  0.103635\t  0.096222\t\tCURRENT LEARNING RATE: 0.05971648413335981\n",
      "previous_iter_valid_loss : 0.07944518327713013\n",
      "\n",
      "    212500\t  0.079315\t  0.079445\t  0.095971\t\tCURRENT LEARNING RATE: 0.05965679749751826\n",
      "previous_iter_valid_loss : 0.10376904904842377\n",
      "\n",
      "    212600\t  0.103552\t  0.103769\t  0.096080\t\tCURRENT LEARNING RATE: 0.05959717051847919\n",
      "previous_iter_valid_loss : 0.08692052960395813\n",
      "\n",
      "    212700\t  0.086741\t  0.086921\t  0.096168\t\tCURRENT LEARNING RATE: 0.05953760313661557\n",
      "previous_iter_valid_loss : 0.11305270344018936\n",
      "\n",
      "    212800\t  0.113221\t  0.113053\t  0.096444\t\tCURRENT LEARNING RATE: 0.059478095292360075\n",
      "previous_iter_valid_loss : 0.09669912606477737\n",
      "\n",
      "    212900\t  0.096543\t  0.096699\t  0.096381\t\tCURRENT LEARNING RATE: 0.05941864692620483\n",
      "previous_iter_valid_loss : 0.08332599699497223\n",
      "\n",
      "    213000\t  0.083307\t  0.083326\t  0.096328\t\tCURRENT LEARNING RATE: 0.05935925797870146\n",
      "previous_iter_valid_loss : 0.08037912845611572\n",
      "\n",
      "    213100\t  0.080285\t  0.080379\t  0.096348\t\tCURRENT LEARNING RATE: 0.05929992839046099\n",
      "previous_iter_valid_loss : 0.08116617053747177\n",
      "\n",
      "    213200\t  0.081209\t  0.081166\t  0.096366\t\tCURRENT LEARNING RATE: 0.05924065810215388\n",
      "previous_iter_valid_loss : 0.18987984955310822\n",
      "\n",
      "    213300\t  0.190316\t  0.189880\t  0.097362\t\tCURRENT LEARNING RATE: 0.05918144705450981\n",
      "previous_iter_valid_loss : 0.08611880987882614\n",
      "\n",
      "    213400\t  0.085935\t  0.086119\t  0.097407\t\tCURRENT LEARNING RATE: 0.05912229518831772\n",
      "previous_iter_valid_loss : 0.09107355773448944\n",
      "\n",
      "    213500\t  0.090852\t  0.091074\t  0.097293\t\tCURRENT LEARNING RATE: 0.05906320244442573\n",
      "previous_iter_valid_loss : 0.08526479452848434\n",
      "\n",
      "    213600\t  0.085242\t  0.085265\t  0.096727\t\tCURRENT LEARNING RATE: 0.05900416876374112\n",
      "previous_iter_valid_loss : 0.08561641722917557\n",
      "\n",
      "    213700\t  0.085642\t  0.085616\t  0.096583\t\tCURRENT LEARNING RATE: 0.0589451940872302\n",
      "previous_iter_valid_loss : 0.08725225180387497\n",
      "\n",
      "    213800\t  0.087107\t  0.087252\t  0.096363\t\tCURRENT LEARNING RATE: 0.058886278355918274\n",
      "previous_iter_valid_loss : 0.08522020280361176\n",
      "\n",
      "    213900\t  0.085230\t  0.085220\t  0.096018\t\tCURRENT LEARNING RATE: 0.05882742151088959\n",
      "previous_iter_valid_loss : 0.0907965824007988\n",
      "\n",
      "    214000\t  0.090791\t  0.090797\t  0.095802\t\tCURRENT LEARNING RATE: 0.05876862349328734\n",
      "previous_iter_valid_loss : 0.08423398435115814\n",
      "\n",
      "    214100\t  0.084366\t  0.084234\t  0.095852\t\tCURRENT LEARNING RATE: 0.05870988424431349\n",
      "previous_iter_valid_loss : 0.11418498307466507\n",
      "\n",
      "    214200\t  0.114448\t  0.114185\t  0.096179\t\tCURRENT LEARNING RATE: 0.05865120370522877\n",
      "previous_iter_valid_loss : 0.08429428935050964\n",
      "\n",
      "    214300\t  0.084210\t  0.084294\t  0.096092\t\tCURRENT LEARNING RATE: 0.058592581817352614\n",
      "previous_iter_valid_loss : 0.180990532040596\n",
      "\n",
      "    214400\t  0.181407\t  0.180991\t  0.097084\t\tCURRENT LEARNING RATE: 0.058534018522063185\n",
      "previous_iter_valid_loss : 0.15981340408325195\n",
      "\n",
      "    214500\t  0.160182\t  0.159813\t  0.097828\t\tCURRENT LEARNING RATE: 0.05847551376079716\n",
      "previous_iter_valid_loss : 0.16363084316253662\n",
      "\n",
      "    214600\t  0.163375\t  0.163631\t  0.098469\t\tCURRENT LEARNING RATE: 0.058417067475049766\n",
      "previous_iter_valid_loss : 0.11382290720939636\n",
      "\n",
      "    214700\t  0.114164\t  0.113823\t  0.098789\t\tCURRENT LEARNING RATE: 0.05835867960637469\n",
      "previous_iter_valid_loss : 0.1401841938495636\n",
      "\n",
      "    214800\t  0.140582\t  0.140184\t  0.099372\t\tCURRENT LEARNING RATE: 0.05830035009638411\n",
      "previous_iter_valid_loss : 0.08985260874032974\n",
      "\n",
      "    214900\t  0.089973\t  0.089853\t  0.099447\t\tCURRENT LEARNING RATE: 0.05824207888674848\n",
      "previous_iter_valid_loss : 0.15003077685832977\n",
      "\n",
      "    215000\t  0.150335\t  0.150031\t  0.099966\t\tCURRENT LEARNING RATE: 0.058183865919196595\n",
      "previous_iter_valid_loss : 0.09364257007837296\n",
      "\n",
      "    215100\t  0.093448\t  0.093643\t  0.100074\t\tCURRENT LEARNING RATE: 0.05812571113551546\n",
      "previous_iter_valid_loss : 0.08322729915380478\n",
      "\n",
      "    215200\t  0.083175\t  0.083227\t  0.099930\t\tCURRENT LEARNING RATE: 0.058067614477550315\n",
      "previous_iter_valid_loss : 0.08944118767976761\n",
      "\n",
      "    215300\t  0.089311\t  0.089441\t  0.099901\t\tCURRENT LEARNING RATE: 0.0580095758872045\n",
      "previous_iter_valid_loss : 0.08423148095607758\n",
      "\n",
      "    215400\t  0.084236\t  0.084231\t  0.099871\t\tCURRENT LEARNING RATE: 0.057951595306439396\n",
      "previous_iter_valid_loss : 0.08238375186920166\n",
      "\n",
      "    215500\t  0.082389\t  0.082384\t  0.099522\t\tCURRENT LEARNING RATE: 0.0578936726772744\n",
      "previous_iter_valid_loss : 0.10040310025215149\n",
      "\n",
      "    215600\t  0.100217\t  0.100403\t  0.099484\t\tCURRENT LEARNING RATE: 0.05783580794178694\n",
      "previous_iter_valid_loss : 0.16354040801525116\n",
      "\n",
      "    215700\t  0.163896\t  0.163540\t  0.100280\t\tCURRENT LEARNING RATE: 0.05777800104211224\n",
      "previous_iter_valid_loss : 0.09397858381271362\n",
      "\n",
      "    215800\t  0.093771\t  0.093979\t  0.099910\t\tCURRENT LEARNING RATE: 0.057720251920443395\n",
      "previous_iter_valid_loss : 0.0813785120844841\n",
      "\n",
      "    215900\t  0.081436\t  0.081379\t  0.099592\t\tCURRENT LEARNING RATE: 0.05766256051903126\n",
      "previous_iter_valid_loss : 0.09456101804971695\n",
      "\n",
      "    216000\t  0.094544\t  0.094561\t  0.099657\t\tCURRENT LEARNING RATE: 0.057604926780184466\n",
      "previous_iter_valid_loss : 0.14231808483600616\n",
      "\n",
      "    216100\t  0.142608\t  0.142318\t  0.100223\t\tCURRENT LEARNING RATE: 0.05754735064626926\n",
      "previous_iter_valid_loss : 0.08646152168512344\n",
      "\n",
      "    216200\t  0.086312\t  0.086462\t  0.100178\t\tCURRENT LEARNING RATE: 0.057489832059709485\n",
      "previous_iter_valid_loss : 0.09288837015628815\n",
      "\n",
      "    216300\t  0.092836\t  0.092888\t  0.100256\t\tCURRENT LEARNING RATE: 0.05743237096298654\n",
      "previous_iter_valid_loss : 0.15551912784576416\n",
      "\n",
      "    216400\t  0.155137\t  0.155519\t  0.100837\t\tCURRENT LEARNING RATE: 0.057374967298639376\n",
      "previous_iter_valid_loss : 0.08931809663772583\n",
      "\n",
      "    216500\t  0.089026\t  0.089318\t  0.100298\t\tCURRENT LEARNING RATE: 0.05731762100926429\n",
      "previous_iter_valid_loss : 0.08307255059480667\n",
      "\n",
      "    216600\t  0.082923\t  0.083073\t  0.100035\t\tCURRENT LEARNING RATE: 0.05726033203751499\n",
      "previous_iter_valid_loss : 0.08550401777029037\n",
      "\n",
      "    216700\t  0.085310\t  0.085504\t  0.099842\t\tCURRENT LEARNING RATE: 0.057203100326102464\n",
      "previous_iter_valid_loss : 0.14937955141067505\n",
      "\n",
      "    216800\t  0.149743\t  0.149380\t  0.100401\t\tCURRENT LEARNING RATE: 0.05714592581779507\n",
      "previous_iter_valid_loss : 0.08788733184337616\n",
      "\n",
      "    216900\t  0.087808\t  0.087887\t  0.100461\t\tCURRENT LEARNING RATE: 0.05708880845541825\n",
      "previous_iter_valid_loss : 0.08380122482776642\n",
      "\n",
      "    217000\t  0.083504\t  0.083801\t  0.100124\t\tCURRENT LEARNING RATE: 0.05703174818185464\n",
      "previous_iter_valid_loss : 0.13055196404457092\n",
      "\n",
      "    217100\t  0.130699\t  0.130552\t  0.100463\t\tCURRENT LEARNING RATE: 0.05697474494004394\n",
      "previous_iter_valid_loss : 0.08053640276193619\n",
      "\n",
      "    217200\t  0.080205\t  0.080536\t  0.100391\t\tCURRENT LEARNING RATE: 0.05691779867298296\n",
      "previous_iter_valid_loss : 0.10095742344856262\n",
      "\n",
      "    217300\t  0.100646\t  0.100957\t  0.100440\t\tCURRENT LEARNING RATE: 0.05686090932372539\n",
      "previous_iter_valid_loss : 0.0879627987742424\n",
      "\n",
      "    217400\t  0.087648\t  0.087963\t  0.100269\t\tCURRENT LEARNING RATE: 0.056804076835381884\n",
      "previous_iter_valid_loss : 0.09843142330646515\n",
      "\n",
      "    217500\t  0.098000\t  0.098431\t  0.100148\t\tCURRENT LEARNING RATE: 0.056747301151119915\n",
      "previous_iter_valid_loss : 0.14403975009918213\n",
      "\n",
      "    217600\t  0.143605\t  0.144040\t  0.100744\t\tCURRENT LEARNING RATE: 0.05669058221416386\n",
      "previous_iter_valid_loss : 0.10658752918243408\n",
      "\n",
      "    217700\t  0.106538\t  0.106588\t  0.100861\t\tCURRENT LEARNING RATE: 0.05663391996779474\n",
      "previous_iter_valid_loss : 0.09389886260032654\n",
      "\n",
      "    217800\t  0.093492\t  0.093899\t  0.100572\t\tCURRENT LEARNING RATE: 0.05657731435535031\n",
      "previous_iter_valid_loss : 0.09194367378950119\n",
      "\n",
      "    217900\t  0.091602\t  0.091944\t  0.100522\t\tCURRENT LEARNING RATE: 0.056520765320224924\n",
      "previous_iter_valid_loss : 0.1669224351644516\n",
      "\n",
      "    218000\t  0.167183\t  0.166922\t  0.100803\t\tCURRENT LEARNING RATE: 0.05646427280586959\n",
      "previous_iter_valid_loss : 0.08315278589725494\n",
      "\n",
      "    218100\t  0.082791\t  0.083153\t  0.100673\t\tCURRENT LEARNING RATE: 0.05640783675579177\n",
      "previous_iter_valid_loss : 0.08950955420732498\n",
      "\n",
      "    218200\t  0.089331\t  0.089510\t  0.100682\t\tCURRENT LEARNING RATE: 0.05635145711355541\n",
      "previous_iter_valid_loss : 0.08164193481206894\n",
      "\n",
      "    218300\t  0.081379\t  0.081642\t  0.100549\t\tCURRENT LEARNING RATE: 0.05629513382278083\n",
      "previous_iter_valid_loss : 0.10994934290647507\n",
      "\n",
      "    218400\t  0.109513\t  0.109949\t  0.100725\t\tCURRENT LEARNING RATE: 0.05623886682714479\n",
      "previous_iter_valid_loss : 0.0849667638540268\n",
      "\n",
      "    218500\t  0.084930\t  0.084967\t  0.100732\t\tCURRENT LEARNING RATE: 0.05618265607038026\n",
      "previous_iter_valid_loss : 0.08386256545782089\n",
      "\n",
      "    218600\t  0.083672\t  0.083863\t  0.100725\t\tCURRENT LEARNING RATE: 0.05612650149627649\n",
      "previous_iter_valid_loss : 0.0815984234213829\n",
      "\n",
      "    218700\t  0.081380\t  0.081598\t  0.100569\t\tCURRENT LEARNING RATE: 0.05607040304867886\n",
      "previous_iter_valid_loss : 0.08546511083841324\n",
      "\n",
      "    218800\t  0.085224\t  0.085465\t  0.100483\t\tCURRENT LEARNING RATE: 0.05601436067148898\n",
      "previous_iter_valid_loss : 0.10145124793052673\n",
      "\n",
      "    218900\t  0.100995\t  0.101451\t  0.100541\t\tCURRENT LEARNING RATE: 0.05595837430866444\n",
      "previous_iter_valid_loss : 0.09471563994884491\n",
      "\n",
      "    219000\t  0.094596\t  0.094716\t  0.100614\t\tCURRENT LEARNING RATE: 0.05590244390421887\n",
      "previous_iter_valid_loss : 0.1126527488231659\n",
      "\n",
      "    219100\t  0.112576\t  0.112653\t  0.100922\t\tCURRENT LEARNING RATE: 0.05584656940222184\n",
      "previous_iter_valid_loss : 0.12041374295949936\n",
      "\n",
      "    219200\t  0.120760\t  0.120414\t  0.101255\t\tCURRENT LEARNING RATE: 0.055790750746798894\n",
      "previous_iter_valid_loss : 0.14931659400463104\n",
      "\n",
      "    219300\t  0.148867\t  0.149317\t  0.101947\t\tCURRENT LEARNING RATE: 0.05573498788213134\n",
      "previous_iter_valid_loss : 0.08495157957077026\n",
      "\n",
      "    219400\t  0.084744\t  0.084952\t  0.101924\t\tCURRENT LEARNING RATE: 0.05567928075245631\n",
      "previous_iter_valid_loss : 0.08367802947759628\n",
      "\n",
      "    219500\t  0.083406\t  0.083678\t  0.101449\t\tCURRENT LEARNING RATE: 0.05562362930206665\n",
      "previous_iter_valid_loss : 0.1179267093539238\n",
      "\n",
      "    219600\t  0.117599\t  0.117927\t  0.101820\t\tCURRENT LEARNING RATE: 0.05556803347531095\n",
      "previous_iter_valid_loss : 0.1256415843963623\n",
      "\n",
      "    219700\t  0.125928\t  0.125642\t  0.101834\t\tCURRENT LEARNING RATE: 0.055512493216593364\n",
      "previous_iter_valid_loss : 0.14434784650802612\n",
      "\n",
      "    219800\t  0.144045\t  0.144348\t  0.102402\t\tCURRENT LEARNING RATE: 0.05545700847037361\n",
      "previous_iter_valid_loss : 0.11780069023370743\n",
      "\n",
      "    219900\t  0.117435\t  0.117801\t  0.102370\t\tCURRENT LEARNING RATE: 0.055401579181166935\n",
      "previous_iter_valid_loss : 0.08478520065546036\n",
      "\n",
      "    220000\t  0.084566\t  0.084785\t  0.102387\t\tCURRENT LEARNING RATE: 0.055346205293544073\n",
      "previous_iter_valid_loss : 0.11631752550601959\n",
      "\n",
      "    220100\t  0.115878\t  0.116318\t  0.102739\t\tCURRENT LEARNING RATE: 0.05529088675213112\n",
      "previous_iter_valid_loss : 0.08294610679149628\n",
      "\n",
      "    220200\t  0.082720\t  0.082946\t  0.102765\t\tCURRENT LEARNING RATE: 0.05523562350160953\n",
      "previous_iter_valid_loss : 0.0873003751039505\n",
      "\n",
      "    220300\t  0.086986\t  0.087300\t  0.102843\t\tCURRENT LEARNING RATE: 0.05518041548671601\n",
      "previous_iter_valid_loss : 0.1356610208749771\n",
      "\n",
      "    220400\t  0.135692\t  0.135661\t  0.103166\t\tCURRENT LEARNING RATE: 0.05512526265224261\n",
      "previous_iter_valid_loss : 0.08112724125385284\n",
      "\n",
      "    220500\t  0.080919\t  0.081127\t  0.102997\t\tCURRENT LEARNING RATE: 0.05507016494303645\n",
      "previous_iter_valid_loss : 0.09582901746034622\n",
      "\n",
      "    220600\t  0.095771\t  0.095829\t  0.102793\t\tCURRENT LEARNING RATE: 0.055015122303999825\n",
      "previous_iter_valid_loss : 0.08623834699392319\n",
      "\n",
      "    220700\t  0.085904\t  0.086238\t  0.102810\t\tCURRENT LEARNING RATE: 0.05496013468009006\n",
      "previous_iter_valid_loss : 0.09603595733642578\n",
      "\n",
      "    220800\t  0.095594\t  0.096036\t  0.102374\t\tCURRENT LEARNING RATE: 0.054905202016319585\n",
      "previous_iter_valid_loss : 0.1686212569475174\n",
      "\n",
      "    220900\t  0.168157\t  0.168621\t  0.103194\t\tCURRENT LEARNING RATE: 0.054850324257755705\n",
      "previous_iter_valid_loss : 0.08141104131937027\n",
      "\n",
      "    221000\t  0.081124\t  0.081411\t  0.103107\t\tCURRENT LEARNING RATE: 0.054795501349520645\n",
      "previous_iter_valid_loss : 0.08665449172258377\n",
      "\n",
      "    221100\t  0.086365\t  0.086654\t  0.103110\t\tCURRENT LEARNING RATE: 0.05474073323679148\n",
      "previous_iter_valid_loss : 0.11942163854837418\n",
      "\n",
      "    221200\t  0.119635\t  0.119422\t  0.103459\t\tCURRENT LEARNING RATE: 0.05468601986480014\n",
      "previous_iter_valid_loss : 0.0898984968662262\n",
      "\n",
      "    221300\t  0.089916\t  0.089898\t  0.103322\t\tCURRENT LEARNING RATE: 0.054631361178833215\n",
      "previous_iter_valid_loss : 0.10087371617555618\n",
      "\n",
      "    221400\t  0.100946\t  0.100874\t  0.103473\t\tCURRENT LEARNING RATE: 0.05457675712423203\n",
      "previous_iter_valid_loss : 0.09133940935134888\n",
      "\n",
      "    221500\t  0.091127\t  0.091339\t  0.103550\t\tCURRENT LEARNING RATE: 0.05452220764639249\n",
      "previous_iter_valid_loss : 0.0840078741312027\n",
      "\n",
      "    221600\t  0.084023\t  0.084008\t  0.103226\t\tCURRENT LEARNING RATE: 0.05446771269076516\n",
      "previous_iter_valid_loss : 0.08732727915048599\n",
      "\n",
      "    221700\t  0.087072\t  0.087327\t  0.103301\t\tCURRENT LEARNING RATE: 0.054413272202855065\n",
      "previous_iter_valid_loss : 0.08417780697345734\n",
      "\n",
      "    221800\t  0.083976\t  0.084178\t  0.103162\t\tCURRENT LEARNING RATE: 0.054358886128221706\n",
      "previous_iter_valid_loss : 0.08111001551151276\n",
      "\n",
      "    221900\t  0.080919\t  0.081110\t  0.103098\t\tCURRENT LEARNING RATE: 0.05430455441247898\n",
      "previous_iter_valid_loss : 0.11664870381355286\n",
      "\n",
      "    222000\t  0.117000\t  0.116649\t  0.103365\t\tCURRENT LEARNING RATE: 0.05425027700129521\n",
      "previous_iter_valid_loss : 0.08655895292758942\n",
      "\n",
      "    222100\t  0.086349\t  0.086559\t  0.103428\t\tCURRENT LEARNING RATE: 0.05419605384039298\n",
      "previous_iter_valid_loss : 0.08373284339904785\n",
      "\n",
      "    222200\t  0.083868\t  0.083733\t  0.103025\t\tCURRENT LEARNING RATE: 0.05414188487554909\n",
      "previous_iter_valid_loss : 0.0856231078505516\n",
      "\n",
      "    222300\t  0.085363\t  0.085623\t  0.103021\t\tCURRENT LEARNING RATE: 0.05408777005259457\n",
      "previous_iter_valid_loss : 0.08254563808441162\n",
      "\n",
      "    222400\t  0.082389\t  0.082546\t  0.102810\t\tCURRENT LEARNING RATE: 0.05403370931741463\n",
      "previous_iter_valid_loss : 0.09183239191770554\n",
      "\n",
      "    222500\t  0.091875\t  0.091832\t  0.102934\t\tCURRENT LEARNING RATE: 0.05397970261594851\n",
      "previous_iter_valid_loss : 0.10119537264108658\n",
      "\n",
      "    222600\t  0.101327\t  0.101195\t  0.102908\t\tCURRENT LEARNING RATE: 0.05392574989418951\n",
      "previous_iter_valid_loss : 0.08670786768198013\n",
      "\n",
      "    222700\t  0.086775\t  0.086708\t  0.102906\t\tCURRENT LEARNING RATE: 0.053871851098184875\n",
      "previous_iter_valid_loss : 0.1896323263645172\n",
      "\n",
      "    222800\t  0.189219\t  0.189632\t  0.103672\t\tCURRENT LEARNING RATE: 0.05381800617403584\n",
      "previous_iter_valid_loss : 0.10090138018131256\n",
      "\n",
      "    222900\t  0.100786\t  0.100901\t  0.103714\t\tCURRENT LEARNING RATE: 0.053764215067897476\n",
      "previous_iter_valid_loss : 0.09831198304891586\n",
      "\n",
      "    223000\t  0.097966\t  0.098312\t  0.103864\t\tCURRENT LEARNING RATE: 0.05371047772597866\n",
      "previous_iter_valid_loss : 0.13219809532165527\n",
      "\n",
      "    223100\t  0.132303\t  0.132198\t  0.104382\t\tCURRENT LEARNING RATE: 0.053656794094542014\n",
      "previous_iter_valid_loss : 0.08808781951665878\n",
      "\n",
      "    223200\t  0.087884\t  0.088088\t  0.104451\t\tCURRENT LEARNING RATE: 0.053603164119903964\n",
      "previous_iter_valid_loss : 0.08381304889917374\n",
      "\n",
      "    223300\t  0.083585\t  0.083813\t  0.103391\t\tCURRENT LEARNING RATE: 0.0535495877484345\n",
      "previous_iter_valid_loss : 0.08277281373739243\n",
      "\n",
      "    223400\t  0.082667\t  0.082773\t  0.103357\t\tCURRENT LEARNING RATE: 0.053496064926557244\n",
      "previous_iter_valid_loss : 0.07975629717111588\n",
      "\n",
      "    223500\t  0.079712\t  0.079756\t  0.103244\t\tCURRENT LEARNING RATE: 0.05344259560074935\n",
      "previous_iter_valid_loss : 0.09063726663589478\n",
      "\n",
      "    223600\t  0.090683\t  0.090637\t  0.103298\t\tCURRENT LEARNING RATE: 0.05338917971754153\n",
      "previous_iter_valid_loss : 0.09763966500759125\n",
      "\n",
      "    223700\t  0.097442\t  0.097640\t  0.103418\t\tCURRENT LEARNING RATE: 0.05333581722351788\n",
      "previous_iter_valid_loss : 0.08054279536008835\n",
      "\n",
      "    223800\t  0.080406\t  0.080543\t  0.103351\t\tCURRENT LEARNING RATE: 0.0532825080653159\n",
      "previous_iter_valid_loss : 0.12834285199642181\n",
      "\n",
      "    223900\t  0.128485\t  0.128343\t  0.103782\t\tCURRENT LEARNING RATE: 0.0532292521896264\n",
      "previous_iter_valid_loss : 0.08653435111045837\n",
      "\n",
      "    224000\t  0.086506\t  0.086534\t  0.103739\t\tCURRENT LEARNING RATE: 0.05317604954319355\n",
      "previous_iter_valid_loss : 0.0848032534122467\n",
      "\n",
      "    224100\t  0.084693\t  0.084803\t  0.103745\t\tCURRENT LEARNING RATE: 0.05312290007281467\n",
      "previous_iter_valid_loss : 0.10454868525266647\n",
      "\n",
      "    224200\t  0.104413\t  0.104549\t  0.103649\t\tCURRENT LEARNING RATE: 0.0530698037253403\n",
      "previous_iter_valid_loss : 0.10320645570755005\n",
      "\n",
      "    224300\t  0.103048\t  0.103206\t  0.103838\t\tCURRENT LEARNING RATE: 0.05301676044767405\n",
      "previous_iter_valid_loss : 0.08304941654205322\n",
      "\n",
      "    224400\t  0.082878\t  0.083049\t  0.102858\t\tCURRENT LEARNING RATE: 0.05296377018677268\n",
      "previous_iter_valid_loss : 0.11541717499494553\n",
      "\n",
      "    224500\t  0.115130\t  0.115417\t  0.102414\t\tCURRENT LEARNING RATE: 0.052910832889645924\n",
      "previous_iter_valid_loss : 0.09298619627952576\n",
      "\n",
      "    224600\t  0.092886\t  0.092986\t  0.101708\t\tCURRENT LEARNING RATE: 0.052857948503356456\n",
      "previous_iter_valid_loss : 0.09253542125225067\n",
      "\n",
      "    224700\t  0.092527\t  0.092535\t  0.101495\t\tCURRENT LEARNING RATE: 0.052805116975019877\n",
      "previous_iter_valid_loss : 0.08256997913122177\n",
      "\n",
      "    224800\t  0.082529\t  0.082570\t  0.100919\t\tCURRENT LEARNING RATE: 0.0527523382518047\n",
      "previous_iter_valid_loss : 0.09137507528066635\n",
      "\n",
      "    224900\t  0.091291\t  0.091375\t  0.100934\t\tCURRENT LEARNING RATE: 0.052699612280932166\n",
      "previous_iter_valid_loss : 0.09483352303504944\n",
      "\n",
      "    225000\t  0.094617\t  0.094834\t  0.100382\t\tCURRENT LEARNING RATE: 0.05264693900967631\n",
      "previous_iter_valid_loss : 0.08716963976621628\n",
      "\n",
      "    225100\t  0.087174\t  0.087170\t  0.100318\t\tCURRENT LEARNING RATE: 0.052594318385363846\n",
      "previous_iter_valid_loss : 0.08305664360523224\n",
      "\n",
      "    225200\t  0.083040\t  0.083057\t  0.100316\t\tCURRENT LEARNING RATE: 0.05254175035537413\n",
      "previous_iter_valid_loss : 0.10176832973957062\n",
      "\n",
      "    225300\t  0.101546\t  0.101768\t  0.100439\t\tCURRENT LEARNING RATE: 0.05248923486713917\n",
      "previous_iter_valid_loss : 0.095889613032341\n",
      "\n",
      "    225400\t  0.095716\t  0.095890\t  0.100556\t\tCURRENT LEARNING RATE: 0.05243677186814345\n",
      "previous_iter_valid_loss : 0.0834256038069725\n",
      "\n",
      "    225500\t  0.083473\t  0.083426\t  0.100566\t\tCURRENT LEARNING RATE: 0.05238436130592397\n",
      "previous_iter_valid_loss : 0.09136584401130676\n",
      "\n",
      "    225600\t  0.091101\t  0.091366\t  0.100476\t\tCURRENT LEARNING RATE: 0.05233200312807013\n",
      "previous_iter_valid_loss : 0.07780071347951889\n",
      "\n",
      "    225700\t  0.077776\t  0.077801\t  0.099618\t\tCURRENT LEARNING RATE: 0.052279697282223814\n",
      "previous_iter_valid_loss : 0.0816052258014679\n",
      "\n",
      "    225800\t  0.081497\t  0.081605\t  0.099495\t\tCURRENT LEARNING RATE: 0.05222744371607913\n",
      "previous_iter_valid_loss : 0.08018562197685242\n",
      "\n",
      "    225900\t  0.080068\t  0.080186\t  0.099483\t\tCURRENT LEARNING RATE: 0.05217524237738252\n",
      "previous_iter_valid_loss : 0.0861293151974678\n",
      "\n",
      "    226000\t  0.086039\t  0.086129\t  0.099398\t\tCURRENT LEARNING RATE: 0.05212309321393261\n",
      "previous_iter_valid_loss : 0.08773624897003174\n",
      "\n",
      "    226100\t  0.087684\t  0.087736\t  0.098852\t\tCURRENT LEARNING RATE: 0.052070996173580276\n",
      "previous_iter_valid_loss : 0.08635534346103668\n",
      "\n",
      "    226200\t  0.086223\t  0.086355\t  0.098851\t\tCURRENT LEARNING RATE: 0.05201895120422846\n",
      "previous_iter_valid_loss : 0.12356414645910263\n",
      "\n",
      "    226300\t  0.123928\t  0.123564\t  0.099158\t\tCURRENT LEARNING RATE: 0.05196695825383218\n",
      "previous_iter_valid_loss : 0.1223331168293953\n",
      "\n",
      "    226400\t  0.122148\t  0.122333\t  0.098826\t\tCURRENT LEARNING RATE: 0.05191501727039846\n",
      "previous_iter_valid_loss : 0.08354486525058746\n",
      "\n",
      "    226500\t  0.083659\t  0.083545\t  0.098769\t\tCURRENT LEARNING RATE: 0.051863128201986367\n",
      "previous_iter_valid_loss : 0.08868755400180817\n",
      "\n",
      "    226600\t  0.088577\t  0.088688\t  0.098825\t\tCURRENT LEARNING RATE: 0.05181129099670679\n",
      "previous_iter_valid_loss : 0.1824917197227478\n",
      "\n",
      "    226700\t  0.182296\t  0.182492\t  0.099795\t\tCURRENT LEARNING RATE: 0.05175950560272253\n",
      "previous_iter_valid_loss : 0.07813891768455505\n",
      "\n",
      "    226800\t  0.078128\t  0.078139\t  0.099082\t\tCURRENT LEARNING RATE: 0.05170777196824817\n",
      "previous_iter_valid_loss : 0.09726016223430634\n",
      "\n",
      "    226900\t  0.097437\t  0.097260\t  0.099176\t\tCURRENT LEARNING RATE: 0.0516560900415501\n",
      "previous_iter_valid_loss : 0.08858795464038849\n",
      "\n",
      "    227000\t  0.088673\t  0.088588\t  0.099224\t\tCURRENT LEARNING RATE: 0.05160445977094638\n",
      "previous_iter_valid_loss : 0.12809863686561584\n",
      "\n",
      "    227100\t  0.128339\t  0.128099\t  0.099199\t\tCURRENT LEARNING RATE: 0.05155288110480673\n",
      "previous_iter_valid_loss : 0.07947033643722534\n",
      "\n",
      "    227200\t  0.079474\t  0.079470\t  0.099189\t\tCURRENT LEARNING RATE: 0.05150135399155246\n",
      "previous_iter_valid_loss : 0.10156598687171936\n",
      "\n",
      "    227300\t  0.101365\t  0.101566\t  0.099195\t\tCURRENT LEARNING RATE: 0.0514498783796565\n",
      "previous_iter_valid_loss : 0.08287164568901062\n",
      "\n",
      "    227400\t  0.082912\t  0.082872\t  0.099144\t\tCURRENT LEARNING RATE: 0.0513984542176432\n",
      "previous_iter_valid_loss : 0.10516444593667984\n",
      "\n",
      "    227500\t  0.105315\t  0.105164\t  0.099211\t\tCURRENT LEARNING RATE: 0.0513470814540884\n",
      "previous_iter_valid_loss : 0.09661879390478134\n",
      "\n",
      "    227600\t  0.096498\t  0.096619\t  0.098737\t\tCURRENT LEARNING RATE: 0.05129576003761931\n",
      "previous_iter_valid_loss : 0.08449740707874298\n",
      "\n",
      "    227700\t  0.084393\t  0.084497\t  0.098516\t\tCURRENT LEARNING RATE: 0.05124448991691456\n",
      "previous_iter_valid_loss : 0.10981918126344681\n",
      "\n",
      "    227800\t  0.109670\t  0.109819\t  0.098675\t\tCURRENT LEARNING RATE: 0.051193271040704\n",
      "previous_iter_valid_loss : 0.08141832798719406\n",
      "\n",
      "    227900\t  0.081339\t  0.081418\t  0.098570\t\tCURRENT LEARNING RATE: 0.05114210335776874\n",
      "previous_iter_valid_loss : 0.11427780985832214\n",
      "\n",
      "    228000\t  0.114093\t  0.114278\t  0.098044\t\tCURRENT LEARNING RATE: 0.05109098681694108\n",
      "previous_iter_valid_loss : 0.09983552992343903\n",
      "\n",
      "    228100\t  0.099660\t  0.099836\t  0.098210\t\tCURRENT LEARNING RATE: 0.051039921367104515\n",
      "previous_iter_valid_loss : 0.09284316748380661\n",
      "\n",
      "    228200\t  0.093073\t  0.092843\t  0.098244\t\tCURRENT LEARNING RATE: 0.050988906957193575\n",
      "previous_iter_valid_loss : 0.08889234066009521\n",
      "\n",
      "    228300\t  0.088964\t  0.088892\t  0.098316\t\tCURRENT LEARNING RATE: 0.05093794353619384\n",
      "previous_iter_valid_loss : 0.08370832353830338\n",
      "\n",
      "    228400\t  0.083800\t  0.083708\t  0.098054\t\tCURRENT LEARNING RATE: 0.05088703105314186\n",
      "previous_iter_valid_loss : 0.09275027364492416\n",
      "\n",
      "    228500\t  0.092944\t  0.092750\t  0.098132\t\tCURRENT LEARNING RATE: 0.0508361694571252\n",
      "previous_iter_valid_loss : 0.10222646594047546\n",
      "\n",
      "    228600\t  0.102033\t  0.102226\t  0.098315\t\tCURRENT LEARNING RATE: 0.050785358697282235\n",
      "previous_iter_valid_loss : 0.0955333486199379\n",
      "\n",
      "    228700\t  0.095650\t  0.095533\t  0.098455\t\tCURRENT LEARNING RATE: 0.05073459872280219\n",
      "previous_iter_valid_loss : 0.09047762304544449\n",
      "\n",
      "    228800\t  0.090313\t  0.090478\t  0.098505\t\tCURRENT LEARNING RATE: 0.050683889482925085\n",
      "previous_iter_valid_loss : 0.0865243598818779\n",
      "\n",
      "    228900\t  0.086620\t  0.086524\t  0.098355\t\tCURRENT LEARNING RATE: 0.0506332309269417\n",
      "previous_iter_valid_loss : 0.08086714893579483\n",
      "\n",
      "    229000\t  0.080868\t  0.080867\t  0.098217\t\tCURRENT LEARNING RATE: 0.050582623004193465\n",
      "previous_iter_valid_loss : 0.09951417148113251\n",
      "\n",
      "    229100\t  0.099723\t  0.099514\t  0.098086\t\tCURRENT LEARNING RATE: 0.05053206566407245\n",
      "previous_iter_valid_loss : 0.08038794994354248\n",
      "\n",
      "    229200\t  0.080516\t  0.080388\t  0.097685\t\tCURRENT LEARNING RATE: 0.050481558856021284\n",
      "previous_iter_valid_loss : 0.08009125292301178\n",
      "\n",
      "    229300\t  0.080004\t  0.080091\t  0.096993\t\tCURRENT LEARNING RATE: 0.05043110252953321\n",
      "previous_iter_valid_loss : 0.0783834233880043\n",
      "\n",
      "    229400\t  0.078264\t  0.078383\t  0.096927\t\tCURRENT LEARNING RATE: 0.050380696634151866\n",
      "previous_iter_valid_loss : 0.08413752913475037\n",
      "\n",
      "    229500\t  0.084002\t  0.084138\t  0.096932\t\tCURRENT LEARNING RATE: 0.05033034111947135\n",
      "previous_iter_valid_loss : 0.08562570065259933\n",
      "\n",
      "    229600\t  0.085622\t  0.085626\t  0.096609\t\tCURRENT LEARNING RATE: 0.05028003593513613\n",
      "previous_iter_valid_loss : 0.10438670217990875\n",
      "\n",
      "    229700\t  0.104167\t  0.104387\t  0.096396\t\tCURRENT LEARNING RATE: 0.05022978103084105\n",
      "previous_iter_valid_loss : 0.07832187414169312\n",
      "\n",
      "    229800\t  0.078367\t  0.078322\t  0.095736\t\tCURRENT LEARNING RATE: 0.0501795763563312\n",
      "previous_iter_valid_loss : 0.07905671745538712\n",
      "\n",
      "    229900\t  0.079000\t  0.079057\t  0.095349\t\tCURRENT LEARNING RATE: 0.050129421861401874\n",
      "previous_iter_valid_loss : 0.08496445417404175\n",
      "\n",
      "    230000\t  0.084723\t  0.084964\t  0.095351\t\tCURRENT LEARNING RATE: 0.05007931749589857\n",
      "previous_iter_valid_loss : 0.10072437673807144\n",
      "\n",
      "    230100\t  0.100521\t  0.100724\t  0.095195\t\tCURRENT LEARNING RATE: 0.05002926320971696\n",
      "previous_iter_valid_loss : 0.13735069334506989\n",
      "\n",
      "    230200\t  0.137645\t  0.137351\t  0.095739\t\tCURRENT LEARNING RATE: 0.04997925895280273\n",
      "previous_iter_valid_loss : 0.09023584425449371\n",
      "\n",
      "    230300\t  0.090008\t  0.090236\t  0.095768\t\tCURRENT LEARNING RATE: 0.049929304675151616\n",
      "previous_iter_valid_loss : 0.08054105937480927\n",
      "\n",
      "    230400\t  0.080491\t  0.080541\t  0.095217\t\tCURRENT LEARNING RATE: 0.04987940032680931\n",
      "previous_iter_valid_loss : 0.07851111143827438\n",
      "\n",
      "    230500\t  0.078537\t  0.078511\t  0.095191\t\tCURRENT LEARNING RATE: 0.04982954585787151\n",
      "previous_iter_valid_loss : 0.07957927882671356\n",
      "\n",
      "    230600\t  0.079537\t  0.079579\t  0.095028\t\tCURRENT LEARNING RATE: 0.049779741218483727\n",
      "previous_iter_valid_loss : 0.08231160789728165\n",
      "\n",
      "    230700\t  0.082324\t  0.082312\t  0.094989\t\tCURRENT LEARNING RATE: 0.04972998635884131\n",
      "previous_iter_valid_loss : 0.09072715044021606\n",
      "\n",
      "    230800\t  0.090798\t  0.090727\t  0.094936\t\tCURRENT LEARNING RATE: 0.049680281229189376\n",
      "previous_iter_valid_loss : 0.08978304266929626\n",
      "\n",
      "    230900\t  0.089647\t  0.089783\t  0.094147\t\tCURRENT LEARNING RATE: 0.04963062577982283\n",
      "previous_iter_valid_loss : 0.08566443622112274\n",
      "\n",
      "    231000\t  0.085767\t  0.085664\t  0.094190\t\tCURRENT LEARNING RATE: 0.049581019961086194\n",
      "previous_iter_valid_loss : 0.07938871532678604\n",
      "\n",
      "    231100\t  0.079282\t  0.079389\t  0.094117\t\tCURRENT LEARNING RATE: 0.04953146372337366\n",
      "previous_iter_valid_loss : 0.10860200226306915\n",
      "\n",
      "    231200\t  0.108910\t  0.108602\t  0.094009\t\tCURRENT LEARNING RATE: 0.04948195701712895\n",
      "previous_iter_valid_loss : 0.07859309017658234\n",
      "\n",
      "    231300\t  0.078479\t  0.078593\t  0.093896\t\tCURRENT LEARNING RATE: 0.049432499792845405\n",
      "previous_iter_valid_loss : 0.08060858398675919\n",
      "\n",
      "    231400\t  0.080659\t  0.080609\t  0.093693\t\tCURRENT LEARNING RATE: 0.04938309200106577\n",
      "previous_iter_valid_loss : 0.08297421038150787\n",
      "\n",
      "    231500\t  0.082836\t  0.082974\t  0.093610\t\tCURRENT LEARNING RATE: 0.04933373359238225\n",
      "previous_iter_valid_loss : 0.07760099321603775\n",
      "\n",
      "    231600\t  0.077609\t  0.077601\t  0.093546\t\tCURRENT LEARNING RATE: 0.04928442451743641\n",
      "previous_iter_valid_loss : 0.09032467007637024\n",
      "\n",
      "    231700\t  0.090105\t  0.090325\t  0.093576\t\tCURRENT LEARNING RATE: 0.049235164726919224\n",
      "previous_iter_valid_loss : 0.07836827635765076\n",
      "\n",
      "    231800\t  0.078394\t  0.078368\t  0.093518\t\tCURRENT LEARNING RATE: 0.049185954171570866\n",
      "previous_iter_valid_loss : 0.08778370171785355\n",
      "\n",
      "    231900\t  0.087689\t  0.087784\t  0.093584\t\tCURRENT LEARNING RATE: 0.04913679280218077\n",
      "previous_iter_valid_loss : 0.09535130113363266\n",
      "\n",
      "    232000\t  0.095142\t  0.095351\t  0.093371\t\tCURRENT LEARNING RATE: 0.04908768056958756\n",
      "previous_iter_valid_loss : 0.07959620654582977\n",
      "\n",
      "    232100\t  0.079403\t  0.079596\t  0.093302\t\tCURRENT LEARNING RATE: 0.04903861742467903\n",
      "previous_iter_valid_loss : 0.08475323021411896\n",
      "\n",
      "    232200\t  0.084822\t  0.084753\t  0.093312\t\tCURRENT LEARNING RATE: 0.04898960331839201\n",
      "previous_iter_valid_loss : 0.08401483297348022\n",
      "\n",
      "    232300\t  0.083874\t  0.084015\t  0.093296\t\tCURRENT LEARNING RATE: 0.048940638201712384\n",
      "previous_iter_valid_loss : 0.09620371460914612\n",
      "\n",
      "    232400\t  0.096004\t  0.096204\t  0.093432\t\tCURRENT LEARNING RATE: 0.04889172202567502\n",
      "previous_iter_valid_loss : 0.08712886273860931\n",
      "\n",
      "    232500\t  0.087195\t  0.087129\t  0.093385\t\tCURRENT LEARNING RATE: 0.04884285474136378\n",
      "previous_iter_valid_loss : 0.10297355055809021\n",
      "\n",
      "    232600\t  0.103091\t  0.102974\t  0.093403\t\tCURRENT LEARNING RATE: 0.04879403629991135\n",
      "previous_iter_valid_loss : 0.08192699402570724\n",
      "\n",
      "    232700\t  0.081893\t  0.081927\t  0.093355\t\tCURRENT LEARNING RATE: 0.04874526665249929\n",
      "previous_iter_valid_loss : 0.09172862023115158\n",
      "\n",
      "    232800\t  0.091519\t  0.091729\t  0.092376\t\tCURRENT LEARNING RATE: 0.04869654575035792\n",
      "previous_iter_valid_loss : 0.07909848541021347\n",
      "\n",
      "    232900\t  0.079054\t  0.079098\t  0.092158\t\tCURRENT LEARNING RATE: 0.04864787354476638\n",
      "previous_iter_valid_loss : 0.0893169716000557\n",
      "\n",
      "    233000\t  0.089074\t  0.089317\t  0.092068\t\tCURRENT LEARNING RATE: 0.04859924998705244\n",
      "previous_iter_valid_loss : 0.09522305428981781\n",
      "\n",
      "    233100\t  0.095116\t  0.095223\t  0.091699\t\tCURRENT LEARNING RATE: 0.04855067502859254\n",
      "previous_iter_valid_loss : 0.08422597497701645\n",
      "\n",
      "    233200\t  0.084330\t  0.084226\t  0.091660\t\tCURRENT LEARNING RATE: 0.04850214862081168\n",
      "previous_iter_valid_loss : 0.08124296367168427\n",
      "\n",
      "    233300\t  0.081317\t  0.081243\t  0.091634\t\tCURRENT LEARNING RATE: 0.04845367071518352\n",
      "previous_iter_valid_loss : 0.1055670902132988\n",
      "\n",
      "    233400\t  0.105733\t  0.105567\t  0.091862\t\tCURRENT LEARNING RATE: 0.048405241263230106\n",
      "previous_iter_valid_loss : 0.09994392842054367\n",
      "\n",
      "    233500\t  0.100078\t  0.099944\t  0.092064\t\tCURRENT LEARNING RATE: 0.04835686021652199\n",
      "previous_iter_valid_loss : 0.09113974124193192\n",
      "\n",
      "    233600\t  0.091232\t  0.091140\t  0.092069\t\tCURRENT LEARNING RATE: 0.048308527526678094\n",
      "previous_iter_valid_loss : 0.09726787358522415\n",
      "\n",
      "    233700\t  0.097360\t  0.097268\t  0.092065\t\tCURRENT LEARNING RATE: 0.048260243145365776\n",
      "previous_iter_valid_loss : 0.07839662581682205\n",
      "\n",
      "    233800\t  0.078415\t  0.078397\t  0.092044\t\tCURRENT LEARNING RATE: 0.048212007024300625\n",
      "previous_iter_valid_loss : 0.08115018904209137\n",
      "\n",
      "    233900\t  0.081206\t  0.081150\t  0.091572\t\tCURRENT LEARNING RATE: 0.04816381911524652\n",
      "previous_iter_valid_loss : 0.07850329577922821\n",
      "\n",
      "    234000\t  0.078440\t  0.078503\t  0.091492\t\tCURRENT LEARNING RATE: 0.04811567937001551\n",
      "previous_iter_valid_loss : 0.10622860491275787\n",
      "\n",
      "    234100\t  0.106004\t  0.106229\t  0.091706\t\tCURRENT LEARNING RATE: 0.04806758774046791\n",
      "previous_iter_valid_loss : 0.08178776502609253\n",
      "\n",
      "    234200\t  0.081669\t  0.081788\t  0.091478\t\tCURRENT LEARNING RATE: 0.04801954417851206\n",
      "previous_iter_valid_loss : 0.09342081099748611\n",
      "\n",
      "    234300\t  0.093454\t  0.093421\t  0.091380\t\tCURRENT LEARNING RATE: 0.04797154863610439\n",
      "previous_iter_valid_loss : 0.09779153764247894\n",
      "\n",
      "    234400\t  0.097980\t  0.097792\t  0.091528\t\tCURRENT LEARNING RATE: 0.04792360106524932\n",
      "previous_iter_valid_loss : 0.09332043677568436\n",
      "\n",
      "    234500\t  0.093392\t  0.093320\t  0.091307\t\tCURRENT LEARNING RATE: 0.04787570141799934\n",
      "previous_iter_valid_loss : 0.0789351537823677\n",
      "\n",
      "    234600\t  0.078843\t  0.078935\t  0.091166\t\tCURRENT LEARNING RATE: 0.04782784964645477\n",
      "previous_iter_valid_loss : 0.08492989093065262\n",
      "\n",
      "    234700\t  0.084817\t  0.084930\t  0.091090\t\tCURRENT LEARNING RATE: 0.047780045702763826\n",
      "previous_iter_valid_loss : 0.08412867039442062\n",
      "\n",
      "    234800\t  0.084170\t  0.084129\t  0.091106\t\tCURRENT LEARNING RATE: 0.04773228953912255\n",
      "previous_iter_valid_loss : 0.07982512563467026\n",
      "\n",
      "    234900\t  0.079808\t  0.079825\t  0.090990\t\tCURRENT LEARNING RATE: 0.04768458110777481\n",
      "previous_iter_valid_loss : 0.10680238157510757\n",
      "\n",
      "    235000\t  0.107002\t  0.106802\t  0.091110\t\tCURRENT LEARNING RATE: 0.04763692036101214\n",
      "previous_iter_valid_loss : 0.11160019785165787\n",
      "\n",
      "    235100\t  0.111357\t  0.111600\t  0.091354\t\tCURRENT LEARNING RATE: 0.047589307251173815\n",
      "previous_iter_valid_loss : 0.08084925264120102\n",
      "\n",
      "    235200\t  0.080877\t  0.080849\t  0.091332\t\tCURRENT LEARNING RATE: 0.04754174173064669\n",
      "previous_iter_valid_loss : 0.08437871932983398\n",
      "\n",
      "    235300\t  0.084472\t  0.084379\t  0.091158\t\tCURRENT LEARNING RATE: 0.04749422375186527\n",
      "previous_iter_valid_loss : 0.08001028001308441\n",
      "\n",
      "    235400\t  0.080069\t  0.080010\t  0.091000\t\tCURRENT LEARNING RATE: 0.047446753267311556\n",
      "previous_iter_valid_loss : 0.10297643393278122\n",
      "\n",
      "    235500\t  0.103202\t  0.102976\t  0.091195\t\tCURRENT LEARNING RATE: 0.04739933022951507\n",
      "previous_iter_valid_loss : 0.08972977846860886\n",
      "\n",
      "    235600\t  0.089530\t  0.089730\t  0.091179\t\tCURRENT LEARNING RATE: 0.047351954591052736\n",
      "previous_iter_valid_loss : 0.07932291179895401\n",
      "\n",
      "    235700\t  0.079299\t  0.079323\t  0.091194\t\tCURRENT LEARNING RATE: 0.047304626304548965\n",
      "previous_iter_valid_loss : 0.08853725343942642\n",
      "\n",
      "    235800\t  0.088366\t  0.088537\t  0.091263\t\tCURRENT LEARNING RATE: 0.04725734532267544\n",
      "previous_iter_valid_loss : 0.07875008881092072\n",
      "\n",
      "    235900\t  0.078723\t  0.078750\t  0.091249\t\tCURRENT LEARNING RATE: 0.047210111598151173\n",
      "previous_iter_valid_loss : 0.08296605199575424\n",
      "\n",
      "    236000\t  0.082790\t  0.082966\t  0.091217\t\tCURRENT LEARNING RATE: 0.047162925083742424\n",
      "previous_iter_valid_loss : 0.08874139189720154\n",
      "\n",
      "    236100\t  0.088802\t  0.088741\t  0.091227\t\tCURRENT LEARNING RATE: 0.0471157857322627\n",
      "previous_iter_valid_loss : 0.10495084524154663\n",
      "\n",
      "    236200\t  0.104721\t  0.104951\t  0.091413\t\tCURRENT LEARNING RATE: 0.047068693496572646\n",
      "previous_iter_valid_loss : 0.09571629762649536\n",
      "\n",
      "    236300\t  0.095532\t  0.095716\t  0.091135\t\tCURRENT LEARNING RATE: 0.04702164832958\n",
      "previous_iter_valid_loss : 0.08605364710092545\n",
      "\n",
      "    236400\t  0.086069\t  0.086054\t  0.090772\t\tCURRENT LEARNING RATE: 0.04697465018423959\n",
      "previous_iter_valid_loss : 0.08091871440410614\n",
      "\n",
      "    236500\t  0.080900\t  0.080919\t  0.090746\t\tCURRENT LEARNING RATE: 0.046927699013553294\n",
      "previous_iter_valid_loss : 0.1212737187743187\n",
      "\n",
      "    236600\t  0.121066\t  0.121274\t  0.091072\t\tCURRENT LEARNING RATE: 0.04688079477056993\n",
      "previous_iter_valid_loss : 0.07787018269300461\n",
      "\n",
      "    236700\t  0.077776\t  0.077870\t  0.090025\t\tCURRENT LEARNING RATE: 0.046833937408385234\n",
      "previous_iter_valid_loss : 0.09896126389503479\n",
      "\n",
      "    236800\t  0.099047\t  0.098961\t  0.090234\t\tCURRENT LEARNING RATE: 0.04678712688014183\n",
      "previous_iter_valid_loss : 0.08110823482275009\n",
      "\n",
      "    236900\t  0.080938\t  0.081108\t  0.090072\t\tCURRENT LEARNING RATE: 0.04674036313902923\n",
      "previous_iter_valid_loss : 0.08480580151081085\n",
      "\n",
      "    237000\t  0.084650\t  0.084806\t  0.090034\t\tCURRENT LEARNING RATE: 0.04669364613828366\n",
      "previous_iter_valid_loss : 0.0911116674542427\n",
      "\n",
      "    237100\t  0.090913\t  0.091112\t  0.089664\t\tCURRENT LEARNING RATE: 0.046646975831188126\n",
      "previous_iter_valid_loss : 0.11787967383861542\n",
      "\n",
      "    237200\t  0.118123\t  0.117880\t  0.090049\t\tCURRENT LEARNING RATE: 0.046600352171072286\n",
      "previous_iter_valid_loss : 0.19819040596485138\n",
      "\n",
      "    237300\t  0.197939\t  0.198190\t  0.091015\t\tCURRENT LEARNING RATE: 0.04655377511131252\n",
      "previous_iter_valid_loss : 0.08685575425624847\n",
      "\n",
      "    237400\t  0.086866\t  0.086856\t  0.091055\t\tCURRENT LEARNING RATE: 0.046507244605331746\n",
      "previous_iter_valid_loss : 0.0783853754401207\n",
      "\n",
      "    237500\t  0.078357\t  0.078385\t  0.090787\t\tCURRENT LEARNING RATE: 0.04646076060659945\n",
      "previous_iter_valid_loss : 0.08514536172151566\n",
      "\n",
      "    237600\t  0.085248\t  0.085145\t  0.090672\t\tCURRENT LEARNING RATE: 0.046414323068631635\n",
      "previous_iter_valid_loss : 0.07971970736980438\n",
      "\n",
      "    237700\t  0.079620\t  0.079720\t  0.090624\t\tCURRENT LEARNING RATE: 0.04636793194499073\n",
      "previous_iter_valid_loss : 0.08369357883930206\n",
      "\n",
      "    237800\t  0.083669\t  0.083694\t  0.090363\t\tCURRENT LEARNING RATE: 0.04632158718928566\n",
      "previous_iter_valid_loss : 0.09104037284851074\n",
      "\n",
      "    237900\t  0.090885\t  0.091040\t  0.090459\t\tCURRENT LEARNING RATE: 0.046275288755171645\n",
      "previous_iter_valid_loss : 0.11420635879039764\n",
      "\n",
      "    238000\t  0.114004\t  0.114206\t  0.090459\t\tCURRENT LEARNING RATE: 0.046229036596350234\n",
      "previous_iter_valid_loss : 0.09093303978443146\n",
      "\n",
      "    238100\t  0.091038\t  0.090933\t  0.090370\t\tCURRENT LEARNING RATE: 0.04618283066656925\n",
      "previous_iter_valid_loss : 0.0838492140173912\n",
      "\n",
      "    238200\t  0.083718\t  0.083849\t  0.090280\t\tCURRENT LEARNING RATE: 0.046136670919622806\n",
      "previous_iter_valid_loss : 0.07849399745464325\n",
      "\n",
      "    238300\t  0.078453\t  0.078494\t  0.090176\t\tCURRENT LEARNING RATE: 0.046090557309351125\n",
      "previous_iter_valid_loss : 0.08174789696931839\n",
      "\n",
      "    238400\t  0.081794\t  0.081748\t  0.090156\t\tCURRENT LEARNING RATE: 0.0460444897896406\n",
      "previous_iter_valid_loss : 0.09366614371538162\n",
      "\n",
      "    238500\t  0.093748\t  0.093666\t  0.090165\t\tCURRENT LEARNING RATE: 0.04599846831442367\n",
      "previous_iter_valid_loss : 0.09300167113542557\n",
      "\n",
      "    238600\t  0.093107\t  0.093002\t  0.090073\t\tCURRENT LEARNING RATE: 0.04595249283767892\n",
      "previous_iter_valid_loss : 0.07914698123931885\n",
      "\n",
      "    238700\t  0.079061\t  0.079147\t  0.089909\t\tCURRENT LEARNING RATE: 0.04590656331343083\n",
      "previous_iter_valid_loss : 0.08111635595560074\n",
      "\n",
      "    238800\t  0.081000\t  0.081116\t  0.089815\t\tCURRENT LEARNING RATE: 0.045860679695749876\n",
      "previous_iter_valid_loss : 0.08037296682596207\n",
      "\n",
      "    238900\t  0.080365\t  0.080373\t  0.089754\t\tCURRENT LEARNING RATE: 0.04581484193875242\n",
      "previous_iter_valid_loss : 0.08309673517942429\n",
      "\n",
      "    239000\t  0.083107\t  0.083097\t  0.089776\t\tCURRENT LEARNING RATE: 0.045769049996600746\n",
      "previous_iter_valid_loss : 0.0866597592830658\n",
      "\n",
      "    239100\t  0.086465\t  0.086660\t  0.089648\t\tCURRENT LEARNING RATE: 0.04572330382350288\n",
      "previous_iter_valid_loss : 0.10161332041025162\n",
      "\n",
      "    239200\t  0.101695\t  0.101613\t  0.089860\t\tCURRENT LEARNING RATE: 0.04567760337371265\n",
      "previous_iter_valid_loss : 0.1214202493429184\n",
      "\n",
      "    239300\t  0.121579\t  0.121420\t  0.090273\t\tCURRENT LEARNING RATE: 0.045631948601529575\n",
      "previous_iter_valid_loss : 0.13917407393455505\n",
      "\n",
      "    239400\t  0.139472\t  0.139174\t  0.090881\t\tCURRENT LEARNING RATE: 0.045586339461298926\n",
      "previous_iter_valid_loss : 0.08216830343008041\n",
      "\n",
      "    239500\t  0.082056\t  0.082168\t  0.090861\t\tCURRENT LEARNING RATE: 0.04554077590741154\n",
      "previous_iter_valid_loss : 0.07981432974338531\n",
      "\n",
      "    239600\t  0.079789\t  0.079814\t  0.090803\t\tCURRENT LEARNING RATE: 0.04549525789430386\n",
      "previous_iter_valid_loss : 0.08218740671873093\n",
      "\n",
      "    239700\t  0.082169\t  0.082187\t  0.090581\t\tCURRENT LEARNING RATE: 0.04544978537645784\n",
      "previous_iter_valid_loss : 0.12847959995269775\n",
      "\n",
      "    239800\t  0.128254\t  0.128480\t  0.091083\t\tCURRENT LEARNING RATE: 0.045404358308401\n",
      "previous_iter_valid_loss : 0.08779248595237732\n",
      "\n",
      "    239900\t  0.087585\t  0.087792\t  0.091170\t\tCURRENT LEARNING RATE: 0.045358976644706256\n",
      "previous_iter_valid_loss : 0.09743359684944153\n",
      "\n",
      "    240000\t  0.097509\t  0.097434\t  0.091295\t\tCURRENT LEARNING RATE: 0.04531364033999194\n",
      "previous_iter_valid_loss : 0.10343598574399948\n",
      "\n",
      "    240100\t  0.103637\t  0.103436\t  0.091322\t\tCURRENT LEARNING RATE: 0.04526834934892172\n",
      "previous_iter_valid_loss : 0.07826251536607742\n",
      "\n",
      "    240200\t  0.078219\t  0.078263\t  0.090731\t\tCURRENT LEARNING RATE: 0.04522310362620463\n",
      "previous_iter_valid_loss : 0.11009050160646439\n",
      "\n",
      "    240300\t  0.110262\t  0.110091\t  0.090930\t\tCURRENT LEARNING RATE: 0.04517790312659495\n",
      "previous_iter_valid_loss : 0.07881557196378708\n",
      "\n",
      "    240400\t  0.078742\t  0.078816\t  0.090913\t\tCURRENT LEARNING RATE: 0.045132747804892154\n",
      "previous_iter_valid_loss : 0.09046060591936111\n",
      "\n",
      "    240500\t  0.090435\t  0.090461\t  0.091032\t\tCURRENT LEARNING RATE: 0.0450876376159409\n",
      "previous_iter_valid_loss : 0.13989727199077606\n",
      "\n",
      "    240600\t  0.140202\t  0.139897\t  0.091635\t\tCURRENT LEARNING RATE: 0.04504257251463105\n",
      "previous_iter_valid_loss : 0.09890107810497284\n",
      "\n",
      "    240700\t  0.099076\t  0.098901\t  0.091801\t\tCURRENT LEARNING RATE: 0.044997552455897455\n",
      "previous_iter_valid_loss : 0.08244751393795013\n",
      "\n",
      "    240800\t  0.082474\t  0.082448\t  0.091718\t\tCURRENT LEARNING RATE: 0.04495257739472008\n",
      "previous_iter_valid_loss : 0.08260013163089752\n",
      "\n",
      "    240900\t  0.082450\t  0.082600\t  0.091646\t\tCURRENT LEARNING RATE: 0.044907647286123814\n",
      "previous_iter_valid_loss : 0.08583145588636398\n",
      "\n",
      "    241000\t  0.085893\t  0.085831\t  0.091648\t\tCURRENT LEARNING RATE: 0.0448627620851786\n",
      "previous_iter_valid_loss : 0.09078526496887207\n",
      "\n",
      "    241100\t  0.090597\t  0.090785\t  0.091762\t\tCURRENT LEARNING RATE: 0.04481792174699921\n",
      "previous_iter_valid_loss : 0.08636834472417831\n",
      "\n",
      "    241200\t  0.086212\t  0.086368\t  0.091540\t\tCURRENT LEARNING RATE: 0.044773126226745306\n",
      "previous_iter_valid_loss : 0.142823725938797\n",
      "\n",
      "    241300\t  0.143145\t  0.142824\t  0.092182\t\tCURRENT LEARNING RATE: 0.044728375479621336\n",
      "previous_iter_valid_loss : 0.07787150144577026\n",
      "\n",
      "    241400\t  0.077835\t  0.077872\t  0.092155\t\tCURRENT LEARNING RATE: 0.044683669460876596\n",
      "previous_iter_valid_loss : 0.07947852462530136\n",
      "\n",
      "    241500\t  0.079352\t  0.079479\t  0.092120\t\tCURRENT LEARNING RATE: 0.044639008125805034\n",
      "previous_iter_valid_loss : 0.08527375012636185\n",
      "\n",
      "    241600\t  0.085183\t  0.085274\t  0.092196\t\tCURRENT LEARNING RATE: 0.04459439142974532\n",
      "previous_iter_valid_loss : 0.08069518953561783\n",
      "\n",
      "    241700\t  0.080603\t  0.080695\t  0.092100\t\tCURRENT LEARNING RATE: 0.044549819328080734\n",
      "previous_iter_valid_loss : 0.13674701750278473\n",
      "\n",
      "    241800\t  0.137052\t  0.136747\t  0.092684\t\tCURRENT LEARNING RATE: 0.044505291776239214\n",
      "previous_iter_valid_loss : 0.078876793384552\n",
      "\n",
      "    241900\t  0.078874\t  0.078877\t  0.092595\t\tCURRENT LEARNING RATE: 0.04446080872969317\n",
      "previous_iter_valid_loss : 0.07877573370933533\n",
      "\n",
      "    242000\t  0.078743\t  0.078776\t  0.092429\t\tCURRENT LEARNING RATE: 0.04441637014395956\n",
      "previous_iter_valid_loss : 0.08835440129041672\n",
      "\n",
      "    242100\t  0.088372\t  0.088354\t  0.092517\t\tCURRENT LEARNING RATE: 0.044371975974599784\n",
      "previous_iter_valid_loss : 0.08615782856941223\n",
      "\n",
      "    242200\t  0.085948\t  0.086158\t  0.092531\t\tCURRENT LEARNING RATE: 0.04432762617721969\n",
      "previous_iter_valid_loss : 0.1533665955066681\n",
      "\n",
      "    242300\t  0.153671\t  0.153367\t  0.093224\t\tCURRENT LEARNING RATE: 0.04428332070746948\n",
      "previous_iter_valid_loss : 0.09781970083713531\n",
      "\n",
      "    242400\t  0.097600\t  0.097820\t  0.093240\t\tCURRENT LEARNING RATE: 0.04423905952104366\n",
      "previous_iter_valid_loss : 0.07809262722730637\n",
      "\n",
      "    242500\t  0.077981\t  0.078093\t  0.093150\t\tCURRENT LEARNING RATE: 0.044194842573681024\n",
      "previous_iter_valid_loss : 0.09399589896202087\n",
      "\n",
      "    242600\t  0.094050\t  0.093996\t  0.093060\t\tCURRENT LEARNING RATE: 0.044150669821164674\n",
      "previous_iter_valid_loss : 0.08922170847654343\n",
      "\n",
      "    242700\t  0.089239\t  0.089222\t  0.093133\t\tCURRENT LEARNING RATE: 0.04410654121932182\n",
      "previous_iter_valid_loss : 0.0836523249745369\n",
      "\n",
      "    242800\t  0.083500\t  0.083652\t  0.093052\t\tCURRENT LEARNING RATE: 0.044062456724023855\n",
      "previous_iter_valid_loss : 0.07797354459762573\n",
      "\n",
      "    242900\t  0.077952\t  0.077974\t  0.093041\t\tCURRENT LEARNING RATE: 0.044018416291186274\n",
      "previous_iter_valid_loss : 0.07783893495798111\n",
      "\n",
      "    243000\t  0.077741\t  0.077839\t  0.092926\t\tCURRENT LEARNING RATE: 0.043974419876768665\n",
      "previous_iter_valid_loss : 0.07976064831018448\n",
      "\n",
      "    243100\t  0.079645\t  0.079761\t  0.092772\t\tCURRENT LEARNING RATE: 0.0439304674367746\n",
      "previous_iter_valid_loss : 0.0788552388548851\n",
      "\n",
      "    243200\t  0.078836\t  0.078855\t  0.092718\t\tCURRENT LEARNING RATE: 0.043886558927251636\n",
      "previous_iter_valid_loss : 0.08626560121774673\n",
      "\n",
      "    243300\t  0.086089\t  0.086266\t  0.092768\t\tCURRENT LEARNING RATE: 0.04384269430429124\n",
      "previous_iter_valid_loss : 0.09650509059429169\n",
      "\n",
      "    243400\t  0.096583\t  0.096505\t  0.092678\t\tCURRENT LEARNING RATE: 0.043798873524028815\n",
      "previous_iter_valid_loss : 0.07810946553945541\n",
      "\n",
      "    243500\t  0.078099\t  0.078109\t  0.092459\t\tCURRENT LEARNING RATE: 0.04375509654264356\n",
      "previous_iter_valid_loss : 0.07985491305589676\n",
      "\n",
      "    243600\t  0.079723\t  0.079855\t  0.092347\t\tCURRENT LEARNING RATE: 0.043711363316358505\n",
      "previous_iter_valid_loss : 0.07742886245250702\n",
      "\n",
      "    243700\t  0.077387\t  0.077429\t  0.092148\t\tCURRENT LEARNING RATE: 0.04366767380144038\n",
      "previous_iter_valid_loss : 0.07703008502721786\n",
      "\n",
      "\n",
      "Current valid loss: 0.07703008502721786;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "    243800\t  0.076942\t  0.077030\t  0.092134\t\tCURRENT LEARNING RATE: 0.04362402795419972\n",
      "previous_iter_valid_loss : 0.08648395538330078\n",
      "\n",
      "    243900\t  0.086481\t  0.086484\t  0.092188\t\tCURRENT LEARNING RATE: 0.04358042573099065\n",
      "previous_iter_valid_loss : 0.0802408903837204\n",
      "\n",
      "    244000\t  0.080227\t  0.080241\t  0.092205\t\tCURRENT LEARNING RATE: 0.04353686708821094\n",
      "previous_iter_valid_loss : 0.07812578231096268\n",
      "\n",
      "    244100\t  0.078067\t  0.078126\t  0.091924\t\tCURRENT LEARNING RATE: 0.04349335198230193\n",
      "previous_iter_valid_loss : 0.10284588485956192\n",
      "\n",
      "    244200\t  0.102630\t  0.102846\t  0.092135\t\tCURRENT LEARNING RATE: 0.04344988036974854\n",
      "previous_iter_valid_loss : 0.08120211958885193\n",
      "\n",
      "    244300\t  0.081206\t  0.081202\t  0.092013\t\tCURRENT LEARNING RATE: 0.043406452207079144\n",
      "previous_iter_valid_loss : 0.08114935457706451\n",
      "\n",
      "    244400\t  0.081000\t  0.081149\t  0.091846\t\tCURRENT LEARNING RATE: 0.04336306745086557\n",
      "previous_iter_valid_loss : 0.0833534225821495\n",
      "\n",
      "    244500\t  0.083347\t  0.083353\t  0.091746\t\tCURRENT LEARNING RATE: 0.04331972605772305\n",
      "previous_iter_valid_loss : 0.08151502162218094\n",
      "\n",
      "    244600\t  0.081394\t  0.081515\t  0.091772\t\tCURRENT LEARNING RATE: 0.04327642798431021\n",
      "previous_iter_valid_loss : 0.1242627426981926\n",
      "\n",
      "    244700\t  0.124022\t  0.124263\t  0.092166\t\tCURRENT LEARNING RATE: 0.04323317318732896\n",
      "previous_iter_valid_loss : 0.08243419975042343\n",
      "\n",
      "    244800\t  0.082346\t  0.082434\t  0.092149\t\tCURRENT LEARNING RATE: 0.0431899616235245\n",
      "previous_iter_valid_loss : 0.08336301147937775\n",
      "\n",
      "    244900\t  0.083323\t  0.083363\t  0.092184\t\tCURRENT LEARNING RATE: 0.04314679324968525\n",
      "previous_iter_valid_loss : 0.08554603904485703\n",
      "\n",
      "    245000\t  0.085640\t  0.085546\t  0.091971\t\tCURRENT LEARNING RATE: 0.04310366802264286\n",
      "previous_iter_valid_loss : 0.07961759716272354\n",
      "\n",
      "    245100\t  0.079492\t  0.079618\t  0.091652\t\tCURRENT LEARNING RATE: 0.04306058589927208\n",
      "previous_iter_valid_loss : 0.07866654545068741\n",
      "\n",
      "    245200\t  0.078550\t  0.078667\t  0.091630\t\tCURRENT LEARNING RATE: 0.04301754683649079\n",
      "previous_iter_valid_loss : 0.09788828343153\n",
      "\n",
      "    245300\t  0.098004\t  0.097888\t  0.091765\t\tCURRENT LEARNING RATE: 0.042974550791259905\n",
      "previous_iter_valid_loss : 0.1941274106502533\n",
      "\n",
      "    245400\t  0.194643\t  0.194127\t  0.092906\t\tCURRENT LEARNING RATE: 0.042931597720583414\n",
      "previous_iter_valid_loss : 0.11745229363441467\n",
      "\n",
      "    245500\t  0.117267\t  0.117452\t  0.093051\t\tCURRENT LEARNING RATE: 0.04288868758150822\n",
      "previous_iter_valid_loss : 0.08358960598707199\n",
      "\n",
      "    245600\t  0.083708\t  0.083590\t  0.092989\t\tCURRENT LEARNING RATE: 0.042845820331124176\n",
      "previous_iter_valid_loss : 0.09357837587594986\n",
      "\n",
      "    245700\t  0.093436\t  0.093578\t  0.093132\t\tCURRENT LEARNING RATE: 0.042802995926564016\n",
      "previous_iter_valid_loss : 0.08752428740262985\n",
      "\n",
      "    245800\t  0.087565\t  0.087524\t  0.093122\t\tCURRENT LEARNING RATE: 0.04276021432500337\n",
      "previous_iter_valid_loss : 0.10355670005083084\n",
      "\n",
      "    245900\t  0.103717\t  0.103557\t  0.093370\t\tCURRENT LEARNING RATE: 0.042717475483660616\n",
      "previous_iter_valid_loss : 0.109913669526577\n",
      "\n",
      "    246000\t  0.110119\t  0.109914\t  0.093639\t\tCURRENT LEARNING RATE: 0.042674779359796904\n",
      "previous_iter_valid_loss : 0.07747375965118408\n",
      "\n",
      "    246100\t  0.077488\t  0.077474\t  0.093527\t\tCURRENT LEARNING RATE: 0.042632125910716086\n",
      "previous_iter_valid_loss : 0.08174880594015121\n",
      "\n",
      "    246200\t  0.081637\t  0.081749\t  0.093295\t\tCURRENT LEARNING RATE: 0.04258951509376475\n",
      "previous_iter_valid_loss : 0.08866557478904724\n",
      "\n",
      "    246300\t  0.088771\t  0.088666\t  0.093224\t\tCURRENT LEARNING RATE: 0.04254694686633206\n",
      "previous_iter_valid_loss : 0.08847946673631668\n",
      "\n",
      "    246400\t  0.088605\t  0.088479\t  0.093248\t\tCURRENT LEARNING RATE: 0.04250442118584978\n",
      "previous_iter_valid_loss : 0.07884100079536438\n",
      "\n",
      "    246500\t  0.078883\t  0.078841\t  0.093228\t\tCURRENT LEARNING RATE: 0.042461938009792206\n",
      "previous_iter_valid_loss : 0.09054234623908997\n",
      "\n",
      "    246600\t  0.090692\t  0.090542\t  0.092920\t\tCURRENT LEARNING RATE: 0.042419497295676206\n",
      "previous_iter_valid_loss : 0.07990463823080063\n",
      "\n",
      "    246700\t  0.079880\t  0.079905\t  0.092941\t\tCURRENT LEARNING RATE: 0.042377099001061035\n",
      "previous_iter_valid_loss : 0.07769323885440826\n",
      "\n",
      "    246800\t  0.077617\t  0.077693\t  0.092728\t\tCURRENT LEARNING RATE: 0.04233474308354839\n",
      "previous_iter_valid_loss : 0.0773480013012886\n",
      "\n",
      "    246900\t  0.077312\t  0.077348\t  0.092690\t\tCURRENT LEARNING RATE: 0.042292429500782346\n",
      "previous_iter_valid_loss : 0.07926752418279648\n",
      "\n",
      "    247000\t  0.079328\t  0.079268\t  0.092635\t\tCURRENT LEARNING RATE: 0.04225015821044934\n",
      "previous_iter_valid_loss : 0.09806991368532181\n",
      "\n",
      "    247100\t  0.097909\t  0.098070\t  0.092705\t\tCURRENT LEARNING RATE: 0.04220792917027807\n",
      "previous_iter_valid_loss : 0.08046094328165054\n",
      "\n",
      "    247200\t  0.080394\t  0.080461\t  0.092330\t\tCURRENT LEARNING RATE: 0.042165742338039484\n",
      "previous_iter_valid_loss : 0.10749233514070511\n",
      "\n",
      "    247300\t  0.107724\t  0.107492\t  0.091423\t\tCURRENT LEARNING RATE: 0.042123597671546734\n",
      "previous_iter_valid_loss : 0.08575928211212158\n",
      "\n",
      "    247400\t  0.085889\t  0.085759\t  0.091412\t\tCURRENT LEARNING RATE: 0.04208149512865518\n",
      "previous_iter_valid_loss : 0.07697205245494843\n",
      "\n",
      "\n",
      "Current valid loss: 0.07697205245494843;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "    247500\t  0.076939\t  0.076972\t  0.091398\t\tCURRENT LEARNING RATE: 0.04203943466726227\n",
      "previous_iter_valid_loss : 0.08559131622314453\n",
      "\n",
      "    247600\t  0.085691\t  0.085591\t  0.091403\t\tCURRENT LEARNING RATE: 0.04199741624530752\n",
      "previous_iter_valid_loss : 0.07961950451135635\n",
      "\n",
      "    247700\t  0.079681\t  0.079620\t  0.091402\t\tCURRENT LEARNING RATE: 0.0419554398207725\n",
      "previous_iter_valid_loss : 0.07728025317192078\n",
      "\n",
      "    247800\t  0.077251\t  0.077280\t  0.091338\t\tCURRENT LEARNING RATE: 0.04191350535168082\n",
      "previous_iter_valid_loss : 0.1021413579583168\n",
      "\n",
      "    247900\t  0.102351\t  0.102141\t  0.091449\t\tCURRENT LEARNING RATE: 0.04187161279609798\n",
      "previous_iter_valid_loss : 0.08486168831586838\n",
      "\n",
      "    248000\t  0.084685\t  0.084862\t  0.091155\t\tCURRENT LEARNING RATE: 0.04182976211213143\n",
      "previous_iter_valid_loss : 0.07947152853012085\n",
      "\n",
      "    248100\t  0.079515\t  0.079472\t  0.091041\t\tCURRENT LEARNING RATE: 0.04178795325793045\n",
      "previous_iter_valid_loss : 0.07740946859121323\n",
      "\n",
      "    248200\t  0.077465\t  0.077409\t  0.090976\t\tCURRENT LEARNING RATE: 0.04174618619168624\n",
      "previous_iter_valid_loss : 0.0972910225391388\n",
      "\n",
      "    248300\t  0.097422\t  0.097291\t  0.091164\t\tCURRENT LEARNING RATE: 0.041704460871631696\n",
      "previous_iter_valid_loss : 0.0801822692155838\n",
      "\n",
      "    248400\t  0.080100\t  0.080182\t  0.091149\t\tCURRENT LEARNING RATE: 0.0416627772560415\n",
      "previous_iter_valid_loss : 0.13569478690624237\n",
      "\n",
      "    248500\t  0.136023\t  0.135695\t  0.091569\t\tCURRENT LEARNING RATE: 0.041621135303232006\n",
      "previous_iter_valid_loss : 0.079655721783638\n",
      "\n",
      "    248600\t  0.079750\t  0.079656\t  0.091435\t\tCURRENT LEARNING RATE: 0.04157953497156131\n",
      "previous_iter_valid_loss : 0.07901709526777267\n",
      "\n",
      "    248700\t  0.079034\t  0.079017\t  0.091434\t\tCURRENT LEARNING RATE: 0.04153797621942905\n",
      "previous_iter_valid_loss : 0.09233806282281876\n",
      "\n",
      "    248800\t  0.092294\t  0.092338\t  0.091546\t\tCURRENT LEARNING RATE: 0.041496459005276466\n",
      "previous_iter_valid_loss : 0.08933758735656738\n",
      "\n",
      "    248900\t  0.089412\t  0.089338\t  0.091636\t\tCURRENT LEARNING RATE: 0.04145498328758633\n",
      "previous_iter_valid_loss : 0.07737725973129272\n",
      "\n",
      "    249000\t  0.077389\t  0.077377\t  0.091579\t\tCURRENT LEARNING RATE: 0.04141354902488296\n",
      "previous_iter_valid_loss : 0.07868918776512146\n",
      "\n",
      "    249100\t  0.078667\t  0.078689\t  0.091499\t\tCURRENT LEARNING RATE: 0.04137215617573206\n",
      "previous_iter_valid_loss : 0.09725415706634521\n",
      "\n",
      "    249200\t  0.097104\t  0.097254\t  0.091455\t\tCURRENT LEARNING RATE: 0.041330804698740786\n",
      "previous_iter_valid_loss : 0.12406431138515472\n",
      "\n",
      "    249300\t  0.123849\t  0.124064\t  0.091482\t\tCURRENT LEARNING RATE: 0.041289494552557635\n",
      "previous_iter_valid_loss : 0.08068393915891647\n",
      "\n",
      "    249400\t  0.080630\t  0.080684\t  0.090897\t\tCURRENT LEARNING RATE: 0.04124822569587249\n",
      "previous_iter_valid_loss : 0.0830264687538147\n",
      "\n",
      "    249500\t  0.082921\t  0.083026\t  0.090906\t\tCURRENT LEARNING RATE: 0.041206998087416485\n",
      "previous_iter_valid_loss : 0.09278827905654907\n",
      "\n",
      "    249600\t  0.092876\t  0.092788\t  0.091035\t\tCURRENT LEARNING RATE: 0.041165811685962006\n",
      "previous_iter_valid_loss : 0.07796984165906906\n",
      "\n",
      "    249700\t  0.077915\t  0.077970\t  0.090993\t\tCURRENT LEARNING RATE: 0.04112466645032262\n",
      "previous_iter_valid_loss : 0.0813470184803009\n",
      "\n",
      "    249800\t  0.081213\t  0.081347\t  0.090522\t\tCURRENT LEARNING RATE: 0.041083562339353126\n",
      "previous_iter_valid_loss : 0.13331127166748047\n",
      "\n",
      "    249900\t  0.133094\t  0.133311\t  0.090977\t\tCURRENT LEARNING RATE: 0.0410424993119494\n",
      "previous_iter_valid_loss : 0.07830938696861267\n",
      "\n",
      "    250000\t  0.078274\t  0.078309\t  0.090786\t\tCURRENT LEARNING RATE: 0.041001477327048404\n",
      "previous_iter_valid_loss : 0.08656519651412964\n",
      "\n",
      "    250100\t  0.086623\t  0.086565\t  0.090617\t\tCURRENT LEARNING RATE: 0.04096049634362815\n",
      "previous_iter_valid_loss : 0.09365131705999374\n",
      "\n",
      "    250200\t  0.093471\t  0.093651\t  0.090771\t\tCURRENT LEARNING RATE: 0.04091955632070764\n",
      "previous_iter_valid_loss : 0.08618366718292236\n",
      "\n",
      "    250300\t  0.086236\t  0.086184\t  0.090532\t\tCURRENT LEARNING RATE: 0.040878657217346875\n",
      "previous_iter_valid_loss : 0.08555712550878525\n",
      "\n",
      "    250400\t  0.085654\t  0.085557\t  0.090599\t\tCURRENT LEARNING RATE: 0.04083779899264673\n",
      "previous_iter_valid_loss : 0.0785057321190834\n",
      "\n",
      "    250500\t  0.078546\t  0.078506\t  0.090480\t\tCURRENT LEARNING RATE: 0.04079698160574899\n",
      "previous_iter_valid_loss : 0.0789748877286911\n",
      "\n",
      "    250600\t  0.079006\t  0.078975\t  0.089870\t\tCURRENT LEARNING RATE: 0.04075620501583623\n",
      "previous_iter_valid_loss : 0.0807768702507019\n",
      "\n",
      "    250700\t  0.080682\t  0.080777\t  0.089689\t\tCURRENT LEARNING RATE: 0.040715469182131904\n",
      "previous_iter_valid_loss : 0.07855615764856339\n",
      "\n",
      "    250800\t  0.078597\t  0.078556\t  0.089650\t\tCURRENT LEARNING RATE: 0.04067477406390015\n",
      "previous_iter_valid_loss : 0.07782205194234848\n",
      "\n",
      "    250900\t  0.077798\t  0.077822\t  0.089603\t\tCURRENT LEARNING RATE: 0.04063411962044585\n",
      "previous_iter_valid_loss : 0.08849453926086426\n",
      "\n",
      "    251000\t  0.088394\t  0.088495\t  0.089629\t\tCURRENT LEARNING RATE: 0.040593505811114546\n",
      "previous_iter_valid_loss : 0.08370323479175568\n",
      "\n",
      "    251100\t  0.083802\t  0.083703\t  0.089558\t\tCURRENT LEARNING RATE: 0.04055293259529245\n",
      "previous_iter_valid_loss : 0.0894223153591156\n",
      "\n",
      "    251200\t  0.089464\t  0.089422\t  0.089589\t\tCURRENT LEARNING RATE: 0.04051239993240632\n",
      "previous_iter_valid_loss : 0.07719605416059494\n",
      "\n",
      "    251300\t  0.077173\t  0.077196\t  0.088933\t\tCURRENT LEARNING RATE: 0.040471907781923507\n",
      "previous_iter_valid_loss : 0.08202462643384933\n",
      "\n",
      "    251400\t  0.082037\t  0.082025\t  0.088974\t\tCURRENT LEARNING RATE: 0.04043145610335183\n",
      "previous_iter_valid_loss : 0.09224463999271393\n",
      "\n",
      "    251500\t  0.092134\t  0.092245\t  0.089102\t\tCURRENT LEARNING RATE: 0.04039104485623964\n",
      "previous_iter_valid_loss : 0.0786251574754715\n",
      "\n",
      "    251600\t  0.078591\t  0.078625\t  0.089035\t\tCURRENT LEARNING RATE: 0.040350674000175675\n",
      "previous_iter_valid_loss : 0.08116511255502701\n",
      "\n",
      "    251700\t  0.081206\t  0.081165\t  0.089040\t\tCURRENT LEARNING RATE: 0.040310343494789076\n",
      "previous_iter_valid_loss : 0.09098649024963379\n",
      "\n",
      "    251800\t  0.090860\t  0.090986\t  0.088582\t\tCURRENT LEARNING RATE: 0.04027005329974931\n",
      "previous_iter_valid_loss : 0.08358573913574219\n",
      "\n",
      "    251900\t  0.083402\t  0.083586\t  0.088630\t\tCURRENT LEARNING RATE: 0.04022980337476622\n",
      "previous_iter_valid_loss : 0.07858991622924805\n",
      "\n",
      "    252000\t  0.078610\t  0.078590\t  0.088628\t\tCURRENT LEARNING RATE: 0.04018959367958985\n",
      "previous_iter_valid_loss : 0.09590576589107513\n",
      "\n",
      "    252100\t  0.095981\t  0.095906\t  0.088703\t\tCURRENT LEARNING RATE: 0.04014942417401051\n",
      "previous_iter_valid_loss : 0.09584925323724747\n",
      "\n",
      "    252200\t  0.095961\t  0.095849\t  0.088800\t\tCURRENT LEARNING RATE: 0.04010929481785868\n",
      "previous_iter_valid_loss : 0.08301516622304916\n",
      "\n",
      "    252300\t  0.083125\t  0.083015\t  0.088097\t\tCURRENT LEARNING RATE: 0.040069205571005025\n",
      "previous_iter_valid_loss : 0.0788104236125946\n",
      "\n",
      "    252400\t  0.078728\t  0.078810\t  0.087906\t\tCURRENT LEARNING RATE: 0.04002915639336027\n",
      "previous_iter_valid_loss : 0.080010324716568\n",
      "\n",
      "    252500\t  0.080062\t  0.080010\t  0.087926\t\tCURRENT LEARNING RATE: 0.039989147244875255\n",
      "previous_iter_valid_loss : 0.1007860004901886\n",
      "\n",
      "    252600\t  0.100570\t  0.100786\t  0.087994\t\tCURRENT LEARNING RATE: 0.0399491780855408\n",
      "previous_iter_valid_loss : 0.09611625969409943\n",
      "\n",
      "    252700\t  0.096209\t  0.096116\t  0.088062\t\tCURRENT LEARNING RATE: 0.03990924887538777\n",
      "previous_iter_valid_loss : 0.0806419849395752\n",
      "\n",
      "    252800\t  0.080655\t  0.080642\t  0.088032\t\tCURRENT LEARNING RATE: 0.03986935957448695\n",
      "previous_iter_valid_loss : 0.07850755006074905\n",
      "\n",
      "    252900\t  0.078483\t  0.078508\t  0.088038\t\tCURRENT LEARNING RATE: 0.03982951014294902\n",
      "previous_iter_valid_loss : 0.10202666372060776\n",
      "\n",
      "    253000\t  0.102133\t  0.102027\t  0.088280\t\tCURRENT LEARNING RATE: 0.03978970054092454\n",
      "previous_iter_valid_loss : 0.07703986018896103\n",
      "\n",
      "    253100\t  0.076987\t  0.077040\t  0.088252\t\tCURRENT LEARNING RATE: 0.03974993072860393\n",
      "previous_iter_valid_loss : 0.0779479369521141\n",
      "\n",
      "    253200\t  0.077905\t  0.077948\t  0.088243\t\tCURRENT LEARNING RATE: 0.03971020066621736\n",
      "previous_iter_valid_loss : 0.09225399792194366\n",
      "\n",
      "    253300\t  0.092051\t  0.092254\t  0.088303\t\tCURRENT LEARNING RATE: 0.03967051031403477\n",
      "previous_iter_valid_loss : 0.07954036444425583\n",
      "\n",
      "    253400\t  0.079541\t  0.079540\t  0.088134\t\tCURRENT LEARNING RATE: 0.039630859632365775\n",
      "previous_iter_valid_loss : 0.07676736265420914\n",
      "\n",
      "\n",
      "Current valid loss: 0.07676736265420914;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "    253500\t  0.076716\t  0.076767\t  0.088120\t\tCURRENT LEARNING RATE: 0.03959124858155974\n",
      "previous_iter_valid_loss : 0.10032340884208679\n",
      "\n",
      "    253600\t  0.100505\t  0.100323\t  0.088325\t\tCURRENT LEARNING RATE: 0.03955167712200559\n",
      "previous_iter_valid_loss : 0.07786480337381363\n",
      "\n",
      "    253700\t  0.077806\t  0.077865\t  0.088329\t\tCURRENT LEARNING RATE: 0.03951214521413184\n",
      "previous_iter_valid_loss : 0.08818163722753525\n",
      "\n",
      "    253800\t  0.088310\t  0.088182\t  0.088441\t\tCURRENT LEARNING RATE: 0.039472652818406596\n",
      "previous_iter_valid_loss : 0.08566026389598846\n",
      "\n",
      "    253900\t  0.085702\t  0.085660\t  0.088432\t\tCURRENT LEARNING RATE: 0.03943319989533747\n",
      "previous_iter_valid_loss : 0.08431966602802277\n",
      "\n",
      "    254000\t  0.084339\t  0.084320\t  0.088473\t\tCURRENT LEARNING RATE: 0.03939378640547153\n",
      "previous_iter_valid_loss : 0.07700781524181366\n",
      "\n",
      "    254100\t  0.076981\t  0.077008\t  0.088462\t\tCURRENT LEARNING RATE: 0.03935441230939527\n",
      "previous_iter_valid_loss : 0.0783199667930603\n",
      "\n",
      "    254200\t  0.078342\t  0.078320\t  0.088217\t\tCURRENT LEARNING RATE: 0.03931507756773459\n",
      "previous_iter_valid_loss : 0.08955331891775131\n",
      "\n",
      "    254300\t  0.089585\t  0.089553\t  0.088300\t\tCURRENT LEARNING RATE: 0.03927578214115477\n",
      "previous_iter_valid_loss : 0.097080759704113\n",
      "\n",
      "    254400\t  0.097166\t  0.097081\t  0.088460\t\tCURRENT LEARNING RATE: 0.039236525990360364\n",
      "previous_iter_valid_loss : 0.11957909166812897\n",
      "\n",
      "    254500\t  0.119319\t  0.119579\t  0.088822\t\tCURRENT LEARNING RATE: 0.03919730907609521\n",
      "previous_iter_valid_loss : 0.09038827568292618\n",
      "\n",
      "    254600\t  0.090257\t  0.090388\t  0.088911\t\tCURRENT LEARNING RATE: 0.039158131359142395\n",
      "previous_iter_valid_loss : 0.0791318342089653\n",
      "\n",
      "    254700\t  0.079115\t  0.079132\t  0.088459\t\tCURRENT LEARNING RATE: 0.03911899280032421\n",
      "previous_iter_valid_loss : 0.07830700278282166\n",
      "\n",
      "    254800\t  0.078255\t  0.078307\t  0.088418\t\tCURRENT LEARNING RATE: 0.03907989336050209\n",
      "previous_iter_valid_loss : 0.08566726744174957\n",
      "\n",
      "    254900\t  0.085517\t  0.085667\t  0.088441\t\tCURRENT LEARNING RATE: 0.039040833000576584\n",
      "previous_iter_valid_loss : 0.08179312944412231\n",
      "\n",
      "    255000\t  0.081793\t  0.081793\t  0.088404\t\tCURRENT LEARNING RATE: 0.039001811681487315\n",
      "previous_iter_valid_loss : 0.08479592204093933\n",
      "\n",
      "    255100\t  0.084867\t  0.084796\t  0.088455\t\tCURRENT LEARNING RATE: 0.038962829364213\n",
      "previous_iter_valid_loss : 0.0791698470711708\n",
      "\n",
      "    255200\t  0.079118\t  0.079170\t  0.088460\t\tCURRENT LEARNING RATE: 0.038923886009771286\n",
      "previous_iter_valid_loss : 0.07777806371450424\n",
      "\n",
      "    255300\t  0.077725\t  0.077778\t  0.088259\t\tCURRENT LEARNING RATE: 0.03888498157921883\n",
      "previous_iter_valid_loss : 0.07935675233602524\n",
      "\n",
      "    255400\t  0.079356\t  0.079357\t  0.087112\t\tCURRENT LEARNING RATE: 0.03884611603365118\n",
      "previous_iter_valid_loss : 0.10104461759328842\n",
      "\n",
      "    255500\t  0.100855\t  0.101045\t  0.086947\t\tCURRENT LEARNING RATE: 0.03880728933420281\n",
      "previous_iter_valid_loss : 0.07782751321792603\n",
      "\n",
      "    255600\t  0.077772\t  0.077828\t  0.086890\t\tCURRENT LEARNING RATE: 0.03876850144204702\n",
      "previous_iter_valid_loss : 0.07889822870492935\n",
      "\n",
      "    255700\t  0.078841\t  0.078898\t  0.086743\t\tCURRENT LEARNING RATE: 0.03872975231839589\n",
      "previous_iter_valid_loss : 0.07691245526075363\n",
      "\n",
      "    255800\t  0.076912\t  0.076912\t  0.086637\t\tCURRENT LEARNING RATE: 0.0386910419245003\n",
      "previous_iter_valid_loss : 0.07888512313365936\n",
      "\n",
      "    255900\t  0.078793\t  0.078885\t  0.086390\t\tCURRENT LEARNING RATE: 0.03865237022164987\n",
      "previous_iter_valid_loss : 0.11147420108318329\n",
      "\n",
      "    256000\t  0.111334\t  0.111474\t  0.086406\t\tCURRENT LEARNING RATE: 0.038613737171172884\n",
      "previous_iter_valid_loss : 0.07817836850881577\n",
      "\n",
      "    256100\t  0.078227\t  0.078178\t  0.086413\t\tCURRENT LEARNING RATE: 0.03857514273443629\n",
      "previous_iter_valid_loss : 0.07727660238742828\n",
      "\n",
      "    256200\t  0.077253\t  0.077277\t  0.086368\t\tCURRENT LEARNING RATE: 0.03853658687284562\n",
      "previous_iter_valid_loss : 0.08037211000919342\n",
      "\n",
      "    256300\t  0.080235\t  0.080372\t  0.086285\t\tCURRENT LEARNING RATE: 0.03849806954784506\n",
      "previous_iter_valid_loss : 0.08201567083597183\n",
      "\n",
      "    256400\t  0.082088\t  0.082016\t  0.086221\t\tCURRENT LEARNING RATE: 0.03845959072091725\n",
      "previous_iter_valid_loss : 0.07966355234384537\n",
      "\n",
      "    256500\t  0.079673\t  0.079664\t  0.086229\t\tCURRENT LEARNING RATE: 0.038421150353583365\n",
      "previous_iter_valid_loss : 0.07849876582622528\n",
      "\n",
      "    256600\t  0.078484\t  0.078499\t  0.086108\t\tCURRENT LEARNING RATE: 0.03838274840740302\n",
      "previous_iter_valid_loss : 0.07750793546438217\n",
      "\n",
      "    256700\t  0.077471\t  0.077508\t  0.086084\t\tCURRENT LEARNING RATE: 0.0383443848439743\n",
      "previous_iter_valid_loss : 0.08910486102104187\n",
      "\n",
      "    256800\t  0.089222\t  0.089105\t  0.086199\t\tCURRENT LEARNING RATE: 0.03830605962493362\n",
      "previous_iter_valid_loss : 0.09328505396842957\n",
      "\n",
      "    256900\t  0.093377\t  0.093285\t  0.086358\t\tCURRENT LEARNING RATE: 0.03826777271195576\n",
      "previous_iter_valid_loss : 0.12296109646558762\n",
      "\n",
      "    257000\t  0.123137\t  0.122961\t  0.086795\t\tCURRENT LEARNING RATE: 0.03822952406675378\n",
      "previous_iter_valid_loss : 0.08019082993268967\n",
      "\n",
      "    257100\t  0.080084\t  0.080191\t  0.086616\t\tCURRENT LEARNING RATE: 0.03819131365107906\n",
      "previous_iter_valid_loss : 0.08291014283895493\n",
      "\n",
      "    257200\t  0.082991\t  0.082910\t  0.086641\t\tCURRENT LEARNING RATE: 0.03815314142672119\n",
      "previous_iter_valid_loss : 0.09264849126338959\n",
      "\n",
      "    257300\t  0.092486\t  0.092648\t  0.086492\t\tCURRENT LEARNING RATE: 0.038115007355507914\n",
      "previous_iter_valid_loss : 0.07813877612352371\n",
      "\n",
      "    257400\t  0.078144\t  0.078139\t  0.086416\t\tCURRENT LEARNING RATE: 0.03807691139930516\n",
      "previous_iter_valid_loss : 0.08016610145568848\n",
      "\n",
      "    257500\t  0.080148\t  0.080166\t  0.086448\t\tCURRENT LEARNING RATE: 0.03803885352001699\n",
      "previous_iter_valid_loss : 0.1161983534693718\n",
      "\n",
      "    257600\t  0.116388\t  0.116198\t  0.086754\t\tCURRENT LEARNING RATE: 0.03800083367958552\n",
      "previous_iter_valid_loss : 0.10388247668743134\n",
      "\n",
      "    257700\t  0.104007\t  0.103882\t  0.086997\t\tCURRENT LEARNING RATE: 0.03796285183999089\n",
      "previous_iter_valid_loss : 0.1012929379940033\n",
      "\n",
      "    257800\t  0.101092\t  0.101293\t  0.087237\t\tCURRENT LEARNING RATE: 0.03792490796325124\n",
      "previous_iter_valid_loss : 0.07810467481613159\n",
      "\n",
      "    257900\t  0.078023\t  0.078105\t  0.086996\t\tCURRENT LEARNING RATE: 0.03788700201142274\n",
      "previous_iter_valid_loss : 0.10903517156839371\n",
      "\n",
      "    258000\t  0.109247\t  0.109035\t  0.087238\t\tCURRENT LEARNING RATE: 0.0378491339465994\n",
      "previous_iter_valid_loss : 0.08216416835784912\n",
      "\n",
      "    258100\t  0.082153\t  0.082164\t  0.087265\t\tCURRENT LEARNING RATE: 0.03781130373091317\n",
      "previous_iter_valid_loss : 0.07837281376123428\n",
      "\n",
      "    258200\t  0.078337\t  0.078373\t  0.087275\t\tCURRENT LEARNING RATE: 0.0377735113265338\n",
      "previous_iter_valid_loss : 0.141387477517128\n",
      "\n",
      "    258300\t  0.141196\t  0.141387\t  0.087716\t\tCURRENT LEARNING RATE: 0.03773575669566892\n",
      "previous_iter_valid_loss : 0.08425702899694443\n",
      "\n",
      "    258400\t  0.084324\t  0.084257\t  0.087756\t\tCURRENT LEARNING RATE: 0.03769803980056388\n",
      "previous_iter_valid_loss : 0.08316470682621002\n",
      "\n",
      "    258500\t  0.083037\t  0.083165\t  0.087231\t\tCURRENT LEARNING RATE: 0.03766036060350179\n",
      "previous_iter_valid_loss : 0.07911514490842819\n",
      "\n",
      "    258600\t  0.079030\t  0.079115\t  0.087226\t\tCURRENT LEARNING RATE: 0.037622719066803416\n",
      "previous_iter_valid_loss : 0.08142794668674469\n",
      "\n",
      "    258700\t  0.081511\t  0.081428\t  0.087250\t\tCURRENT LEARNING RATE: 0.03758511515282727\n",
      "previous_iter_valid_loss : 0.0942791998386383\n",
      "\n",
      "    258800\t  0.094084\t  0.094279\t  0.087269\t\tCURRENT LEARNING RATE: 0.0375475488239694\n",
      "previous_iter_valid_loss : 0.1490360051393509\n",
      "\n",
      "    258900\t  0.149402\t  0.149036\t  0.087866\t\tCURRENT LEARNING RATE: 0.03751002004266349\n",
      "previous_iter_valid_loss : 0.08924607932567596\n",
      "\n",
      "    259000\t  0.089127\t  0.089246\t  0.087985\t\tCURRENT LEARNING RATE: 0.03747252877138072\n",
      "previous_iter_valid_loss : 0.07690156996250153\n",
      "\n",
      "    259100\t  0.076898\t  0.076902\t  0.087967\t\tCURRENT LEARNING RATE: 0.03743507497262987\n",
      "previous_iter_valid_loss : 0.0777667760848999\n",
      "\n",
      "    259200\t  0.077729\t  0.077767\t  0.087772\t\tCURRENT LEARNING RATE: 0.037397658608957114\n",
      "previous_iter_valid_loss : 0.07727576792240143\n",
      "\n",
      "    259300\t  0.077211\t  0.077276\t  0.087304\t\tCURRENT LEARNING RATE: 0.03736027964294608\n",
      "previous_iter_valid_loss : 0.07822934538125992\n",
      "\n",
      "    259400\t  0.078210\t  0.078229\t  0.087280\t\tCURRENT LEARNING RATE: 0.037322938037217784\n",
      "previous_iter_valid_loss : 0.07708367705345154\n",
      "\n",
      "    259500\t  0.077013\t  0.077084\t  0.087220\t\tCURRENT LEARNING RATE: 0.037285633754430655\n",
      "previous_iter_valid_loss : 0.07823972404003143\n",
      "\n",
      "    259600\t  0.078118\t  0.078240\t  0.087075\t\tCURRENT LEARNING RATE: 0.03724836675728039\n",
      "previous_iter_valid_loss : 0.08323436230421066\n",
      "\n",
      "    259700\t  0.083268\t  0.083234\t  0.087127\t\tCURRENT LEARNING RATE: 0.03721113700849998\n",
      "previous_iter_valid_loss : 0.07784163951873779\n",
      "\n",
      "    259800\t  0.077807\t  0.077842\t  0.087092\t\tCURRENT LEARNING RATE: 0.037173944470859664\n",
      "previous_iter_valid_loss : 0.0796007439494133\n",
      "\n",
      "    259900\t  0.079459\t  0.079601\t  0.086555\t\tCURRENT LEARNING RATE: 0.03713678910716694\n",
      "previous_iter_valid_loss : 0.0856042206287384\n",
      "\n",
      "    260000\t  0.085411\t  0.085604\t  0.086628\t\tCURRENT LEARNING RATE: 0.03709967088026641\n",
      "previous_iter_valid_loss : 0.07721475511789322\n",
      "\n",
      "    260100\t  0.077195\t  0.077215\t  0.086535\t\tCURRENT LEARNING RATE: 0.03706258975303985\n",
      "previous_iter_valid_loss : 0.0896906852722168\n",
      "\n",
      "    260200\t  0.089501\t  0.089691\t  0.086495\t\tCURRENT LEARNING RATE: 0.037025545688406124\n",
      "previous_iter_valid_loss : 0.09368126094341278\n",
      "\n",
      "    260300\t  0.093514\t  0.093681\t  0.086570\t\tCURRENT LEARNING RATE: 0.03698853864932118\n",
      "previous_iter_valid_loss : 0.0889509841799736\n",
      "\n",
      "    260400\t  0.089031\t  0.088951\t  0.086604\t\tCURRENT LEARNING RATE: 0.036951568598777976\n",
      "previous_iter_valid_loss : 0.07692867517471313\n",
      "\n",
      "    260500\t  0.076881\t  0.076929\t  0.086588\t\tCURRENT LEARNING RATE: 0.03691463549980645\n",
      "previous_iter_valid_loss : 0.07757895439863205\n",
      "\n",
      "    260600\t  0.077513\t  0.077579\t  0.086574\t\tCURRENT LEARNING RATE: 0.03687773931547347\n",
      "previous_iter_valid_loss : 0.08150158077478409\n",
      "\n",
      "    260700\t  0.081341\t  0.081502\t  0.086581\t\tCURRENT LEARNING RATE: 0.036840880008882915\n",
      "previous_iter_valid_loss : 0.07680130004882812\n",
      "\n",
      "    260800\t  0.076740\t  0.076801\t  0.086564\t\tCURRENT LEARNING RATE: 0.03680405754317542\n",
      "previous_iter_valid_loss : 0.0959494560956955\n",
      "\n",
      "    260900\t  0.096006\t  0.095949\t  0.086745\t\tCURRENT LEARNING RATE: 0.03676727188152855\n",
      "previous_iter_valid_loss : 0.09748226404190063\n",
      "\n",
      "    261000\t  0.097610\t  0.097482\t  0.086835\t\tCURRENT LEARNING RATE: 0.0367305229871566\n",
      "previous_iter_valid_loss : 0.0813281238079071\n",
      "\n",
      "    261100\t  0.081230\t  0.081328\t  0.086811\t\tCURRENT LEARNING RATE: 0.03669381082331072\n",
      "previous_iter_valid_loss : 0.0799240991473198\n",
      "\n",
      "    261200\t  0.079946\t  0.079924\t  0.086716\t\tCURRENT LEARNING RATE: 0.03665713535327872\n",
      "previous_iter_valid_loss : 0.08421825617551804\n",
      "\n",
      "    261300\t  0.084242\t  0.084218\t  0.086787\t\tCURRENT LEARNING RATE: 0.03662049654038512\n",
      "previous_iter_valid_loss : 0.09086662530899048\n",
      "\n",
      "    261400\t  0.090970\t  0.090867\t  0.086875\t\tCURRENT LEARNING RATE: 0.03658389434799111\n",
      "previous_iter_valid_loss : 0.08440535515546799\n",
      "\n",
      "    261500\t  0.084310\t  0.084405\t  0.086797\t\tCURRENT LEARNING RATE: 0.036547328739494504\n",
      "previous_iter_valid_loss : 0.07920163869857788\n",
      "\n",
      "    261600\t  0.079168\t  0.079202\t  0.086802\t\tCURRENT LEARNING RATE: 0.03651079967832968\n",
      "previous_iter_valid_loss : 0.07700230926275253\n",
      "\n",
      "    261700\t  0.076934\t  0.077002\t  0.086761\t\tCURRENT LEARNING RATE: 0.036474307127967585\n",
      "previous_iter_valid_loss : 0.08159738779067993\n",
      "\n",
      "    261800\t  0.081466\t  0.081597\t  0.086667\t\tCURRENT LEARNING RATE: 0.03643785105191564\n",
      "previous_iter_valid_loss : 0.10650476068258286\n",
      "\n",
      "    261900\t  0.106261\t  0.106505\t  0.086896\t\tCURRENT LEARNING RATE: 0.036401431413717794\n",
      "previous_iter_valid_loss : 0.07752520591020584\n",
      "\n",
      "    262000\t  0.077478\t  0.077525\t  0.086885\t\tCURRENT LEARNING RATE: 0.0363650481769544\n",
      "previous_iter_valid_loss : 0.07789263874292374\n",
      "\n",
      "    262100\t  0.077808\t  0.077893\t  0.086705\t\tCURRENT LEARNING RATE: 0.03632870130524221\n",
      "previous_iter_valid_loss : 0.08506768941879272\n",
      "\n",
      "    262200\t  0.085108\t  0.085068\t  0.086597\t\tCURRENT LEARNING RATE: 0.03629239076223434\n",
      "previous_iter_valid_loss : 0.08308940380811691\n",
      "\n",
      "    262300\t  0.083066\t  0.083089\t  0.086598\t\tCURRENT LEARNING RATE: 0.036256116511620265\n",
      "previous_iter_valid_loss : 0.07960975915193558\n",
      "\n",
      "    262400\t  0.079504\t  0.079610\t  0.086606\t\tCURRENT LEARNING RATE: 0.03621987851712573\n",
      "previous_iter_valid_loss : 0.1350916177034378\n",
      "\n",
      "    262500\t  0.135333\t  0.135092\t  0.087157\t\tCURRENT LEARNING RATE: 0.03618367674251273\n",
      "previous_iter_valid_loss : 0.07868287712335587\n",
      "\n",
      "    262600\t  0.078661\t  0.078683\t  0.086936\t\tCURRENT LEARNING RATE: 0.036147511151579485\n",
      "previous_iter_valid_loss : 0.09081059694290161\n",
      "\n",
      "    262700\t  0.090843\t  0.090811\t  0.086883\t\tCURRENT LEARNING RATE: 0.03611138170816039\n",
      "previous_iter_valid_loss : 0.10426471382379532\n",
      "\n",
      "    262800\t  0.104370\t  0.104265\t  0.087119\t\tCURRENT LEARNING RATE: 0.03607528837612603\n",
      "previous_iter_valid_loss : 0.07878805696964264\n",
      "\n",
      "    262900\t  0.078663\t  0.078788\t  0.087122\t\tCURRENT LEARNING RATE: 0.03603923111938305\n",
      "previous_iter_valid_loss : 0.07676003873348236\n",
      "\n",
      "\n",
      "Current valid loss: 0.07676003873348236;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "    263000\t  0.076702\t  0.076760\t  0.086869\t\tCURRENT LEARNING RATE: 0.036003209901874195\n",
      "previous_iter_valid_loss : 0.09818529337644577\n",
      "\n",
      "    263100\t  0.098032\t  0.098185\t  0.087081\t\tCURRENT LEARNING RATE: 0.03596722468757822\n",
      "previous_iter_valid_loss : 0.07956172525882721\n",
      "\n",
      "    263200\t  0.079528\t  0.079562\t  0.087097\t\tCURRENT LEARNING RATE: 0.035931275440509954\n",
      "previous_iter_valid_loss : 0.083356112241745\n",
      "\n",
      "    263300\t  0.083348\t  0.083356\t  0.087008\t\tCURRENT LEARNING RATE: 0.03589536212472012\n",
      "previous_iter_valid_loss : 0.07853639125823975\n",
      "\n",
      "    263400\t  0.078520\t  0.078536\t  0.086998\t\tCURRENT LEARNING RATE: 0.035859484704295404\n",
      "previous_iter_valid_loss : 0.0866670310497284\n",
      "\n",
      "    263500\t  0.086768\t  0.086667\t  0.087097\t\tCURRENT LEARNING RATE: 0.03582364314335836\n",
      "previous_iter_valid_loss : 0.07987052202224731\n",
      "\n",
      "    263600\t  0.079766\t  0.079871\t  0.086892\t\tCURRENT LEARNING RATE: 0.03578783740606746\n",
      "previous_iter_valid_loss : 0.07679508626461029\n",
      "\n",
      "    263700\t  0.076752\t  0.076795\t  0.086882\t\tCURRENT LEARNING RATE: 0.03575206745661695\n",
      "previous_iter_valid_loss : 0.0888778492808342\n",
      "\n",
      "    263800\t  0.088769\t  0.088878\t  0.086889\t\tCURRENT LEARNING RATE: 0.03571633325923688\n",
      "previous_iter_valid_loss : 0.07734926789999008\n",
      "\n",
      "    263900\t  0.077283\t  0.077349\t  0.086805\t\tCURRENT LEARNING RATE: 0.03568063477819303\n",
      "previous_iter_valid_loss : 0.0788983404636383\n",
      "\n",
      "    264000\t  0.078814\t  0.078898\t  0.086751\t\tCURRENT LEARNING RATE: 0.03564497197778694\n",
      "previous_iter_valid_loss : 0.08371836692094803\n",
      "\n",
      "    264100\t  0.083768\t  0.083718\t  0.086818\t\tCURRENT LEARNING RATE: 0.0356093448223558\n",
      "previous_iter_valid_loss : 0.12679563462734222\n",
      "\n",
      "    264200\t  0.126560\t  0.126796\t  0.087303\t\tCURRENT LEARNING RATE: 0.035573753276272456\n",
      "previous_iter_valid_loss : 0.07846584916114807\n",
      "\n",
      "    264300\t  0.078344\t  0.078466\t  0.087192\t\tCURRENT LEARNING RATE: 0.03553819730394533\n",
      "previous_iter_valid_loss : 0.07774224132299423\n",
      "\n",
      "    264400\t  0.077794\t  0.077742\t  0.086999\t\tCURRENT LEARNING RATE: 0.03550267686981849\n",
      "previous_iter_valid_loss : 0.07776200771331787\n",
      "\n",
      "    264500\t  0.077684\t  0.077762\t  0.086581\t\tCURRENT LEARNING RATE: 0.03546719193837147\n",
      "previous_iter_valid_loss : 0.08716543763875961\n",
      "\n",
      "    264600\t  0.087189\t  0.087165\t  0.086548\t\tCURRENT LEARNING RATE: 0.03543174247411936\n",
      "previous_iter_valid_loss : 0.10457497835159302\n",
      "\n",
      "    264700\t  0.104378\t  0.104575\t  0.086803\t\tCURRENT LEARNING RATE: 0.03539632844161265\n",
      "previous_iter_valid_loss : 0.08897339552640915\n",
      "\n",
      "    264800\t  0.089003\t  0.088973\t  0.086909\t\tCURRENT LEARNING RATE: 0.035360949805437344\n",
      "previous_iter_valid_loss : 0.07661378383636475\n",
      "\n",
      "\n",
      "Current valid loss: 0.07661378383636475;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "    264900\t  0.076530\t  0.076614\t  0.086819\t\tCURRENT LEARNING RATE: 0.0353256065302148\n",
      "previous_iter_valid_loss : 0.08578663319349289\n",
      "\n",
      "    265000\t  0.085624\t  0.085787\t  0.086859\t\tCURRENT LEARNING RATE: 0.035290298580601724\n",
      "previous_iter_valid_loss : 0.08726897090673447\n",
      "\n",
      "    265100\t  0.087339\t  0.087269\t  0.086884\t\tCURRENT LEARNING RATE: 0.03525502592129015\n",
      "previous_iter_valid_loss : 0.07734613120555878\n",
      "\n",
      "    265200\t  0.077304\t  0.077346\t  0.086865\t\tCURRENT LEARNING RATE: 0.03521978851700746\n",
      "previous_iter_valid_loss : 0.07675281912088394\n",
      "\n",
      "    265300\t  0.076710\t  0.076753\t  0.086855\t\tCURRENT LEARNING RATE: 0.03518458633251621\n",
      "previous_iter_valid_loss : 0.07841474562883377\n",
      "\n",
      "    265400\t  0.078281\t  0.078415\t  0.086846\t\tCURRENT LEARNING RATE: 0.035149419332614236\n",
      "previous_iter_valid_loss : 0.07807788997888565\n",
      "\n",
      "    265500\t  0.078083\t  0.078078\t  0.086616\t\tCURRENT LEARNING RATE: 0.03511428748213451\n",
      "previous_iter_valid_loss : 0.0771278515458107\n",
      "\n",
      "    265600\t  0.077116\t  0.077128\t  0.086609\t\tCURRENT LEARNING RATE: 0.0350791907459452\n",
      "previous_iter_valid_loss : 0.07972121983766556\n",
      "\n",
      "    265700\t  0.079566\t  0.079721\t  0.086617\t\tCURRENT LEARNING RATE: 0.035044129088949556\n",
      "previous_iter_valid_loss : 0.16207148134708405\n",
      "\n",
      "    265800\t  0.162414\t  0.162071\t  0.087469\t\tCURRENT LEARNING RATE: 0.03500910247608593\n",
      "previous_iter_valid_loss : 0.07819658517837524\n",
      "\n",
      "    265900\t  0.078186\t  0.078197\t  0.087462\t\tCURRENT LEARNING RATE: 0.03497411087232768\n",
      "previous_iter_valid_loss : 0.08064502477645874\n",
      "\n",
      "    266000\t  0.080517\t  0.080645\t  0.087154\t\tCURRENT LEARNING RATE: 0.03493915424268323\n",
      "previous_iter_valid_loss : 0.08773059397935867\n",
      "\n",
      "    266100\t  0.087815\t  0.087731\t  0.087249\t\tCURRENT LEARNING RATE: 0.034904232552195935\n",
      "previous_iter_valid_loss : 0.0809980258345604\n",
      "\n",
      "    266200\t  0.080821\t  0.080998\t  0.087286\t\tCURRENT LEARNING RATE: 0.034869345765944096\n",
      "previous_iter_valid_loss : 0.08362256735563278\n",
      "\n",
      "    266300\t  0.083662\t  0.083623\t  0.087319\t\tCURRENT LEARNING RATE: 0.03483449384904092\n",
      "previous_iter_valid_loss : 0.08692557364702225\n",
      "\n",
      "    266400\t  0.086772\t  0.086926\t  0.087368\t\tCURRENT LEARNING RATE: 0.03479967676663451\n",
      "previous_iter_valid_loss : 0.08007705211639404\n",
      "\n",
      "    266500\t  0.079927\t  0.080077\t  0.087372\t\tCURRENT LEARNING RATE: 0.034764894483907766\n",
      "previous_iter_valid_loss : 0.0769280269742012\n",
      "\n",
      "    266600\t  0.076885\t  0.076928\t  0.087356\t\tCURRENT LEARNING RATE: 0.0347301469660784\n",
      "previous_iter_valid_loss : 0.08055204898118973\n",
      "\n",
      "    266700\t  0.080449\t  0.080552\t  0.087387\t\tCURRENT LEARNING RATE: 0.03469543417839888\n",
      "previous_iter_valid_loss : 0.09395837038755417\n",
      "\n",
      "    266800\t  0.093825\t  0.093958\t  0.087435\t\tCURRENT LEARNING RATE: 0.03466075608615645\n",
      "previous_iter_valid_loss : 0.07712677121162415\n",
      "\n",
      "    266900\t  0.077108\t  0.077127\t  0.087274\t\tCURRENT LEARNING RATE: 0.034626112654673\n",
      "previous_iter_valid_loss : 0.08487532287836075\n",
      "\n",
      "    267000\t  0.084926\t  0.084875\t  0.086893\t\tCURRENT LEARNING RATE: 0.03459150384930507\n",
      "previous_iter_valid_loss : 0.08726434409618378\n",
      "\n",
      "    267100\t  0.087346\t  0.087264\t  0.086964\t\tCURRENT LEARNING RATE: 0.03455692963544387\n",
      "previous_iter_valid_loss : 0.09680723398923874\n",
      "\n",
      "    267200\t  0.096689\t  0.096807\t  0.087103\t\tCURRENT LEARNING RATE: 0.03452238997851521\n",
      "previous_iter_valid_loss : 0.07867743819952011\n",
      "\n",
      "    267300\t  0.078612\t  0.078677\t  0.086963\t\tCURRENT LEARNING RATE: 0.03448788484397939\n",
      "previous_iter_valid_loss : 0.07971539348363876\n",
      "\n",
      "    267400\t  0.079627\t  0.079715\t  0.086979\t\tCURRENT LEARNING RATE: 0.03445341419733129\n",
      "previous_iter_valid_loss : 0.0769406259059906\n",
      "\n",
      "    267500\t  0.076924\t  0.076941\t  0.086946\t\tCURRENT LEARNING RATE: 0.034418978004100244\n",
      "previous_iter_valid_loss : 0.07721693813800812\n",
      "\n",
      "    267600\t  0.077109\t  0.077217\t  0.086557\t\tCURRENT LEARNING RATE: 0.03438457622985009\n",
      "previous_iter_valid_loss : 0.08486106246709824\n",
      "\n",
      "    267700\t  0.084882\t  0.084861\t  0.086366\t\tCURRENT LEARNING RATE: 0.034350208840179024\n",
      "previous_iter_valid_loss : 0.08154267072677612\n",
      "\n",
      "    267800\t  0.081522\t  0.081543\t  0.086169\t\tCURRENT LEARNING RATE: 0.03431587580071967\n",
      "previous_iter_valid_loss : 0.08061765879392624\n",
      "\n",
      "    267900\t  0.080482\t  0.080618\t  0.086194\t\tCURRENT LEARNING RATE: 0.034281577077138956\n",
      "previous_iter_valid_loss : 0.09448891133069992\n",
      "\n",
      "    268000\t  0.094330\t  0.094489\t  0.086049\t\tCURRENT LEARNING RATE: 0.03424731263513819\n",
      "previous_iter_valid_loss : 0.07912353426218033\n",
      "\n",
      "    268100\t  0.079139\t  0.079124\t  0.086018\t\tCURRENT LEARNING RATE: 0.034213082440452916\n",
      "previous_iter_valid_loss : 0.0861596167087555\n",
      "\n",
      "    268200\t  0.086038\t  0.086160\t  0.086096\t\tCURRENT LEARNING RATE: 0.03417888645885293\n",
      "previous_iter_valid_loss : 0.09116235375404358\n",
      "\n",
      "    268300\t  0.091256\t  0.091162\t  0.085594\t\tCURRENT LEARNING RATE: 0.03414472465614224\n",
      "previous_iter_valid_loss : 0.09360124915838242\n",
      "\n",
      "    268400\t  0.093461\t  0.093601\t  0.085687\t\tCURRENT LEARNING RATE: 0.03411059699815906\n",
      "previous_iter_valid_loss : 0.07807226479053497\n",
      "\n",
      "    268500\t  0.077972\t  0.078072\t  0.085636\t\tCURRENT LEARNING RATE: 0.03407650345077573\n",
      "previous_iter_valid_loss : 0.0802498310804367\n",
      "\n",
      "    268600\t  0.080142\t  0.080250\t  0.085648\t\tCURRENT LEARNING RATE: 0.03404244397989868\n",
      "previous_iter_valid_loss : 0.07815060764551163\n",
      "\n",
      "    268700\t  0.078158\t  0.078151\t  0.085615\t\tCURRENT LEARNING RATE: 0.03400841855146844\n",
      "previous_iter_valid_loss : 0.08458559960126877\n",
      "\n",
      "    268800\t  0.084361\t  0.084586\t  0.085518\t\tCURRENT LEARNING RATE: 0.0339744271314596\n",
      "previous_iter_valid_loss : 0.0763724222779274\n",
      "\n",
      "\n",
      "Current valid loss: 0.0763724222779274;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "    268900\t  0.076262\t  0.076372\t  0.084791\t\tCURRENT LEARNING RATE: 0.03394046968588072\n",
      "previous_iter_valid_loss : 0.09080210328102112\n",
      "\n",
      "    269000\t  0.090864\t  0.090802\t  0.084807\t\tCURRENT LEARNING RATE: 0.033906546180774357\n",
      "previous_iter_valid_loss : 0.08614303171634674\n",
      "\n",
      "    269100\t  0.086226\t  0.086143\t  0.084899\t\tCURRENT LEARNING RATE: 0.033872656582216984\n",
      "previous_iter_valid_loss : 0.07769788801670074\n",
      "\n",
      "    269200\t  0.077674\t  0.077698\t  0.084899\t\tCURRENT LEARNING RATE: 0.033838800856319025\n",
      "previous_iter_valid_loss : 0.08078160881996155\n",
      "\n",
      "    269300\t  0.080806\t  0.080782\t  0.084934\t\tCURRENT LEARNING RATE: 0.03380497896922475\n",
      "previous_iter_valid_loss : 0.10574205964803696\n",
      "\n",
      "    269400\t  0.105555\t  0.105742\t  0.085209\t\tCURRENT LEARNING RATE: 0.03377119088711226\n",
      "previous_iter_valid_loss : 0.12235220521688461\n",
      "\n",
      "    269500\t  0.122177\t  0.122352\t  0.085662\t\tCURRENT LEARNING RATE: 0.03373743657619345\n",
      "previous_iter_valid_loss : 0.08284518122673035\n",
      "\n",
      "    269600\t  0.082664\t  0.082845\t  0.085708\t\tCURRENT LEARNING RATE: 0.03370371600271405\n",
      "previous_iter_valid_loss : 0.0941658467054367\n",
      "\n",
      "    269700\t  0.093993\t  0.094166\t  0.085817\t\tCURRENT LEARNING RATE: 0.03367002913295346\n",
      "previous_iter_valid_loss : 0.0865892842411995\n",
      "\n",
      "    269800\t  0.086426\t  0.086589\t  0.085904\t\tCURRENT LEARNING RATE: 0.033636375933224806\n",
      "previous_iter_valid_loss : 0.10795927792787552\n",
      "\n",
      "    269900\t  0.107734\t  0.107959\t  0.086188\t\tCURRENT LEARNING RATE: 0.03360275636987488\n",
      "previous_iter_valid_loss : 0.07913370430469513\n",
      "\n",
      "    270000\t  0.079101\t  0.079134\t  0.086123\t\tCURRENT LEARNING RATE: 0.03356917040928413\n",
      "previous_iter_valid_loss : 0.10560985654592514\n",
      "\n",
      "    270100\t  0.105395\t  0.105610\t  0.086407\t\tCURRENT LEARNING RATE: 0.03353561801786659\n",
      "previous_iter_valid_loss : 0.08502763509750366\n",
      "\n",
      "    270200\t  0.084840\t  0.085028\t  0.086361\t\tCURRENT LEARNING RATE: 0.033502099162069865\n",
      "previous_iter_valid_loss : 0.09538712352514267\n",
      "\n",
      "    270300\t  0.095242\t  0.095387\t  0.086378\t\tCURRENT LEARNING RATE: 0.033468613808375076\n",
      "previous_iter_valid_loss : 0.08421707153320312\n",
      "\n",
      "    270400\t  0.084044\t  0.084217\t  0.086330\t\tCURRENT LEARNING RATE: 0.0334351619232969\n",
      "previous_iter_valid_loss : 0.08426547050476074\n",
      "\n",
      "    270500\t  0.084108\t  0.084265\t  0.086404\t\tCURRENT LEARNING RATE: 0.033401743473383434\n",
      "previous_iter_valid_loss : 0.07717648148536682\n",
      "\n",
      "    270600\t  0.077125\t  0.077176\t  0.086400\t\tCURRENT LEARNING RATE: 0.03336835842521623\n",
      "previous_iter_valid_loss : 0.11755774915218353\n",
      "\n",
      "    270700\t  0.117718\t  0.117558\t  0.086760\t\tCURRENT LEARNING RATE: 0.03333500674541021\n",
      "previous_iter_valid_loss : 0.07925863564014435\n",
      "\n",
      "    270800\t  0.079246\t  0.079259\t  0.086785\t\tCURRENT LEARNING RATE: 0.03330168840061373\n",
      "previous_iter_valid_loss : 0.07681150734424591\n",
      "\n",
      "    270900\t  0.076702\t  0.076812\t  0.086593\t\tCURRENT LEARNING RATE: 0.03326840335750843\n",
      "previous_iter_valid_loss : 0.076911062002182\n",
      "\n",
      "    271000\t  0.076796\t  0.076911\t  0.086388\t\tCURRENT LEARNING RATE: 0.03323515158280925\n",
      "previous_iter_valid_loss : 0.07828369736671448\n",
      "\n",
      "    271100\t  0.078216\t  0.078284\t  0.086357\t\tCURRENT LEARNING RATE: 0.033201933043264416\n",
      "previous_iter_valid_loss : 0.08722995221614838\n",
      "\n",
      "    271200\t  0.087260\t  0.087230\t  0.086430\t\tCURRENT LEARNING RATE: 0.03316874770565541\n",
      "previous_iter_valid_loss : 0.07703503221273422\n",
      "\n",
      "    271300\t  0.076933\t  0.077035\t  0.086358\t\tCURRENT LEARNING RATE: 0.03313559553679686\n",
      "previous_iter_valid_loss : 0.08050502091646194\n",
      "\n",
      "    271400\t  0.080387\t  0.080505\t  0.086255\t\tCURRENT LEARNING RATE: 0.03310247650353662\n",
      "previous_iter_valid_loss : 0.08733750879764557\n",
      "\n",
      "    271500\t  0.087179\t  0.087338\t  0.086284\t\tCURRENT LEARNING RATE: 0.033069390572755625\n",
      "previous_iter_valid_loss : 0.08475305885076523\n",
      "\n",
      "    271600\t  0.084652\t  0.084753\t  0.086340\t\tCURRENT LEARNING RATE: 0.03303633771136797\n",
      "previous_iter_valid_loss : 0.08085360378026962\n",
      "\n",
      "    271700\t  0.080712\t  0.080854\t  0.086378\t\tCURRENT LEARNING RATE: 0.03300331788632078\n",
      "previous_iter_valid_loss : 0.08986018598079681\n",
      "\n",
      "    271800\t  0.089688\t  0.089860\t  0.086461\t\tCURRENT LEARNING RATE: 0.03297033106459423\n",
      "previous_iter_valid_loss : 0.08117309957742691\n",
      "\n",
      "    271900\t  0.080989\t  0.081173\t  0.086207\t\tCURRENT LEARNING RATE: 0.032937377213201474\n",
      "previous_iter_valid_loss : 0.07604563981294632\n",
      "\n",
      "\n",
      "Current valid loss: 0.07604563981294632;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "    272000\t  0.075991\t  0.076046\t  0.086193\t\tCURRENT LEARNING RATE: 0.03290445629918869\n",
      "previous_iter_valid_loss : 0.09081847220659256\n",
      "\n",
      "    272100\t  0.090891\t  0.090818\t  0.086322\t\tCURRENT LEARNING RATE: 0.03287156828963495\n",
      "previous_iter_valid_loss : 0.08071800321340561\n",
      "\n",
      "    272200\t  0.080684\t  0.080718\t  0.086278\t\tCURRENT LEARNING RATE: 0.03283871315165224\n",
      "previous_iter_valid_loss : 0.13595744967460632\n",
      "\n",
      "    272300\t  0.135672\t  0.135957\t  0.086807\t\tCURRENT LEARNING RATE: 0.0328058908523854\n",
      "previous_iter_valid_loss : 0.1268470138311386\n",
      "\n",
      "    272400\t  0.126623\t  0.126847\t  0.087280\t\tCURRENT LEARNING RATE: 0.032773101359012166\n",
      "previous_iter_valid_loss : 0.08261220157146454\n",
      "\n",
      "    272500\t  0.082622\t  0.082612\t  0.086755\t\tCURRENT LEARNING RATE: 0.032740344638743014\n",
      "previous_iter_valid_loss : 0.07655445486307144\n",
      "\n",
      "    272600\t  0.076526\t  0.076554\t  0.086733\t\tCURRENT LEARNING RATE: 0.03270762065882123\n",
      "previous_iter_valid_loss : 0.0778266116976738\n",
      "\n",
      "    272700\t  0.077685\t  0.077827\t  0.086604\t\tCURRENT LEARNING RATE: 0.032674929386522826\n",
      "previous_iter_valid_loss : 0.07689273357391357\n",
      "\n",
      "    272800\t  0.076786\t  0.076893\t  0.086330\t\tCURRENT LEARNING RATE: 0.03264227078915654\n",
      "previous_iter_valid_loss : 0.07855603843927383\n",
      "\n",
      "    272900\t  0.078538\t  0.078556\t  0.086328\t\tCURRENT LEARNING RATE: 0.03260964483406376\n",
      "previous_iter_valid_loss : 0.08645334839820862\n",
      "\n",
      "    273000\t  0.086260\t  0.086453\t  0.086424\t\tCURRENT LEARNING RATE: 0.03257705148861854\n",
      "previous_iter_valid_loss : 0.08070310950279236\n",
      "\n",
      "    273100\t  0.080681\t  0.080703\t  0.086250\t\tCURRENT LEARNING RATE: 0.0325444907202275\n",
      "previous_iter_valid_loss : 0.08560404181480408\n",
      "\n",
      "    273200\t  0.085466\t  0.085604\t  0.086310\t\tCURRENT LEARNING RATE: 0.03251196249632991\n",
      "previous_iter_valid_loss : 0.08021031320095062\n",
      "\n",
      "    273300\t  0.080067\t  0.080210\t  0.086279\t\tCURRENT LEARNING RATE: 0.032479466784397525\n",
      "previous_iter_valid_loss : 0.0862959772348404\n",
      "\n",
      "    273400\t  0.086068\t  0.086296\t  0.086356\t\tCURRENT LEARNING RATE: 0.03244700355193463\n",
      "previous_iter_valid_loss : 0.10514149814844131\n",
      "\n",
      "    273500\t  0.104885\t  0.105141\t  0.086541\t\tCURRENT LEARNING RATE: 0.03241457276647798\n",
      "previous_iter_valid_loss : 0.08661716431379318\n",
      "\n",
      "    273600\t  0.086669\t  0.086617\t  0.086608\t\tCURRENT LEARNING RATE: 0.03238217439559681\n",
      "previous_iter_valid_loss : 0.07689846307039261\n",
      "\n",
      "    273700\t  0.076861\t  0.076898\t  0.086609\t\tCURRENT LEARNING RATE: 0.032349808406892736\n",
      "previous_iter_valid_loss : 0.0779862105846405\n",
      "\n",
      "    273800\t  0.077824\t  0.077986\t  0.086501\t\tCURRENT LEARNING RATE: 0.03231747476799977\n",
      "previous_iter_valid_loss : 0.08083155006170273\n",
      "\n",
      "    273900\t  0.080785\t  0.080832\t  0.086535\t\tCURRENT LEARNING RATE: 0.032285173446584235\n",
      "previous_iter_valid_loss : 0.07921869307756424\n",
      "\n",
      "    274000\t  0.079053\t  0.079219\t  0.086539\t\tCURRENT LEARNING RATE: 0.03225290441034486\n",
      "previous_iter_valid_loss : 0.07725939899682999\n",
      "\n",
      "    274100\t  0.077152\t  0.077259\t  0.086474\t\tCURRENT LEARNING RATE: 0.03222066762701259\n",
      "previous_iter_valid_loss : 0.0766574963927269\n",
      "\n",
      "    274200\t  0.076586\t  0.076657\t  0.085973\t\tCURRENT LEARNING RATE: 0.03218846306435062\n",
      "previous_iter_valid_loss : 0.07638717442750931\n",
      "\n",
      "    274300\t  0.076253\t  0.076387\t  0.085952\t\tCURRENT LEARNING RATE: 0.03215629069015439\n",
      "previous_iter_valid_loss : 0.09058396518230438\n",
      "\n",
      "    274400\t  0.090430\t  0.090584\t  0.086080\t\tCURRENT LEARNING RATE: 0.03212415047225154\n",
      "previous_iter_valid_loss : 0.07865110784769058\n",
      "\n",
      "    274500\t  0.078592\t  0.078651\t  0.086089\t\tCURRENT LEARNING RATE: 0.03209204237850184\n",
      "previous_iter_valid_loss : 0.0763486698269844\n",
      "\n",
      "    274600\t  0.076247\t  0.076349\t  0.085981\t\tCURRENT LEARNING RATE: 0.0320599663767972\n",
      "previous_iter_valid_loss : 0.07646913826465607\n",
      "\n",
      "    274700\t  0.076382\t  0.076469\t  0.085700\t\tCURRENT LEARNING RATE: 0.032027922435061584\n",
      "previous_iter_valid_loss : 0.08114240318536758\n",
      "\n",
      "    274800\t  0.080927\t  0.081142\t  0.085622\t\tCURRENT LEARNING RATE: 0.03199591052125109\n",
      "previous_iter_valid_loss : 0.07668640464544296\n",
      "\n",
      "    274900\t  0.076622\t  0.076686\t  0.085622\t\tCURRENT LEARNING RATE: 0.031963930603353785\n",
      "previous_iter_valid_loss : 0.07738105207681656\n",
      "\n",
      "    275000\t  0.077261\t  0.077381\t  0.085538\t\tCURRENT LEARNING RATE: 0.03193198264938975\n",
      "previous_iter_valid_loss : 0.09017471224069595\n",
      "\n",
      "    275100\t  0.090216\t  0.090175\t  0.085567\t\tCURRENT LEARNING RATE: 0.03190006662741102\n",
      "previous_iter_valid_loss : 0.0882558599114418\n",
      "\n",
      "    275200\t  0.088320\t  0.088256\t  0.085676\t\tCURRENT LEARNING RATE: 0.03186818250550156\n",
      "previous_iter_valid_loss : 0.07632021605968475\n",
      "\n",
      "    275300\t  0.076241\t  0.076320\t  0.085672\t\tCURRENT LEARNING RATE: 0.03183633025177728\n",
      "previous_iter_valid_loss : 0.078700952231884\n",
      "\n",
      "    275400\t  0.078564\t  0.078701\t  0.085675\t\tCURRENT LEARNING RATE: 0.0318045098343859\n",
      "previous_iter_valid_loss : 0.09240606427192688\n",
      "\n",
      "    275500\t  0.092435\t  0.092406\t  0.085818\t\tCURRENT LEARNING RATE: 0.03177272122150701\n",
      "previous_iter_valid_loss : 0.11681599915027618\n",
      "\n",
      "    275600\t  0.116563\t  0.116816\t  0.086215\t\tCURRENT LEARNING RATE: 0.031740964381351974\n",
      "previous_iter_valid_loss : 0.07762013375759125\n",
      "\n",
      "    275700\t  0.077579\t  0.077620\t  0.086194\t\tCURRENT LEARNING RATE: 0.03170923928216398\n",
      "previous_iter_valid_loss : 0.0761205181479454\n",
      "\n",
      "    275800\t  0.076040\t  0.076121\t  0.085335\t\tCURRENT LEARNING RATE: 0.031677545892217905\n",
      "previous_iter_valid_loss : 0.078104168176651\n",
      "\n",
      "    275900\t  0.077979\t  0.078104\t  0.085334\t\tCURRENT LEARNING RATE: 0.031645884179820366\n",
      "previous_iter_valid_loss : 0.0859140157699585\n",
      "\n",
      "    276000\t  0.085900\t  0.085914\t  0.085386\t\tCURRENT LEARNING RATE: 0.031614254113309634\n",
      "previous_iter_valid_loss : 0.0786256492137909\n",
      "\n",
      "    276100\t  0.078533\t  0.078626\t  0.085295\t\tCURRENT LEARNING RATE: 0.031582655661055656\n",
      "previous_iter_valid_loss : 0.09232234954833984\n",
      "\n",
      "    276200\t  0.092374\t  0.092322\t  0.085409\t\tCURRENT LEARNING RATE: 0.03155108879145997\n",
      "previous_iter_valid_loss : 0.09101693332195282\n",
      "\n",
      "    276300\t  0.090830\t  0.091017\t  0.085482\t\tCURRENT LEARNING RATE: 0.031519553472955715\n",
      "previous_iter_valid_loss : 0.07934662699699402\n",
      "\n",
      "    276400\t  0.079333\t  0.079347\t  0.085407\t\tCURRENT LEARNING RATE: 0.031488049674007534\n",
      "previous_iter_valid_loss : 0.0767873078584671\n",
      "\n",
      "    276500\t  0.076721\t  0.076787\t  0.085374\t\tCURRENT LEARNING RATE: 0.03145657736311167\n",
      "previous_iter_valid_loss : 0.08719170093536377\n",
      "\n",
      "    276600\t  0.086996\t  0.087192\t  0.085476\t\tCURRENT LEARNING RATE: 0.031425136508795797\n",
      "previous_iter_valid_loss : 0.0901808962225914\n",
      "\n",
      "    276700\t  0.090020\t  0.090181\t  0.085573\t\tCURRENT LEARNING RATE: 0.031393727079619044\n",
      "previous_iter_valid_loss : 0.0866456925868988\n",
      "\n",
      "    276800\t  0.086513\t  0.086646\t  0.085500\t\tCURRENT LEARNING RATE: 0.031362349044171976\n",
      "previous_iter_valid_loss : 0.09711789339780807\n",
      "\n",
      "    276900\t  0.097190\t  0.097118\t  0.085699\t\tCURRENT LEARNING RATE: 0.031331002371076576\n",
      "previous_iter_valid_loss : 0.07908037304878235\n",
      "\n",
      "    277000\t  0.078921\t  0.079080\t  0.085642\t\tCURRENT LEARNING RATE: 0.03129968702898616\n",
      "previous_iter_valid_loss : 0.08070380985736847\n",
      "\n",
      "    277100\t  0.080545\t  0.080704\t  0.085576\t\tCURRENT LEARNING RATE: 0.031268402986585384\n",
      "previous_iter_valid_loss : 0.0761164203286171\n",
      "\n",
      "    277200\t  0.076008\t  0.076116\t  0.085369\t\tCURRENT LEARNING RATE: 0.03123715021259018\n",
      "previous_iter_valid_loss : 0.08630315959453583\n",
      "\n",
      "    277300\t  0.086327\t  0.086303\t  0.085445\t\tCURRENT LEARNING RATE: 0.03120592867574781\n",
      "previous_iter_valid_loss : 0.0783180296421051\n",
      "\n",
      "    277400\t  0.078288\t  0.078318\t  0.085431\t\tCURRENT LEARNING RATE: 0.031174738344836715\n",
      "previous_iter_valid_loss : 0.08327675610780716\n",
      "\n",
      "    277500\t  0.083130\t  0.083277\t  0.085495\t\tCURRENT LEARNING RATE: 0.031143579188666563\n",
      "previous_iter_valid_loss : 0.07798915356397629\n",
      "\n",
      "    277600\t  0.077977\t  0.077989\t  0.085502\t\tCURRENT LEARNING RATE: 0.03111245117607818\n",
      "previous_iter_valid_loss : 0.08360323309898376\n",
      "\n",
      "    277700\t  0.083606\t  0.083603\t  0.085490\t\tCURRENT LEARNING RATE: 0.031081354275943582\n",
      "previous_iter_valid_loss : 0.07699542492628098\n",
      "\n",
      "    277800\t  0.076948\t  0.076995\t  0.085444\t\tCURRENT LEARNING RATE: 0.03105028845716585\n",
      "previous_iter_valid_loss : 0.0835212916135788\n",
      "\n",
      "    277900\t  0.083501\t  0.083521\t  0.085473\t\tCURRENT LEARNING RATE: 0.03101925368867916\n",
      "previous_iter_valid_loss : 0.07643954455852509\n",
      "\n",
      "    278000\t  0.076355\t  0.076440\t  0.085293\t\tCURRENT LEARNING RATE: 0.030988249939448733\n",
      "previous_iter_valid_loss : 0.0792766734957695\n",
      "\n",
      "    278100\t  0.079204\t  0.079277\t  0.085294\t\tCURRENT LEARNING RATE: 0.030957277178470837\n",
      "previous_iter_valid_loss : 0.07749134302139282\n",
      "\n",
      "    278200\t  0.077410\t  0.077491\t  0.085208\t\tCURRENT LEARNING RATE: 0.030926335374772705\n",
      "previous_iter_valid_loss : 0.12515372037887573\n",
      "\n",
      "    278300\t  0.125319\t  0.125154\t  0.085548\t\tCURRENT LEARNING RATE: 0.030895424497412522\n",
      "previous_iter_valid_loss : 0.07857611030340195\n",
      "\n",
      "    278400\t  0.078436\t  0.078576\t  0.085397\t\tCURRENT LEARNING RATE: 0.030864544515479396\n",
      "previous_iter_valid_loss : 0.07925695180892944\n",
      "\n",
      "    278500\t  0.079129\t  0.079257\t  0.085409\t\tCURRENT LEARNING RATE: 0.030833695398093372\n",
      "previous_iter_valid_loss : 0.07681390643119812\n",
      "\n",
      "    278600\t  0.076753\t  0.076814\t  0.085375\t\tCURRENT LEARNING RATE: 0.030802877114405318\n",
      "previous_iter_valid_loss : 0.08383144438266754\n",
      "\n",
      "    278700\t  0.083682\t  0.083831\t  0.085432\t\tCURRENT LEARNING RATE: 0.030772089633596945\n",
      "previous_iter_valid_loss : 0.07664082199335098\n",
      "\n",
      "    278800\t  0.076584\t  0.076641\t  0.085352\t\tCURRENT LEARNING RATE: 0.03074133292488075\n",
      "previous_iter_valid_loss : 0.08315922319889069\n",
      "\n",
      "    278900\t  0.082976\t  0.083159\t  0.085420\t\tCURRENT LEARNING RATE: 0.030710606957500063\n",
      "previous_iter_valid_loss : 0.07876333594322205\n",
      "\n",
      "    279000\t  0.078670\t  0.078763\t  0.085300\t\tCURRENT LEARNING RATE: 0.03067991170072889\n",
      "previous_iter_valid_loss : 0.07665956765413284\n",
      "\n",
      "    279100\t  0.076552\t  0.076660\t  0.085205\t\tCURRENT LEARNING RATE: 0.030649247123871976\n",
      "previous_iter_valid_loss : 0.0763259083032608\n",
      "\n",
      "    279200\t  0.076237\t  0.076326\t  0.085191\t\tCURRENT LEARNING RATE: 0.030618613196264723\n",
      "previous_iter_valid_loss : 0.0966193899512291\n",
      "\n",
      "    279300\t  0.096757\t  0.096619\t  0.085350\t\tCURRENT LEARNING RATE: 0.030588009887273233\n",
      "previous_iter_valid_loss : 0.07668903470039368\n",
      "\n",
      "    279400\t  0.076613\t  0.076689\t  0.085059\t\tCURRENT LEARNING RATE: 0.03055743716629418\n",
      "previous_iter_valid_loss : 0.08030521869659424\n",
      "\n",
      "    279500\t  0.080241\t  0.080305\t  0.084639\t\tCURRENT LEARNING RATE: 0.03052689500275484\n",
      "previous_iter_valid_loss : 0.07595418393611908\n",
      "\n",
      "\n",
      "Current valid loss: 0.07595418393611908;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "    279600\t  0.075851\t  0.075954\t  0.084570\t\tCURRENT LEARNING RATE: 0.03049638336611303\n",
      "previous_iter_valid_loss : 0.0871729627251625\n",
      "\n",
      "    279700\t  0.086973\t  0.087173\t  0.084500\t\tCURRENT LEARNING RATE: 0.030465902225857145\n",
      "previous_iter_valid_loss : 0.0821947380900383\n",
      "\n",
      "    279800\t  0.082194\t  0.082195\t  0.084456\t\tCURRENT LEARNING RATE: 0.030435451551506024\n",
      "previous_iter_valid_loss : 0.07668714970350266\n",
      "\n",
      "    279900\t  0.076527\t  0.076687\t  0.084143\t\tCURRENT LEARNING RATE: 0.030405031312608986\n",
      "previous_iter_valid_loss : 0.07937213778495789\n",
      "\n",
      "    280000\t  0.079256\t  0.079372\t  0.084145\t\tCURRENT LEARNING RATE: 0.030374641478745787\n",
      "previous_iter_valid_loss : 0.12447618693113327\n",
      "\n",
      "    280100\t  0.124298\t  0.124476\t  0.084334\t\tCURRENT LEARNING RATE: 0.03034428201952661\n",
      "previous_iter_valid_loss : 0.08665001392364502\n",
      "\n",
      "    280200\t  0.086720\t  0.086650\t  0.084350\t\tCURRENT LEARNING RATE: 0.03031395290459198\n",
      "previous_iter_valid_loss : 0.08181947469711304\n",
      "\n",
      "    280300\t  0.081649\t  0.081819\t  0.084215\t\tCURRENT LEARNING RATE: 0.030283654103612778\n",
      "previous_iter_valid_loss : 0.09224054962396622\n",
      "\n",
      "    280400\t  0.092303\t  0.092241\t  0.084295\t\tCURRENT LEARNING RATE: 0.030253385586290194\n",
      "previous_iter_valid_loss : 0.07905155420303345\n",
      "\n",
      "    280500\t  0.079054\t  0.079052\t  0.084243\t\tCURRENT LEARNING RATE: 0.03022314732235573\n",
      "previous_iter_valid_loss : 0.08016915619373322\n",
      "\n",
      "    280600\t  0.080150\t  0.080169\t  0.084273\t\tCURRENT LEARNING RATE: 0.030192939281571105\n",
      "previous_iter_valid_loss : 0.07614053040742874\n",
      "\n",
      "    280700\t  0.076100\t  0.076141\t  0.083859\t\tCURRENT LEARNING RATE: 0.030162761433728282\n",
      "previous_iter_valid_loss : 0.07866481691598892\n",
      "\n",
      "    280800\t  0.078532\t  0.078665\t  0.083853\t\tCURRENT LEARNING RATE: 0.030132613748649388\n",
      "previous_iter_valid_loss : 0.0792359784245491\n",
      "\n",
      "    280900\t  0.079244\t  0.079236\t  0.083877\t\tCURRENT LEARNING RATE: 0.03010249619618677\n",
      "previous_iter_valid_loss : 0.0793854296207428\n",
      "\n",
      "    281000\t  0.079238\t  0.079385\t  0.083902\t\tCURRENT LEARNING RATE: 0.030072408746222856\n",
      "previous_iter_valid_loss : 0.09840060025453568\n",
      "\n",
      "    281100\t  0.098189\t  0.098401\t  0.084103\t\tCURRENT LEARNING RATE: 0.030042351368670193\n",
      "previous_iter_valid_loss : 0.10409210622310638\n",
      "\n",
      "    281200\t  0.104265\t  0.104092\t  0.084271\t\tCURRENT LEARNING RATE: 0.030012324033471392\n",
      "previous_iter_valid_loss : 0.07700085639953613\n",
      "\n",
      "    281300\t  0.076927\t  0.077001\t  0.084271\t\tCURRENT LEARNING RATE: 0.029982326710599135\n",
      "previous_iter_valid_loss : 0.07705756276845932\n",
      "\n",
      "    281400\t  0.076999\t  0.077058\t  0.084237\t\tCURRENT LEARNING RATE: 0.02995235937005609\n",
      "previous_iter_valid_loss : 0.07655788213014603\n",
      "\n",
      "    281500\t  0.076492\t  0.076558\t  0.084129\t\tCURRENT LEARNING RATE: 0.029922421981874912\n",
      "previous_iter_valid_loss : 0.08542953431606293\n",
      "\n",
      "    281600\t  0.085446\t  0.085430\t  0.084135\t\tCURRENT LEARNING RATE: 0.029892514516118192\n",
      "previous_iter_valid_loss : 0.07858125120401382\n",
      "\n",
      "    281700\t  0.078486\t  0.078581\t  0.084113\t\tCURRENT LEARNING RATE: 0.029862636942878495\n",
      "previous_iter_valid_loss : 0.09050773084163666\n",
      "\n",
      "    281800\t  0.090551\t  0.090508\t  0.084119\t\tCURRENT LEARNING RATE: 0.02983278923227823\n",
      "previous_iter_valid_loss : 0.08681328594684601\n",
      "\n",
      "    281900\t  0.086834\t  0.086813\t  0.084176\t\tCURRENT LEARNING RATE: 0.029802971354469684\n",
      "previous_iter_valid_loss : 0.09878206998109818\n",
      "\n",
      "    282000\t  0.098563\t  0.098782\t  0.084403\t\tCURRENT LEARNING RATE: 0.02977318327963496\n",
      "previous_iter_valid_loss : 0.09264196455478668\n",
      "\n",
      "    282100\t  0.092430\t  0.092642\t  0.084421\t\tCURRENT LEARNING RATE: 0.02974342497798601\n",
      "previous_iter_valid_loss : 0.08029145002365112\n",
      "\n",
      "    282200\t  0.080143\t  0.080291\t  0.084417\t\tCURRENT LEARNING RATE: 0.02971369641976452\n",
      "previous_iter_valid_loss : 0.07710418850183487\n",
      "\n",
      "    282300\t  0.077026\t  0.077104\t  0.083828\t\tCURRENT LEARNING RATE: 0.029683997575241924\n",
      "previous_iter_valid_loss : 0.07774551212787628\n",
      "\n",
      "    282400\t  0.077586\t  0.077746\t  0.083337\t\tCURRENT LEARNING RATE: 0.02965432841471936\n",
      "previous_iter_valid_loss : 0.07650549709796906\n",
      "\n",
      "    282500\t  0.076392\t  0.076505\t  0.083276\t\tCURRENT LEARNING RATE: 0.0296246889085277\n",
      "previous_iter_valid_loss : 0.0785554051399231\n",
      "\n",
      "    282600\t  0.078448\t  0.078555\t  0.083296\t\tCURRENT LEARNING RATE: 0.029595079027027415\n",
      "previous_iter_valid_loss : 0.08881080895662308\n",
      "\n",
      "    282700\t  0.088661\t  0.088811\t  0.083406\t\tCURRENT LEARNING RATE: 0.029565498740608626\n",
      "previous_iter_valid_loss : 0.07598519325256348\n",
      "\n",
      "    282800\t  0.075889\t  0.075985\t  0.083397\t\tCURRENT LEARNING RATE: 0.029535948019691026\n",
      "previous_iter_valid_loss : 0.0792076364159584\n",
      "\n",
      "    282900\t  0.079071\t  0.079208\t  0.083404\t\tCURRENT LEARNING RATE: 0.02950642683472392\n",
      "previous_iter_valid_loss : 0.0759284496307373\n",
      "\n",
      "\n",
      "Current valid loss: 0.0759284496307373;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "    283000\t  0.075811\t  0.075928\t  0.083298\t\tCURRENT LEARNING RATE: 0.02947693515618611\n",
      "previous_iter_valid_loss : 0.07991638779640198\n",
      "\n",
      "    283100\t  0.079758\t  0.079916\t  0.083291\t\tCURRENT LEARNING RATE: 0.02944747295458591\n",
      "previous_iter_valid_loss : 0.10007672756910324\n",
      "\n",
      "    283200\t  0.100212\t  0.100077\t  0.083435\t\tCURRENT LEARNING RATE: 0.029418040200461106\n",
      "previous_iter_valid_loss : 0.10456764698028564\n",
      "\n",
      "    283300\t  0.104327\t  0.104568\t  0.083679\t\tCURRENT LEARNING RATE: 0.029388636864378967\n",
      "previous_iter_valid_loss : 0.077595554292202\n",
      "\n",
      "    283400\t  0.077512\t  0.077596\t  0.083592\t\tCURRENT LEARNING RATE: 0.029359262916936142\n",
      "previous_iter_valid_loss : 0.07741596549749374\n",
      "\n",
      "    283500\t  0.077252\t  0.077416\t  0.083315\t\tCURRENT LEARNING RATE: 0.02932991832875868\n",
      "previous_iter_valid_loss : 0.0849958136677742\n",
      "\n",
      "    283600\t  0.084993\t  0.084996\t  0.083298\t\tCURRENT LEARNING RATE: 0.029300603070501977\n",
      "previous_iter_valid_loss : 0.11101171374320984\n",
      "\n",
      "    283700\t  0.110794\t  0.111012\t  0.083640\t\tCURRENT LEARNING RATE: 0.0292713171128508\n",
      "previous_iter_valid_loss : 0.0820973739027977\n",
      "\n",
      "    283800\t  0.082128\t  0.082097\t  0.083681\t\tCURRENT LEARNING RATE: 0.029242060426519174\n",
      "previous_iter_valid_loss : 0.1004251092672348\n",
      "\n",
      "    283900\t  0.100240\t  0.100425\t  0.083877\t\tCURRENT LEARNING RATE: 0.029212832982250414\n",
      "previous_iter_valid_loss : 0.08341699838638306\n",
      "\n",
      "    284000\t  0.083408\t  0.083417\t  0.083919\t\tCURRENT LEARNING RATE: 0.029183634750817058\n",
      "previous_iter_valid_loss : 0.09866710007190704\n",
      "\n",
      "    284100\t  0.098766\t  0.098667\t  0.084133\t\tCURRENT LEARNING RATE: 0.029154465703020896\n",
      "previous_iter_valid_loss : 0.07944796979427338\n",
      "\n",
      "    284200\t  0.079286\t  0.079448\t  0.084161\t\tCURRENT LEARNING RATE: 0.029125325809692865\n",
      "previous_iter_valid_loss : 0.08372434228658676\n",
      "\n",
      "    284300\t  0.083517\t  0.083724\t  0.084234\t\tCURRENT LEARNING RATE: 0.029096215041693074\n",
      "previous_iter_valid_loss : 0.07907333225011826\n",
      "\n",
      "    284400\t  0.079036\t  0.079073\t  0.084119\t\tCURRENT LEARNING RATE: 0.029067133369910732\n",
      "previous_iter_valid_loss : 0.08960604667663574\n",
      "\n",
      "    284500\t  0.089411\t  0.089606\t  0.084228\t\tCURRENT LEARNING RATE: 0.0290380807652642\n",
      "previous_iter_valid_loss : 0.08476725220680237\n",
      "\n",
      "    284600\t  0.084766\t  0.084767\t  0.084313\t\tCURRENT LEARNING RATE: 0.029009057198700852\n",
      "previous_iter_valid_loss : 0.08660247176885605\n",
      "\n",
      "    284700\t  0.086628\t  0.086602\t  0.084414\t\tCURRENT LEARNING RATE: 0.028980062641197117\n",
      "previous_iter_valid_loss : 0.0781799778342247\n",
      "\n",
      "    284800\t  0.078028\t  0.078180\t  0.084384\t\tCURRENT LEARNING RATE: 0.028951097063758428\n",
      "previous_iter_valid_loss : 0.07731840759515762\n",
      "\n",
      "    284900\t  0.077160\t  0.077318\t  0.084391\t\tCURRENT LEARNING RATE: 0.028922160437419228\n",
      "previous_iter_valid_loss : 0.07883214205503464\n",
      "\n",
      "    285000\t  0.078687\t  0.078832\t  0.084405\t\tCURRENT LEARNING RATE: 0.028893252733242877\n",
      "previous_iter_valid_loss : 0.07843920588493347\n",
      "\n",
      "    285100\t  0.078356\t  0.078439\t  0.084288\t\tCURRENT LEARNING RATE: 0.028864373922321666\n",
      "previous_iter_valid_loss : 0.07652057707309723\n",
      "\n",
      "    285200\t  0.076425\t  0.076521\t  0.084170\t\tCURRENT LEARNING RATE: 0.028835523975776767\n",
      "previous_iter_valid_loss : 0.07825005799531937\n",
      "\n",
      "    285300\t  0.078182\t  0.078250\t  0.084190\t\tCURRENT LEARNING RATE: 0.02880670286475826\n",
      "previous_iter_valid_loss : 0.0810546725988388\n",
      "\n",
      "    285400\t  0.080876\t  0.081055\t  0.084213\t\tCURRENT LEARNING RATE: 0.028777910560445024\n",
      "previous_iter_valid_loss : 0.07587894052267075\n",
      "\n",
      "\n",
      "Current valid loss: 0.07587894052267075;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "    285500\t  0.075774\t  0.075879\t  0.084048\t\tCURRENT LEARNING RATE: 0.028749147034044742\n",
      "previous_iter_valid_loss : 0.07908472418785095\n",
      "\n",
      "    285600\t  0.079026\t  0.079085\t  0.083671\t\tCURRENT LEARNING RATE: 0.02872041225679388\n",
      "previous_iter_valid_loss : 0.07635956257581711\n",
      "\n",
      "    285700\t  0.076240\t  0.076360\t  0.083658\t\tCURRENT LEARNING RATE: 0.028691706199957676\n",
      "previous_iter_valid_loss : 0.07745661586523056\n",
      "\n",
      "    285800\t  0.077356\t  0.077457\t  0.083671\t\tCURRENT LEARNING RATE: 0.028663028834830066\n",
      "previous_iter_valid_loss : 0.07590959221124649\n",
      "\n",
      "    285900\t  0.075813\t  0.075910\t  0.083649\t\tCURRENT LEARNING RATE: 0.02863438013273368\n",
      "previous_iter_valid_loss : 0.10195237398147583\n",
      "\n",
      "    286000\t  0.102109\t  0.101952\t  0.083810\t\tCURRENT LEARNING RATE: 0.0286057600650198\n",
      "previous_iter_valid_loss : 0.07687003165483475\n",
      "\n",
      "    286100\t  0.076816\t  0.076870\t  0.083792\t\tCURRENT LEARNING RATE: 0.02857716860306838\n",
      "previous_iter_valid_loss : 0.07633223384618759\n",
      "\n",
      "    286200\t  0.076260\t  0.076332\t  0.083632\t\tCURRENT LEARNING RATE: 0.028548605718287944\n",
      "previous_iter_valid_loss : 0.0762072205543518\n",
      "\n",
      "    286300\t  0.076131\t  0.076207\t  0.083484\t\tCURRENT LEARNING RATE: 0.028520071382115608\n",
      "previous_iter_valid_loss : 0.07838154584169388\n",
      "\n",
      "    286400\t  0.078291\t  0.078382\t  0.083475\t\tCURRENT LEARNING RATE: 0.028491565566017018\n",
      "previous_iter_valid_loss : 0.09156107902526855\n",
      "\n",
      "    286500\t  0.091618\t  0.091561\t  0.083622\t\tCURRENT LEARNING RATE: 0.028463088241486377\n",
      "previous_iter_valid_loss : 0.08019079267978668\n",
      "\n",
      "    286600\t  0.080155\t  0.080191\t  0.083552\t\tCURRENT LEARNING RATE: 0.028434639380046353\n",
      "previous_iter_valid_loss : 0.08910145610570908\n",
      "\n",
      "    286700\t  0.089117\t  0.089101\t  0.083542\t\tCURRENT LEARNING RATE: 0.028406218953248078\n",
      "previous_iter_valid_loss : 0.07620903104543686\n",
      "\n",
      "    286800\t  0.076108\t  0.076209\t  0.083437\t\tCURRENT LEARNING RATE: 0.028377826932671112\n",
      "previous_iter_valid_loss : 0.08246076107025146\n",
      "\n",
      "    286900\t  0.082450\t  0.082461\t  0.083291\t\tCURRENT LEARNING RATE: 0.02834946328992345\n",
      "previous_iter_valid_loss : 0.07921449840068817\n",
      "\n",
      "    287000\t  0.079068\t  0.079214\t  0.083292\t\tCURRENT LEARNING RATE: 0.028321127996641448\n",
      "previous_iter_valid_loss : 0.09460876882076263\n",
      "\n",
      "    287100\t  0.094422\t  0.094609\t  0.083431\t\tCURRENT LEARNING RATE: 0.028292821024489802\n",
      "previous_iter_valid_loss : 0.08855076879262924\n",
      "\n",
      "    287200\t  0.088364\t  0.088551\t  0.083555\t\tCURRENT LEARNING RATE: 0.02826454234516152\n",
      "previous_iter_valid_loss : 0.08394608646631241\n",
      "\n",
      "    287300\t  0.083993\t  0.083946\t  0.083532\t\tCURRENT LEARNING RATE: 0.028236291930377955\n",
      "previous_iter_valid_loss : 0.08491848409175873\n",
      "\n",
      "    287400\t  0.084709\t  0.084918\t  0.083598\t\tCURRENT LEARNING RATE: 0.028208069751888675\n",
      "previous_iter_valid_loss : 0.08692321926355362\n",
      "\n",
      "    287500\t  0.086736\t  0.086923\t  0.083634\t\tCURRENT LEARNING RATE: 0.028179875781471495\n",
      "previous_iter_valid_loss : 0.08774320781230927\n",
      "\n",
      "    287600\t  0.087820\t  0.087743\t  0.083732\t\tCURRENT LEARNING RATE: 0.028151709990932444\n",
      "previous_iter_valid_loss : 0.07772104442119598\n",
      "\n",
      "    287700\t  0.077573\t  0.077721\t  0.083673\t\tCURRENT LEARNING RATE: 0.02812357235210572\n",
      "previous_iter_valid_loss : 0.08068031817674637\n",
      "\n",
      "    287800\t  0.080472\t  0.080680\t  0.083710\t\tCURRENT LEARNING RATE: 0.028095462836853703\n",
      "previous_iter_valid_loss : 0.07658447325229645\n",
      "\n",
      "    287900\t  0.076569\t  0.076584\t  0.083640\t\tCURRENT LEARNING RATE: 0.028067381417066863\n",
      "previous_iter_valid_loss : 0.07643254846334457\n",
      "\n",
      "    288000\t  0.076390\t  0.076433\t  0.083640\t\tCURRENT LEARNING RATE: 0.02803932806466378\n",
      "previous_iter_valid_loss : 0.0855359360575676\n",
      "\n",
      "    288100\t  0.085333\t  0.085536\t  0.083703\t\tCURRENT LEARNING RATE: 0.028011302751591086\n",
      "previous_iter_valid_loss : 0.08366689085960388\n",
      "\n",
      "    288200\t  0.083540\t  0.083667\t  0.083765\t\tCURRENT LEARNING RATE: 0.02798330544982349\n",
      "previous_iter_valid_loss : 0.08036010712385178\n",
      "\n",
      "    288300\t  0.080264\t  0.080360\t  0.083317\t\tCURRENT LEARNING RATE: 0.027955336131363678\n",
      "previous_iter_valid_loss : 0.08689922839403152\n",
      "\n",
      "    288400\t  0.086752\t  0.086899\t  0.083400\t\tCURRENT LEARNING RATE: 0.027927394768242325\n",
      "previous_iter_valid_loss : 0.08161803334951401\n",
      "\n",
      "    288500\t  0.081650\t  0.081618\t  0.083424\t\tCURRENT LEARNING RATE: 0.027899481332518055\n",
      "previous_iter_valid_loss : 0.07751975208520889\n",
      "\n",
      "    288600\t  0.077413\t  0.077520\t  0.083431\t\tCURRENT LEARNING RATE: 0.027871595796277453\n",
      "previous_iter_valid_loss : 0.07622285932302475\n",
      "\n",
      "    288700\t  0.076118\t  0.076223\t  0.083355\t\tCURRENT LEARNING RATE: 0.027843738131634974\n",
      "previous_iter_valid_loss : 0.08311698585748672\n",
      "\n",
      "    288800\t  0.083110\t  0.083117\t  0.083419\t\tCURRENT LEARNING RATE: 0.027815908310732943\n",
      "previous_iter_valid_loss : 0.07679939270019531\n",
      "\n",
      "    288900\t  0.076714\t  0.076799\t  0.083356\t\tCURRENT LEARNING RATE: 0.02778810630574153\n",
      "previous_iter_valid_loss : 0.08027614653110504\n",
      "\n",
      "    289000\t  0.080136\t  0.080276\t  0.083371\t\tCURRENT LEARNING RATE: 0.027760332088858752\n",
      "previous_iter_valid_loss : 0.09202495217323303\n",
      "\n",
      "    289100\t  0.092162\t  0.092025\t  0.083525\t\tCURRENT LEARNING RATE: 0.027732585632310375\n",
      "previous_iter_valid_loss : 0.07774427533149719\n",
      "\n",
      "    289200\t  0.077702\t  0.077744\t  0.083539\t\tCURRENT LEARNING RATE: 0.027704866908349942\n",
      "previous_iter_valid_loss : 0.08319618552923203\n",
      "\n",
      "    289300\t  0.083238\t  0.083196\t  0.083404\t\tCURRENT LEARNING RATE: 0.027677175889258714\n",
      "previous_iter_valid_loss : 0.09356802701950073\n",
      "\n",
      "    289400\t  0.093406\t  0.093568\t  0.083573\t\tCURRENT LEARNING RATE: 0.02764951254734569\n",
      "previous_iter_valid_loss : 0.07628408074378967\n",
      "\n",
      "    289500\t  0.076259\t  0.076284\t  0.083533\t\tCURRENT LEARNING RATE: 0.027621876854947523\n",
      "previous_iter_valid_loss : 0.07593120634555817\n",
      "\n",
      "    289600\t  0.075902\t  0.075931\t  0.083533\t\tCURRENT LEARNING RATE: 0.02759426878442851\n",
      "previous_iter_valid_loss : 0.08657748252153397\n",
      "\n",
      "    289700\t  0.086423\t  0.086577\t  0.083527\t\tCURRENT LEARNING RATE: 0.02756668830818057\n",
      "previous_iter_valid_loss : 0.07634014636278152\n",
      "\n",
      "    289800\t  0.076294\t  0.076340\t  0.083468\t\tCURRENT LEARNING RATE: 0.027539135398623245\n",
      "previous_iter_valid_loss : 0.08471208065748215\n",
      "\n",
      "    289900\t  0.084800\t  0.084712\t  0.083549\t\tCURRENT LEARNING RATE: 0.027511610028203615\n",
      "previous_iter_valid_loss : 0.07644364982843399\n",
      "\n",
      "    290000\t  0.076380\t  0.076444\t  0.083519\t\tCURRENT LEARNING RATE: 0.027484112169396308\n",
      "previous_iter_valid_loss : 0.08418698608875275\n",
      "\n",
      "    290100\t  0.084262\t  0.084187\t  0.083116\t\tCURRENT LEARNING RATE: 0.027456641794703446\n",
      "previous_iter_valid_loss : 0.0773746594786644\n",
      "\n",
      "    290200\t  0.077362\t  0.077375\t  0.083024\t\tCURRENT LEARNING RATE: 0.02742919887665468\n",
      "previous_iter_valid_loss : 0.07761292159557343\n",
      "\n",
      "    290300\t  0.077479\t  0.077613\t  0.082982\t\tCURRENT LEARNING RATE: 0.027401783387807077\n",
      "previous_iter_valid_loss : 0.0860588401556015\n",
      "\n",
      "    290400\t  0.086137\t  0.086059\t  0.082920\t\tCURRENT LEARNING RATE: 0.027374395300745143\n",
      "previous_iter_valid_loss : 0.07813787460327148\n",
      "\n",
      "    290500\t  0.078044\t  0.078138\t  0.082911\t\tCURRENT LEARNING RATE: 0.02734703458808078\n",
      "previous_iter_valid_loss : 0.09253831952810287\n",
      "\n",
      "    290600\t  0.092639\t  0.092538\t  0.083034\t\tCURRENT LEARNING RATE: 0.027319701222453297\n",
      "previous_iter_valid_loss : 0.10456795245409012\n",
      "\n",
      "    290700\t  0.104378\t  0.104568\t  0.083319\t\tCURRENT LEARNING RATE: 0.027292395176529313\n",
      "previous_iter_valid_loss : 0.07712982594966888\n",
      "\n",
      "    290800\t  0.077020\t  0.077130\t  0.083303\t\tCURRENT LEARNING RATE: 0.02726511642300278\n",
      "previous_iter_valid_loss : 0.09815426915884018\n",
      "\n",
      "    290900\t  0.097915\t  0.098154\t  0.083492\t\tCURRENT LEARNING RATE: 0.02723786493459493\n",
      "previous_iter_valid_loss : 0.08612525463104248\n",
      "\n",
      "    291000\t  0.086173\t  0.086125\t  0.083560\t\tCURRENT LEARNING RATE: 0.027210640684054294\n",
      "previous_iter_valid_loss : 0.0838451161980629\n",
      "\n",
      "    291100\t  0.083643\t  0.083845\t  0.083414\t\tCURRENT LEARNING RATE: 0.02718344364415661\n",
      "previous_iter_valid_loss : 0.08333392441272736\n",
      "\n",
      "    291200\t  0.083367\t  0.083334\t  0.083207\t\tCURRENT LEARNING RATE: 0.02715627378770484\n",
      "previous_iter_valid_loss : 0.0759822353720665\n",
      "\n",
      "    291300\t  0.075892\t  0.075982\t  0.083196\t\tCURRENT LEARNING RATE: 0.027129131087529106\n",
      "previous_iter_valid_loss : 0.08701571822166443\n",
      "\n",
      "    291400\t  0.087082\t  0.087016\t  0.083296\t\tCURRENT LEARNING RATE: 0.027102015516486732\n",
      "previous_iter_valid_loss : 0.07999676465988159\n",
      "\n",
      "    291500\t  0.079993\t  0.079997\t  0.083330\t\tCURRENT LEARNING RATE: 0.027074927047462134\n",
      "previous_iter_valid_loss : 0.08389674127101898\n",
      "\n",
      "    291600\t  0.083731\t  0.083897\t  0.083315\t\tCURRENT LEARNING RATE: 0.027047865653366837\n",
      "previous_iter_valid_loss : 0.07725050300359726\n",
      "\n",
      "    291700\t  0.077222\t  0.077251\t  0.083302\t\tCURRENT LEARNING RATE: 0.027020831307139438\n",
      "previous_iter_valid_loss : 0.08386411517858505\n",
      "\n",
      "    291800\t  0.083700\t  0.083864\t  0.083235\t\tCURRENT LEARNING RATE: 0.02699382398174561\n",
      "previous_iter_valid_loss : 0.07789363712072372\n",
      "\n",
      "    291900\t  0.077771\t  0.077894\t  0.083146\t\tCURRENT LEARNING RATE: 0.02696684365017801\n",
      "previous_iter_valid_loss : 0.07605426758527756\n",
      "\n",
      "    292000\t  0.076014\t  0.076054\t  0.082919\t\tCURRENT LEARNING RATE: 0.02693989028545631\n",
      "previous_iter_valid_loss : 0.08155679702758789\n",
      "\n",
      "    292100\t  0.081575\t  0.081557\t  0.082808\t\tCURRENT LEARNING RATE: 0.026912963860627127\n",
      "previous_iter_valid_loss : 0.07649573683738708\n",
      "\n",
      "    292200\t  0.076445\t  0.076496\t  0.082770\t\tCURRENT LEARNING RATE: 0.02688606434876406\n",
      "previous_iter_valid_loss : 0.11375239491462708\n",
      "\n",
      "    292300\t  0.113954\t  0.113752\t  0.083137\t\tCURRENT LEARNING RATE: 0.026859191722967583\n",
      "previous_iter_valid_loss : 0.07701275497674942\n",
      "\n",
      "    292400\t  0.076957\t  0.077013\t  0.083129\t\tCURRENT LEARNING RATE: 0.026832345956365068\n",
      "previous_iter_valid_loss : 0.07601671665906906\n",
      "\n",
      "    292500\t  0.075899\t  0.076017\t  0.083124\t\tCURRENT LEARNING RATE: 0.026805527022110733\n",
      "previous_iter_valid_loss : 0.07601580023765564\n",
      "\n",
      "    292600\t  0.075954\t  0.076016\t  0.083099\t\tCURRENT LEARNING RATE: 0.026778734893385663\n",
      "previous_iter_valid_loss : 0.08021696656942368\n",
      "\n",
      "    292700\t  0.080247\t  0.080217\t  0.083013\t\tCURRENT LEARNING RATE: 0.02675196954339772\n",
      "previous_iter_valid_loss : 0.09544916450977325\n",
      "\n",
      "    292800\t  0.095540\t  0.095449\t  0.083208\t\tCURRENT LEARNING RATE: 0.02672523094538155\n",
      "previous_iter_valid_loss : 0.07639876008033752\n",
      "\n",
      "    292900\t  0.076303\t  0.076399\t  0.083180\t\tCURRENT LEARNING RATE: 0.026698519072598542\n",
      "previous_iter_valid_loss : 0.08643190562725067\n",
      "\n",
      "    293000\t  0.086445\t  0.086432\t  0.083285\t\tCURRENT LEARNING RATE: 0.02667183389833684\n",
      "previous_iter_valid_loss : 0.0796876922249794\n",
      "\n",
      "    293100\t  0.079522\t  0.079688\t  0.083282\t\tCURRENT LEARNING RATE: 0.026645175395911262\n",
      "previous_iter_valid_loss : 0.08663289248943329\n",
      "\n",
      "    293200\t  0.086382\t  0.086633\t  0.083148\t\tCURRENT LEARNING RATE: 0.0266185435386633\n",
      "previous_iter_valid_loss : 0.07638827711343765\n",
      "\n",
      "    293300\t  0.076360\t  0.076388\t  0.082866\t\tCURRENT LEARNING RATE: 0.02659193829996108\n",
      "previous_iter_valid_loss : 0.08114363253116608\n",
      "\n",
      "    293400\t  0.080976\t  0.081144\t  0.082902\t\tCURRENT LEARNING RATE: 0.02656535965319939\n",
      "previous_iter_valid_loss : 0.0756835862994194\n",
      "\n",
      "\n",
      "Current valid loss: 0.0756835862994194;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "    293500\t  0.075596\t  0.075684\t  0.082884\t\tCURRENT LEARNING RATE: 0.026538807571799567\n",
      "previous_iter_valid_loss : 0.0782080814242363\n",
      "\n",
      "    293600\t  0.078052\t  0.078208\t  0.082816\t\tCURRENT LEARNING RATE: 0.02651228202920953\n",
      "previous_iter_valid_loss : 0.07642098516225815\n",
      "\n",
      "    293700\t  0.076320\t  0.076421\t  0.082470\t\tCURRENT LEARNING RATE: 0.026485782998903713\n",
      "previous_iter_valid_loss : 0.12378642708063126\n",
      "\n",
      "    293800\t  0.123561\t  0.123786\t  0.082887\t\tCURRENT LEARNING RATE: 0.026459310454383118\n",
      "previous_iter_valid_loss : 0.07619038969278336\n",
      "\n",
      "    293900\t  0.076095\t  0.076190\t  0.082645\t\tCURRENT LEARNING RATE: 0.026432864369175184\n",
      "previous_iter_valid_loss : 0.07629626989364624\n",
      "\n",
      "    294000\t  0.076213\t  0.076296\t  0.082574\t\tCURRENT LEARNING RATE: 0.02640644471683382\n",
      "previous_iter_valid_loss : 0.07717776298522949\n",
      "\n",
      "    294100\t  0.077150\t  0.077178\t  0.082359\t\tCURRENT LEARNING RATE: 0.026380051470939362\n",
      "previous_iter_valid_loss : 0.07686015963554382\n",
      "\n",
      "    294200\t  0.076803\t  0.076860\t  0.082333\t\tCURRENT LEARNING RATE: 0.026353684605098585\n",
      "previous_iter_valid_loss : 0.07762042433023453\n",
      "\n",
      "    294300\t  0.077559\t  0.077620\t  0.082272\t\tCURRENT LEARNING RATE: 0.026327344092944606\n",
      "previous_iter_valid_loss : 0.07853061705827713\n",
      "\n",
      "    294400\t  0.078433\t  0.078531\t  0.082267\t\tCURRENT LEARNING RATE: 0.02630102990813692\n",
      "previous_iter_valid_loss : 0.08187538385391235\n",
      "\n",
      "    294500\t  0.081697\t  0.081875\t  0.082189\t\tCURRENT LEARNING RATE: 0.02627474202436132\n",
      "previous_iter_valid_loss : 0.07903540879487991\n",
      "\n",
      "    294600\t  0.079024\t  0.079035\t  0.082132\t\tCURRENT LEARNING RATE: 0.02624848041532994\n",
      "previous_iter_valid_loss : 0.07724183797836304\n",
      "\n",
      "    294700\t  0.077220\t  0.077242\t  0.082038\t\tCURRENT LEARNING RATE: 0.02622224505478117\n",
      "previous_iter_valid_loss : 0.11136527359485626\n",
      "\n",
      "    294800\t  0.111113\t  0.111365\t  0.082370\t\tCURRENT LEARNING RATE: 0.026196035916479638\n",
      "previous_iter_valid_loss : 0.07623648643493652\n",
      "\n",
      "    294900\t  0.076136\t  0.076236\t  0.082359\t\tCURRENT LEARNING RATE: 0.02616985297421619\n",
      "previous_iter_valid_loss : 0.09676603227853775\n",
      "\n",
      "    295000\t  0.096556\t  0.096766\t  0.082539\t\tCURRENT LEARNING RATE: 0.026143696201807915\n",
      "previous_iter_valid_loss : 0.07569185644388199\n",
      "\n",
      "    295100\t  0.075605\t  0.075692\t  0.082511\t\tCURRENT LEARNING RATE: 0.026117565573098016\n",
      "previous_iter_valid_loss : 0.08500559628009796\n",
      "\n",
      "    295200\t  0.084813\t  0.085006\t  0.082596\t\tCURRENT LEARNING RATE: 0.026091461061955867\n",
      "previous_iter_valid_loss : 0.0964544340968132\n",
      "\n",
      "    295300\t  0.096224\t  0.096454\t  0.082778\t\tCURRENT LEARNING RATE: 0.026065382642276945\n",
      "previous_iter_valid_loss : 0.07597554475069046\n",
      "\n",
      "    295400\t  0.075908\t  0.075976\t  0.082727\t\tCURRENT LEARNING RATE: 0.026039330287982845\n",
      "previous_iter_valid_loss : 0.08200470358133316\n",
      "\n",
      "    295500\t  0.081803\t  0.082005\t  0.082789\t\tCURRENT LEARNING RATE: 0.026013303973021207\n",
      "previous_iter_valid_loss : 0.07570814341306686\n",
      "\n",
      "    295600\t  0.075615\t  0.075708\t  0.082755\t\tCURRENT LEARNING RATE: 0.02598730367136571\n",
      "previous_iter_valid_loss : 0.08441880345344543\n",
      "\n",
      "    295700\t  0.084445\t  0.084419\t  0.082835\t\tCURRENT LEARNING RATE: 0.025961329357016037\n",
      "previous_iter_valid_loss : 0.07590721547603607\n",
      "\n",
      "    295800\t  0.075792\t  0.075907\t  0.082820\t\tCURRENT LEARNING RATE: 0.025935381003997893\n",
      "previous_iter_valid_loss : 0.07695908099412918\n",
      "\n",
      "    295900\t  0.076817\t  0.076959\t  0.082830\t\tCURRENT LEARNING RATE: 0.025909458586362916\n",
      "previous_iter_valid_loss : 0.07741117477416992\n",
      "\n",
      "    296000\t  0.077354\t  0.077411\t  0.082585\t\tCURRENT LEARNING RATE: 0.025883562078188687\n",
      "previous_iter_valid_loss : 0.08858713507652283\n",
      "\n",
      "    296100\t  0.088706\t  0.088587\t  0.082702\t\tCURRENT LEARNING RATE: 0.02585769145357868\n",
      "previous_iter_valid_loss : 0.10001526772975922\n",
      "\n",
      "    296200\t  0.099814\t  0.100015\t  0.082939\t\tCURRENT LEARNING RATE: 0.02583184668666229\n",
      "previous_iter_valid_loss : 0.07751240581274033\n",
      "\n",
      "    296300\t  0.077397\t  0.077512\t  0.082952\t\tCURRENT LEARNING RATE: 0.025806027751594744\n",
      "previous_iter_valid_loss : 0.13049496710300446\n",
      "\n",
      "    296400\t  0.130251\t  0.130495\t  0.083473\t\tCURRENT LEARNING RATE: 0.0257802346225571\n",
      "previous_iter_valid_loss : 0.0754973515868187\n",
      "\n",
      "\n",
      "Current valid loss: 0.0754973515868187;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "    296500\t  0.075414\t  0.075497\t  0.083313\t\tCURRENT LEARNING RATE: 0.025754467273756212\n",
      "previous_iter_valid_loss : 0.07884715497493744\n",
      "\n",
      "    296600\t  0.078822\t  0.078847\t  0.083299\t\tCURRENT LEARNING RATE: 0.025728725679424757\n",
      "previous_iter_valid_loss : 0.0822729840874672\n",
      "\n",
      "    296700\t  0.082052\t  0.082273\t  0.083231\t\tCURRENT LEARNING RATE: 0.025703009813821127\n",
      "previous_iter_valid_loss : 0.0948043167591095\n",
      "\n",
      "    296800\t  0.094578\t  0.094804\t  0.083417\t\tCURRENT LEARNING RATE: 0.025677319651229453\n",
      "previous_iter_valid_loss : 0.07869190722703934\n",
      "\n",
      "    296900\t  0.078560\t  0.078692\t  0.083379\t\tCURRENT LEARNING RATE: 0.025651655165959554\n",
      "previous_iter_valid_loss : 0.07885950803756714\n",
      "\n",
      "    297000\t  0.078867\t  0.078860\t  0.083376\t\tCURRENT LEARNING RATE: 0.025626016332346974\n",
      "previous_iter_valid_loss : 0.09272392839193344\n",
      "\n",
      "    297100\t  0.092506\t  0.092724\t  0.083357\t\tCURRENT LEARNING RATE: 0.02560040312475286\n",
      "previous_iter_valid_loss : 0.0900997519493103\n",
      "\n",
      "    297200\t  0.089887\t  0.090100\t  0.083372\t\tCURRENT LEARNING RATE: 0.025574815517564006\n",
      "previous_iter_valid_loss : 0.07623066753149033\n",
      "\n",
      "    297300\t  0.076131\t  0.076231\t  0.083295\t\tCURRENT LEARNING RATE: 0.02554925348519279\n",
      "previous_iter_valid_loss : 0.17911185324192047\n",
      "\n",
      "    297400\t  0.179480\t  0.179112\t  0.084237\t\tCURRENT LEARNING RATE: 0.025523717002077197\n",
      "previous_iter_valid_loss : 0.07768859714269638\n",
      "\n",
      "    297500\t  0.077658\t  0.077689\t  0.084145\t\tCURRENT LEARNING RATE: 0.025498206042680733\n",
      "previous_iter_valid_loss : 0.08283203095197678\n",
      "\n",
      "    297600\t  0.082821\t  0.082832\t  0.084096\t\tCURRENT LEARNING RATE: 0.02547272058149244\n",
      "previous_iter_valid_loss : 0.07714680582284927\n",
      "\n",
      "    297700\t  0.077006\t  0.077147\t  0.084090\t\tCURRENT LEARNING RATE: 0.025447260593026835\n",
      "previous_iter_valid_loss : 0.08419231325387955\n",
      "\n",
      "    297800\t  0.084033\t  0.084192\t  0.084125\t\tCURRENT LEARNING RATE: 0.02542182605182396\n",
      "previous_iter_valid_loss : 0.07601504772901535\n",
      "\n",
      "    297900\t  0.075935\t  0.076015\t  0.084119\t\tCURRENT LEARNING RATE: 0.02539641693244925\n",
      "previous_iter_valid_loss : 0.08090425282716751\n",
      "\n",
      "    298000\t  0.080695\t  0.080904\t  0.084164\t\tCURRENT LEARNING RATE: 0.025371033209493594\n",
      "previous_iter_valid_loss : 0.09071949124336243\n",
      "\n",
      "    298100\t  0.090511\t  0.090719\t  0.084216\t\tCURRENT LEARNING RATE: 0.025345674857573247\n",
      "previous_iter_valid_loss : 0.07848146557807922\n",
      "\n",
      "    298200\t  0.078432\t  0.078481\t  0.084164\t\tCURRENT LEARNING RATE: 0.02532034185132988\n",
      "previous_iter_valid_loss : 0.07810164242982864\n",
      "\n",
      "    298300\t  0.078098\t  0.078102\t  0.084141\t\tCURRENT LEARNING RATE: 0.02529503416543048\n",
      "previous_iter_valid_loss : 0.09577971696853638\n",
      "\n",
      "    298400\t  0.095873\t  0.095780\t  0.084230\t\tCURRENT LEARNING RATE: 0.025269751774567348\n",
      "previous_iter_valid_loss : 0.07709396630525589\n",
      "\n",
      "    298500\t  0.076967\t  0.077094\t  0.084185\t\tCURRENT LEARNING RATE: 0.025244494653458086\n",
      "previous_iter_valid_loss : 0.07833567261695862\n",
      "\n",
      "    298600\t  0.078180\t  0.078336\t  0.084193\t\tCURRENT LEARNING RATE: 0.025219262776845594\n",
      "previous_iter_valid_loss : 0.08045241236686707\n",
      "\n",
      "    298700\t  0.080289\t  0.080452\t  0.084235\t\tCURRENT LEARNING RATE: 0.02519405611949798\n",
      "previous_iter_valid_loss : 0.0776195302605629\n",
      "\n",
      "    298800\t  0.077482\t  0.077620\t  0.084180\t\tCURRENT LEARNING RATE: 0.025168874656208585\n",
      "previous_iter_valid_loss : 0.0804000049829483\n",
      "\n",
      "    298900\t  0.080190\t  0.080400\t  0.084216\t\tCURRENT LEARNING RATE: 0.025143718361795932\n",
      "previous_iter_valid_loss : 0.08001699298620224\n",
      "\n",
      "    299000\t  0.079823\t  0.080017\t  0.084214\t\tCURRENT LEARNING RATE: 0.025118587211103747\n",
      "previous_iter_valid_loss : 0.08098437637090683\n",
      "\n",
      "    299100\t  0.080942\t  0.080984\t  0.084103\t\tCURRENT LEARNING RATE: 0.025093481179000867\n",
      "previous_iter_valid_loss : 0.07861359417438507\n",
      "\n",
      "    299200\t  0.078553\t  0.078614\t  0.084112\t\tCURRENT LEARNING RATE: 0.025068400240381258\n",
      "previous_iter_valid_loss : 0.08811034262180328\n",
      "\n",
      "    299300\t  0.087871\t  0.088110\t  0.084161\t\tCURRENT LEARNING RATE: 0.025043344370163964\n",
      "previous_iter_valid_loss : 0.08015625923871994\n",
      "\n",
      "    299400\t  0.080138\t  0.080156\t  0.084027\t\tCURRENT LEARNING RATE: 0.02501831354329314\n",
      "previous_iter_valid_loss : 0.07961387187242508\n",
      "\n",
      "    299500\t  0.079614\t  0.079614\t  0.084060\t\tCURRENT LEARNING RATE: 0.024993307734737947\n",
      "previous_iter_valid_loss : 0.08326946943998337\n",
      "\n",
      "    299600\t  0.083244\t  0.083269\t  0.084134\t\tCURRENT LEARNING RATE: 0.024968326919492568\n",
      "previous_iter_valid_loss : 0.0771164521574974\n",
      "\n",
      "    299700\t  0.076960\t  0.077116\t  0.084039\t\tCURRENT LEARNING RATE: 0.02494337107257618\n",
      "previous_iter_valid_loss : 0.09090743958950043\n",
      "\n",
      "    299800\t  0.090703\t  0.090907\t  0.084185\t\tCURRENT LEARNING RATE: 0.02491844016903295\n",
      "previous_iter_valid_loss : 0.08010401576757431\n",
      "\n",
      "    299900\t  0.079960\t  0.080104\t  0.084139\t\tCURRENT LEARNING RATE: 0.024893534183931972\n",
      "previous_iter_valid_loss : 0.07595817744731903\n",
      "\n",
      "    300000\t  0.075844\t  0.075958\t  0.084134\t\tCURRENT LEARNING RATE: 0.02486865309236725\n",
      "previous_iter_valid_loss : 0.09379834681749344\n",
      "\n",
      "    300100\t  0.093863\t  0.093798\t  0.084230\t\tCURRENT LEARNING RATE: 0.02484379686945769\n",
      "previous_iter_valid_loss : 0.08062851428985596\n",
      "\n",
      "    300200\t  0.080630\t  0.080629\t  0.084263\t\tCURRENT LEARNING RATE: 0.024818965490347063\n",
      "previous_iter_valid_loss : 0.11351268738508224\n",
      "\n",
      "    300300\t  0.113736\t  0.113513\t  0.084622\t\tCURRENT LEARNING RATE: 0.024794158930204\n",
      "previous_iter_valid_loss : 0.12449931353330612\n",
      "\n",
      "    300400\t  0.124291\t  0.124499\t  0.085006\t\tCURRENT LEARNING RATE: 0.02476937716422194\n",
      "previous_iter_valid_loss : 0.07870800048112869\n",
      "\n",
      "    300500\t  0.078535\t  0.078708\t  0.085012\t\tCURRENT LEARNING RATE: 0.024744620167619105\n",
      "previous_iter_valid_loss : 0.07573531568050385\n",
      "\n",
      "    300600\t  0.075624\t  0.075735\t  0.084844\t\tCURRENT LEARNING RATE: 0.024719887915638488\n",
      "previous_iter_valid_loss : 0.08636901527643204\n",
      "\n",
      "    300700\t  0.086396\t  0.086369\t  0.084662\t\tCURRENT LEARNING RATE: 0.024695180383547857\n",
      "previous_iter_valid_loss : 0.07944945245981216\n",
      "\n",
      "    300800\t  0.079403\t  0.079449\t  0.084685\t\tCURRENT LEARNING RATE: 0.02467049754663967\n",
      "previous_iter_valid_loss : 0.07586687803268433\n",
      "\n",
      "    300900\t  0.075782\t  0.075867\t  0.084462\t\tCURRENT LEARNING RATE: 0.024645839380231085\n",
      "previous_iter_valid_loss : 0.08287734538316727\n",
      "\n",
      "    301000\t  0.082882\t  0.082877\t  0.084430\t\tCURRENT LEARNING RATE: 0.024621205859663924\n",
      "previous_iter_valid_loss : 0.07590591907501221\n",
      "\n",
      "    301100\t  0.075872\t  0.075906\t  0.084350\t\tCURRENT LEARNING RATE: 0.02459659696030468\n",
      "previous_iter_valid_loss : 0.08194247633218765\n",
      "\n",
      "    301200\t  0.081931\t  0.081942\t  0.084336\t\tCURRENT LEARNING RATE: 0.024572012657544454\n",
      "previous_iter_valid_loss : 0.07743539661169052\n",
      "\n",
      "    301300\t  0.077276\t  0.077435\t  0.084351\t\tCURRENT LEARNING RATE: 0.024547452926798927\n",
      "previous_iter_valid_loss : 0.08547163754701614\n",
      "\n",
      "    301400\t  0.085534\t  0.085472\t  0.084335\t\tCURRENT LEARNING RATE: 0.024522917743508364\n",
      "previous_iter_valid_loss : 0.07776138931512833\n",
      "\n",
      "    301500\t  0.077649\t  0.077761\t  0.084313\t\tCURRENT LEARNING RATE: 0.0244984070831376\n",
      "previous_iter_valid_loss : 0.08755599707365036\n",
      "\n",
      "    301600\t  0.087379\t  0.087556\t  0.084350\t\tCURRENT LEARNING RATE: 0.024473920921175958\n",
      "previous_iter_valid_loss : 0.10860715806484222\n",
      "\n",
      "    301700\t  0.108785\t  0.108607\t  0.084663\t\tCURRENT LEARNING RATE: 0.02444945923313728\n",
      "previous_iter_valid_loss : 0.0756627768278122\n",
      "\n",
      "    301800\t  0.075620\t  0.075663\t  0.084581\t\tCURRENT LEARNING RATE: 0.02442502199455986\n",
      "previous_iter_valid_loss : 0.07663843035697937\n",
      "\n",
      "    301900\t  0.076515\t  0.076638\t  0.084569\t\tCURRENT LEARNING RATE: 0.02440060918100648\n",
      "previous_iter_valid_loss : 0.08073654770851135\n",
      "\n",
      "    302000\t  0.080571\t  0.080737\t  0.084615\t\tCURRENT LEARNING RATE: 0.024376220768064314\n",
      "previous_iter_valid_loss : 0.07945409417152405\n",
      "\n",
      "    302100\t  0.079438\t  0.079454\t  0.084594\t\tCURRENT LEARNING RATE: 0.024351856731344948\n",
      "previous_iter_valid_loss : 0.0857367217540741\n",
      "\n",
      "    302200\t  0.085744\t  0.085737\t  0.084687\t\tCURRENT LEARNING RATE: 0.024327517046484334\n",
      "previous_iter_valid_loss : 0.07605490833520889\n",
      "\n",
      "    302300\t  0.075914\t  0.076055\t  0.084310\t\tCURRENT LEARNING RATE: 0.024303201689142802\n",
      "previous_iter_valid_loss : 0.07548584789037704\n",
      "\n",
      "\n",
      "Current valid loss: 0.07548584789037704;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "    302400\t  0.075385\t  0.075486\t  0.084294\t\tCURRENT LEARNING RATE: 0.024278910635004987\n",
      "previous_iter_valid_loss : 0.07624485343694687\n",
      "\n",
      "    302500\t  0.076189\t  0.076245\t  0.084297\t\tCURRENT LEARNING RATE: 0.024254643859779827\n",
      "previous_iter_valid_loss : 0.09260747581720352\n",
      "\n",
      "    302600\t  0.092434\t  0.092607\t  0.084463\t\tCURRENT LEARNING RATE: 0.024230401339200538\n",
      "previous_iter_valid_loss : 0.08143066614866257\n",
      "\n",
      "    302700\t  0.081398\t  0.081431\t  0.084475\t\tCURRENT LEARNING RATE: 0.02420618304902462\n",
      "previous_iter_valid_loss : 0.07713732123374939\n",
      "\n",
      "    302800\t  0.077106\t  0.077137\t  0.084292\t\tCURRENT LEARNING RATE: 0.024181988965033766\n",
      "previous_iter_valid_loss : 0.07578916847705841\n",
      "\n",
      "    302900\t  0.075720\t  0.075789\t  0.084286\t\tCURRENT LEARNING RATE: 0.024157819063033895\n",
      "previous_iter_valid_loss : 0.08274193108081818\n",
      "\n",
      "    303000\t  0.082723\t  0.082742\t  0.084249\t\tCURRENT LEARNING RATE: 0.024133673318855086\n",
      "previous_iter_valid_loss : 0.09141193330287933\n",
      "\n",
      "    303100\t  0.091470\t  0.091412\t  0.084366\t\tCURRENT LEARNING RATE: 0.02410955170835162\n",
      "previous_iter_valid_loss : 0.09029322117567062\n",
      "\n",
      "    303200\t  0.090096\t  0.090293\t  0.084403\t\tCURRENT LEARNING RATE: 0.024085454207401873\n",
      "previous_iter_valid_loss : 0.07673899084329605\n",
      "\n",
      "    303300\t  0.076725\t  0.076739\t  0.084406\t\tCURRENT LEARNING RATE: 0.024061380791908338\n",
      "previous_iter_valid_loss : 0.07745949923992157\n",
      "\n",
      "    303400\t  0.077324\t  0.077459\t  0.084369\t\tCURRENT LEARNING RATE: 0.02403733143779759\n",
      "previous_iter_valid_loss : 0.07716726511716843\n",
      "\n",
      "    303500\t  0.077149\t  0.077167\t  0.084384\t\tCURRENT LEARNING RATE: 0.024013306121020293\n",
      "previous_iter_valid_loss : 0.08775699883699417\n",
      "\n",
      "    303600\t  0.087586\t  0.087757\t  0.084480\t\tCURRENT LEARNING RATE: 0.023989304817551117\n",
      "previous_iter_valid_loss : 0.07952465862035751\n",
      "\n",
      "    303700\t  0.079431\t  0.079525\t  0.084511\t\tCURRENT LEARNING RATE: 0.02396532750338876\n",
      "previous_iter_valid_loss : 0.07714342325925827\n",
      "\n",
      "    303800\t  0.077030\t  0.077143\t  0.084044\t\tCURRENT LEARNING RATE: 0.02394137415455589\n",
      "previous_iter_valid_loss : 0.07624050229787827\n",
      "\n",
      "    303900\t  0.076199\t  0.076241\t  0.084045\t\tCURRENT LEARNING RATE: 0.023917444747099184\n",
      "previous_iter_valid_loss : 0.07543335855007172\n",
      "\n",
      "\n",
      "Current valid loss: 0.07543335855007172;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "    304000\t  0.075364\t  0.075433\t  0.084036\t\tCURRENT LEARNING RATE: 0.023893539257089216\n",
      "previous_iter_valid_loss : 0.07826574891805649\n",
      "\n",
      "    304100\t  0.078159\t  0.078266\t  0.084047\t\tCURRENT LEARNING RATE: 0.023869657660620498\n",
      "previous_iter_valid_loss : 0.0868062674999237\n",
      "\n",
      "    304200\t  0.086842\t  0.086806\t  0.084146\t\tCURRENT LEARNING RATE: 0.023845799933811418\n",
      "previous_iter_valid_loss : 0.07715734094381332\n",
      "\n",
      "    304300\t  0.077129\t  0.077157\t  0.084142\t\tCURRENT LEARNING RATE: 0.023821966052804268\n",
      "previous_iter_valid_loss : 0.07858522236347198\n",
      "\n",
      "    304400\t  0.078459\t  0.078585\t  0.084142\t\tCURRENT LEARNING RATE: 0.02379815599376516\n",
      "previous_iter_valid_loss : 0.09300871938467026\n",
      "\n",
      "    304500\t  0.093120\t  0.093009\t  0.084254\t\tCURRENT LEARNING RATE: 0.023774369732884024\n",
      "previous_iter_valid_loss : 0.08689122647047043\n",
      "\n",
      "    304600\t  0.086718\t  0.086891\t  0.084332\t\tCURRENT LEARNING RATE: 0.023750607246374594\n",
      "previous_iter_valid_loss : 0.07612721621990204\n",
      "\n",
      "    304700\t  0.076039\t  0.076127\t  0.084321\t\tCURRENT LEARNING RATE: 0.0237268685104744\n",
      "previous_iter_valid_loss : 0.08080392330884933\n",
      "\n",
      "    304800\t  0.080643\t  0.080804\t  0.084015\t\tCURRENT LEARNING RATE: 0.023703153501444696\n",
      "previous_iter_valid_loss : 0.11733854562044144\n",
      "\n",
      "    304900\t  0.117569\t  0.117339\t  0.084426\t\tCURRENT LEARNING RATE: 0.023679462195570464\n",
      "previous_iter_valid_loss : 0.08224157989025116\n",
      "\n",
      "    305000\t  0.082061\t  0.082242\t  0.084281\t\tCURRENT LEARNING RATE: 0.023655794569160393\n",
      "previous_iter_valid_loss : 0.07864189147949219\n",
      "\n",
      "    305100\t  0.078496\t  0.078642\t  0.084311\t\tCURRENT LEARNING RATE: 0.023632150598546873\n",
      "previous_iter_valid_loss : 0.07992129772901535\n",
      "\n",
      "    305200\t  0.079953\t  0.079921\t  0.084260\t\tCURRENT LEARNING RATE: 0.02360853026008592\n",
      "previous_iter_valid_loss : 0.08544861525297165\n",
      "\n",
      "    305300\t  0.085513\t  0.085449\t  0.084150\t\tCURRENT LEARNING RATE: 0.023584933530157195\n",
      "previous_iter_valid_loss : 0.07850492745637894\n",
      "\n",
      "    305400\t  0.078350\t  0.078505\t  0.084175\t\tCURRENT LEARNING RATE: 0.023561360385163956\n",
      "previous_iter_valid_loss : 0.07622278481721878\n",
      "\n",
      "    305500\t  0.076125\t  0.076223\t  0.084117\t\tCURRENT LEARNING RATE: 0.023537810801533075\n",
      "previous_iter_valid_loss : 0.09471803903579712\n",
      "\n",
      "    305600\t  0.094510\t  0.094718\t  0.084307\t\tCURRENT LEARNING RATE: 0.02351428475571496\n",
      "previous_iter_valid_loss : 0.07606763392686844\n",
      "\n",
      "    305700\t  0.075925\t  0.076068\t  0.084224\t\tCURRENT LEARNING RATE: 0.023490782224183555\n",
      "previous_iter_valid_loss : 0.07848583161830902\n",
      "\n",
      "    305800\t  0.078441\t  0.078486\t  0.084250\t\tCURRENT LEARNING RATE: 0.023467303183436324\n",
      "previous_iter_valid_loss : 0.08812452107667923\n",
      "\n",
      "    305900\t  0.087936\t  0.088125\t  0.084361\t\tCURRENT LEARNING RATE: 0.023443847609994243\n",
      "previous_iter_valid_loss : 0.08705402910709381\n",
      "\n",
      "    306000\t  0.086870\t  0.087054\t  0.084458\t\tCURRENT LEARNING RATE: 0.023420415480401725\n",
      "previous_iter_valid_loss : 0.08245889842510223\n",
      "\n",
      "    306100\t  0.082292\t  0.082459\t  0.084396\t\tCURRENT LEARNING RATE: 0.02339700677122664\n",
      "previous_iter_valid_loss : 0.09272418171167374\n",
      "\n",
      "    306200\t  0.092547\t  0.092724\t  0.084324\t\tCURRENT LEARNING RATE: 0.023373621459060263\n",
      "previous_iter_valid_loss : 0.08786387741565704\n",
      "\n",
      "    306300\t  0.087686\t  0.087864\t  0.084427\t\tCURRENT LEARNING RATE: 0.023350259520517305\n",
      "previous_iter_valid_loss : 0.07553993165493011\n",
      "\n",
      "    306400\t  0.075443\t  0.075540\t  0.083877\t\tCURRENT LEARNING RATE: 0.023326920932235814\n",
      "previous_iter_valid_loss : 0.07642506062984467\n",
      "\n",
      "    306500\t  0.076294\t  0.076425\t  0.083887\t\tCURRENT LEARNING RATE: 0.0233036056708772\n",
      "previous_iter_valid_loss : 0.07854647934436798\n",
      "\n",
      "    306600\t  0.078514\t  0.078546\t  0.083884\t\tCURRENT LEARNING RATE: 0.023280313713126187\n",
      "previous_iter_valid_loss : 0.0804484412074089\n",
      "\n",
      "    306700\t  0.080431\t  0.080448\t  0.083866\t\tCURRENT LEARNING RATE: 0.023257045035690836\n",
      "previous_iter_valid_loss : 0.08963081240653992\n",
      "\n",
      "    306800\t  0.089466\t  0.089631\t  0.083814\t\tCURRENT LEARNING RATE: 0.02323379961530246\n",
      "previous_iter_valid_loss : 0.07680346816778183\n",
      "\n",
      "    306900\t  0.076751\t  0.076803\t  0.083795\t\tCURRENT LEARNING RATE: 0.023210577428715636\n",
      "previous_iter_valid_loss : 0.07630151510238647\n",
      "\n",
      "    307000\t  0.076261\t  0.076302\t  0.083769\t\tCURRENT LEARNING RATE: 0.023187378452708164\n",
      "previous_iter_valid_loss : 0.07554470747709274\n",
      "\n",
      "    307100\t  0.075453\t  0.075545\t  0.083598\t\tCURRENT LEARNING RATE: 0.023164202664081087\n",
      "previous_iter_valid_loss : 0.07766745239496231\n",
      "\n",
      "    307200\t  0.077532\t  0.077667\t  0.083473\t\tCURRENT LEARNING RATE: 0.023141050039658606\n",
      "previous_iter_valid_loss : 0.09235794097185135\n",
      "\n",
      "    307300\t  0.092440\t  0.092358\t  0.083634\t\tCURRENT LEARNING RATE: 0.023117920556288092\n",
      "previous_iter_valid_loss : 0.07709542661905289\n",
      "\n",
      "    307400\t  0.077089\t  0.077095\t  0.082614\t\tCURRENT LEARNING RATE: 0.02309481419084005\n",
      "previous_iter_valid_loss : 0.09810739010572433\n",
      "\n",
      "    307500\t  0.098260\t  0.098107\t  0.082819\t\tCURRENT LEARNING RATE: 0.023071730920208134\n",
      "previous_iter_valid_loss : 0.08626262843608856\n",
      "\n",
      "    307600\t  0.086310\t  0.086263\t  0.082853\t\tCURRENT LEARNING RATE: 0.02304867072130906\n",
      "previous_iter_valid_loss : 0.0762069821357727\n",
      "\n",
      "    307700\t  0.076163\t  0.076207\t  0.082843\t\tCURRENT LEARNING RATE: 0.023025633571082633\n",
      "previous_iter_valid_loss : 0.07775208353996277\n",
      "\n",
      "    307800\t  0.077685\t  0.077752\t  0.082779\t\tCURRENT LEARNING RATE: 0.02300261944649168\n",
      "previous_iter_valid_loss : 0.07877584546804428\n",
      "\n",
      "    307900\t  0.078601\t  0.078776\t  0.082807\t\tCURRENT LEARNING RATE: 0.022979628324522102\n",
      "previous_iter_valid_loss : 0.07870184630155563\n",
      "\n",
      "    308000\t  0.078592\t  0.078702\t  0.082785\t\tCURRENT LEARNING RATE: 0.022956660182182766\n",
      "previous_iter_valid_loss : 0.0822700634598732\n",
      "\n",
      "    308100\t  0.082274\t  0.082270\t  0.082700\t\tCURRENT LEARNING RATE: 0.02293371499650552\n",
      "previous_iter_valid_loss : 0.07889986038208008\n",
      "\n",
      "    308200\t  0.078881\t  0.078900\t  0.082704\t\tCURRENT LEARNING RATE: 0.022910792744545178\n",
      "previous_iter_valid_loss : 0.10063061863183975\n",
      "\n",
      "    308300\t  0.100787\t  0.100631\t  0.082930\t\tCURRENT LEARNING RATE: 0.022887893403379496\n",
      "previous_iter_valid_loss : 0.08162016421556473\n",
      "\n",
      "    308400\t  0.081412\t  0.081620\t  0.082788\t\tCURRENT LEARNING RATE: 0.022865016950109125\n",
      "previous_iter_valid_loss : 0.07567927986383438\n",
      "\n",
      "    308500\t  0.075567\t  0.075679\t  0.082774\t\tCURRENT LEARNING RATE: 0.02284216336185761\n",
      "previous_iter_valid_loss : 0.07542572915554047\n",
      "\n",
      "\n",
      "Current valid loss: 0.07542572915554047;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "    308600\t  0.075323\t  0.075426\t  0.082745\t\tCURRENT LEARNING RATE: 0.02281933261577135\n",
      "previous_iter_valid_loss : 0.07844268530607224\n",
      "\n",
      "    308700\t  0.078286\t  0.078443\t  0.082725\t\tCURRENT LEARNING RATE: 0.022796524689019618\n",
      "previous_iter_valid_loss : 0.08310512453317642\n",
      "\n",
      "    308800\t  0.082974\t  0.083105\t  0.082780\t\tCURRENT LEARNING RATE: 0.022773739558794474\n",
      "previous_iter_valid_loss : 0.07994559407234192\n",
      "\n",
      "    308900\t  0.079821\t  0.079946\t  0.082775\t\tCURRENT LEARNING RATE: 0.022750977202310785\n",
      "previous_iter_valid_loss : 0.08306858688592911\n",
      "\n",
      "    309000\t  0.082914\t  0.083069\t  0.082805\t\tCURRENT LEARNING RATE: 0.022728237596806186\n",
      "previous_iter_valid_loss : 0.08099837601184845\n",
      "\n",
      "    309100\t  0.080853\t  0.080998\t  0.082806\t\tCURRENT LEARNING RATE: 0.02270552071954109\n",
      "previous_iter_valid_loss : 0.09799530357122421\n",
      "\n",
      "    309200\t  0.098139\t  0.097995\t  0.082999\t\tCURRENT LEARNING RATE: 0.0226828265477986\n",
      "previous_iter_valid_loss : 0.09569087624549866\n",
      "\n",
      "    309300\t  0.095530\t  0.095691\t  0.083075\t\tCURRENT LEARNING RATE: 0.022660155058884555\n",
      "previous_iter_valid_loss : 0.09441899508237839\n",
      "\n",
      "    309400\t  0.094563\t  0.094419\t  0.083218\t\tCURRENT LEARNING RATE: 0.022637506230127443\n",
      "previous_iter_valid_loss : 0.09059759974479675\n",
      "\n",
      "    309500\t  0.090716\t  0.090598\t  0.083328\t\tCURRENT LEARNING RATE: 0.02261488003887846\n",
      "previous_iter_valid_loss : 0.1013977974653244\n",
      "\n",
      "    309600\t  0.101192\t  0.101398\t  0.083509\t\tCURRENT LEARNING RATE: 0.0225922764625114\n",
      "previous_iter_valid_loss : 0.0771198645234108\n",
      "\n",
      "    309700\t  0.077081\t  0.077120\t  0.083509\t\tCURRENT LEARNING RATE: 0.02256969547842268\n",
      "previous_iter_valid_loss : 0.08524380624294281\n",
      "\n",
      "    309800\t  0.085079\t  0.085244\t  0.083452\t\tCURRENT LEARNING RATE: 0.022547137064031313\n",
      "previous_iter_valid_loss : 0.07565194368362427\n",
      "\n",
      "    309900\t  0.075576\t  0.075652\t  0.083408\t\tCURRENT LEARNING RATE: 0.0225246011967789\n",
      "previous_iter_valid_loss : 0.08238238841295242\n",
      "\n",
      "    310000\t  0.082224\t  0.082382\t  0.083472\t\tCURRENT LEARNING RATE: 0.022502087854129563\n",
      "previous_iter_valid_loss : 0.07553824782371521\n",
      "\n",
      "    310100\t  0.075430\t  0.075538\t  0.083290\t\tCURRENT LEARNING RATE: 0.02247959701356995\n",
      "previous_iter_valid_loss : 0.07843827456235886\n",
      "\n",
      "    310200\t  0.078398\t  0.078438\t  0.083268\t\tCURRENT LEARNING RATE: 0.022457128652609216\n",
      "previous_iter_valid_loss : 0.08052301406860352\n",
      "\n",
      "    310300\t  0.080353\t  0.080523\t  0.082938\t\tCURRENT LEARNING RATE: 0.022434682748779015\n",
      "previous_iter_valid_loss : 0.07898392528295517\n",
      "\n",
      "    310400\t  0.078853\t  0.078984\t  0.082483\t\tCURRENT LEARNING RATE: 0.022412259279633435\n",
      "previous_iter_valid_loss : 0.13863980770111084\n",
      "\n",
      "    310500\t  0.138487\t  0.138640\t  0.083082\t\tCURRENT LEARNING RATE: 0.022389858222749002\n",
      "previous_iter_valid_loss : 0.0805145874619484\n",
      "\n",
      "    310600\t  0.080340\t  0.080515\t  0.083130\t\tCURRENT LEARNING RATE: 0.022367479555724646\n",
      "previous_iter_valid_loss : 0.08200943470001221\n",
      "\n",
      "    310700\t  0.081903\t  0.082009\t  0.083086\t\tCURRENT LEARNING RATE: 0.02234512325618172\n",
      "previous_iter_valid_loss : 0.08656548708677292\n",
      "\n",
      "    310800\t  0.086620\t  0.086565\t  0.083157\t\tCURRENT LEARNING RATE: 0.02232278930176391\n",
      "previous_iter_valid_loss : 0.07618960738182068\n",
      "\n",
      "    310900\t  0.076035\t  0.076190\t  0.083160\t\tCURRENT LEARNING RATE: 0.022300477670137268\n",
      "previous_iter_valid_loss : 0.08420407772064209\n",
      "\n",
      "    311000\t  0.084269\t  0.084204\t  0.083174\t\tCURRENT LEARNING RATE: 0.02227818833899014\n",
      "previous_iter_valid_loss : 0.09570343792438507\n",
      "\n",
      "    311100\t  0.095495\t  0.095703\t  0.083372\t\tCURRENT LEARNING RATE: 0.02225592128603322\n",
      "previous_iter_valid_loss : 0.07593999803066254\n",
      "\n",
      "    311200\t  0.075875\t  0.075940\t  0.083312\t\tCURRENT LEARNING RATE: 0.02223367648899944\n",
      "previous_iter_valid_loss : 0.08226559311151505\n",
      "\n",
      "    311300\t  0.082142\t  0.082266\t  0.083360\t\tCURRENT LEARNING RATE: 0.022211453925643998\n",
      "previous_iter_valid_loss : 0.07549721002578735\n",
      "\n",
      "    311400\t  0.075415\t  0.075497\t  0.083260\t\tCURRENT LEARNING RATE: 0.022189253573744325\n",
      "previous_iter_valid_loss : 0.07881259173154831\n",
      "\n",
      "    311500\t  0.078676\t  0.078813\t  0.083271\t\tCURRENT LEARNING RATE: 0.022167075411100086\n",
      "previous_iter_valid_loss : 0.11935216933488846\n",
      "\n",
      "    311600\t  0.119105\t  0.119352\t  0.083589\t\tCURRENT LEARNING RATE: 0.022144919415533107\n",
      "previous_iter_valid_loss : 0.07898497581481934\n",
      "\n",
      "    311700\t  0.078869\t  0.078985\t  0.083293\t\tCURRENT LEARNING RATE: 0.022122785564887386\n",
      "previous_iter_valid_loss : 0.0774056538939476\n",
      "\n",
      "    311800\t  0.077283\t  0.077406\t  0.083310\t\tCURRENT LEARNING RATE: 0.022100673837029065\n",
      "previous_iter_valid_loss : 0.08153744041919708\n",
      "\n",
      "    311900\t  0.081562\t  0.081537\t  0.083359\t\tCURRENT LEARNING RATE: 0.02207858420984643\n",
      "previous_iter_valid_loss : 0.07712872326374054\n",
      "\n",
      "    312000\t  0.077086\t  0.077129\t  0.083323\t\tCURRENT LEARNING RATE: 0.022056516661249848\n",
      "previous_iter_valid_loss : 0.08970914781093597\n",
      "\n",
      "    312100\t  0.089533\t  0.089709\t  0.083425\t\tCURRENT LEARNING RATE: 0.022034471169171763\n",
      "previous_iter_valid_loss : 0.08850763738155365\n",
      "\n",
      "    312200\t  0.088605\t  0.088508\t  0.083453\t\tCURRENT LEARNING RATE: 0.022012447711566675\n",
      "previous_iter_valid_loss : 0.08120772242546082\n",
      "\n",
      "    312300\t  0.081036\t  0.081208\t  0.083505\t\tCURRENT LEARNING RATE: 0.021990446266411143\n",
      "previous_iter_valid_loss : 0.07556576281785965\n",
      "\n",
      "    312400\t  0.075460\t  0.075566\t  0.083505\t\tCURRENT LEARNING RATE: 0.02196846681170371\n",
      "previous_iter_valid_loss : 0.08085109293460846\n",
      "\n",
      "    312500\t  0.080908\t  0.080851\t  0.083552\t\tCURRENT LEARNING RATE: 0.02194650932546492\n",
      "previous_iter_valid_loss : 0.10163713991641998\n",
      "\n",
      "    312600\t  0.101840\t  0.101637\t  0.083642\t\tCURRENT LEARNING RATE: 0.02192457378573728\n",
      "previous_iter_valid_loss : 0.07939495146274567\n",
      "\n",
      "    312700\t  0.079455\t  0.079395\t  0.083621\t\tCURRENT LEARNING RATE: 0.021902660170585245\n",
      "previous_iter_valid_loss : 0.0825890526175499\n",
      "\n",
      "    312800\t  0.082622\t  0.082589\t  0.083676\t\tCURRENT LEARNING RATE: 0.021880768458095216\n",
      "previous_iter_valid_loss : 0.09045682847499847\n",
      "\n",
      "    312900\t  0.090293\t  0.090457\t  0.083823\t\tCURRENT LEARNING RATE: 0.02185889862637547\n",
      "previous_iter_valid_loss : 0.09259684383869171\n",
      "\n",
      "    313000\t  0.092710\t  0.092597\t  0.083921\t\tCURRENT LEARNING RATE: 0.02183705065355617\n",
      "previous_iter_valid_loss : 0.07749960571527481\n",
      "\n",
      "    313100\t  0.077362\t  0.077500\t  0.083782\t\tCURRENT LEARNING RATE: 0.021815224517789337\n",
      "previous_iter_valid_loss : 0.07792729884386063\n",
      "\n",
      "    313200\t  0.077811\t  0.077927\t  0.083658\t\tCURRENT LEARNING RATE: 0.021793420197248847\n",
      "previous_iter_valid_loss : 0.07781844586133957\n",
      "\n",
      "    313300\t  0.077825\t  0.077818\t  0.083669\t\tCURRENT LEARNING RATE: 0.02177163767013037\n",
      "previous_iter_valid_loss : 0.07749728113412857\n",
      "\n",
      "    313400\t  0.077478\t  0.077497\t  0.083670\t\tCURRENT LEARNING RATE: 0.021749876914651377\n",
      "previous_iter_valid_loss : 0.0771595910191536\n",
      "\n",
      "    313500\t  0.077090\t  0.077160\t  0.083669\t\tCURRENT LEARNING RATE: 0.021728137909051103\n",
      "previous_iter_valid_loss : 0.08405382931232452\n",
      "\n",
      "    313600\t  0.084155\t  0.084054\t  0.083632\t\tCURRENT LEARNING RATE: 0.021706420631590558\n",
      "previous_iter_valid_loss : 0.07591001689434052\n",
      "\n",
      "    313700\t  0.075825\t  0.075910\t  0.083596\t\tCURRENT LEARNING RATE: 0.021684725060552454\n",
      "previous_iter_valid_loss : 0.10977234691381454\n",
      "\n",
      "    313800\t  0.109984\t  0.109772\t  0.083923\t\tCURRENT LEARNING RATE: 0.021663051174241214\n",
      "previous_iter_valid_loss : 0.08380681276321411\n",
      "\n",
      "    313900\t  0.083836\t  0.083807\t  0.083998\t\tCURRENT LEARNING RATE: 0.021641398950982948\n",
      "previous_iter_valid_loss : 0.0797128900885582\n",
      "\n",
      "    314000\t  0.079719\t  0.079713\t  0.084041\t\tCURRENT LEARNING RATE: 0.021619768369125443\n",
      "previous_iter_valid_loss : 0.08274216204881668\n",
      "\n",
      "    314100\t  0.082603\t  0.082742\t  0.084086\t\tCURRENT LEARNING RATE: 0.02159815940703811\n",
      "previous_iter_valid_loss : 0.08515078574419022\n",
      "\n",
      "    314200\t  0.084952\t  0.085151\t  0.084069\t\tCURRENT LEARNING RATE: 0.021576572043111985\n",
      "previous_iter_valid_loss : 0.08573001623153687\n",
      "\n",
      "    314300\t  0.085540\t  0.085730\t  0.084155\t\tCURRENT LEARNING RATE: 0.021555006255759693\n",
      "previous_iter_valid_loss : 0.07609176635742188\n",
      "\n",
      "    314400\t  0.076039\t  0.076092\t  0.084130\t\tCURRENT LEARNING RATE: 0.02153346202341546\n",
      "previous_iter_valid_loss : 0.091019406914711\n",
      "\n",
      "    314500\t  0.091103\t  0.091019\t  0.084110\t\tCURRENT LEARNING RATE: 0.021511939324535045\n",
      "previous_iter_valid_loss : 0.08244962990283966\n",
      "\n",
      "    314600\t  0.082481\t  0.082450\t  0.084066\t\tCURRENT LEARNING RATE: 0.021490438137595748\n",
      "previous_iter_valid_loss : 0.08611135929822922\n",
      "\n",
      "    314700\t  0.085953\t  0.086111\t  0.084166\t\tCURRENT LEARNING RATE: 0.021468958441096368\n",
      "previous_iter_valid_loss : 0.07700472325086594\n",
      "\n",
      "    314800\t  0.076891\t  0.077005\t  0.084128\t\tCURRENT LEARNING RATE: 0.02144750021355723\n",
      "previous_iter_valid_loss : 0.07727494835853577\n",
      "\n",
      "    314900\t  0.077230\t  0.077275\t  0.083727\t\tCURRENT LEARNING RATE: 0.021426063433520093\n",
      "previous_iter_valid_loss : 0.07590846717357635\n",
      "\n",
      "    315000\t  0.075797\t  0.075908\t  0.083664\t\tCURRENT LEARNING RATE: 0.021404648079548172\n",
      "previous_iter_valid_loss : 0.07976030558347702\n",
      "\n",
      "    315100\t  0.079742\t  0.079760\t  0.083675\t\tCURRENT LEARNING RATE: 0.02138325413022611\n",
      "previous_iter_valid_loss : 0.09086780995130539\n",
      "\n",
      "    315200\t  0.090695\t  0.090868\t  0.083784\t\tCURRENT LEARNING RATE: 0.021361881564159965\n",
      "previous_iter_valid_loss : 0.0838003158569336\n",
      "\n",
      "    315300\t  0.083630\t  0.083800\t  0.083768\t\tCURRENT LEARNING RATE: 0.021340530359977166\n",
      "previous_iter_valid_loss : 0.07906842976808548\n",
      "\n",
      "    315400\t  0.078912\t  0.079068\t  0.083773\t\tCURRENT LEARNING RATE: 0.021319200496326504\n",
      "previous_iter_valid_loss : 0.07695192843675613\n",
      "\n",
      "    315500\t  0.076880\t  0.076952\t  0.083781\t\tCURRENT LEARNING RATE: 0.021297891951878107\n",
      "previous_iter_valid_loss : 0.07567887753248215\n",
      "\n",
      "    315600\t  0.075575\t  0.075679\t  0.083590\t\tCURRENT LEARNING RATE: 0.021276604705323447\n",
      "previous_iter_valid_loss : 0.07536888122558594\n",
      "\n",
      "\n",
      "Current valid loss: 0.07536888122558594;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "    315700\t  0.075261\t  0.075369\t  0.083583\t\tCURRENT LEARNING RATE: 0.021255338735375263\n",
      "previous_iter_valid_loss : 0.08319225162267685\n",
      "\n",
      "    315800\t  0.083222\t  0.083192\t  0.083630\t\tCURRENT LEARNING RATE: 0.021234094020767588\n",
      "previous_iter_valid_loss : 0.0757913589477539\n",
      "\n",
      "    315900\t  0.075694\t  0.075791\t  0.083507\t\tCURRENT LEARNING RATE: 0.021212870540255693\n",
      "previous_iter_valid_loss : 0.07676780968904495\n",
      "\n",
      "    316000\t  0.076627\t  0.076768\t  0.083404\t\tCURRENT LEARNING RATE: 0.021191668272616114\n",
      "previous_iter_valid_loss : 0.07557780295610428\n",
      "\n",
      "    316100\t  0.075487\t  0.075578\t  0.083335\t\tCURRENT LEARNING RATE: 0.021170487196646572\n",
      "previous_iter_valid_loss : 0.10281023383140564\n",
      "\n",
      "    316200\t  0.102977\t  0.102810\t  0.083436\t\tCURRENT LEARNING RATE: 0.021149327291165997\n",
      "previous_iter_valid_loss : 0.07743413746356964\n",
      "\n",
      "    316300\t  0.077287\t  0.077434\t  0.083332\t\tCURRENT LEARNING RATE: 0.021128188535014462\n",
      "previous_iter_valid_loss : 0.08221538364887238\n",
      "\n",
      "    316400\t  0.082055\t  0.082215\t  0.083399\t\tCURRENT LEARNING RATE: 0.021107070907053233\n",
      "previous_iter_valid_loss : 0.09408394247293472\n",
      "\n",
      "    316500\t  0.094225\t  0.094084\t  0.083575\t\tCURRENT LEARNING RATE: 0.021085974386164667\n",
      "previous_iter_valid_loss : 0.08865845948457718\n",
      "\n",
      "    316600\t  0.088738\t  0.088658\t  0.083676\t\tCURRENT LEARNING RATE: 0.02106489895125225\n",
      "previous_iter_valid_loss : 0.07720965892076492\n",
      "\n",
      "    316700\t  0.077073\t  0.077210\t  0.083644\t\tCURRENT LEARNING RATE: 0.021043844581240527\n",
      "previous_iter_valid_loss : 0.07565142959356308\n",
      "\n",
      "    316800\t  0.075569\t  0.075651\t  0.083504\t\tCURRENT LEARNING RATE: 0.021022811255075147\n",
      "previous_iter_valid_loss : 0.07621625810861588\n",
      "\n",
      "    316900\t  0.076122\t  0.076216\t  0.083498\t\tCURRENT LEARNING RATE: 0.021001798951722776\n",
      "previous_iter_valid_loss : 0.10970835387706757\n",
      "\n",
      "    317000\t  0.109901\t  0.109708\t  0.083832\t\tCURRENT LEARNING RATE: 0.020980807650171105\n",
      "previous_iter_valid_loss : 0.08067786693572998\n",
      "\n",
      "    317100\t  0.080494\t  0.080678\t  0.083884\t\tCURRENT LEARNING RATE: 0.020959837329428826\n",
      "previous_iter_valid_loss : 0.08297013491392136\n",
      "\n",
      "    317200\t  0.082985\t  0.082970\t  0.083937\t\tCURRENT LEARNING RATE: 0.02093888796852563\n",
      "previous_iter_valid_loss : 0.07536792010068893\n",
      "\n",
      "\n",
      "Current valid loss: 0.07536792010068893;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "    317300\t  0.075271\t  0.075368\t  0.083767\t\tCURRENT LEARNING RATE: 0.02091795954651215\n",
      "previous_iter_valid_loss : 0.09024497121572495\n",
      "\n",
      "    317400\t  0.090362\t  0.090245\t  0.083898\t\tCURRENT LEARNING RATE: 0.02089705204245996\n",
      "previous_iter_valid_loss : 0.09761321544647217\n",
      "\n",
      "    317500\t  0.097701\t  0.097613\t  0.083893\t\tCURRENT LEARNING RATE: 0.02087616543546154\n",
      "previous_iter_valid_loss : 0.08191782981157303\n",
      "\n",
      "    317600\t  0.081757\t  0.081918\t  0.083850\t\tCURRENT LEARNING RATE: 0.02085529970463031\n",
      "previous_iter_valid_loss : 0.08100996166467667\n",
      "\n",
      "    317700\t  0.081011\t  0.081010\t  0.083898\t\tCURRENT LEARNING RATE: 0.02083445482910052\n",
      "previous_iter_valid_loss : 0.0877087339758873\n",
      "\n",
      "    317800\t  0.087501\t  0.087709\t  0.083998\t\tCURRENT LEARNING RATE: 0.020813630788027292\n",
      "previous_iter_valid_loss : 0.09409229457378387\n",
      "\n",
      "    317900\t  0.094159\t  0.094092\t  0.084151\t\tCURRENT LEARNING RATE: 0.02079282756058658\n",
      "previous_iter_valid_loss : 0.07592692226171494\n",
      "\n",
      "    318000\t  0.075794\t  0.075927\t  0.084123\t\tCURRENT LEARNING RATE: 0.02077204512597517\n",
      "previous_iter_valid_loss : 0.07675597071647644\n",
      "\n",
      "    318100\t  0.076704\t  0.076756\t  0.084068\t\tCURRENT LEARNING RATE: 0.02075128346341062\n",
      "previous_iter_valid_loss : 0.0791286900639534\n",
      "\n",
      "    318200\t  0.078995\t  0.079129\t  0.084070\t\tCURRENT LEARNING RATE: 0.020730542552131262\n",
      "previous_iter_valid_loss : 0.08261065930128098\n",
      "\n",
      "    318300\t  0.082447\t  0.082611\t  0.083890\t\tCURRENT LEARNING RATE: 0.020709822371396173\n",
      "previous_iter_valid_loss : 0.07655426114797592\n",
      "\n",
      "    318400\t  0.076526\t  0.076554\t  0.083839\t\tCURRENT LEARNING RATE: 0.02068912290048519\n",
      "previous_iter_valid_loss : 0.11059717833995819\n",
      "\n",
      "    318500\t  0.110827\t  0.110597\t  0.084189\t\tCURRENT LEARNING RATE: 0.020668444118698833\n",
      "previous_iter_valid_loss : 0.07604770362377167\n",
      "\n",
      "    318600\t  0.076018\t  0.076048\t  0.084195\t\tCURRENT LEARNING RATE: 0.020647786005358316\n",
      "previous_iter_valid_loss : 0.09980762004852295\n",
      "\n",
      "    318700\t  0.099943\t  0.099808\t  0.084408\t\tCURRENT LEARNING RATE: 0.020627148539805514\n",
      "previous_iter_valid_loss : 0.08080971986055374\n",
      "\n",
      "    318800\t  0.080836\t  0.080810\t  0.084385\t\tCURRENT LEARNING RATE: 0.02060653170140298\n",
      "previous_iter_valid_loss : 0.102690190076828\n",
      "\n",
      "    318900\t  0.102836\t  0.102690\t  0.084613\t\tCURRENT LEARNING RATE: 0.02058593546953387\n",
      "previous_iter_valid_loss : 0.07807864993810654\n",
      "\n",
      "    319000\t  0.077947\t  0.078079\t  0.084563\t\tCURRENT LEARNING RATE: 0.020565359823601942\n",
      "previous_iter_valid_loss : 0.07915899902582169\n",
      "\n",
      "    319100\t  0.079023\t  0.079159\t  0.084545\t\tCURRENT LEARNING RATE: 0.02054480474303154\n",
      "previous_iter_valid_loss : 0.07738860696554184\n",
      "\n",
      "    319200\t  0.077250\t  0.077389\t  0.084339\t\tCURRENT LEARNING RATE: 0.020524270207267603\n",
      "previous_iter_valid_loss : 0.07907890528440475\n",
      "\n",
      "    319300\t  0.079091\t  0.079079\t  0.084172\t\tCURRENT LEARNING RATE: 0.020503756195775585\n",
      "previous_iter_valid_loss : 0.07569700479507446\n",
      "\n",
      "    319400\t  0.075591\t  0.075697\t  0.083985\t\tCURRENT LEARNING RATE: 0.020483262688041473\n",
      "previous_iter_valid_loss : 0.07597614079713821\n",
      "\n",
      "    319500\t  0.075876\t  0.075976\t  0.083839\t\tCURRENT LEARNING RATE: 0.020462789663571745\n",
      "previous_iter_valid_loss : 0.07555738836526871\n",
      "\n",
      "    319600\t  0.075429\t  0.075557\t  0.083581\t\tCURRENT LEARNING RATE: 0.020442337101893394\n",
      "previous_iter_valid_loss : 0.07776245474815369\n",
      "\n",
      "    319700\t  0.077608\t  0.077762\t  0.083587\t\tCURRENT LEARNING RATE: 0.02042190498255385\n",
      "previous_iter_valid_loss : 0.07559327036142349\n",
      "\n",
      "    319800\t  0.075522\t  0.075593\t  0.083490\t\tCURRENT LEARNING RATE: 0.02040149328512099\n",
      "previous_iter_valid_loss : 0.0752255991101265\n",
      "\n",
      "\n",
      "Current valid loss: 0.0752255991101265;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "    319900\t  0.075139\t  0.075226\t  0.083486\t\tCURRENT LEARNING RATE: 0.020381101989183106\n",
      "previous_iter_valid_loss : 0.07592983543872833\n",
      "\n",
      "    320000\t  0.075848\t  0.075930\t  0.083422\t\tCURRENT LEARNING RATE: 0.020360731074348916\n",
      "previous_iter_valid_loss : 0.09988929331302643\n",
      "\n",
      "    320100\t  0.100041\t  0.099889\t  0.083665\t\tCURRENT LEARNING RATE: 0.0203403805202475\n",
      "previous_iter_valid_loss : 0.07630115747451782\n",
      "\n",
      "    320200\t  0.076157\t  0.076301\t  0.083644\t\tCURRENT LEARNING RATE: 0.0203200503065283\n",
      "previous_iter_valid_loss : 0.0819394588470459\n",
      "\n",
      "    320300\t  0.081906\t  0.081939\t  0.083658\t\tCURRENT LEARNING RATE: 0.02029974041286109\n",
      "previous_iter_valid_loss : 0.09578303247690201\n",
      "\n",
      "    320400\t  0.095864\t  0.095783\t  0.083826\t\tCURRENT LEARNING RATE: 0.020279450818935993\n",
      "previous_iter_valid_loss : 0.08494265377521515\n",
      "\n",
      "    320500\t  0.085026\t  0.084943\t  0.083289\t\tCURRENT LEARNING RATE: 0.020259181504463403\n",
      "previous_iter_valid_loss : 0.09897619485855103\n",
      "\n",
      "    320600\t  0.099084\t  0.098976\t  0.083474\t\tCURRENT LEARNING RATE: 0.020238932449174008\n",
      "previous_iter_valid_loss : 0.08004401624202728\n",
      "\n",
      "    320700\t  0.079891\t  0.080044\t  0.083454\t\tCURRENT LEARNING RATE: 0.02021870363281874\n",
      "previous_iter_valid_loss : 0.0754372626543045\n",
      "\n",
      "    320800\t  0.075361\t  0.075437\t  0.083343\t\tCURRENT LEARNING RATE: 0.0201984950351688\n",
      "previous_iter_valid_loss : 0.07713408768177032\n",
      "\n",
      "    320900\t  0.076976\t  0.077134\t  0.083352\t\tCURRENT LEARNING RATE: 0.020178306636015574\n",
      "previous_iter_valid_loss : 0.09135598689317703\n",
      "\n",
      "    321000\t  0.091398\t  0.091356\t  0.083424\t\tCURRENT LEARNING RATE: 0.020158138415170668\n",
      "previous_iter_valid_loss : 0.07691574096679688\n",
      "\n",
      "    321100\t  0.076778\t  0.076916\t  0.083236\t\tCURRENT LEARNING RATE: 0.02013799035246585\n",
      "previous_iter_valid_loss : 0.07687017321586609\n",
      "\n",
      "    321200\t  0.076751\t  0.076870\t  0.083245\t\tCURRENT LEARNING RATE: 0.02011786242775307\n",
      "previous_iter_valid_loss : 0.08188890665769577\n",
      "\n",
      "    321300\t  0.081736\t  0.081889\t  0.083241\t\tCURRENT LEARNING RATE: 0.020097754620904393\n",
      "previous_iter_valid_loss : 0.07546380162239075\n",
      "\n",
      "    321400\t  0.075347\t  0.075464\t  0.083241\t\tCURRENT LEARNING RATE: 0.020077666911812012\n",
      "previous_iter_valid_loss : 0.07625127583742142\n",
      "\n",
      "    321500\t  0.076122\t  0.076251\t  0.083215\t\tCURRENT LEARNING RATE: 0.020057599280388208\n",
      "previous_iter_valid_loss : 0.07572740316390991\n",
      "\n",
      "    321600\t  0.075630\t  0.075727\t  0.082779\t\tCURRENT LEARNING RATE: 0.020037551706565366\n",
      "previous_iter_valid_loss : 0.07630512863397598\n",
      "\n",
      "    321700\t  0.076220\t  0.076305\t  0.082752\t\tCURRENT LEARNING RATE: 0.020017524170295897\n",
      "previous_iter_valid_loss : 0.0774620771408081\n",
      "\n",
      "    321800\t  0.077316\t  0.077462\t  0.082753\t\tCURRENT LEARNING RATE: 0.01999751665155227\n",
      "previous_iter_valid_loss : 0.07676729559898376\n",
      "\n",
      "    321900\t  0.076651\t  0.076767\t  0.082705\t\tCURRENT LEARNING RATE: 0.019977529130326948\n",
      "previous_iter_valid_loss : 0.08253396302461624\n",
      "\n",
      "    322000\t  0.082323\t  0.082534\t  0.082759\t\tCURRENT LEARNING RATE: 0.019957561586632436\n",
      "previous_iter_valid_loss : 0.09018915146589279\n",
      "\n",
      "    322100\t  0.090022\t  0.090189\t  0.082764\t\tCURRENT LEARNING RATE: 0.019937614000501168\n",
      "previous_iter_valid_loss : 0.07621518522500992\n",
      "\n",
      "    322200\t  0.076122\t  0.076215\t  0.082641\t\tCURRENT LEARNING RATE: 0.019917686351985566\n",
      "previous_iter_valid_loss : 0.0805436372756958\n",
      "\n",
      "    322300\t  0.080579\t  0.080544\t  0.082634\t\tCURRENT LEARNING RATE: 0.019897778621157963\n",
      "previous_iter_valid_loss : 0.09497813880443573\n",
      "\n",
      "    322400\t  0.094794\t  0.094978\t  0.082829\t\tCURRENT LEARNING RATE: 0.019877890788110652\n",
      "previous_iter_valid_loss : 0.07506971061229706\n",
      "\n",
      "\n",
      "Current valid loss: 0.07506971061229706;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "    322500\t  0.074999\t  0.075070\t  0.082771\t\tCURRENT LEARNING RATE: 0.019858022832955784\n",
      "previous_iter_valid_loss : 0.08229438215494156\n",
      "\n",
      "    322600\t  0.082334\t  0.082294\t  0.082577\t\tCURRENT LEARNING RATE: 0.0198381747358254\n",
      "previous_iter_valid_loss : 0.07703670114278793\n",
      "\n",
      "    322700\t  0.076927\t  0.077037\t  0.082554\t\tCURRENT LEARNING RATE: 0.0198183464768714\n",
      "previous_iter_valid_loss : 0.07723632454872131\n",
      "\n",
      "    322800\t  0.077236\t  0.077236\t  0.082500\t\tCURRENT LEARNING RATE: 0.01979853803626554\n",
      "previous_iter_valid_loss : 0.07559233903884888\n",
      "\n",
      "    322900\t  0.075540\t  0.075592\t  0.082352\t\tCURRENT LEARNING RATE: 0.019778749394199362\n",
      "previous_iter_valid_loss : 0.07685864716768265\n",
      "\n",
      "    323000\t  0.076759\t  0.076859\t  0.082194\t\tCURRENT LEARNING RATE: 0.019758980530884228\n",
      "previous_iter_valid_loss : 0.076264888048172\n",
      "\n",
      "    323100\t  0.076136\t  0.076265\t  0.082182\t\tCURRENT LEARNING RATE: 0.019739231426551263\n",
      "previous_iter_valid_loss : 0.0762975811958313\n",
      "\n",
      "    323200\t  0.076244\t  0.076298\t  0.082166\t\tCURRENT LEARNING RATE: 0.01971950206145138\n",
      "previous_iter_valid_loss : 0.07860726863145828\n",
      "\n",
      "    323300\t  0.078399\t  0.078607\t  0.082173\t\tCURRENT LEARNING RATE: 0.019699792415855195\n",
      "previous_iter_valid_loss : 0.0783657506108284\n",
      "\n",
      "    323400\t  0.078226\t  0.078366\t  0.082182\t\tCURRENT LEARNING RATE: 0.019680102470053074\n",
      "previous_iter_valid_loss : 0.08005405962467194\n",
      "\n",
      "    323500\t  0.080083\t  0.080054\t  0.082211\t\tCURRENT LEARNING RATE: 0.019660432204355052\n",
      "previous_iter_valid_loss : 0.0775647833943367\n",
      "\n",
      "    323600\t  0.077421\t  0.077565\t  0.082146\t\tCURRENT LEARNING RATE: 0.01964078159909088\n",
      "previous_iter_valid_loss : 0.07512086629867554\n",
      "\n",
      "    323700\t  0.075042\t  0.075121\t  0.082138\t\tCURRENT LEARNING RATE: 0.019621150634609945\n",
      "previous_iter_valid_loss : 0.08562719076871872\n",
      "\n",
      "    323800\t  0.085690\t  0.085627\t  0.081897\t\tCURRENT LEARNING RATE: 0.01960153929128128\n",
      "previous_iter_valid_loss : 0.07631296664476395\n",
      "\n",
      "    323900\t  0.076278\t  0.076313\t  0.081822\t\tCURRENT LEARNING RATE: 0.019581947549493533\n",
      "previous_iter_valid_loss : 0.0829886943101883\n",
      "\n",
      "    324000\t  0.082820\t  0.082989\t  0.081855\t\tCURRENT LEARNING RATE: 0.019562375389654975\n",
      "previous_iter_valid_loss : 0.09487190842628479\n",
      "\n",
      "    324100\t  0.094993\t  0.094872\t  0.081976\t\tCURRENT LEARNING RATE: 0.019542822792193434\n",
      "previous_iter_valid_loss : 0.0755295604467392\n",
      "\n",
      "    324200\t  0.075503\t  0.075530\t  0.081880\t\tCURRENT LEARNING RATE: 0.019523289737556317\n",
      "previous_iter_valid_loss : 0.07834272086620331\n",
      "\n",
      "    324300\t  0.078344\t  0.078343\t  0.081806\t\tCURRENT LEARNING RATE: 0.019503776206210556\n",
      "previous_iter_valid_loss : 0.0968509316444397\n",
      "\n",
      "    324400\t  0.096682\t  0.096851\t  0.082013\t\tCURRENT LEARNING RATE: 0.01948428217864263\n",
      "previous_iter_valid_loss : 0.07713638246059418\n",
      "\n",
      "    324500\t  0.077018\t  0.077136\t  0.081875\t\tCURRENT LEARNING RATE: 0.019464807635358513\n",
      "previous_iter_valid_loss : 0.07810233533382416\n",
      "\n",
      "    324600\t  0.078079\t  0.078102\t  0.081831\t\tCURRENT LEARNING RATE: 0.01944535255688365\n",
      "previous_iter_valid_loss : 0.08020292967557907\n",
      "\n",
      "    324700\t  0.080210\t  0.080203\t  0.081772\t\tCURRENT LEARNING RATE: 0.019425916923762956\n",
      "previous_iter_valid_loss : 0.08297145366668701\n",
      "\n",
      "    324800\t  0.082795\t  0.082971\t  0.081832\t\tCURRENT LEARNING RATE: 0.019406500716560814\n",
      "previous_iter_valid_loss : 0.08071011304855347\n",
      "\n",
      "    324900\t  0.080560\t  0.080710\t  0.081866\t\tCURRENT LEARNING RATE: 0.019387103915861004\n",
      "previous_iter_valid_loss : 0.08929409086704254\n",
      "\n",
      "    325000\t  0.089446\t  0.089294\t  0.082000\t\tCURRENT LEARNING RATE: 0.019367726502266727\n",
      "previous_iter_valid_loss : 0.08250197023153305\n",
      "\n",
      "    325100\t  0.082284\t  0.082502\t  0.082027\t\tCURRENT LEARNING RATE: 0.019348368456400568\n",
      "previous_iter_valid_loss : 0.08020386844873428\n",
      "\n",
      "    325200\t  0.080172\t  0.080204\t  0.081921\t\tCURRENT LEARNING RATE: 0.019329029758904465\n",
      "previous_iter_valid_loss : 0.07708635926246643\n",
      "\n",
      "    325300\t  0.077049\t  0.077086\t  0.081854\t\tCURRENT LEARNING RATE: 0.019309710390439744\n",
      "previous_iter_valid_loss : 0.09044633060693741\n",
      "\n",
      "    325400\t  0.090218\t  0.090446\t  0.081967\t\tCURRENT LEARNING RATE: 0.01929041033168702\n",
      "previous_iter_valid_loss : 0.0781395360827446\n",
      "\n",
      "    325500\t  0.077984\t  0.078140\t  0.081979\t\tCURRENT LEARNING RATE: 0.019271129563346236\n",
      "previous_iter_valid_loss : 0.08718129992485046\n",
      "\n",
      "    325600\t  0.087260\t  0.087181\t  0.082094\t\tCURRENT LEARNING RATE: 0.019251868066136612\n",
      "previous_iter_valid_loss : 0.08416351675987244\n",
      "\n",
      "    325700\t  0.084212\t  0.084164\t  0.082182\t\tCURRENT LEARNING RATE: 0.01923262582079667\n",
      "previous_iter_valid_loss : 0.07826027274131775\n",
      "\n",
      "    325800\t  0.078104\t  0.078260\t  0.082133\t\tCURRENT LEARNING RATE: 0.01921340280808415\n",
      "previous_iter_valid_loss : 0.07698594778776169\n",
      "\n",
      "    325900\t  0.076903\t  0.076986\t  0.082145\t\tCURRENT LEARNING RATE: 0.019194199008776038\n",
      "previous_iter_valid_loss : 0.09661270678043365\n",
      "\n",
      "    326000\t  0.096416\t  0.096613\t  0.082343\t\tCURRENT LEARNING RATE: 0.019175014403668526\n",
      "previous_iter_valid_loss : 0.08313507586717606\n",
      "\n",
      "    326100\t  0.083153\t  0.083135\t  0.082419\t\tCURRENT LEARNING RATE: 0.019155848973577024\n",
      "previous_iter_valid_loss : 0.07666928321123123\n",
      "\n",
      "    326200\t  0.076605\t  0.076669\t  0.082157\t\tCURRENT LEARNING RATE: 0.01913670269933609\n",
      "previous_iter_valid_loss : 0.10167519748210907\n",
      "\n",
      "    326300\t  0.101833\t  0.101675\t  0.082400\t\tCURRENT LEARNING RATE: 0.019117575561799455\n",
      "previous_iter_valid_loss : 0.09115829318761826\n",
      "\n",
      "    326400\t  0.091257\t  0.091158\t  0.082489\t\tCURRENT LEARNING RATE: 0.019098467541839963\n",
      "previous_iter_valid_loss : 0.07553895562887192\n",
      "\n",
      "    326500\t  0.075502\t  0.075539\t  0.082304\t\tCURRENT LEARNING RATE: 0.019079378620349613\n",
      "previous_iter_valid_loss : 0.07614950090646744\n",
      "\n",
      "    326600\t  0.076077\t  0.076150\t  0.082179\t\tCURRENT LEARNING RATE: 0.019060308778239474\n",
      "previous_iter_valid_loss : 0.07720951735973358\n",
      "\n",
      "    326700\t  0.077179\t  0.077210\t  0.082179\t\tCURRENT LEARNING RATE: 0.019041257996439704\n",
      "previous_iter_valid_loss : 0.08711361885070801\n",
      "\n",
      "    326800\t  0.086914\t  0.087114\t  0.082293\t\tCURRENT LEARNING RATE: 0.019022226255899506\n",
      "previous_iter_valid_loss : 0.07692014425992966\n",
      "\n",
      "    326900\t  0.076831\t  0.076920\t  0.082300\t\tCURRENT LEARNING RATE: 0.019003213537587157\n",
      "previous_iter_valid_loss : 0.08110949397087097\n",
      "\n",
      "    327000\t  0.081130\t  0.081109\t  0.082014\t\tCURRENT LEARNING RATE: 0.01898421982248993\n",
      "previous_iter_valid_loss : 0.07554939389228821\n",
      "\n",
      "    327100\t  0.075452\t  0.075549\t  0.081963\t\tCURRENT LEARNING RATE: 0.018965245091614107\n",
      "previous_iter_valid_loss : 0.07519116252660751\n",
      "\n",
      "    327200\t  0.075113\t  0.075191\t  0.081885\t\tCURRENT LEARNING RATE: 0.01894628932598495\n",
      "previous_iter_valid_loss : 0.0756106972694397\n",
      "\n",
      "    327300\t  0.075521\t  0.075611\t  0.081888\t\tCURRENT LEARNING RATE: 0.018927352506646705\n",
      "previous_iter_valid_loss : 0.07661725580692291\n",
      "\n",
      "    327400\t  0.076614\t  0.076617\t  0.081751\t\tCURRENT LEARNING RATE: 0.01890843461466254\n",
      "previous_iter_valid_loss : 0.09604688733816147\n",
      "\n",
      "    327500\t  0.095863\t  0.096047\t  0.081736\t\tCURRENT LEARNING RATE: 0.01888953563111457\n",
      "previous_iter_valid_loss : 0.07688365131616592\n",
      "\n",
      "    327600\t  0.076783\t  0.076884\t  0.081685\t\tCURRENT LEARNING RATE: 0.018870655537103796\n",
      "previous_iter_valid_loss : 0.09539009630680084\n",
      "\n",
      "    327700\t  0.095220\t  0.095390\t  0.081829\t\tCURRENT LEARNING RATE: 0.018851794313750142\n",
      "previous_iter_valid_loss : 0.07544974237680435\n",
      "\n",
      "    327800\t  0.075384\t  0.075450\t  0.081707\t\tCURRENT LEARNING RATE: 0.01883295194219237\n",
      "previous_iter_valid_loss : 0.07672735303640366\n",
      "\n",
      "    327900\t  0.076622\t  0.076727\t  0.081533\t\tCURRENT LEARNING RATE: 0.01881412840358811\n",
      "previous_iter_valid_loss : 0.07659643888473511\n",
      "\n",
      "    328000\t  0.076550\t  0.076596\t  0.081540\t\tCURRENT LEARNING RATE: 0.018795323679113813\n",
      "previous_iter_valid_loss : 0.07548338919878006\n",
      "\n",
      "    328100\t  0.075372\t  0.075483\t  0.081527\t\tCURRENT LEARNING RATE: 0.01877653774996477\n",
      "previous_iter_valid_loss : 0.07617828249931335\n",
      "\n",
      "    328200\t  0.076024\t  0.076178\t  0.081498\t\tCURRENT LEARNING RATE: 0.01875777059735504\n",
      "previous_iter_valid_loss : 0.07534195482730865\n",
      "\n",
      "    328300\t  0.075283\t  0.075342\t  0.081425\t\tCURRENT LEARNING RATE: 0.018739022202517473\n",
      "previous_iter_valid_loss : 0.07519848644733429\n",
      "\n",
      "    328400\t  0.075114\t  0.075198\t  0.081411\t\tCURRENT LEARNING RATE: 0.01872029254670366\n",
      "previous_iter_valid_loss : 0.07999023795127869\n",
      "\n",
      "    328500\t  0.079831\t  0.079990\t  0.081105\t\tCURRENT LEARNING RATE: 0.018701581611183963\n",
      "previous_iter_valid_loss : 0.07590997964143753\n",
      "\n",
      "    328600\t  0.075793\t  0.075910\t  0.081104\t\tCURRENT LEARNING RATE: 0.018682889377247436\n",
      "previous_iter_valid_loss : 0.07719462364912033\n",
      "\n",
      "    328700\t  0.077139\t  0.077195\t  0.080878\t\tCURRENT LEARNING RATE: 0.01866421582620184\n",
      "previous_iter_valid_loss : 0.07533453404903412\n",
      "\n",
      "    328800\t  0.075269\t  0.075335\t  0.080823\t\tCURRENT LEARNING RATE: 0.018645560939373623\n",
      "previous_iter_valid_loss : 0.07580719888210297\n",
      "\n",
      "    328900\t  0.075758\t  0.075807\t  0.080554\t\tCURRENT LEARNING RATE: 0.018626924698107904\n",
      "previous_iter_valid_loss : 0.08300168067216873\n",
      "\n",
      "    329000\t  0.082842\t  0.083002\t  0.080603\t\tCURRENT LEARNING RATE: 0.018608307083768434\n",
      "previous_iter_valid_loss : 0.07740119099617004\n",
      "\n",
      "    329100\t  0.077367\t  0.077401\t  0.080586\t\tCURRENT LEARNING RATE: 0.0185897080777376\n",
      "previous_iter_valid_loss : 0.07671691477298737\n",
      "\n",
      "    329200\t  0.076615\t  0.076717\t  0.080579\t\tCURRENT LEARNING RATE: 0.018571127661416387\n",
      "previous_iter_valid_loss : 0.0824679359793663\n",
      "\n",
      "    329300\t  0.082314\t  0.082468\t  0.080613\t\tCURRENT LEARNING RATE: 0.018552565816224387\n",
      "previous_iter_valid_loss : 0.07591642439365387\n",
      "\n",
      "    329400\t  0.075889\t  0.075916\t  0.080615\t\tCURRENT LEARNING RATE: 0.01853402252359975\n",
      "previous_iter_valid_loss : 0.07729793339967728\n",
      "\n",
      "    329500\t  0.077264\t  0.077298\t  0.080628\t\tCURRENT LEARNING RATE: 0.018515497764999184\n",
      "previous_iter_valid_loss : 0.07989892363548279\n",
      "\n",
      "    329600\t  0.079900\t  0.079899\t  0.080672\t\tCURRENT LEARNING RATE: 0.018496991521897918\n",
      "previous_iter_valid_loss : 0.11078107357025146\n",
      "\n",
      "    329700\t  0.111026\t  0.110781\t  0.081002\t\tCURRENT LEARNING RATE: 0.01847850377578972\n",
      "previous_iter_valid_loss : 0.09406345337629318\n",
      "\n",
      "    329800\t  0.093912\t  0.094063\t  0.081187\t\tCURRENT LEARNING RATE: 0.01846003450818684\n",
      "previous_iter_valid_loss : 0.07542584836483002\n",
      "\n",
      "    329900\t  0.075359\t  0.075426\t  0.081189\t\tCURRENT LEARNING RATE: 0.018441583700620007\n",
      "previous_iter_valid_loss : 0.07785629481077194\n",
      "\n",
      "    330000\t  0.077800\t  0.077856\t  0.081208\t\tCURRENT LEARNING RATE: 0.018423151334638403\n",
      "previous_iter_valid_loss : 0.08402904868125916\n",
      "\n",
      "    330100\t  0.084108\t  0.084029\t  0.081049\t\tCURRENT LEARNING RATE: 0.018404737391809676\n",
      "previous_iter_valid_loss : 0.09574497491121292\n",
      "\n",
      "    330200\t  0.095634\t  0.095745\t  0.081244\t\tCURRENT LEARNING RATE: 0.018386341853719873\n",
      "previous_iter_valid_loss : 0.07789555937051773\n",
      "\n",
      "    330300\t  0.077755\t  0.077896\t  0.081203\t\tCURRENT LEARNING RATE: 0.01836796470197346\n",
      "previous_iter_valid_loss : 0.09935101866722107\n",
      "\n",
      "    330400\t  0.099564\t  0.099351\t  0.081239\t\tCURRENT LEARNING RATE: 0.018349605918193266\n",
      "previous_iter_valid_loss : 0.10957106202840805\n",
      "\n",
      "    330500\t  0.109418\t  0.109571\t  0.081485\t\tCURRENT LEARNING RATE: 0.01833126548402053\n",
      "previous_iter_valid_loss : 0.07605116069316864\n",
      "\n",
      "    330600\t  0.075934\t  0.076051\t  0.081256\t\tCURRENT LEARNING RATE: 0.018312943381114808\n",
      "previous_iter_valid_loss : 0.07510332763195038\n",
      "\n",
      "    330700\t  0.075049\t  0.075103\t  0.081207\t\tCURRENT LEARNING RATE: 0.018294639591153992\n",
      "previous_iter_valid_loss : 0.08863070607185364\n",
      "\n",
      "    330800\t  0.088730\t  0.088631\t  0.081339\t\tCURRENT LEARNING RATE: 0.018276354095834283\n",
      "previous_iter_valid_loss : 0.07777472585439682\n",
      "\n",
      "    330900\t  0.077777\t  0.077775\t  0.081345\t\tCURRENT LEARNING RATE: 0.0182580868768702\n",
      "previous_iter_valid_loss : 0.08536724001169205\n",
      "\n",
      "    331000\t  0.085252\t  0.085367\t  0.081285\t\tCURRENT LEARNING RATE: 0.018239837915994518\n",
      "previous_iter_valid_loss : 0.07782953232526779\n",
      "\n",
      "    331100\t  0.077745\t  0.077830\t  0.081294\t\tCURRENT LEARNING RATE: 0.01822160719495827\n",
      "previous_iter_valid_loss : 0.07695282995700836\n",
      "\n",
      "    331200\t  0.076860\t  0.076953\t  0.081295\t\tCURRENT LEARNING RATE: 0.018203394695530728\n",
      "previous_iter_valid_loss : 0.08113053441047668\n",
      "\n",
      "    331300\t  0.081037\t  0.081131\t  0.081287\t\tCURRENT LEARNING RATE: 0.018185200399499404\n",
      "previous_iter_valid_loss : 0.07766276597976685\n",
      "\n",
      "    331400\t  0.077583\t  0.077663\t  0.081309\t\tCURRENT LEARNING RATE: 0.018167024288669998\n",
      "previous_iter_valid_loss : 0.0756572037935257\n",
      "\n",
      "    331500\t  0.075625\t  0.075657\t  0.081303\t\tCURRENT LEARNING RATE: 0.018148866344866392\n",
      "previous_iter_valid_loss : 0.0760037824511528\n",
      "\n",
      "    331600\t  0.075970\t  0.076004\t  0.081306\t\tCURRENT LEARNING RATE: 0.01813072654993064\n",
      "previous_iter_valid_loss : 0.07649070024490356\n",
      "\n",
      "    331700\t  0.076520\t  0.076491\t  0.081308\t\tCURRENT LEARNING RATE: 0.018112604885722954\n",
      "previous_iter_valid_loss : 0.0763484314084053\n",
      "\n",
      "    331800\t  0.076271\t  0.076348\t  0.081297\t\tCURRENT LEARNING RATE: 0.01809450133412166\n",
      "previous_iter_valid_loss : 0.07853756844997406\n",
      "\n",
      "    331900\t  0.078547\t  0.078538\t  0.081315\t\tCURRENT LEARNING RATE: 0.018076415877023213\n",
      "previous_iter_valid_loss : 0.07579703629016876\n",
      "\n",
      "    332000\t  0.075759\t  0.075797\t  0.081247\t\tCURRENT LEARNING RATE: 0.01805834849634214\n",
      "previous_iter_valid_loss : 0.09906835854053497\n",
      "\n",
      "    332100\t  0.098942\t  0.099068\t  0.081336\t\tCURRENT LEARNING RATE: 0.018040299174011076\n",
      "previous_iter_valid_loss : 0.08717379719018936\n",
      "\n",
      "    332200\t  0.087334\t  0.087174\t  0.081446\t\tCURRENT LEARNING RATE: 0.01802226789198069\n",
      "previous_iter_valid_loss : 0.08369262516498566\n",
      "\n",
      "    332300\t  0.083793\t  0.083693\t  0.081477\t\tCURRENT LEARNING RATE: 0.018004254632219694\n",
      "previous_iter_valid_loss : 0.07862243801355362\n",
      "\n",
      "    332400\t  0.078642\t  0.078622\t  0.081314\t\tCURRENT LEARNING RATE: 0.017986259376714827\n",
      "previous_iter_valid_loss : 0.0776139497756958\n",
      "\n",
      "    332500\t  0.077539\t  0.077614\t  0.081339\t\tCURRENT LEARNING RATE: 0.01796828210747084\n",
      "previous_iter_valid_loss : 0.07717660069465637\n",
      "\n",
      "    332600\t  0.077165\t  0.077177\t  0.081288\t\tCURRENT LEARNING RATE: 0.01795032280651046\n",
      "previous_iter_valid_loss : 0.07529406249523163\n",
      "\n",
      "    332700\t  0.075285\t  0.075294\t  0.081270\t\tCURRENT LEARNING RATE: 0.01793238145587438\n",
      "previous_iter_valid_loss : 0.08113822340965271\n",
      "\n",
      "    332800\t  0.081198\t  0.081138\t  0.081309\t\tCURRENT LEARNING RATE: 0.017914458037621248\n",
      "previous_iter_valid_loss : 0.09138014167547226\n",
      "\n",
      "    332900\t  0.091266\t  0.091380\t  0.081467\t\tCURRENT LEARNING RATE: 0.01789655253382765\n",
      "previous_iter_valid_loss : 0.07503334432840347\n",
      "\n",
      "\n",
      "Current valid loss: 0.07503334432840347;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "    333000\t  0.075029\t  0.075033\t  0.081449\t\tCURRENT LEARNING RATE: 0.017878664926588076\n",
      "previous_iter_valid_loss : 0.10218968987464905\n",
      "\n",
      "    333100\t  0.102390\t  0.102190\t  0.081708\t\tCURRENT LEARNING RATE: 0.017860795198014923\n",
      "previous_iter_valid_loss : 0.07580143958330154\n",
      "\n",
      "    333200\t  0.075817\t  0.075801\t  0.081703\t\tCURRENT LEARNING RATE: 0.017842943330238444\n",
      "previous_iter_valid_loss : 0.08245601505041122\n",
      "\n",
      "    333300\t  0.082576\t  0.082456\t  0.081742\t\tCURRENT LEARNING RATE: 0.017825109305406792\n",
      "previous_iter_valid_loss : 0.07831920683383942\n",
      "\n",
      "    333400\t  0.078206\t  0.078319\t  0.081741\t\tCURRENT LEARNING RATE: 0.01780729310568593\n",
      "previous_iter_valid_loss : 0.08759485930204391\n",
      "\n",
      "    333500\t  0.087730\t  0.087595\t  0.081817\t\tCURRENT LEARNING RATE: 0.01778949471325966\n",
      "previous_iter_valid_loss : 0.08935720473527908\n",
      "\n",
      "    333600\t  0.089465\t  0.089357\t  0.081935\t\tCURRENT LEARNING RATE: 0.017771714110329576\n",
      "previous_iter_valid_loss : 0.08598217368125916\n",
      "\n",
      "    333700\t  0.085868\t  0.085982\t  0.082043\t\tCURRENT LEARNING RATE: 0.017753951279115093\n",
      "previous_iter_valid_loss : 0.07540348172187805\n",
      "\n",
      "    333800\t  0.075344\t  0.075403\t  0.081941\t\tCURRENT LEARNING RATE: 0.017736206201853365\n",
      "previous_iter_valid_loss : 0.0754043459892273\n",
      "\n",
      "    333900\t  0.075405\t  0.075404\t  0.081932\t\tCURRENT LEARNING RATE: 0.01771847886079932\n",
      "previous_iter_valid_loss : 0.07493618875741959\n",
      "\n",
      "\n",
      "Current valid loss: 0.07493618875741959;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_3_layer16_hiddenLeakyReLU_activation1024_batchsize2000_Kiteration.dict\n",
      "    334000\t  0.074944\t  0.074936\t  0.081852\t\tCURRENT LEARNING RATE: 0.017700769238225604\n",
      "previous_iter_valid_loss : 0.07693131268024445\n",
      "\n",
      "    334100\t  0.076906\t  0.076931\t  0.081672\t\tCURRENT LEARNING RATE: 0.01768307731642261\n",
      "previous_iter_valid_loss : 0.07642513513565063\n",
      "\n",
      "    334200\t  0.076396\t  0.076425\t  0.081681\t\tCURRENT LEARNING RATE: 0.017665403077698403\n",
      "previous_iter_valid_loss : 0.08280011266469955\n",
      "\n",
      "    334300\t  0.082917\t  0.082800\t  0.081726\t\tCURRENT LEARNING RATE: 0.017647746504378746\n",
      "previous_iter_valid_loss : 0.08263523876667023\n",
      "\n",
      "    334400\t  0.082730\t  0.082635\t  0.081583\t\tCURRENT LEARNING RATE: 0.01763010757880706\n",
      "previous_iter_valid_loss : 0.07926557958126068\n",
      "\n",
      "    334500\t  0.079184\t  0.079266\t  0.081605\t\tCURRENT LEARNING RATE: 0.017612486283344428\n",
      "previous_iter_valid_loss : 0.07520284503698349\n",
      "\n",
      "    334600\t  0.075203\t  0.075203\t  0.081576\t\tCURRENT LEARNING RATE: 0.017594882600369545\n",
      "previous_iter_valid_loss : 0.08174343407154083\n",
      "\n",
      "    334700\t  0.081663\t  0.081743\t  0.081591\t\tCURRENT LEARNING RATE: 0.01757729651227873\n",
      "previous_iter_valid_loss : 0.07562746852636337\n",
      "\n",
      "    334800\t  0.075658\t  0.075627\t  0.081518\t\tCURRENT LEARNING RATE: 0.017559728001485884\n",
      "previous_iter_valid_loss : 0.07874248176813126\n",
      "\n",
      "    334900\t  0.078750\t  0.078742\t  0.081498\t\tCURRENT LEARNING RATE: 0.017542177050422512\n",
      "previous_iter_valid_loss : 0.08284333348274231\n",
      "\n",
      "    335000\t  0.082959\t  0.082843\t  0.081434\t\tCURRENT LEARNING RATE: 0.017524643641537652\n",
      "previous_iter_valid_loss : 0.07763353735208511\n",
      "\n",
      "    335100\t  0.077555\t  0.077634\t  0.081385\t\tCURRENT LEARNING RATE: 0.017507127757297892\n",
      "previous_iter_valid_loss : 0.12923945486545563\n",
      "\n",
      "    335200\t  0.129126\t  0.129239\t  0.081875\t\tCURRENT LEARNING RATE: 0.017489629380187343\n",
      "previous_iter_valid_loss : 0.07559973746538162\n",
      "\n",
      "    335300\t  0.075573\t  0.075600\t  0.081860\t\tCURRENT LEARNING RATE: 0.017472148492707635\n",
      "previous_iter_valid_loss : 0.08006922155618668\n",
      "\n",
      "    335400\t  0.079984\t  0.080069\t  0.081757\t\tCURRENT LEARNING RATE: 0.01745468507737788\n",
      "previous_iter_valid_loss : 0.08138654381036758\n",
      "\n",
      "    335500\t  0.081332\t  0.081387\t  0.081789\t\tCURRENT LEARNING RATE: 0.017437239116734657\n",
      "previous_iter_valid_loss : 0.07688163220882416\n",
      "\n",
      "    335600\t  0.076917\t  0.076882\t  0.081686\t\tCURRENT LEARNING RATE: 0.017419810593331992\n",
      "previous_iter_valid_loss : 0.07607094198465347\n",
      "\n",
      "    335700\t  0.076042\t  0.076071\t  0.081605\t\tCURRENT LEARNING RATE: 0.017402399489741385\n",
      "previous_iter_valid_loss : 0.08229579031467438\n",
      "\n",
      "    335800\t  0.082398\t  0.082296\t  0.081646\t\tCURRENT LEARNING RATE: 0.017385005788551715\n",
      "previous_iter_valid_loss : 0.0776200145483017\n",
      "\n",
      "    335900\t  0.077667\t  0.077620\t  0.081652\t\tCURRENT LEARNING RATE: 0.01736762947236928\n",
      "previous_iter_valid_loss : 0.07615181058645248\n",
      "\n",
      "    336000\t  0.076196\t  0.076152\t  0.081447\t\tCURRENT LEARNING RATE: 0.01735027052381776\n",
      "previous_iter_valid_loss : 0.07617809623479843\n",
      "\n",
      "    336100\t  0.076155\t  0.076178\t  0.081378\t\tCURRENT LEARNING RATE: 0.01733292892553822\n",
      "previous_iter_valid_loss : 0.07529821991920471\n",
      "\n",
      "    336200\t  0.075325\t  0.075298\t  0.081364\t\tCURRENT LEARNING RATE: 0.017315604660189048\n",
      "previous_iter_valid_loss : 0.08096762746572495\n",
      "\n",
      "    336300\t  0.081080\t  0.080968\t  0.081157\t\tCURRENT LEARNING RATE: 0.017298297710445977\n",
      "previous_iter_valid_loss : 0.08001623302698135\n",
      "\n",
      "    336400\t  0.080118\t  0.080016\t  0.081045\t\tCURRENT LEARNING RATE: 0.01728100805900205\n",
      "previous_iter_valid_loss : 0.07552862167358398\n",
      "\n",
      "    336500\t  0.075571\t  0.075529\t  0.081045\t\tCURRENT LEARNING RATE: 0.017263735688567632\n",
      "previous_iter_valid_loss : 0.07525020837783813\n",
      "\n",
      "    336600\t  0.075273\t  0.075250\t  0.081036\t\tCURRENT LEARNING RATE: 0.01724648058187034\n",
      "previous_iter_valid_loss : 0.09359248727560043\n",
      "\n",
      "    336700\t  0.093498\t  0.093592\t  0.081200\t\tCURRENT LEARNING RATE: 0.017229242721655068\n",
      "previous_iter_valid_loss : 0.07757601886987686\n",
      "\n",
      "    336800\t  0.077503\t  0.077576\t  0.081105\t\tCURRENT LEARNING RATE: 0.017212022090683947\n",
      "previous_iter_valid_loss : 0.08032199740409851\n",
      "\n",
      "    336900\t  0.080423\t  0.080322\t  0.081139\t\tCURRENT LEARNING RATE: 0.017194818671736355\n",
      "previous_iter_valid_loss : 0.07663428038358688\n",
      "\n",
      "    337000\t  0.076580\t  0.076634\t  0.081094\t\tCURRENT LEARNING RATE: 0.01717763244760887\n",
      "previous_iter_valid_loss : 0.07942944020032883\n",
      "\n",
      "    337100\t  0.079490\t  0.079429\t  0.081133\t\tCURRENT LEARNING RATE: 0.017160463401115263\n",
      "previous_iter_valid_loss : 0.08741404861211777\n",
      "\n",
      "    337200\t  0.087563\t  0.087414\t  0.081255\t\tCURRENT LEARNING RATE: 0.017143311515086482\n",
      "previous_iter_valid_loss : 0.07667403668165207\n",
      "\n",
      "    337300\t  0.076647\t  0.076674\t  0.081266\t\tCURRENT LEARNING RATE: 0.01712617677237065\n",
      "previous_iter_valid_loss : 0.0796755775809288\n",
      "\n",
      "    337400\t  0.079587\t  0.079676\t  0.081296\t\tCURRENT LEARNING RATE: 0.017109059155833016\n",
      "previous_iter_valid_loss : 0.08271022886037827\n",
      "\n",
      "    337500\t  0.082631\t  0.082710\t  0.081163\t\tCURRENT LEARNING RATE: 0.017091958648355967\n",
      "previous_iter_valid_loss : 0.07545140385627747\n",
      "\n",
      "    337600\t  0.075441\t  0.075451\t  0.081149\t\tCURRENT LEARNING RATE: 0.01707487523283899\n",
      "previous_iter_valid_loss : 0.10410112142562866\n",
      "\n",
      "    337700\t  0.104010\t  0.104101\t  0.081236\t\tCURRENT LEARNING RATE: 0.01705780889219866\n",
      "previous_iter_valid_loss : 0.08075470477342606\n",
      "\n",
      "    337800\t  0.080635\t  0.080755\t  0.081289\t\tCURRENT LEARNING RATE: 0.017040759609368652\n",
      "previous_iter_valid_loss : 0.07505335658788681\n",
      "\n",
      "    337900\t  0.075040\t  0.075053\t  0.081272\t\tCURRENT LEARNING RATE: 0.017023727367299672\n",
      "previous_iter_valid_loss : 0.0766904279589653\n",
      "\n",
      "    338000\t  0.076692\t  0.076690\t  0.081273\t\tCURRENT LEARNING RATE: 0.01700671214895948\n",
      "previous_iter_valid_loss : 0.08158010244369507\n",
      "\n",
      "    338100\t  0.081628\t  0.081580\t  0.081334\t\tCURRENT LEARNING RATE: 0.016989713937332847\n",
      "previous_iter_valid_loss : 0.08382601290941238\n",
      "\n",
      "    338200\t  0.083912\t  0.083826\t  0.081410\t\tCURRENT LEARNING RATE: 0.016972732715421573\n",
      "previous_iter_valid_loss : 0.08167115598917007\n",
      "\n",
      "    338300\t  0.081794\t  0.081671\t  0.081474\t\tCURRENT LEARNING RATE: 0.016955768466244428\n",
      "previous_iter_valid_loss : 0.08340946584939957\n",
      "\n",
      "    338400\t  0.083326\t  0.083409\t  0.081556\t\tCURRENT LEARNING RATE: 0.016938821172837164\n",
      "previous_iter_valid_loss : 0.07642634212970734\n",
      "\n",
      "    338500\t  0.076389\t  0.076426\t  0.081520\t\tCURRENT LEARNING RATE: 0.016921890818252475\n",
      "previous_iter_valid_loss : 0.11026239395141602\n",
      "\n",
      "    338600\t  0.110175\t  0.110262\t  0.081864\t\tCURRENT LEARNING RATE: 0.016904977385560023\n",
      "previous_iter_valid_loss : 0.07511641085147858\n",
      "\n",
      "    338700\t  0.075097\t  0.075116\t  0.081843\t\tCURRENT LEARNING RATE: 0.016888080857846367\n",
      "previous_iter_valid_loss : 0.07542891055345535\n",
      "\n",
      "    338800\t  0.075403\t  0.075429\t  0.081844\t\tCURRENT LEARNING RATE: 0.016871201218214976\n",
      "previous_iter_valid_loss : 0.07551935315132141\n",
      "\n",
      "    338900\t  0.075531\t  0.075519\t  0.081841\t\tCURRENT LEARNING RATE: 0.016854338449786198\n",
      "previous_iter_valid_loss : 0.08485209196805954\n",
      "\n",
      "    339000\t  0.084993\t  0.084852\t  0.081860\t\tCURRENT LEARNING RATE: 0.016837492535697284\n",
      "previous_iter_valid_loss : 0.09204574674367905\n",
      "\n",
      "    339100\t  0.092242\t  0.092046\t  0.082006\t\tCURRENT LEARNING RATE: 0.01682066345910231\n",
      "previous_iter_valid_loss : 0.0978970006108284\n",
      "\n",
      "    339200\t  0.097776\t  0.097897\t  0.082218\t\tCURRENT LEARNING RATE: 0.016803851203172196\n",
      "previous_iter_valid_loss : 0.08082281798124313\n",
      "\n",
      "    339300\t  0.080700\t  0.080823\t  0.082201\t\tCURRENT LEARNING RATE: 0.016787055751094678\n",
      "previous_iter_valid_loss : 0.07513777166604996\n",
      "\n",
      "    339400\t  0.075122\t  0.075138\t  0.082194\t\tCURRENT LEARNING RATE: 0.016770277086074318\n",
      "previous_iter_valid_loss : 0.07544562220573425\n",
      "\n",
      "    339500\t  0.075455\t  0.075446\t  0.082175\t\tCURRENT LEARNING RATE: 0.01675351519133244\n",
      "previous_iter_valid_loss : 0.09726618975400925\n",
      "\n",
      "    339600\t  0.097158\t  0.097266\t  0.082349\t\tCURRENT LEARNING RATE: 0.016736770050107153\n",
      "previous_iter_valid_loss : 0.07519156485795975\n",
      "\n",
      "    339700\t  0.075185\t  0.075192\t  0.081993\t\tCURRENT LEARNING RATE: 0.0167200416456533\n",
      "previous_iter_valid_loss : 0.07499626278877258\n",
      "\n",
      "    339800\t  0.075003\t  0.074996\t  0.081802\t\tCURRENT LEARNING RATE: 0.016703329961242495\n",
      "previous_iter_valid_loss : 0.07639086991548538\n",
      "\n",
      "    339900\t  0.076427\t  0.076391\t  0.081812\t\tCURRENT LEARNING RATE: 0.01668663498016304\n",
      "previous_iter_valid_loss : 0.07743562012910843\n",
      "\n",
      "    340000\t  0.077492\t  0.077436\t  0.081808\t\tCURRENT LEARNING RATE: 0.01666995668571996\n",
      "previous_iter_valid_loss : 0.08334019035100937\n",
      "\n",
      "    340100\t  0.083222\t  0.083340\t  0.081801\t\tCURRENT LEARNING RATE: 0.016653295061234946\n",
      "previous_iter_valid_loss : 0.08898915350437164\n",
      "\n",
      "    340200\t  0.089127\t  0.088989\t  0.081733\t\tCURRENT LEARNING RATE: 0.016636650090046386\n",
      "previous_iter_valid_loss : 0.07623566687107086\n",
      "\n",
      "    340300\t  0.076236\t  0.076236\t  0.081717\t\tCURRENT LEARNING RATE: 0.016620021755509307\n",
      "previous_iter_valid_loss : 0.09768613427877426\n",
      "\n",
      "    340400\t  0.097876\t  0.097686\t  0.081700\t\tCURRENT LEARNING RATE: 0.016603410040995366\n",
      "previous_iter_valid_loss : 0.07875534892082214\n",
      "\n",
      "    340500\t  0.078648\t  0.078755\t  0.081392\t\tCURRENT LEARNING RATE: 0.01658681492989284\n",
      "previous_iter_valid_loss : 0.07977402210235596\n",
      "\n",
      "    340600\t  0.079708\t  0.079774\t  0.081429\t\tCURRENT LEARNING RATE: 0.016570236405606637\n",
      "previous_iter_valid_loss : 0.08170481026172638\n",
      "\n",
      "    340700\t  0.081601\t  0.081705\t  0.081495\t\tCURRENT LEARNING RATE: 0.01655367445155822\n",
      "previous_iter_valid_loss : 0.08592108637094498\n",
      "\n",
      "    340800\t  0.085791\t  0.085921\t  0.081468\t\tCURRENT LEARNING RATE: 0.016537129051185633\n",
      "previous_iter_valid_loss : 0.08210799843072891\n",
      "\n",
      "    340900\t  0.081988\t  0.082108\t  0.081511\t\tCURRENT LEARNING RATE: 0.016520600187943466\n",
      "previous_iter_valid_loss : 0.10174165666103363\n",
      "\n",
      "    341000\t  0.101981\t  0.101742\t  0.081675\t\tCURRENT LEARNING RATE: 0.016504087845302873\n",
      "previous_iter_valid_loss : 0.09891936182975769\n",
      "\n",
      "    341100\t  0.099169\t  0.098919\t  0.081886\t\tCURRENT LEARNING RATE: 0.0164875920067515\n",
      "previous_iter_valid_loss : 0.08649422973394394\n",
      "\n",
      "    341200\t  0.086358\t  0.086494\t  0.081981\t\tCURRENT LEARNING RATE: 0.01647111265579351\n",
      "previous_iter_valid_loss : 0.08174029737710953\n",
      "\n",
      "    341300\t  0.081624\t  0.081740\t  0.081987\t\tCURRENT LEARNING RATE: 0.01645464977594954\n",
      "previous_iter_valid_loss : 0.08644181489944458\n",
      "\n",
      "    341400\t  0.086346\t  0.086442\t  0.082075\t\tCURRENT LEARNING RATE: 0.016438203350756724\n",
      "previous_iter_valid_loss : 0.07855236530303955\n",
      "\n",
      "    341500\t  0.078601\t  0.078552\t  0.082104\t\tCURRENT LEARNING RATE: 0.01642177336376863\n",
      "previous_iter_valid_loss : 0.07607672363519669\n",
      "\n",
      "    341600\t  0.076067\t  0.076077\t  0.082105\t\tCURRENT LEARNING RATE: 0.016405359798555265\n",
      "previous_iter_valid_loss : 0.07700517028570175\n",
      "\n",
      "    341700\t  0.076962\t  0.077005\t  0.082110\t\tCURRENT LEARNING RATE: 0.016388962638703063\n",
      "previous_iter_valid_loss : 0.07904640585184097\n",
      "\n",
      "    341800\t  0.079131\t  0.079046\t  0.082137\t\tCURRENT LEARNING RATE: 0.01637258186781487\n",
      "previous_iter_valid_loss : 0.08323952555656433\n",
      "\n",
      "    341900\t  0.083335\t  0.083240\t  0.082184\t\tCURRENT LEARNING RATE: 0.01635621746950991\n",
      "previous_iter_valid_loss : 0.07798022776842117\n",
      "\n",
      "    342000\t  0.077895\t  0.077980\t  0.082206\t\tCURRENT LEARNING RATE: 0.01633986942742378\n",
      "previous_iter_valid_loss : 0.08762180805206299\n",
      "\n",
      "    342100\t  0.087507\t  0.087622\t  0.082091\t\tCURRENT LEARNING RATE: 0.016323537725208434\n",
      "previous_iter_valid_loss : 0.09614510834217072\n",
      "\n",
      "    342200\t  0.096029\t  0.096145\t  0.082181\t\tCURRENT LEARNING RATE: 0.01630722234653218\n",
      "previous_iter_valid_loss : 0.08379483222961426\n",
      "\n",
      "    342300\t  0.083652\t  0.083795\t  0.082182\t\tCURRENT LEARNING RATE: 0.01629092327507963\n",
      "previous_iter_valid_loss : 0.10017746686935425\n",
      "\n",
      "    342400\t  0.100439\t  0.100177\t  0.082398\t\tCURRENT LEARNING RATE: 0.016274640494551715\n",
      "previous_iter_valid_loss : 0.07773178070783615\n",
      "\n",
      "    342500\t  0.077680\t  0.077732\t  0.082399\t\tCURRENT LEARNING RATE: 0.016258373988665645\n",
      "previous_iter_valid_loss : 0.07575321942567825\n",
      "\n",
      "    342600\t  0.075736\t  0.075753\t  0.082385\t\tCURRENT LEARNING RATE: 0.016242123741154923\n",
      "previous_iter_valid_loss : 0.07623295485973358\n",
      "\n",
      "    342700\t  0.076191\t  0.076233\t  0.082394\t\tCURRENT LEARNING RATE: 0.016225889735769296\n",
      "previous_iter_valid_loss : 0.07656126469373703\n",
      "\n",
      "    342800\t  0.076612\t  0.076561\t  0.082348\t\tCURRENT LEARNING RATE: 0.016209671956274756\n",
      "previous_iter_valid_loss : 0.0849897488951683\n",
      "\n",
      "    342900\t  0.085092\t  0.084990\t  0.082284\t\tCURRENT LEARNING RATE: 0.01619347038645352\n",
      "previous_iter_valid_loss : 0.07771655917167664\n",
      "\n",
      "    343000\t  0.077655\t  0.077717\t  0.082311\t\tCURRENT LEARNING RATE: 0.01617728501010402\n",
      "previous_iter_valid_loss : 0.075632244348526\n",
      "\n",
      "    343100\t  0.075618\t  0.075632\t  0.082046\t\tCURRENT LEARNING RATE: 0.016161115811040884\n",
      "previous_iter_valid_loss : 0.08051643520593643\n",
      "\n",
      "    343200\t  0.080381\t  0.080516\t  0.082093\t\tCURRENT LEARNING RATE: 0.016144962773094906\n",
      "previous_iter_valid_loss : 0.07542603462934494\n",
      "\n",
      "    343300\t  0.075436\t  0.075426\t  0.082022\t\tCURRENT LEARNING RATE: 0.016128825880113037\n",
      "previous_iter_valid_loss : 0.0848754420876503\n",
      "\n",
      "    343400\t  0.084760\t  0.084875\t  0.082088\t\tCURRENT LEARNING RATE: 0.0161127051159584\n",
      "previous_iter_valid_loss : 0.08166356384754181\n",
      "\n",
      "    343500\t  0.081705\t  0.081664\t  0.082029\t\tCURRENT LEARNING RATE: 0.01609660046451022\n",
      "previous_iter_valid_loss : 0.07537434250116348\n",
      "\n",
      "    343600\t  0.075385\t  0.075374\t  0.081889\t\tCURRENT LEARNING RATE: 0.01608051190966385\n",
      "previous_iter_valid_loss : 0.0880630761384964\n",
      "\n",
      "    343700\t  0.088230\t  0.088063\t  0.081910\t\tCURRENT LEARNING RATE: 0.01606443943533072\n",
      "previous_iter_valid_loss : 0.07932259142398834\n",
      "\n",
      "    343800\t  0.079255\t  0.079323\t  0.081949\t\tCURRENT LEARNING RATE: 0.016048383025438373\n",
      "previous_iter_valid_loss : 0.08032302558422089\n",
      "\n",
      "    343900\t  0.080227\t  0.080323\t  0.081998\t\tCURRENT LEARNING RATE: 0.016032342663930384\n",
      "previous_iter_valid_loss : 0.07842221111059189\n",
      "\n",
      "    344000\t  0.078500\t  0.078422\t  0.082033\t\tCURRENT LEARNING RATE: 0.0160163183347664\n",
      "previous_iter_valid_loss : 0.08886303007602692\n",
      "\n",
      "    344100\t  0.089052\t  0.088863\t  0.082152\t\tCURRENT LEARNING RATE: 0.016000310021922075\n",
      "previous_iter_valid_loss : 0.07528453320264816\n",
      "\n",
      "    344200\t  0.075290\t  0.075285\t  0.082141\t\tCURRENT LEARNING RATE: 0.015984317709389115\n",
      "previous_iter_valid_loss : 0.0754343569278717\n",
      "\n",
      "    344300\t  0.075399\t  0.075434\t  0.082067\t\tCURRENT LEARNING RATE: 0.015968341381175196\n",
      "previous_iter_valid_loss : 0.07713503390550613\n",
      "\n",
      "    344400\t  0.077223\t  0.077135\t  0.082012\t\tCURRENT LEARNING RATE: 0.015952381021303988\n",
      "previous_iter_valid_loss : 0.10552860051393509\n",
      "\n",
      "    344500\t  0.105822\t  0.105529\t  0.082275\t\tCURRENT LEARNING RATE: 0.015936436613815122\n",
      "previous_iter_valid_loss : 0.09634098410606384\n",
      "\n",
      "    344600\t  0.096248\t  0.096341\t  0.082486\t\tCURRENT LEARNING RATE: 0.015920508142764207\n",
      "previous_iter_valid_loss : 0.08980640769004822\n",
      "\n",
      "    344700\t  0.089989\t  0.089806\t  0.082567\t\tCURRENT LEARNING RATE: 0.01590459559222276\n",
      "previous_iter_valid_loss : 0.0757622942328453\n",
      "\n",
      "    344800\t  0.075748\t  0.075762\t  0.082568\t\tCURRENT LEARNING RATE: 0.015888698946278233\n",
      "previous_iter_valid_loss : 0.07770854979753494\n",
      "\n",
      "    344900\t  0.077778\t  0.077709\t  0.082558\t\tCURRENT LEARNING RATE: 0.01587281818903397\n",
      "previous_iter_valid_loss : 0.09690317511558533\n",
      "\n",
      "    345000\t  0.097106\t  0.096903\t  0.082698\t\tCURRENT LEARNING RATE: 0.015856953304609223\n",
      "previous_iter_valid_loss : 0.08368347585201263\n",
      "\n",
      "    345100\t  0.083819\t  0.083683\t  0.082759\t\tCURRENT LEARNING RATE: 0.0158411042771391\n",
      "previous_iter_valid_loss : 0.08355594426393509\n",
      "\n",
      "    345200\t  0.083676\t  0.083556\t  0.082302\t\tCURRENT LEARNING RATE: 0.01582527109077458\n",
      "previous_iter_valid_loss : 0.07622998207807541\n",
      "\n",
      "    345300\t  0.076171\t  0.076230\t  0.082308\t\tCURRENT LEARNING RATE: 0.015809453729682458\n",
      "previous_iter_valid_loss : 0.08399835973978043\n",
      "\n",
      "    345400\t  0.083891\t  0.083998\t  0.082348\t\tCURRENT LEARNING RATE: 0.015793652178045393\n",
      "previous_iter_valid_loss : 0.08431990444660187\n",
      "\n",
      "    345500\t  0.084233\t  0.084320\t  0.082377\t\tCURRENT LEARNING RATE: 0.01577786642006182\n",
      "previous_iter_valid_loss : 0.10025566071271896\n",
      "\n",
      "    345600\t  0.100523\t  0.100256\t  0.082611\t\tCURRENT LEARNING RATE: 0.015762096439945982\n",
      "previous_iter_valid_loss : 0.08816064149141312\n",
      "\n",
      "    345700\t  0.088032\t  0.088161\t  0.082732\t\tCURRENT LEARNING RATE: 0.015746342221927893\n",
      "previous_iter_valid_loss : 0.07983463257551193\n",
      "\n",
      "    345800\t  0.079920\t  0.079835\t  0.082707\t\tCURRENT LEARNING RATE: 0.015730603750253345\n",
      "previous_iter_valid_loss : 0.07727532833814621\n",
      "\n",
      "    345900\t  0.077188\t  0.077275\t  0.082704\t\tCURRENT LEARNING RATE: 0.015714881009183855\n",
      "previous_iter_valid_loss : 0.08729091286659241\n",
      "\n",
      "    346000\t  0.087430\t  0.087291\t  0.082815\t\tCURRENT LEARNING RATE: 0.015699173982996684\n",
      "previous_iter_valid_loss : 0.079845130443573\n",
      "\n",
      "    346100\t  0.079911\t  0.079845\t  0.082852\t\tCURRENT LEARNING RATE: 0.0156834826559848\n",
      "previous_iter_valid_loss : 0.07650165259838104\n",
      "\n",
      "    346200\t  0.076439\t  0.076502\t  0.082864\t\tCURRENT LEARNING RATE: 0.015667807012456885\n",
      "previous_iter_valid_loss : 0.07812634110450745\n",
      "\n",
      "    346300\t  0.078181\t  0.078126\t  0.082835\t\tCURRENT LEARNING RATE: 0.01565214703673729\n",
      "previous_iter_valid_loss : 0.08820790797472\n",
      "\n",
      "    346400\t  0.088372\t  0.088208\t  0.082917\t\tCURRENT LEARNING RATE: 0.01563650271316603\n",
      "previous_iter_valid_loss : 0.11523579061031342\n",
      "\n",
      "    346500\t  0.115107\t  0.115236\t  0.083314\t\tCURRENT LEARNING RATE: 0.015620874026098783\n",
      "previous_iter_valid_loss : 0.07526998221874237\n",
      "\n",
      "    346600\t  0.075249\t  0.075270\t  0.083314\t\tCURRENT LEARNING RATE: 0.015605260959906872\n",
      "previous_iter_valid_loss : 0.07692629098892212\n",
      "\n",
      "    346700\t  0.076962\t  0.076926\t  0.083148\t\tCURRENT LEARNING RATE: 0.015589663498977219\n",
      "previous_iter_valid_loss : 0.0756932869553566\n",
      "\n",
      "    346800\t  0.075627\t  0.075693\t  0.083129\t\tCURRENT LEARNING RATE: 0.015574081627712365\n",
      "previous_iter_valid_loss : 0.07705418020486832\n",
      "\n",
      "    346900\t  0.077094\t  0.077054\t  0.083096\t\tCURRENT LEARNING RATE: 0.01555851533053043\n",
      "previous_iter_valid_loss : 0.08541068434715271\n",
      "\n",
      "    347000\t  0.085287\t  0.085411\t  0.083184\t\tCURRENT LEARNING RATE: 0.01554296459186513\n",
      "previous_iter_valid_loss : 0.07600265741348267\n",
      "\n",
      "    347100\t  0.075915\t  0.076003\t  0.083150\t\tCURRENT LEARNING RATE: 0.015527429396165715\n",
      "previous_iter_valid_loss : 0.07608851045370102\n",
      "\n",
      "    347200\t  0.076031\t  0.076089\t  0.083036\t\tCURRENT LEARNING RATE: 0.015511909727896992\n",
      "previous_iter_valid_loss : 0.08711754530668259\n",
      "\n",
      "    347300\t  0.086981\t  0.087118\t  0.083141\t\tCURRENT LEARNING RATE: 0.01549640557153928\n",
      "previous_iter_valid_loss : 0.0772676169872284\n",
      "\n",
      "    347400\t  0.077189\t  0.077268\t  0.083117\t\tCURRENT LEARNING RATE: 0.015480916911588441\n",
      "previous_iter_valid_loss : 0.08398273587226868\n",
      "\n",
      "    347500\t  0.083888\t  0.083983\t  0.083130\t\tCURRENT LEARNING RATE: 0.015465443732555801\n",
      "previous_iter_valid_loss : 0.07675012946128845\n",
      "\n",
      "    347600\t  0.076703\t  0.076750\t  0.083143\t\tCURRENT LEARNING RATE: 0.015449986018968184\n",
      "previous_iter_valid_loss : 0.07564541697502136\n",
      "\n",
      "    347700\t  0.075667\t  0.075645\t  0.082858\t\tCURRENT LEARNING RATE: 0.015434543755367866\n",
      "previous_iter_valid_loss : 0.07632959634065628\n",
      "\n",
      "    347800\t  0.076320\t  0.076330\t  0.082814\t\tCURRENT LEARNING RATE: 0.015419116926312596\n",
      "previous_iter_valid_loss : 0.07562164962291718\n",
      "\n",
      "    347900\t  0.075651\t  0.075622\t  0.082819\t\tCURRENT LEARNING RATE: 0.015403705516375538\n",
      "previous_iter_valid_loss : 0.08134496957063675\n",
      "\n",
      "    348000\t  0.081405\t  0.081345\t  0.082866\t\tCURRENT LEARNING RATE: 0.01538830951014528\n",
      "previous_iter_valid_loss : 0.0775977075099945\n",
      "\n",
      "    348100\t  0.077568\t  0.077598\t  0.082826\t\tCURRENT LEARNING RATE: 0.015372928892225808\n",
      "previous_iter_valid_loss : 0.0781562477350235\n",
      "\n",
      "    348200\t  0.078218\t  0.078156\t  0.082769\t\tCURRENT LEARNING RATE: 0.015357563647236516\n",
      "previous_iter_valid_loss : 0.07908088713884354\n",
      "\n",
      "    348300\t  0.079114\t  0.079081\t  0.082744\t\tCURRENT LEARNING RATE: 0.01534221375981215\n",
      "previous_iter_valid_loss : 0.07616785168647766\n",
      "\n",
      "    348400\t  0.076103\t  0.076168\t  0.082671\t\tCURRENT LEARNING RATE: 0.015326879214602823\n",
      "previous_iter_valid_loss : 0.07627969980239868\n",
      "\n",
      "    348500\t  0.076223\t  0.076280\t  0.082670\t\tCURRENT LEARNING RATE: 0.01531155999627398\n",
      "previous_iter_valid_loss : 0.0763491839170456\n",
      "\n",
      "    348600\t  0.076300\t  0.076349\t  0.082331\t\tCURRENT LEARNING RATE: 0.015296256089506417\n",
      "previous_iter_valid_loss : 0.07505301386117935\n",
      "\n",
      "    348700\t  0.075056\t  0.075053\t  0.082330\t\tCURRENT LEARNING RATE: 0.015280967478996219\n",
      "previous_iter_valid_loss : 0.07704167068004608\n",
      "\n",
      "    348800\t  0.077065\t  0.077042\t  0.082346\t\tCURRENT LEARNING RATE: 0.015265694149454773\n",
      "previous_iter_valid_loss : 0.07502908259630203\n",
      "\n",
      "    348900\t  0.075017\t  0.075029\t  0.082341\t\tCURRENT LEARNING RATE: 0.015250436085608741\n",
      "previous_iter_valid_loss : 0.08438904583454132\n",
      "\n",
      "    349000\t  0.084256\t  0.084389\t  0.082337\t\tCURRENT LEARNING RATE: 0.015235193272200073\n",
      "previous_iter_valid_loss : 0.07795502245426178\n",
      "\n",
      "    349100\t  0.077995\t  0.077955\t  0.082196\t\tCURRENT LEARNING RATE: 0.015219965693985945\n",
      "previous_iter_valid_loss : 0.07519979029893875\n",
      "\n",
      "    349200\t  0.075221\t  0.075200\t  0.081969\t\tCURRENT LEARNING RATE: 0.015204753335738782\n",
      "previous_iter_valid_loss : 0.07569368928670883\n",
      "\n",
      "    349300\t  0.075651\t  0.075694\t  0.081917\t\tCURRENT LEARNING RATE: 0.015189556182246215\n",
      "previous_iter_valid_loss : 0.07644437998533249\n",
      "\n",
      "    349400\t  0.076459\t  0.076444\t  0.081930\t\tCURRENT LEARNING RATE: 0.015174374218311101\n",
      "previous_iter_valid_loss : 0.07673516869544983\n",
      "\n",
      "    349500\t  0.076765\t  0.076735\t  0.081943\t\tCURRENT LEARNING RATE: 0.01515920742875147\n",
      "previous_iter_valid_loss : 0.07534381002187729\n",
      "\n",
      "    349600\t  0.075295\t  0.075344\t  0.081724\t\tCURRENT LEARNING RATE: 0.015144055798400531\n",
      "previous_iter_valid_loss : 0.0755583718419075\n",
      "\n",
      "    349700\t  0.075521\t  0.075558\t  0.081728\t\tCURRENT LEARNING RATE: 0.015128919312106647\n",
      "previous_iter_valid_loss : 0.07732468098402023\n",
      "\n",
      "    349800\t  0.077270\t  0.077325\t  0.081751\t\tCURRENT LEARNING RATE: 0.015113797954733341\n",
      "previous_iter_valid_loss : 0.09998398274183273\n",
      "\n",
      "    349900\t  0.099868\t  0.099984\t  0.081987\t\tCURRENT LEARNING RATE: 0.01509869171115925\n",
      "previous_iter_valid_loss : 0.07740757614374161\n",
      "\n",
      "    350000\t  0.077430\t  0.077408\t  0.081987\t\tCURRENT LEARNING RATE: 0.01508360056627813\n",
      "previous_iter_valid_loss : 0.0759233608841896\n",
      "\n",
      "    350100\t  0.075906\t  0.075923\t  0.081913\t\tCURRENT LEARNING RATE: 0.01506852450499883\n",
      "previous_iter_valid_loss : 0.07981648296117783\n",
      "\n",
      "    350200\t  0.079914\t  0.079816\t  0.081821\t\tCURRENT LEARNING RATE: 0.015053463512245286\n",
      "previous_iter_valid_loss : 0.08142205327749252\n",
      "\n",
      "    350300\t  0.081527\t  0.081422\t  0.081873\t\tCURRENT LEARNING RATE: 0.015038417572956516\n",
      "previous_iter_valid_loss : 0.1120225042104721\n",
      "\n",
      "    350400\t  0.111886\t  0.112023\t  0.082016\t\tCURRENT LEARNING RATE: 0.01502338667208657\n",
      "previous_iter_valid_loss : 0.07617253065109253\n",
      "\n",
      "    350500\t  0.076175\t  0.076173\t  0.081990\t\tCURRENT LEARNING RATE: 0.015008370794604549\n",
      "previous_iter_valid_loss : 0.07591374963521957\n",
      "\n",
      "    350600\t  0.075853\t  0.075914\t  0.081952\t\tCURRENT LEARNING RATE: 0.014993369925494568\n",
      "previous_iter_valid_loss : 0.07889948785305023\n",
      "\n",
      "    350700\t  0.078895\t  0.078899\t  0.081924\t\tCURRENT LEARNING RATE: 0.014978384049755766\n",
      "previous_iter_valid_loss : 0.07642648369073868\n",
      "\n",
      "    350800\t  0.076363\t  0.076426\t  0.081829\t\tCURRENT LEARNING RATE: 0.014963413152402264\n",
      "previous_iter_valid_loss : 0.07536035776138306\n",
      "\n",
      "    350900\t  0.075328\t  0.075360\t  0.081761\t\tCURRENT LEARNING RATE: 0.01494845721846316\n",
      "previous_iter_valid_loss : 0.09441229701042175\n",
      "\n",
      "    351000\t  0.094616\t  0.094412\t  0.081688\t\tCURRENT LEARNING RATE: 0.014933516232982514\n",
      "previous_iter_valid_loss : 0.09358014911413193\n",
      "\n",
      "    351100\t  0.093470\t  0.093580\t  0.081634\t\tCURRENT LEARNING RATE: 0.014918590181019353\n",
      "previous_iter_valid_loss : 0.07674750685691833\n",
      "\n",
      "    351200\t  0.076756\t  0.076748\t  0.081537\t\tCURRENT LEARNING RATE: 0.014903679047647616\n",
      "previous_iter_valid_loss : 0.07950685173273087\n",
      "\n",
      "    351300\t  0.079390\t  0.079507\t  0.081515\t\tCURRENT LEARNING RATE: 0.014888782817956168\n",
      "previous_iter_valid_loss : 0.07750372588634491\n",
      "\n",
      "    351400\t  0.077515\t  0.077504\t  0.081425\t\tCURRENT LEARNING RATE: 0.014873901477048772\n",
      "previous_iter_valid_loss : 0.08386990427970886\n",
      "\n",
      "    351500\t  0.083983\t  0.083870\t  0.081478\t\tCURRENT LEARNING RATE: 0.0148590350100441\n",
      "previous_iter_valid_loss : 0.0764504224061966\n",
      "\n",
      "    351600\t  0.076395\t  0.076450\t  0.081482\t\tCURRENT LEARNING RATE: 0.014844183402075675\n",
      "previous_iter_valid_loss : 0.07813675701618195\n",
      "\n",
      "    351700\t  0.078069\t  0.078137\t  0.081493\t\tCURRENT LEARNING RATE: 0.01482934663829189\n",
      "previous_iter_valid_loss : 0.08035940676927567\n",
      "\n",
      "    351800\t  0.080270\t  0.080359\t  0.081507\t\tCURRENT LEARNING RATE: 0.014814524703855973\n",
      "previous_iter_valid_loss : 0.07645884156227112\n",
      "\n",
      "    351900\t  0.076413\t  0.076459\t  0.081439\t\tCURRENT LEARNING RATE: 0.014799717583946\n",
      "previous_iter_valid_loss : 0.07944592088460922\n",
      "\n",
      "    352000\t  0.079375\t  0.079446\t  0.081453\t\tCURRENT LEARNING RATE: 0.014784925263754845\n",
      "previous_iter_valid_loss : 0.07630077004432678\n",
      "\n",
      "    352100\t  0.076314\t  0.076301\t  0.081340\t\tCURRENT LEARNING RATE: 0.014770147728490186\n",
      "previous_iter_valid_loss : 0.08030211180448532\n",
      "\n",
      "    352200\t  0.080172\t  0.080302\t  0.081182\t\tCURRENT LEARNING RATE: 0.014755384963374477\n",
      "previous_iter_valid_loss : 0.09674139320850372\n",
      "\n",
      "    352300\t  0.096933\t  0.096741\t  0.081311\t\tCURRENT LEARNING RATE: 0.01474063695364497\n",
      "previous_iter_valid_loss : 0.08185117691755295\n",
      "\n",
      "    352400\t  0.081933\t  0.081851\t  0.081128\t\tCURRENT LEARNING RATE: 0.014725903684553645\n",
      "previous_iter_valid_loss : 0.07648368924856186\n",
      "\n",
      "    352500\t  0.076531\t  0.076484\t  0.081116\t\tCURRENT LEARNING RATE: 0.014711185141367232\n",
      "previous_iter_valid_loss : 0.08033861964941025\n",
      "\n",
      "    352600\t  0.080216\t  0.080339\t  0.081161\t\tCURRENT LEARNING RATE: 0.014696481309367179\n",
      "previous_iter_valid_loss : 0.07555156201124191\n",
      "\n",
      "    352700\t  0.075519\t  0.075552\t  0.081155\t\tCURRENT LEARNING RATE: 0.014681792173849666\n",
      "previous_iter_valid_loss : 0.08210813254117966\n",
      "\n",
      "    352800\t  0.082217\t  0.082108\t  0.081210\t\tCURRENT LEARNING RATE: 0.014667117720125552\n",
      "previous_iter_valid_loss : 0.0786842480301857\n",
      "\n",
      "    352900\t  0.078593\t  0.078684\t  0.081147\t\tCURRENT LEARNING RATE: 0.01465245793352038\n",
      "previous_iter_valid_loss : 0.07637649774551392\n",
      "\n",
      "    353000\t  0.076388\t  0.076376\t  0.081134\t\tCURRENT LEARNING RATE: 0.014637812799374355\n",
      "previous_iter_valid_loss : 0.07776202261447906\n",
      "\n",
      "    353100\t  0.077687\t  0.077762\t  0.081155\t\tCURRENT LEARNING RATE: 0.014623182303042357\n",
      "previous_iter_valid_loss : 0.07717426866292953\n",
      "\n",
      "    353200\t  0.077133\t  0.077174\t  0.081121\t\tCURRENT LEARNING RATE: 0.014608566429893879\n",
      "previous_iter_valid_loss : 0.07713409513235092\n",
      "\n",
      "    353300\t  0.077120\t  0.077134\t  0.081139\t\tCURRENT LEARNING RATE: 0.01459396516531305\n",
      "previous_iter_valid_loss : 0.07839988172054291\n",
      "\n",
      "    353400\t  0.078312\t  0.078400\t  0.081074\t\tCURRENT LEARNING RATE: 0.014579378494698595\n",
      "previous_iter_valid_loss : 0.0751456543803215\n",
      "\n",
      "    353500\t  0.075122\t  0.075146\t  0.081009\t\tCURRENT LEARNING RATE: 0.014564806403463856\n",
      "previous_iter_valid_loss : 0.08843084424734116\n",
      "\n",
      "    353600\t  0.088580\t  0.088431\t  0.081139\t\tCURRENT LEARNING RATE: 0.014550248877036735\n",
      "previous_iter_valid_loss : 0.07614045590162277\n",
      "\n",
      "    353700\t  0.076131\t  0.076140\t  0.081020\t\tCURRENT LEARNING RATE: 0.014535705900859702\n",
      "previous_iter_valid_loss : 0.08343833684921265\n",
      "\n",
      "    353800\t  0.083342\t  0.083438\t  0.081061\t\tCURRENT LEARNING RATE: 0.014521177460389776\n",
      "previous_iter_valid_loss : 0.07746421545743942\n",
      "\n",
      "    353900\t  0.077457\t  0.077464\t  0.081033\t\tCURRENT LEARNING RATE: 0.014506663541098527\n",
      "previous_iter_valid_loss : 0.07506340742111206\n",
      "\n",
      "    354000\t  0.075025\t  0.075063\t  0.080999\t\tCURRENT LEARNING RATE: 0.014492164128472028\n",
      "previous_iter_valid_loss : 0.07970467209815979\n",
      "\n",
      "    354100\t  0.079598\t  0.079705\t  0.080907\t\tCURRENT LEARNING RATE: 0.014477679208010864\n",
      "previous_iter_valid_loss : 0.07515037804841995\n",
      "\n",
      "    354200\t  0.075125\t  0.075150\t  0.080906\t\tCURRENT LEARNING RATE: 0.014463208765230108\n",
      "previous_iter_valid_loss : 0.07557620853185654\n",
      "\n",
      "    354300\t  0.075565\t  0.075576\t  0.080907\t\tCURRENT LEARNING RATE: 0.014448752785659331\n",
      "previous_iter_valid_loss : 0.07790787518024445\n",
      "\n",
      "    354400\t  0.077933\t  0.077908\t  0.080915\t\tCURRENT LEARNING RATE: 0.014434311254842543\n",
      "previous_iter_valid_loss : 0.10490588843822479\n",
      "\n",
      "    354500\t  0.105140\t  0.104906\t  0.080909\t\tCURRENT LEARNING RATE: 0.014419884158338211\n",
      "previous_iter_valid_loss : 0.08329218626022339\n",
      "\n",
      "    354600\t  0.083163\t  0.083292\t  0.080778\t\tCURRENT LEARNING RATE: 0.014405471481719235\n",
      "previous_iter_valid_loss : 0.07683189958333969\n",
      "\n",
      "    354700\t  0.076755\t  0.076832\t  0.080649\t\tCURRENT LEARNING RATE: 0.014391073210572945\n",
      "previous_iter_valid_loss : 0.08086629956960678\n",
      "\n",
      "    354800\t  0.080764\t  0.080866\t  0.080700\t\tCURRENT LEARNING RATE: 0.014376689330501067\n",
      "previous_iter_valid_loss : 0.0821618065237999\n",
      "\n",
      "    354900\t  0.082263\t  0.082162\t  0.080744\t\tCURRENT LEARNING RATE: 0.014362319827119717\n",
      "previous_iter_valid_loss : 0.078065425157547\n",
      "\n",
      "    355000\t  0.077985\t  0.078065\t  0.080556\t\tCURRENT LEARNING RATE: 0.014347964686059384\n",
      "previous_iter_valid_loss : 0.07841020077466965\n",
      "\n",
      "    355100\t  0.078322\t  0.078410\t  0.080503\t\tCURRENT LEARNING RATE: 0.01433362389296494\n",
      "previous_iter_valid_loss : 0.07611553370952606\n",
      "\n",
      "    355200\t  0.076072\t  0.076116\t  0.080429\t\tCURRENT LEARNING RATE: 0.014319297433495583\n",
      "previous_iter_valid_loss : 0.07607443630695343\n",
      "\n",
      "    355300\t  0.075995\t  0.076074\t  0.080427\t\tCURRENT LEARNING RATE: 0.014304985293324853\n",
      "previous_iter_valid_loss : 0.088303342461586\n",
      "\n",
      "    355400\t  0.088211\t  0.088303\t  0.080470\t\tCURRENT LEARNING RATE: 0.014290687458140602\n",
      "previous_iter_valid_loss : 0.07533884793519974\n",
      "\n",
      "    355500\t  0.075345\t  0.075339\t  0.080380\t\tCURRENT LEARNING RATE: 0.014276403913645005\n",
      "previous_iter_valid_loss : 0.07823198288679123\n",
      "\n",
      "    355600\t  0.078139\t  0.078232\t  0.080160\t\tCURRENT LEARNING RATE: 0.014262134645554514\n",
      "previous_iter_valid_loss : 0.0804409384727478\n",
      "\n",
      "    355700\t  0.080491\t  0.080441\t  0.080083\t\tCURRENT LEARNING RATE: 0.014247879639599854\n",
      "previous_iter_valid_loss : 0.07564198970794678\n",
      "\n",
      "    355800\t  0.075589\t  0.075642\t  0.080041\t\tCURRENT LEARNING RATE: 0.014233638881526017\n",
      "previous_iter_valid_loss : 0.07569917291402817\n",
      "\n",
      "    355900\t  0.075680\t  0.075699\t  0.080025\t\tCURRENT LEARNING RATE: 0.014219412357092252\n",
      "previous_iter_valid_loss : 0.08309898525476456\n",
      "\n",
      "    356000\t  0.083195\t  0.083099\t  0.079983\t\tCURRENT LEARNING RATE: 0.01420520005207203\n",
      "previous_iter_valid_loss : 0.07843576371669769\n",
      "\n",
      "    356100\t  0.078464\t  0.078436\t  0.079969\t\tCURRENT LEARNING RATE: 0.014191001952253045\n",
      "previous_iter_valid_loss : 0.07681722193956375\n",
      "\n",
      "    356200\t  0.076764\t  0.076817\t  0.079972\t\tCURRENT LEARNING RATE: 0.014176818043437187\n",
      "previous_iter_valid_loss : 0.07943243533372879\n",
      "\n",
      "    356300\t  0.079495\t  0.079432\t  0.079986\t\tCURRENT LEARNING RATE: 0.01416264831144056\n",
      "previous_iter_valid_loss : 0.07584097236394882\n",
      "\n",
      "    356400\t  0.075845\t  0.075841\t  0.079862\t\tCURRENT LEARNING RATE: 0.014148492742093427\n",
      "previous_iter_valid_loss : 0.07650627195835114\n",
      "\n",
      "    356500\t  0.076439\t  0.076506\t  0.079475\t\tCURRENT LEARNING RATE: 0.014134351321240213\n",
      "previous_iter_valid_loss : 0.07527723908424377\n",
      "\n",
      "    356600\t  0.075265\t  0.075277\t  0.079475\t\tCURRENT LEARNING RATE: 0.014120224034739491\n",
      "previous_iter_valid_loss : 0.07546491175889969\n",
      "\n",
      "    356700\t  0.075487\t  0.075465\t  0.079460\t\tCURRENT LEARNING RATE: 0.01410611086846399\n",
      "previous_iter_valid_loss : 0.07497788965702057\n",
      "\n",
      "    356800\t  0.074931\t  0.074978\t  0.079453\t\tCURRENT LEARNING RATE: 0.01409201180830053\n",
      "previous_iter_valid_loss : 0.08636931329965591\n",
      "\n",
      "    356900\t  0.086252\t  0.086369\t  0.079546\t\tCURRENT LEARNING RATE: 0.014077926840150053\n",
      "previous_iter_valid_loss : 0.08192526549100876\n",
      "\n",
      "    357000\t  0.082006\t  0.081925\t  0.079511\t\tCURRENT LEARNING RATE: 0.014063855949927585\n",
      "previous_iter_valid_loss : 0.07536152005195618\n",
      "\n",
      "    357100\t  0.075313\t  0.075362\t  0.079505\t\tCURRENT LEARNING RATE: 0.014049799123562244\n",
      "previous_iter_valid_loss : 0.08346233516931534\n",
      "\n",
      "    357200\t  0.083339\t  0.083462\t  0.079578\t\tCURRENT LEARNING RATE: 0.014035756346997197\n",
      "previous_iter_valid_loss : 0.08636021614074707\n",
      "\n",
      "    357300\t  0.086468\t  0.086360\t  0.079571\t\tCURRENT LEARNING RATE: 0.014021727606189666\n",
      "previous_iter_valid_loss : 0.07578925043344498\n",
      "\n",
      "    357400\t  0.075795\t  0.075789\t  0.079556\t\tCURRENT LEARNING RATE: 0.014007712887110904\n",
      "previous_iter_valid_loss : 0.07598965615034103\n",
      "\n",
      "    357500\t  0.075933\t  0.075990\t  0.079476\t\tCURRENT LEARNING RATE: 0.013993712175746202\n",
      "previous_iter_valid_loss : 0.08622943609952927\n",
      "\n",
      "    357600\t  0.086377\t  0.086229\t  0.079571\t\tCURRENT LEARNING RATE: 0.013979725458094843\n",
      "previous_iter_valid_loss : 0.0989198312163353\n",
      "\n",
      "    357700\t  0.099162\t  0.098920\t  0.079804\t\tCURRENT LEARNING RATE: 0.013965752720170107\n",
      "previous_iter_valid_loss : 0.09498269110918045\n",
      "\n",
      "    357800\t  0.094875\t  0.094983\t  0.079990\t\tCURRENT LEARNING RATE: 0.013951793947999249\n",
      "previous_iter_valid_loss : 0.09420254081487656\n",
      "\n",
      "    357900\t  0.094083\t  0.094203\t  0.080176\t\tCURRENT LEARNING RATE: 0.013937849127623508\n",
      "previous_iter_valid_loss : 0.07617562264204025\n",
      "\n",
      "    358000\t  0.076115\t  0.076176\t  0.080124\t\tCURRENT LEARNING RATE: 0.013923918245098055\n",
      "previous_iter_valid_loss : 0.08013167232275009\n",
      "\n",
      "    358100\t  0.080212\t  0.080132\t  0.080150\t\tCURRENT LEARNING RATE: 0.013910001286492009\n",
      "previous_iter_valid_loss : 0.07636060565710068\n",
      "\n",
      "    358200\t  0.076330\t  0.076361\t  0.080132\t\tCURRENT LEARNING RATE: 0.0138960982378884\n",
      "previous_iter_valid_loss : 0.0968688353896141\n",
      "\n",
      "    358300\t  0.097077\t  0.096869\t  0.080310\t\tCURRENT LEARNING RATE: 0.013882209085384196\n",
      "previous_iter_valid_loss : 0.07609287649393082\n",
      "\n",
      "    358400\t  0.076043\t  0.076093\t  0.080309\t\tCURRENT LEARNING RATE: 0.013868333815090233\n",
      "previous_iter_valid_loss : 0.08178719878196716\n",
      "\n",
      "    358500\t  0.081866\t  0.081787\t  0.080364\t\tCURRENT LEARNING RATE: 0.01385447241313124\n",
      "previous_iter_valid_loss : 0.0840587317943573\n",
      "\n",
      "    358600\t  0.083922\t  0.084059\t  0.080441\t\tCURRENT LEARNING RATE: 0.01384062486564581\n",
      "previous_iter_valid_loss : 0.07766101509332657\n",
      "\n",
      "    358700\t  0.077679\t  0.077661\t  0.080467\t\tCURRENT LEARNING RATE: 0.013826791158786404\n",
      "previous_iter_valid_loss : 0.07663507759571075\n",
      "\n",
      "    358800\t  0.076617\t  0.076635\t  0.080463\t\tCURRENT LEARNING RATE: 0.013812971278719308\n",
      "previous_iter_valid_loss : 0.09430564194917679\n",
      "\n",
      "    358900\t  0.094494\t  0.094306\t  0.080656\t\tCURRENT LEARNING RATE: 0.013799165211624644\n",
      "previous_iter_valid_loss : 0.07850098609924316\n",
      "\n",
      "    359000\t  0.078529\t  0.078501\t  0.080597\t\tCURRENT LEARNING RATE: 0.013785372943696335\n",
      "previous_iter_valid_loss : 0.07639676332473755\n",
      "\n",
      "    359100\t  0.076394\t  0.076397\t  0.080581\t\tCURRENT LEARNING RATE: 0.013771594461142124\n",
      "previous_iter_valid_loss : 0.09551124274730682\n",
      "\n",
      "    359200\t  0.095368\t  0.095511\t  0.080784\t\tCURRENT LEARNING RATE: 0.013757829750183522\n",
      "previous_iter_valid_loss : 0.07533165067434311\n",
      "\n",
      "    359300\t  0.075325\t  0.075332\t  0.080781\t\tCURRENT LEARNING RATE: 0.013744078797055817\n",
      "previous_iter_valid_loss : 0.09618992358446121\n",
      "\n",
      "    359400\t  0.096071\t  0.096190\t  0.080978\t\tCURRENT LEARNING RATE: 0.013730341588008047\n",
      "previous_iter_valid_loss : 0.07525008916854858\n",
      "\n",
      "    359500\t  0.075219\t  0.075250\t  0.080963\t\tCURRENT LEARNING RATE: 0.013716618109303016\n",
      "previous_iter_valid_loss : 0.09094787389039993\n",
      "\n",
      "    359600\t  0.090796\t  0.090948\t  0.081120\t\tCURRENT LEARNING RATE: 0.013702908347217237\n",
      "previous_iter_valid_loss : 0.07670978456735611\n",
      "\n",
      "    359700\t  0.076725\t  0.076710\t  0.081131\t\tCURRENT LEARNING RATE: 0.013689212288040948\n",
      "previous_iter_valid_loss : 0.07767634093761444\n",
      "\n",
      "    359800\t  0.077617\t  0.077676\t  0.081135\t\tCURRENT LEARNING RATE: 0.013675529918078083\n",
      "previous_iter_valid_loss : 0.08151347935199738\n",
      "\n",
      "    359900\t  0.081617\t  0.081513\t  0.080950\t\tCURRENT LEARNING RATE: 0.01366186122364628\n",
      "previous_iter_valid_loss : 0.12735013663768768\n",
      "\n",
      "    360000\t  0.127262\t  0.127350\t  0.081449\t\tCURRENT LEARNING RATE: 0.013648206191076838\n",
      "previous_iter_valid_loss : 0.07510598748922348\n",
      "\n",
      "    360100\t  0.075083\t  0.075106\t  0.081441\t\tCURRENT LEARNING RATE: 0.013634564806714726\n",
      "previous_iter_valid_loss : 0.08527779579162598\n",
      "\n",
      "    360200\t  0.085157\t  0.085278\t  0.081496\t\tCURRENT LEARNING RATE: 0.013620937056918551\n",
      "previous_iter_valid_loss : 0.07576701045036316\n",
      "\n",
      "    360300\t  0.075706\t  0.075767\t  0.081439\t\tCURRENT LEARNING RATE: 0.013607322928060573\n",
      "previous_iter_valid_loss : 0.07682610303163528\n",
      "\n",
      "    360400\t  0.076791\t  0.076826\t  0.081087\t\tCURRENT LEARNING RATE: 0.013593722406526659\n",
      "previous_iter_valid_loss : 0.07929141819477081\n",
      "\n",
      "    360500\t  0.079343\t  0.079291\t  0.081118\t\tCURRENT LEARNING RATE: 0.013580135478716282\n",
      "previous_iter_valid_loss : 0.07500693947076797\n",
      "\n",
      "    360600\t  0.074988\t  0.075007\t  0.081109\t\tCURRENT LEARNING RATE: 0.013566562131042511\n",
      "previous_iter_valid_loss : 0.07550685107707977\n",
      "\n",
      "    360700\t  0.075452\t  0.075507\t  0.081075\t\tCURRENT LEARNING RATE: 0.013553002349932007\n",
      "previous_iter_valid_loss : 0.09577182680368423\n",
      "\n",
      "    360800\t  0.095639\t  0.095772\t  0.081269\t\tCURRENT LEARNING RATE: 0.013539456121824982\n",
      "previous_iter_valid_loss : 0.07594245672225952\n",
      "\n",
      "    360900\t  0.075942\t  0.075942\t  0.081275\t\tCURRENT LEARNING RATE: 0.013525923433175208\n",
      "previous_iter_valid_loss : 0.08611425757408142\n",
      "\n",
      "    361000\t  0.085996\t  0.086114\t  0.081192\t\tCURRENT LEARNING RATE: 0.013512404270449987\n",
      "previous_iter_valid_loss : 0.07663365453481674\n",
      "\n",
      "    361100\t  0.076628\t  0.076634\t  0.081022\t\tCURRENT LEARNING RATE: 0.01349889862013017\n",
      "previous_iter_valid_loss : 0.0780937597155571\n",
      "\n",
      "    361200\t  0.078148\t  0.078094\t  0.081036\t\tCURRENT LEARNING RATE: 0.013485406468710097\n",
      "previous_iter_valid_loss : 0.07518129795789719\n",
      "\n",
      "    361300\t  0.075182\t  0.075181\t  0.080992\t\tCURRENT LEARNING RATE: 0.013471927802697617\n",
      "previous_iter_valid_loss : 0.07610954344272614\n",
      "\n",
      "    361400\t  0.076059\t  0.076110\t  0.080978\t\tCURRENT LEARNING RATE: 0.013458462608614056\n",
      "previous_iter_valid_loss : 0.08451557904481888\n",
      "\n",
      "    361500\t  0.084621\t  0.084516\t  0.080985\t\tCURRENT LEARNING RATE: 0.013445010872994231\n",
      "previous_iter_valid_loss : 0.08453090488910675\n",
      "\n",
      "    361600\t  0.084620\t  0.084531\t  0.081066\t\tCURRENT LEARNING RATE: 0.013431572582386399\n",
      "previous_iter_valid_loss : 0.07544349879026413\n",
      "\n",
      "    361700\t  0.075413\t  0.075443\t  0.081039\t\tCURRENT LEARNING RATE: 0.01341814772335227\n",
      "previous_iter_valid_loss : 0.0760221853852272\n",
      "\n",
      "    361800\t  0.075969\t  0.076022\t  0.080995\t\tCURRENT LEARNING RATE: 0.013404736282466976\n",
      "previous_iter_valid_loss : 0.07760386168956757\n",
      "\n",
      "    361900\t  0.077607\t  0.077604\t  0.081007\t\tCURRENT LEARNING RATE: 0.013391338246319088\n",
      "previous_iter_valid_loss : 0.07682152092456818\n",
      "\n",
      "    362000\t  0.076842\t  0.076822\t  0.080981\t\tCURRENT LEARNING RATE: 0.013377953601510562\n",
      "previous_iter_valid_loss : 0.07560117542743683\n",
      "\n",
      "    362100\t  0.075597\t  0.075601\t  0.080974\t\tCURRENT LEARNING RATE: 0.01336458233465675\n",
      "previous_iter_valid_loss : 0.07508611679077148\n",
      "\n",
      "    362200\t  0.075044\t  0.075086\t  0.080921\t\tCURRENT LEARNING RATE: 0.013351224432386384\n",
      "previous_iter_valid_loss : 0.090651735663414\n",
      "\n",
      "    362300\t  0.090532\t  0.090652\t  0.080861\t\tCURRENT LEARNING RATE: 0.013337879881341566\n",
      "previous_iter_valid_loss : 0.07744451612234116\n",
      "\n",
      "    362400\t  0.077386\t  0.077445\t  0.080817\t\tCURRENT LEARNING RATE: 0.013324548668177743\n",
      "previous_iter_valid_loss : 0.07508417963981628\n",
      "\n",
      "    362500\t  0.075056\t  0.075084\t  0.080803\t\tCURRENT LEARNING RATE: 0.013311230779563699\n",
      "previous_iter_valid_loss : 0.07677450031042099\n",
      "\n",
      "    362600\t  0.076769\t  0.076775\t  0.080767\t\tCURRENT LEARNING RATE: 0.013297926202181542\n",
      "previous_iter_valid_loss : 0.0761319026350975\n",
      "\n",
      "    362700\t  0.076159\t  0.076132\t  0.080773\t\tCURRENT LEARNING RATE: 0.01328463492272669\n",
      "previous_iter_valid_loss : 0.08063012361526489\n",
      "\n",
      "    362800\t  0.080701\t  0.080630\t  0.080758\t\tCURRENT LEARNING RATE: 0.013271356927907874\n",
      "previous_iter_valid_loss : 0.08806098997592926\n",
      "\n",
      "    362900\t  0.088242\t  0.088061\t  0.080852\t\tCURRENT LEARNING RATE: 0.01325809220444709\n",
      "previous_iter_valid_loss : 0.07541391998529434\n",
      "\n",
      "    363000\t  0.075379\t  0.075414\t  0.080842\t\tCURRENT LEARNING RATE: 0.013244840739079618\n",
      "previous_iter_valid_loss : 0.0805586725473404\n",
      "\n",
      "    363100\t  0.080617\t  0.080559\t  0.080870\t\tCURRENT LEARNING RATE: 0.013231602518553981\n",
      "previous_iter_valid_loss : 0.08430799841880798\n",
      "\n",
      "    363200\t  0.084202\t  0.084308\t  0.080941\t\tCURRENT LEARNING RATE: 0.013218377529631972\n",
      "previous_iter_valid_loss : 0.09596576541662216\n",
      "\n",
      "    363300\t  0.095853\t  0.095966\t  0.081130\t\tCURRENT LEARNING RATE: 0.013205165759088594\n",
      "previous_iter_valid_loss : 0.07618765532970428\n",
      "\n",
      "    363400\t  0.076207\t  0.076188\t  0.081108\t\tCURRENT LEARNING RATE: 0.013191967193712077\n",
      "previous_iter_valid_loss : 0.08283799141645432\n",
      "\n",
      "    363500\t  0.082740\t  0.082838\t  0.081184\t\tCURRENT LEARNING RATE: 0.013178781820303844\n",
      "previous_iter_valid_loss : 0.08121631294488907\n",
      "\n",
      "    363600\t  0.081294\t  0.081216\t  0.081112\t\tCURRENT LEARNING RATE: 0.013165609625678538\n",
      "previous_iter_valid_loss : 0.0772877186536789\n",
      "\n",
      "    363700\t  0.077307\t  0.077288\t  0.081124\t\tCURRENT LEARNING RATE: 0.013152450596663954\n",
      "previous_iter_valid_loss : 0.09575854986906052\n",
      "\n",
      "    363800\t  0.095957\t  0.095759\t  0.081247\t\tCURRENT LEARNING RATE: 0.013139304720101063\n",
      "previous_iter_valid_loss : 0.08986137062311172\n",
      "\n",
      "    363900\t  0.089746\t  0.089861\t  0.081371\t\tCURRENT LEARNING RATE: 0.01312617198284398\n",
      "previous_iter_valid_loss : 0.09935637563467026\n",
      "\n",
      "    364000\t  0.099223\t  0.099356\t  0.081614\t\tCURRENT LEARNING RATE: 0.01311305237175998\n",
      "previous_iter_valid_loss : 0.08197134733200073\n",
      "\n",
      "    364100\t  0.082053\t  0.081971\t  0.081637\t\tCURRENT LEARNING RATE: 0.013099945873729445\n",
      "previous_iter_valid_loss : 0.09868565201759338\n",
      "\n",
      "    364200\t  0.098908\t  0.098686\t  0.081872\t\tCURRENT LEARNING RATE: 0.013086852475645876\n",
      "previous_iter_valid_loss : 0.07733625918626785\n",
      "\n",
      "    364300\t  0.077368\t  0.077336\t  0.081890\t\tCURRENT LEARNING RATE: 0.013073772164415867\n",
      "previous_iter_valid_loss : 0.08314865827560425\n",
      "\n",
      "    364400\t  0.083221\t  0.083149\t  0.081942\t\tCURRENT LEARNING RATE: 0.013060704926959116\n",
      "previous_iter_valid_loss : 0.07578939199447632\n",
      "\n",
      "    364500\t  0.075781\t  0.075789\t  0.081651\t\tCURRENT LEARNING RATE: 0.013047650750208382\n",
      "previous_iter_valid_loss : 0.07658777385950089\n",
      "\n",
      "    364600\t  0.076578\t  0.076588\t  0.081584\t\tCURRENT LEARNING RATE: 0.013034609621109486\n",
      "previous_iter_valid_loss : 0.07801365852355957\n",
      "\n",
      "    364700\t  0.078061\t  0.078014\t  0.081596\t\tCURRENT LEARNING RATE: 0.01302158152662129\n",
      "previous_iter_valid_loss : 0.07527576386928558\n",
      "\n",
      "    364800\t  0.075233\t  0.075276\t  0.081540\t\tCURRENT LEARNING RATE: 0.013008566453715713\n",
      "previous_iter_valid_loss : 0.08060167729854584\n",
      "\n",
      "    364900\t  0.080491\t  0.080602\t  0.081524\t\tCURRENT LEARNING RATE: 0.012995564389377674\n",
      "previous_iter_valid_loss : 0.08067604154348373\n",
      "\n",
      "    365000\t  0.080746\t  0.080676\t  0.081550\t\tCURRENT LEARNING RATE: 0.012982575320605105\n",
      "previous_iter_valid_loss : 0.07877037674188614\n",
      "\n",
      "    365100\t  0.078797\t  0.078770\t  0.081554\t\tCURRENT LEARNING RATE: 0.012969599234408935\n",
      "previous_iter_valid_loss : 0.07503291964530945\n",
      "\n",
      "    365200\t  0.075003\t  0.075033\t  0.081543\t\tCURRENT LEARNING RATE: 0.012956636117813084\n",
      "previous_iter_valid_loss : 0.0870894342660904\n",
      "\n",
      "    365300\t  0.087212\t  0.087089\t  0.081653\t\tCURRENT LEARNING RATE: 0.012943685957854433\n",
      "previous_iter_valid_loss : 0.09748659282922745\n",
      "\n",
      "    365400\t  0.097358\t  0.097487\t  0.081745\t\tCURRENT LEARNING RATE: 0.012930748741582817\n",
      "previous_iter_valid_loss : 0.07935633510351181\n",
      "\n",
      "    365500\t  0.079263\t  0.079356\t  0.081785\t\tCURRENT LEARNING RATE: 0.012917824456061013\n",
      "previous_iter_valid_loss : 0.07514646649360657\n",
      "\n",
      "    365600\t  0.075136\t  0.075146\t  0.081754\t\tCURRENT LEARNING RATE: 0.01290491308836475\n",
      "previous_iter_valid_loss : 0.07565788179636002\n",
      "\n",
      "    365700\t  0.075648\t  0.075658\t  0.081706\t\tCURRENT LEARNING RATE: 0.01289201462558265\n",
      "previous_iter_valid_loss : 0.08069818466901779\n",
      "\n",
      "    365800\t  0.080734\t  0.080698\t  0.081757\t\tCURRENT LEARNING RATE: 0.012879129054816248\n",
      "previous_iter_valid_loss : 0.08070917427539825\n",
      "\n",
      "    365900\t  0.080621\t  0.080709\t  0.081807\t\tCURRENT LEARNING RATE: 0.01286625636317997\n",
      "previous_iter_valid_loss : 0.07783327251672745\n",
      "\n",
      "    366000\t  0.077892\t  0.077833\t  0.081754\t\tCURRENT LEARNING RATE: 0.012853396537801133\n",
      "previous_iter_valid_loss : 0.07540732622146606\n",
      "\n",
      "    366100\t  0.075410\t  0.075407\t  0.081724\t\tCURRENT LEARNING RATE: 0.012840549565819906\n",
      "previous_iter_valid_loss : 0.07817050814628601\n",
      "\n",
      "    366200\t  0.078197\t  0.078171\t  0.081738\t\tCURRENT LEARNING RATE: 0.012827715434389313\n",
      "previous_iter_valid_loss : 0.07910898327827454\n",
      "\n",
      "    366300\t  0.079041\t  0.079109\t  0.081734"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "target = \"RecoDatapT\"\n",
    "source = FIELDS[target]\n",
    "features = source[\"inputs\"]\n",
    "print(\"Training Features:\\n\", features)\n",
    "print(\"\\nTarget = \", target)\n",
    "\n",
    "print(\"USING NEW DATASET\\n\")\n",
    "######################################\n",
    "USE_BRADEN_SCALING=False\n",
    "#####################################\n",
    "################################### CONFIGURATIONS ###################################\n",
    "\n",
    "JUPYTER = True\n",
    "use_subsample = False\n",
    "# use_subsample = True\n",
    "if use_subsample:\n",
    "    SUBSAMPLE = int(\n",
    "        1e5\n",
    "    )  # subsample use for development - in production use whole dataset\n",
    "else:\n",
    "    SUBSAMPLE = None\n",
    "\n",
    "# Load scaled data\n",
    "# scaled_train_data, scaled_test_data, scaled_valid_data = load_scaled_dataframes()\n",
    "\n",
    "\n",
    "# Get targets and features\n",
    "# if USE_BRADEN_SCALING==True:\n",
    "#     print(f\"spliting data for {target}\")\n",
    "#     train_t, train_x = split_t_x(\n",
    "#         df=scaled_train_data, target=target, input_features=features\n",
    "#     )\n",
    "#     print(\"train_t shape = \", train_t.shape, \"train_x shape = \", train_x.shape)\n",
    "#     print(\"\\n Training features:\\n\")\n",
    "#     print(train_x)\n",
    "#     valid_t, valid_x = split_t_x(\n",
    "#         df=scaled_valid_data, target=target, input_features=features\n",
    "#     )\n",
    "#     print(\"valid_t shape = \", valid_t.shape, \"valid_x shape = \", valid_x.shape)\n",
    "#     test_t, test_x = split_t_x(df=scaled_test_data, target=target, input_features=features)\n",
    "#     print(\"test_t shape = \", test_t.shape, \"test_x shape = \", test_x.shape)\n",
    "\n",
    "# else:\n",
    "#     print(f\"spliting data for {target}\")\n",
    "#     train_t, train_x = normal_split_t_x(\n",
    "#     df=raw_train_data, target=target, input_features=features\n",
    "#     )\n",
    "#     print(\"train_t shape = \", train_t.shape, \"train_x shape = \", train_x.shape)\n",
    "#     print(\"\\n Training features:\\n\")\n",
    "#     print(train_x)\n",
    "#     valid_t, valid_x = normal_split_t_x(\n",
    "#     df=raw_valid_data, target=target, input_features=features\n",
    "#     )\n",
    "#     print(\"valid_t shape = \", valid_t.shape, \"valid_x shape = \", valid_x.shape)\n",
    "#     test_t, test_x = normal_split_t_x(df=raw_test_data, target=target, input_features=features)\n",
    "#     print(\"test_t shape = \", test_t.shape, \"test_x shape = \", test_x.shape)\n",
    "\n",
    "\n",
    "print(f\"spliting data for {target}\")\n",
    "train_t, train_x = normal_split_t_x(\n",
    "df=raw_train_data, target=target, input_features=features\n",
    ")\n",
    "print(\"train_t shape = \", train_t.shape, \"train_x shape = \", train_x.shape)\n",
    "print(\"\\n Training features:\\n\")\n",
    "print(train_x)\n",
    "valid_t, valid_x = normal_split_t_x(\n",
    "df=raw_valid_data, target=target, input_features=features\n",
    ")\n",
    "print(\"valid_t shape = \", valid_t.shape, \"valid_x shape = \", valid_x.shape)\n",
    "test_t, test_x = normal_split_t_x(df=raw_test_data, target=target, input_features=features)\n",
    "print(\"test_t shape = \", test_t.shape, \"test_x shape = \", test_x.shape)\n",
    "\n",
    "\n",
    "print(\"no need to train_test_split since we already have the split dataframes\")\n",
    "print(valid_x.mean(axis=0), valid_x.std(axis=0))\n",
    "print(train_x.mean(axis=0), train_x.std(axis=0))\n",
    "print(valid_t.mean(), valid_t.std())\n",
    "print(train_t.mean(), train_t.std())\n",
    "NFEATURES = train_x.shape[1]\n",
    "######################################################\n",
    "\n",
    "# Apply z scaling to features and targets\n",
    "# to features\n",
    "TRAIN_SCALE_DICT=get_train_scale_dict(USE_BRADEN_SCALING)\n",
    "apply_z_generator = apply_z_to_features(TRAIN_SCALE_DICT, train_x, test_x, valid_x)\n",
    "train_x_z_scaled = next(apply_z_generator)\n",
    "test_x_z_scaled = next(apply_z_generator)\n",
    "valid_x_z_scaled = next(apply_z_generator)\n",
    "print(valid_x_z_scaled.mean(axis=0), valid_x_z_scaled.std(axis=0))\n",
    "print(train_x_z_scaled.mean(axis=0), train_x_z_scaled.std(axis=0))\n",
    "\n",
    "# to targets\n",
    "apply_z_to_targets_generator = apply_z_to_targets(\n",
    "    train_t, test_t, valid_t\n",
    ")\n",
    "train_t_z_scaled = next(apply_z_to_targets_generator)\n",
    "test_t_z_scaled = next(apply_z_to_targets_generator)\n",
    "valid_t_z_scaled = next(apply_z_to_targets_generator)\n",
    "print(valid_t_z_scaled.mean(), valid_t_z_scaled.std())\n",
    "print(train_t_z_scaled.mean(), train_t_z_scaled.std())\n",
    "\n",
    "\n",
    "\n",
    "###########################################################\n",
    "# Decide on parameters for this model and training\n",
    "PARAMS_pT = {\n",
    "\"n_layers\": int(3),\n",
    "\"hidden_size\": int(16),\n",
    "\"dropout_1\": float(0.6),\n",
    "\"dropout_2\": float(0.1),\n",
    "\"activation\": \"LeakyReLU\",\n",
    "    'optimizer_name':'NAdam',\n",
    "    'starting_learning_rate':float(0.5),\n",
    "    'momentum':float(0.6),\n",
    "    'batch_size':int(1024),\n",
    "    'n_iterations': int(2e6),\n",
    "}\n",
    "\n",
    "optimizer_name=PARAMS_pT['optimizer_name']\n",
    "print(type(optimizer_name))\n",
    "# optimizer_name = BEST_PARAMS[\"optimizer_name\"].to_string().split()[1]\n",
    "NITERATIONS=PARAMS_pT['n_iterations']\n",
    "BATCHSIZE=PARAMS_pT['batch_size']\n",
    "comment=''\n",
    "\n",
    "\n",
    "\n",
    "# N_epochs X N_train_examples = N_iterations X batch_size\n",
    "N_epochs = (NITERATIONS * BATCHSIZE) / int(train_x.shape[0])\n",
    "print(f\"training for {NITERATIONS} iteration, which is  {N_epochs} epochs\")\n",
    "\n",
    "#train model from scratch\n",
    "filename_model = utils.get_model_filename(target, PARAMS_pT)\n",
    "#or pick up trained model\n",
    "# filename_model = 'Trained_IQNx4_RecoDatapT_10_layer6_hiddenLeakyReLU_activation512_batchsize300_Kiteration.dict'\n",
    "\n",
    "trained_models_dir = \"trained_models\"\n",
    "utils.mkdir(trained_models_dir)\n",
    "# on cluster, Im using another TRAIN directory\n",
    "PATH_model = os.path.join(\n",
    "    IQN_BASE, #the loaction of the repo\n",
    "    \"JupyterBook\", #up tp TRAIN could be combined in a srs dicretory\n",
    "    \"Cluster\", \n",
    "    \"TRAIN\",\n",
    "    trained_models_dir, #/trained_models \n",
    "    filename_model # utils.get_model_filename has the saved file format \n",
    ")\n",
    "\n",
    "#LOAD EITHER TRAINED OR UNTRAINED MODEL\n",
    "# to load untrained model (start training from scratch), uncomment the next line\n",
    "untrained_model = load_untrained_model(PARAMS_pT)\n",
    "# to continune training of model (pickup where the previous training left off), uncomment below\n",
    "# trained_model =load_trained_model(PATH=PATH_model, PARAMS=PARAMS_pT)\n",
    "\n",
    "IQN_trace = ([], [], [], [])\n",
    "traces_step = int(100)\n",
    "traces_window = traces_step\n",
    "IQN = run(\n",
    "    target=target,\n",
    "    model=untrained_model,\n",
    "    train_x=train_x_z_scaled,\n",
    "    train_t=train_t_z_scaled,\n",
    "    valid_x=test_x_z_scaled,\n",
    "    valid_t=test_t_z_scaled,\n",
    "    traces=IQN_trace,\n",
    "    PARAMS=PARAMS_pT,\n",
    "    traces_step=traces_step,\n",
    "    traces_window=traces_window,\n",
    "    save_model=False,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "SAVE_LAST_MODEL=False\n",
    "if SAVE_LAST_MODEL:\n",
    "    # ## Save last iteration of trained model \n",
    "    #dont save the last model, it might be worse than previous iterations, which were automatically savedby model checkpoints\n",
    "\n",
    "    final_path = utils.get_model_filename(target, PARAMS_pT).split('.dict')[0]+'_FINAL.dict'\n",
    "\n",
    "    trained_models_dir = \"trained_models\"\n",
    "    utils.mkdir(trained_models_dir)\n",
    "    # on cluster, Im using another TRAIN directory\n",
    "    PATH_final_model = os.path.join(\n",
    "    IQN_BASE, \"JupyterBook\", \"Cluster\", \"TRAIN\", trained_models_dir, final_path\n",
    "    )\n",
    "\n",
    "    save_model(IQN, PATH_final_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb6e75c-af85-4e41-9c7b-591ae354c773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}