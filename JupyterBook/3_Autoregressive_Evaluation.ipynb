{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37d6920b-1452-45a8-8751-0b7d6e8e8fd0",
   "metadata": {},
   "source": [
    "# IQNx4: Chapter 3: Autoregressive Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c623666-defa-4463-adfe-f7667c7d385d",
   "metadata": {},
   "source": [
    "## 3.1: Imports and Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31994c2b-a804-4348-a5a9-8bd8c89ff64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using torch version 1.11.0.post2\n",
      "matplotlib version=  3.5.3\n",
      "using (optional) optuna version 3.0.0\n",
      "BASE directoy properly set =  /home/ali/Desktop/Pulled_Github_Repositories/torchQN\n",
      "using torch version 1.11.0.post2\n",
      "matplotlib version=  3.5.3\n",
      "using (optional) optuna version 3.0.0\n",
      "BASE directoy properly set =  /home/ali/Desktop/Pulled_Github_Repositories/torchQN\n",
      "DATA directory also properly set, in /home/ali/Desktop/Pulled_Github_Repositories/IQN_HEP/Davidson/data\n",
      "DATA directory also properly set, in /home/ali/Desktop/Pulled_Github_Repositories/IQN_HEP/Davidson/data\n",
      "BASE directoy properly set =  /home/ali/Desktop/Pulled_Github_Repositories/torchQN\n",
      "using DATA_DIR=/home/ali/Desktop/Pulled_Github_Repositories/IQN_HEP/Davidson/data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_378619/2263036294.py:54: MatplotlibDeprecationWarning: Support for setting an rcParam that expects a str value to a non-str value is deprecated since 3.5 and support will be removed two minor releases later.\n",
      "  mp.rcParams[\"text.latex.preamble\"] = [r\"\\usepackage{amsmath}\"]  # for \\text command\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import scipy as sp; import scipy.stats as st\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "print(f\"using torch version {torch.__version__}\")\n",
    "# use numba's just-in-time compiler to speed things up\n",
    "# from numba import njit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib as mp\n",
    "\n",
    "print(\"matplotlib version= \", mp.__version__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# reset matplotlib stle/parameters\n",
    "# reset matplotlib parameters to their defaults\n",
    "# plt.style.use('seaborn-deep')\n",
    "# mp.rcParams['agg.path.chunksize'] = 10000\n",
    "font_legend = 15\n",
    "font_axes = 15\n",
    "# %matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# from IPython.display import Image, display\n",
    "# from importlib import import_module\n",
    "# import plotly\n",
    "try:\n",
    "    import optuna\n",
    "\n",
    "    print(f\"using (optional) optuna version {optuna.__version__}\")\n",
    "except Exception:\n",
    "    print(\"optuna is only used for hyperparameter tuning, not critical!\")\n",
    "    pass\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "# import sympy as sy\n",
    "# import ipywidgets as wid;\n",
    "\n",
    "# update fonts\n",
    "font = {\"family\": \"serif\", \"size\": 10}\n",
    "mp.rc(\"font\", **font)\n",
    "\n",
    "# set usetex = False if LaTex is not\n",
    "# available on your system or if the\n",
    "# rendering is too slow\n",
    "mp.rcParams.update({\"text.usetex\": True})\n",
    "# plt.rcParams['text.usetex'] = True\n",
    "mp.rcParams[\"text.latex.preamble\"] = [r\"\\usepackage{amsmath}\"]  # for \\text command\n",
    "\n",
    "\n",
    "# set a seed to ensure reproducibility\n",
    "# seed = 128\n",
    "# rnd  = np.random.RandomState(seed)\n",
    "# sometimes jupyter doesnt initialize MathJax automatically for latex, so do this:\n",
    "\n",
    "try:\n",
    "    IQN_BASE = os.environ[\"IQN_BASE\"]\n",
    "    print(\"BASE directoy properly set = \", IQN_BASE)\n",
    "    utils_dir = os.path.join(IQN_BASE, 'utils/')\n",
    "    sys.path.append(utils_dir)\n",
    "    import utils\n",
    "\n",
    "    # usually its not recommended to import everything from a module, but we know\n",
    "    # whats in it so its fine\n",
    "    # from utils import *\n",
    "    print(\"DATA directory also properly set, in %s\" % os.environ[\"DATA_DIR\"])\n",
    "except Exception:\n",
    "    # IQN_BASE=os.getcwd()\n",
    "    print(\n",
    "        \"\"\"\\nBASE directory not properly set. Read repo README.    If you need a function from utils, use the decorator below, or add utils to sys.path\\n\n",
    "    You can also do \n",
    "    os.environ['IQN_BASE']=<ABSOLUTE PATH FOR THE IQN REPO>\n",
    "    or\n",
    "    os.environ['IQN_BASE']=os.getcwd()\"\"\"\n",
    "    )\n",
    "    pass\n",
    "\n",
    "\n",
    "IQN_BASE = os.environ[\"IQN_BASE\"]\n",
    "print(\"BASE directoy properly set = \", IQN_BASE)\n",
    "utils_dir = os.path.join(IQN_BASE, \"utils/\")\n",
    "sys.path.append(utils_dir)\n",
    "# usually its not recommended to import everything from a module, but we know\n",
    "# whats in it so its fine\n",
    "\n",
    "# or use joblib for caching on disk\n",
    "from joblib import Memory\n",
    "\n",
    "\n",
    "################################### CONFIGURATIONS ###################################\n",
    "DATA_DIR = os.environ[\"DATA_DIR\"]\n",
    "print(f\"using DATA_DIR={DATA_DIR}\")\n",
    "JUPYTER = False\n",
    "use_subsample = False\n",
    "# use_subsample=True\n",
    "if use_subsample:\n",
    "    SUBSAMPLE = int(\n",
    "        1e5\n",
    "    )  # subsample use for development - in production use whole dataset\n",
    "else:\n",
    "    SUBSAMPLE = None\n",
    "\n",
    "memory = Memory(DATA_DIR)\n",
    "\n",
    "\n",
    "###############################################################################################\n",
    "y_label_dict = {\n",
    "    \"RecoDatapT\": \"$p(p_T)$\" + \" [ GeV\" + \"$^{-1} $\" + \"]\",\n",
    "    \"RecoDataeta\": \"$p(\\eta)$\",\n",
    "    \"RecoDataphi\": \"$p(\\phi)$\",\n",
    "    \"RecoDatam\": \"$p(m)$\" + \" [ GeV\" + \"$^{-1} $\" + \"]\",\n",
    "}\n",
    "\n",
    "loss_y_label_dict = {\n",
    "    \"RecoDatapT\": \"$p_T^{reco}$\",\n",
    "    \"RecoDataeta\": \"$\\eta^{reco}$\",\n",
    "    \"RecoDataphi\": \"$\\phi^{reco}$\",\n",
    "    \"RecoDatam\": \"$m^{reco}$\",\n",
    "}\n",
    "\n",
    "\n",
    "################################### SET DATA CONFIGURATIONS ###################################\n",
    "X = [\"genDatapT\", \"genDataeta\", \"genDataphi\", \"genDatam\", \"tau\"]\n",
    "\n",
    "# set order of training:\n",
    "# pT_first: pT->>m->eta->phi\n",
    "# m_first: m->pT->eta->phi\n",
    "\n",
    "\n",
    "ORDER = \"m_First\"\n",
    "\n",
    "if ORDER == \"m_First\":\n",
    "    FIELDS = {\n",
    "        \"RecoDatam\": {\n",
    "            \"inputs\": X,\n",
    "            \"xlabel\": r\"$m$ (GeV)\",\n",
    "            \"ylabel\": \"$m^{reco}$\",\n",
    "            \"xmin\": 0,\n",
    "            \"xmax\": 25,\n",
    "        },\n",
    "        \"RecoDatapT\": {\n",
    "            \"inputs\": [\"RecoDatam\"] + X,\n",
    "            \"xlabel\": r\"$p_T$ (GeV)\",\n",
    "            \"ylabel\": \"$p_T^{reco}$\",\n",
    "            \"xmin\": 20,\n",
    "            \"xmax\": 80,\n",
    "        },\n",
    "        \"RecoDataeta\": {\n",
    "            \"inputs\": [\"RecoDatam\", \"RecoDatapT\"] + X,\n",
    "            \"xlabel\": r\"$\\eta$\",\n",
    "            \"ylabel\": \"$\\eta^{reco}$\",\n",
    "            \"xmin\": -5,\n",
    "            \"xmax\": 5,\n",
    "        },\n",
    "        \"RecoDataphi\": {\n",
    "            \"inputs\": [\"RecoDatam\", \"RecoDatapT\", \"RecoDataeta\"] + X,\n",
    "            \"xlabel\": r\"$\\phi$\",\n",
    "            \"ylabel\": \"$\\phi^{reco}$\",\n",
    "            \"xmin\": -3.2,\n",
    "            \"xmax\": 3.2,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "# Load and explore raw (unscaled) dataframes\n",
    "\n",
    "\n",
    "all_variable_cols = [\n",
    "    \"genDatapT\",\n",
    "    \"genDataeta\",\n",
    "    \"genDataphi\",\n",
    "    \"genDatam\",\n",
    "    \"RecoDatapT\",\n",
    "    \"RecoDataeta\",\n",
    "    \"RecoDataphi\",\n",
    "    \"RecoDatam\",\n",
    "]\n",
    "all_cols = [\n",
    "    \"genDatapT\",\n",
    "    \"genDataeta\",\n",
    "    \"genDataphi\",\n",
    "    \"genDatam\",\n",
    "    \"RecoDatapT\",\n",
    "    \"RecoDataeta\",\n",
    "    \"RecoDataphi\",\n",
    "    \"RecoDatam\",\n",
    "    \"tau\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdb2b41-f128-45d0-993a-cfdd421b768d",
   "metadata": {},
   "source": [
    "## 3.2: Needed Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29814968-1591-409f-9655-42a962b5eddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features:\n",
      " ['genDatapT', 'genDataeta', 'genDataphi', 'genDatam', 'tau']\n",
      "\n",
      "Target =  RecoDatam\n",
      "USING NEW DATASET\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target = \"RecoDatam\"\n",
    "source = FIELDS[target]\n",
    "features = source[\"inputs\"]\n",
    "print(\"Training Features:\\n\", features)\n",
    "print(\"\\nTarget = \", target)\n",
    "AUTOREGRESSIVE_DIST_NAME = \"AUTOREGRESSIVE_m_Prime.csv\"\n",
    "print(\"USING NEW DATASET\\n\")\n",
    "######################################\n",
    "USE_BRADEN_SCALING = False\n",
    "#####################################\n",
    "################################### CONFIGURATIONS ###################################\n",
    "\n",
    "JUPYTER = True\n",
    "use_subsample = False\n",
    "# use_subsample = True\n",
    "if use_subsample:\n",
    "    SUBSAMPLE = int(\n",
    "        1e5\n",
    "    )  # subsample use for development - in production use whole dataset\n",
    "else:\n",
    "    SUBSAMPLE = None\n",
    "\n",
    "########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d3c5cc4-9f36-4642-b4c2-9fc9e3150955",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## Load unscaled dataframes ###################################\n",
    "@memory.cache\n",
    "def load_raw_data():\n",
    "    \"\"\"Dont use AUTOREGRESSIVE_DIST_NAME for training of any variable. \n",
    "    For mass evaluation: dont use AUTOREGRESSIVE_DIST_NAME. For pT evaluation use AUTOREGRESSIVE_DIST_NAME \n",
    "    as the distribution predicted by mass, etc.  \"\"\"\n",
    "    print(f\"\\nSUBSAMPLE = {SUBSAMPLE}\\n\")\n",
    "    raw_train_data = pd.read_csv(\n",
    "        os.path.join(DATA_DIR, \"train_data_10M_2.csv\"),\n",
    "        usecols=all_cols,\n",
    "        nrows=SUBSAMPLE,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    raw_valid_data = pd.read_csv(\n",
    "        os.path.join(DATA_DIR, \"validation_data_10M_2.csv\"),\n",
    "        usecols=all_cols,\n",
    "        nrows=SUBSAMPLE,\n",
    "    )\n",
    "    \n",
    "\n",
    "    \n",
    "    raw_test_data = pd.read_csv(\n",
    "    os.path.join(DATA_DIR, \"test_data_10M_2.csv\"), \n",
    "    usecols=all_cols, \n",
    "    nrows=SUBSAMPLE\n",
    "    )\n",
    "\n",
    "    print(\"\\n RAW TRAIN DATA\\n\")\n",
    "    print(raw_train_data.shape)\n",
    "    raw_train_data.describe()  # unscaled\n",
    "    print(\"\\n RAW TEST DATA\\n\")\n",
    "    print(raw_test_data.shape)\n",
    "    raw_test_data.describe()  # unscaled\n",
    "\n",
    "    return raw_train_data, raw_test_data, raw_valid_data\n",
    "\n",
    "\n",
    "########## Generate scaled data###############\n",
    "# scaled_train_data = L_scale_df(raw_train_data, title='scaled_train_data_10M_2.csv',\n",
    "#                              save=True)\n",
    "# print('\\n\\n')\n",
    "# scaled_test_data = L_scale_df(raw_test_data,  title='scaled_test_data_10M_2.csv',\n",
    "#                             save=True)\n",
    "# print('\\n\\n')\n",
    "\n",
    "# scaled_valid_data = L_scale_df(raw_valid_data,  title='scaled_valid_data_10M_2.csv',\n",
    "#                             save=True)\n",
    "\n",
    "# explore_data(df=scaled_train_data, title='Braden Kronheim-L-scaled Dataframe', scaled=True)\n",
    "\n",
    "################ Load scaled data##############\n",
    "@utils.time_type_of_func(tuning_or_training=\"loading\")\n",
    "# @memory.cache\n",
    "def load_scaled_dataframes():\n",
    "    print(\"SCALED TRAIN DATA\")\n",
    "    scaled_train_data = pd.read_csv(\n",
    "        os.path.join(DATA_DIR, \"scaled_train_data_10M_2.csv\"),\n",
    "        usecols=all_cols,\n",
    "        nrows=SUBSAMPLE,\n",
    "    )\n",
    "\n",
    "    print(\"TRAINING FEATURES\\n\", scaled_train_data.head())\n",
    "\n",
    "    scaled_test_data = pd.read_csv(\n",
    "        os.path.join(DATA_DIR, \"scaled_test_data_10M_2.csv\"),\n",
    "        usecols=all_cols,\n",
    "        nrows=SUBSAMPLE,\n",
    "    )\n",
    "\n",
    "    scaled_valid_data = pd.read_csv(\n",
    "        os.path.join(DATA_DIR, \"scaled_valid_data_10M_2.csv\"),\n",
    "        usecols=all_cols,\n",
    "        nrows=SUBSAMPLE,\n",
    "    )\n",
    "    return scaled_train_data, scaled_test_data, scaled_valid_data\n",
    "\n",
    "\n",
    "#######################################\n",
    "#\n",
    "# # print('\\nTESTING FEATURES\\n', scaled_test_data.head())\n",
    "\n",
    "# print('\\ntrain set shape:',  scaled_train_data.shape)\n",
    "# print('\\ntest set shape:  ', scaled_test_data.shape)\n",
    "# # print('validation set shape:', valid_data.shape)\n",
    "# @memory.cache\n",
    "def get_train_scale_dict(USE_BRADEN_SCALING):\n",
    "    if USE_BRADEN_SCALING==True:\n",
    "        TRAIN_SCALE_DICT = utils.get_scaling_info(scaled_train_data)\n",
    "        print(\"BRADEN SCALING DICTIONARY\")\n",
    "        print(TRAIN_SCALE_DICT)\n",
    "        print(\"\\n\\n\")\n",
    "        # TEST_SCALE_DICT = get_scaling_info(scaled_test_data)\n",
    "        # print(TEST_SCALE_DICT)\n",
    "    else:\n",
    "        print(\"NORMAL UNSCALED DICTIONARY\")\n",
    "        TRAIN_SCALE_DICT = utils.get_scaling_info(raw_train_data)\n",
    "        print(TRAIN_SCALE_DICT)\n",
    "        print(\"\\n\\n\")\n",
    "        # TEST_SCALE_DICT = get_scaling_info(scaled_test_data)\n",
    "        # print(TEST_SCALE_DICT)\n",
    "    return TRAIN_SCALE_DICT\n",
    "\n",
    "\n",
    "################################ SPLIT###########\n",
    "# @memory.cache\n",
    "def T(variable, scaled_df):\n",
    "    if variable == \"pT\":\n",
    "        L_pT_gen = scaled_df[\"genDatapT\"]\n",
    "        L_pT_reco = scaled_df[\"RecoDatapT\"]\n",
    "        target = (L_pT_reco + 10) / (L_pT_gen + 10)\n",
    "    if variable == \"eta\":\n",
    "        L_eta_gen = scaled_df[\"genDataeta\"]\n",
    "        L_eta_reco = scaled_df[\"RecoDataeta\"]\n",
    "        target = (L_eta_reco + 10) / (L_eta_gen + 10)\n",
    "    if variable == \"phi\":\n",
    "        L_phi_gen = scaled_df[\"genDataphi\"]\n",
    "        L_phi_reco = scaled_df[\"RecoDataphi\"]\n",
    "        target = (L_phi_reco + 10) / (L_phi_gen + 10)\n",
    "    if variable == \"m\":\n",
    "        L_m_gen = scaled_df[\"genDatam\"]\n",
    "        L_m_reco = scaled_df[\"RecoDatam\"]\n",
    "        target = (L_m_reco + 10) / (L_m_gen + 10)\n",
    "\n",
    "    return target\n",
    "\n",
    "\n",
    "# @memory.cache\n",
    "def split_t_x(df, target, input_features):\n",
    "    \"\"\"Get teh target as the ratio, according to the T equation\"\"\"\n",
    "\n",
    "    if target == \"RecoDatam\":\n",
    "        t = T(\"m\", scaled_df=scaled_train_data)\n",
    "    if target == \"RecoDatapT\":\n",
    "        t = T(\"pT\", scaled_df=scaled_train_data)\n",
    "    if target == \"RecoDataeta\":\n",
    "        t = T(\"eta\", scaled_df=scaled_train_data)\n",
    "    if target == \"RecoDataphi\":\n",
    "        t = T(\"phi\", scaled_df=scaled_train_data)\n",
    "    x = np.array(df[input_features])\n",
    "    return np.array(t), x\n",
    "\n",
    "\n",
    "# @memory.cache\n",
    "def split_t_x_test(df, target, input_features):\n",
    "    \"\"\"Get teh target as the ratio, according to the T equation\"\"\"\n",
    "\n",
    "    if target == \"RecoDatam\":\n",
    "        t = T(\"m\", scaled_df=scaled_test_data)\n",
    "    if target == \"RecoDatapT\":\n",
    "        t = T(\"pT\", scaled_df=scaled_test_data)\n",
    "    if target == \"RecoDataeta\":\n",
    "        t = T(\"eta\", scaled_df=scaled_test_data)\n",
    "    if target == \"RecoDataphi\":\n",
    "        t = T(\"phi\", scaled_df=scaled_test_data)\n",
    "    x = np.array(df[input_features])\n",
    "    return np.array(t), x\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "# @memory.cache\n",
    "def normal_split_t_x(df, target, input_features):\n",
    "    # change from pandas dataframe format to a numpy\n",
    "    # array of the specified types\n",
    "    # t = np.array(df[target])\n",
    "    t = np.array(df[target])\n",
    "    x = np.array(df[input_features])\n",
    "    return t, x\n",
    "\n",
    "\n",
    "################ Apply Z scaling############\n",
    "def z(x):\n",
    "    eps = 1e-20\n",
    "    return (x - np.mean(x)) / (np.std(x) + eps)\n",
    "\n",
    "\n",
    "def z_inverse(xprime, x):\n",
    "    return xprime * np.std(x) + np.mean(x)\n",
    "\n",
    "\n",
    "# @memory.cache\n",
    "def z2(x, mean, std):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x ([type]): [description]\n",
    "        mean ([type]): [description]\n",
    "        std ([type]): [description]\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "    eps = 1e-20\n",
    "    scaled = (x - mean) / (std + eps)\n",
    "    return np.array(scaled, dtype=np.float64)\n",
    "\n",
    "\n",
    "def z_inverse(xprime, x):\n",
    "    unscaled = xprime * np.std(x) + np.mean(x)\n",
    "    return np.array(unscaled, dtype=np.float64)\n",
    "\n",
    "\n",
    "# @memory.cache\n",
    "def z_inverse2(xprime, train_mean, train_std):\n",
    "    \"\"\"mean original train mean, std: original. Probably not needed\"\"\"\n",
    "    return xprime * train_std + train_mean\n",
    "\n",
    "\n",
    "# @memory.cache\n",
    "def apply_z_to_features(TRAIN_SCALE_DICT, train_x, test_x, valid_x):\n",
    "    \"\"\"TO ensure this z scaling is only applied once to the training features, we use a generator.\n",
    "    This doesn't change the shapes of anything, just applies z to all the feature columns other than tau\"\"\"\n",
    "    NFEATURES = train_x.shape[1]\n",
    "    for i in range(NFEATURES - 1):\n",
    "        variable = list(TRAIN_SCALE_DICT)[i]\n",
    "        train_mean = float(TRAIN_SCALE_DICT[variable][\"mean\"])\n",
    "        train_std = float(TRAIN_SCALE_DICT[variable][\"std\"])\n",
    "        train_x[:, i] = z2(train_x[:, i], mean=train_mean, std=train_std)\n",
    "        test_x[:, i] = z2(test_x[:, i], mean=train_mean, std=train_std)\n",
    "        valid_x[:, i] = z2(valid_x[:, i], mean=train_mean, std=train_std)\n",
    "    yield train_x\n",
    "    yield test_x\n",
    "    yield valid_x\n",
    "\n",
    "\n",
    "# @memory.cache\n",
    "def apply_z_to_targets(train_t, test_t, valid_t):\n",
    "    train_mean = np.mean(train_t)\n",
    "    train_std = np.std(train_t)\n",
    "    train_t_ = z2(train_t, mean=train_mean, std=train_std)\n",
    "    test_t_ = z2(test_t, mean=train_mean, std=train_std)\n",
    "    valid_t_ = z2(valid_t, mean=train_mean, std=train_std)\n",
    "\n",
    "    yield train_t_\n",
    "    yield test_t_\n",
    "    yield valid_t_\n",
    "\n",
    "\n",
    "# @utils.debug\n",
    "def save_model(model, PATH):\n",
    "    print(model)\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    print(\"\\ntrained model dictionary saved in %s\" % PATH)\n",
    "\n",
    "\n",
    "# @utils.debug\n",
    "def load_model(PATH, PARAMS):\n",
    "    # n_layers = int(BEST_PARAMS[\"n_layers\"])\n",
    "    # hidden_size = int(BEST_PARAMS[\"hidden_size\"])\n",
    "    # dropout = float(BEST_PARAMS[\"dropout\"])\n",
    "    # optimizer_name = BEST_PARAMS[\"optimizer_name\"].to_string().split()[1]\n",
    "    # learning_rate =  float(BEST_PARAMS[\"learning_rate\"])\n",
    "    # batch_size = int(BEST_PARAMS[\"batch_size\"])\n",
    "    model = utils.RegularizedRegressionModel(\n",
    "        nfeatures=NFEATURES,\n",
    "        ntargets=1,\n",
    "        nlayers=PARAMS[\"n_layers\"],\n",
    "        hidden_size=PARAMS[\"hidden_size\"],\n",
    "        dropout_1=PARAMS[\"dropout_1\"],\n",
    "        dropout_2=PARAMS[\"dropout_2\"],\n",
    "        activation=PARAMS[\"activation\"],\n",
    "    )\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    # OR\n",
    "    # model=torch.load(PATH)#BUT HERE IT WILL BE A DICT (CANT BE EVALUATED RIGHT AWAY) DISCOURAGED! Also, use dictionary \".pth\" which has both the model state dict and the PARAMS dict\n",
    "    model.eval()\n",
    "    print(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "# @memory.cache\n",
    "def simple_eval(model, test_x_z_scaled):\n",
    "    model.eval()\n",
    "    # evaluate on the scaled features\n",
    "    valid_x_tensor = torch.from_numpy(test_x_z_scaled).float()\n",
    "    # valid_x_tensor=torch.from_numpy(train_x).float()\n",
    "    pred = model(valid_x_tensor)\n",
    "    p = pred.detach().numpy()\n",
    "    # if USE_BRADEN_SCALING:\n",
    "    #     fig, ax = plt.subplots(1,1)\n",
    "    #     label=FIELDS[target]['ylabel']\n",
    "    #     ax.hist(p, label=f'Predicted post-z ratio for {label}', alpha=0.4, density=True)\n",
    "    #     # orig_ratio = z(T('m', scaled_df=scaled_train_data))\n",
    "    #     orig_ratio = z(T('m', scaled_df=scaled_test_data))\n",
    "    #     print(orig_ratio[:5])\n",
    "    #     ax.hist(orig_ratio, label = f'original post-z ratio for {label}', alpha=0.4,density=True)\n",
    "    #     ax.grid()\n",
    "    #     set_axes(ax, xlabel='predicted $T$')\n",
    "    # print('predicted ratio shape: ', p.shape)\n",
    "    return p\n",
    "\n",
    "def get_previous_autoregressive_dist(AUTOREGRESSIVE_DIST_NAME):\n",
    "        \n",
    "    print(f'Test (evaluation) Data is Autoregressive, loading {AUTOREGRESSIVE_DIST_NAME}')\n",
    "    eval_data = pd.read_csv(\n",
    "        os.path.join(\n",
    "            IQN_BASE,\n",
    "            \"JupyterBook\",\n",
    "            \"Cluster\",\n",
    "            \"EVALUATE\",\n",
    "            AUTOREGRESSIVE_DIST_NAME,\n",
    "        )\n",
    "    )\n",
    "    return eval_data\n",
    "\n",
    "\n",
    "# @memory.cache\n",
    "def get_hist(label):\n",
    "    \"\"\"label could be \"pT\", \"eta\", \"phi\", \"m\" \"\"\"\n",
    "    predicted_label_counts, label_edges = np.histogram(\n",
    "        JETS_DICT[\"Predicted_RecoData\" + label][\"dist\"],\n",
    "        range=JETS_DICT[\"Predicted_RecoData\" + label][\"range\"],\n",
    "        bins=bins,\n",
    "    )\n",
    "    real_label_counts, _ = np.histogram(\n",
    "        JETS_DICT[\"Real_RecoData\" + label][\"dist\"],\n",
    "        range=JETS_DICT[\"Real_RecoData\" + label][\"range\"],\n",
    "        bins=bins,\n",
    "    )\n",
    "    label_edges = label_edges[1:] / 2 + label_edges[:-1] / 2\n",
    "\n",
    "    return real_label_counts, predicted_label_counts, label_edges\n",
    "\n",
    "\n",
    "# @memory.cache\n",
    "def get_hist_simple(predicted_dist, target):\n",
    "    \n",
    "    range_ = (FIELDS[target][\"xmin\"], FIELDS[target][\"xmax\"])\n",
    "    bins=50\n",
    "    predicted_label_counts, label_edges = np.histogram(\n",
    "        predicted_dist, range=range_, bins=bins\n",
    "    )\n",
    "    \n",
    "    \n",
    "    real_label_counts, _ = np.histogram(REAL_DIST, range=range_, bins=bins)\n",
    "    label_edges = label_edges[1:] / 2 + label_edges[:-1] / 2\n",
    "    return real_label_counts, predicted_label_counts, label_edges\n",
    "\n",
    "\n",
    "# @memory.cache\n",
    "def plot_one(\n",
    "    target, real_edges, real_counts, predicted_counts, save_plot=False, PARAMS=None, JUPYTER=True\n",
    "):\n",
    "    fig, (ax1, ax2) = plt.subplots(\n",
    "        2, 1, figsize=(3.5 * 3 / 2.5, 3.8), gridspec_kw={\"height_ratios\": [2, 0.5]}\n",
    "    )\n",
    "    ax1.step(\n",
    "        real_edges, real_counts / norm_data, where=\"mid\", color=\"k\", linewidth=0.5\n",
    "    )  # step real_count_pt\n",
    "    ax1.step(\n",
    "        real_edges,\n",
    "        predicted_counts / norm_IQN,\n",
    "        where=\"mid\",\n",
    "        color=\"#D7301F\",\n",
    "        linewidth=0.5,\n",
    "    )  # step predicted_count_pt\n",
    "    ax1.scatter(\n",
    "        real_edges,\n",
    "        real_counts / norm_data,\n",
    "        label=\"reco\",\n",
    "        color=\"k\",\n",
    "        facecolors=\"none\",\n",
    "        marker=\"o\",\n",
    "        s=5,\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "    ax1.scatter(\n",
    "        real_edges,\n",
    "        predicted_counts / norm_IQN,\n",
    "        label=\"predicted\",\n",
    "        color=\"#D7301F\",\n",
    "        marker=\"x\",\n",
    "        s=5,\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "    ax1.set_xlim(range_)\n",
    "    ax1.set_ylim(0, max(predicted_counts / norm_IQN) * 1.1)\n",
    "    ax1.set_ylabel(\"counts\")\n",
    "    ax1.set_xticklabels([])\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "\n",
    "    ratio = (predicted_counts / norm_IQN) / (real_counts / norm_data)\n",
    "    ax2.scatter(\n",
    "        real_edges, ratio, color=\"r\", marker=\"x\", s=5, linewidth=0.5\n",
    "    )  # PREDICTED (IQN)/Reco (Data)\n",
    "    ax2.scatter(\n",
    "        real_edges,\n",
    "        ratio / ratio,\n",
    "        color=\"k\",\n",
    "        marker=\"o\",\n",
    "        facecolors=\"none\",\n",
    "        s=5,\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "    ax2.set_xlim(range_)\n",
    "    ax2.set_xlabel(FIELDS[target][\"xlabel\"])\n",
    "    ax2.set_ylabel(\n",
    "        r\"$\\frac{\\textnormal{predicted}}{\\textnormal{reco}}$\"\n",
    "        #    , fontsize=10\n",
    "    )\n",
    "    ax2.set_ylim((YLIM))\n",
    "    ax2.set_xlim(range_)\n",
    "    ax2.set_yticklabels([0.8, 1.0, 1.2])\n",
    "    if JUPYTER==True:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.tight_layout()\n",
    "        fig.subplots_adjust(wspace=0.5, hspace=0.2)\n",
    "        fig.subplots_adjust(wspace=0.0, hspace=0.1)\n",
    "        plt.axis('off')\n",
    "\n",
    "    # plt.gca().set_position([0, 0, 1, 1])\n",
    "    if save_plot:\n",
    "        plot_filename = utils.get_model_filename(target, PARAMS).split(\".dict\")[0] + \".png\"\n",
    "        plt.savefig(\n",
    "            os.path.join(IQN_BASE, \"JupyterBook\", \"Cluster\", \"EVALUATE\", plot_filename)\n",
    "        )\n",
    "\n",
    "    \n",
    "    # fig.show()\n",
    "    # plt.show();\n",
    "    # plt.axis(\"off\")\n",
    "    # plt.gca().set_position([0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3336b47e-6e8a-43ba-a93a-5067d6b44dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data only once, and with caching!\n",
    "raw_train_data, raw_test_data, raw_valid_data = load_raw_data()\n",
    "\n",
    "# Load scaled data\n",
    "# scaled_train_data, scaled_test_data, scaled_valid_data = load_scaled_dataframes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d40d613-52be-4b51-ab10-822df7976083",
   "metadata": {},
   "source": [
    "## 3.3: Evaluate Mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a42c5cef-a246-45ea-9ee4-d4d22452a547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features:\n",
      " ['genDatapT', 'genDataeta', 'genDataphi', 'genDatam', 'tau']\n",
      "\n",
      "Target =  RecoDatam\n",
      "USING NEW DATASET\n",
      "\n",
      "spliting data for RecoDatam\n",
      "train_t shape =  (8000000,) train_x shape =  (8000000, 5)\n",
      "\n",
      " Training features:\n",
      "\n",
      "[[29.4452      0.828187    2.90213     2.85348     0.36130954]\n",
      " [24.3193     -1.16351     0.636469    5.83685     0.12689925]\n",
      " [24.3193     -1.16351     0.636469    5.83685     0.96230681]\n",
      " ...\n",
      " [41.4192     -2.23358    -2.81921     7.19348     0.08421659]\n",
      " [35.4637     -1.12318     0.356494    6.06597     0.05535172]\n",
      " [26.5586     -1.09427    -1.49334     4.25409     0.07489863]]\n",
      "valid_t shape =  (1000000,) valid_x shape =  (1000000, 5)\n",
      "test_t shape =  (1000000,) test_x shape =  (1000000, 5)\n",
      "no need to train_test_split since we already have the split dataframes\n",
      "[ 3.27223764e+01  6.98189368e-04 -8.95543973e-04  6.96116528e+00\n",
      "  5.00485136e-01] [15.19914133  2.20425356  1.81362773  2.78097831  0.28852734]\n",
      "[ 3.26952341e+01 -1.78188172e-03 -3.83090331e-04  6.96299435e+00\n",
      "  4.99915289e-01] [14.93793254  2.20430976  1.81382516  2.78133203  0.28867295]\n",
      "5.5514112643334546 2.664124544901276\n",
      "5.555567451922438 2.664339857066051\n",
      "NORMAL UNSCALED DICTIONARY\n",
      "{'genDatapT': {'mean': 32.695234084987476, 'std': 14.937932540562551}, 'genDataeta': {'mean': -0.0017818817154031672, 'std': 2.204309760627079}, 'genDataphi': {'mean': -0.0003830903308450233, 'std': 1.8138251604791067}, 'genDatam': {'mean': 6.962994352358474, 'std': 2.781332025286383}, 'RecoDatapT': {'mean': 32.86720151648752, 'std': 15.829355769531851}, 'RecoDataeta': {'mean': -0.0017898858568513964, 'std': 2.197968491495457}, 'RecoDataphi': {'mean': -0.0004719170328962474, 'std': 1.8144739820043825}, 'RecoDatam': {'mean': 5.555567451922438, 'std': 2.664339857066051}}\n",
      "\n",
      "\n",
      "\n",
      "[ 1.81700902e-03  1.12510099e-03 -2.82526482e-04 -6.57626105e-04\n",
      "  5.00485136e-01] [1.01748627 0.9999745  0.99989115 0.99987283 0.28852734]\n",
      "[ 1.61650249e-15 -1.10134124e-18 -3.12905257e-17  5.01036723e-15\n",
      "  4.99915289e-01] [1.         1.         1.         1.         0.28867295]\n",
      "-0.0015599314696879494 0.9999191874249058\n",
      "6.996216939114674e-16 1.0000000000000002\n",
      "<class 'str'>\n",
      "This model was trained for 2000000 iteration, which is  256.0 epochs\n",
      "RegularizedRegressionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=6, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.3)\n",
      "    (2): Linear(in_features=6, out_features=6, bias=True)\n",
      "    (3): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.3)\n",
      "    (5): Linear(in_features=6, out_features=6, bias=True)\n",
      "    (6): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.3)\n",
      "    (8): Linear(in_features=6, out_features=6, bias=True)\n",
      "    (9): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.3)\n",
      "    (11): Linear(in_features=6, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "EVALUATION DATA NEW INDEX\n",
      "    RecoDatam  genDatapT  genDataeta  genDataphi  genDatam       tau\n",
      "0   4.840796    43.6113    0.824891    -1.26949   5.93310  0.250046\n",
      "1   7.059293    43.6113    0.824891    -1.26949   5.93310  0.847493\n",
      "2   5.725040    26.0153    3.529970     1.55495   7.41270  0.851995\n",
      "3   3.605120    28.4944   -1.159650     1.82602   7.84157  0.052378\n",
      "4   3.521224    21.9840    2.747660     2.03085   5.18315  0.542549\n",
      "norm_data 1000000 \n",
      "norm IQN 1000000 \n",
      "norm_autoregressive 1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_378619/3379445305.py:403: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax2.set_yticklabels([0.8, 1.0, 1.2])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 420x380 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: plot the loss curves (train and valid) of all 4 networks on the same plot,\n",
    "# and with the learning rate plotted on the same plot but on a different y axis \n",
    "# (x axis being iteration, with marks indicating epochs)\n",
    "\n",
    "target = \"RecoDatam\"\n",
    "source = FIELDS[target]\n",
    "features = source[\"inputs\"]\n",
    "print(\"Training Features:\\n\", features)\n",
    "print(\"\\nTarget = \", target)\n",
    "AUTOREGRESSIVE_DIST_NAME = \"AUTOREGRESSIVE_m_Prime.csv\"\n",
    "print(\"USING NEW DATASET\\n\")\n",
    "######################################\n",
    "USE_BRADEN_SCALING = False\n",
    "#####################################\n",
    "################################### CONFIGURATIONS ###################################\n",
    "\n",
    "JUPYTER = True\n",
    "use_subsample = False\n",
    "# use_subsample = True\n",
    "if use_subsample:\n",
    "    SUBSAMPLE = int(\n",
    "        1e5\n",
    "    )  # subsample use for development - in production use whole dataset\n",
    "else:\n",
    "    SUBSAMPLE = None\n",
    "\n",
    "########################################################################################\n",
    "# Get targets and features\n",
    "if USE_BRADEN_SCALING==True:\n",
    "    print(f\"spliting data for {target}\")\n",
    "    train_t, train_x = split_t_x(\n",
    "        df=scaled_train_data, target=target, input_features=features\n",
    "    )\n",
    "    print(\"train_t shape = \", train_t.shape, \"train_x shape = \", train_x.shape)\n",
    "    print(\"\\n Training features:\\n\")\n",
    "    print(train_x)\n",
    "    valid_t, valid_x = split_t_x(\n",
    "        df=scaled_valid_data, target=target, input_features=features\n",
    "    )\n",
    "    print(\"valid_t shape = \", valid_t.shape, \"valid_x shape = \", valid_x.shape)\n",
    "    test_t, test_x = split_t_x(\n",
    "        df=scaled_test_data, target=target, input_features=features\n",
    "    )\n",
    "    print(\"test_t shape = \", test_t.shape, \"test_x shape = \", test_x.shape)\n",
    "\n",
    "else:\n",
    "    print(f\"spliting data for {target}\")\n",
    "    train_t, train_x = normal_split_t_x(\n",
    "        df=raw_train_data, target=target, input_features=features\n",
    "    )\n",
    "    print(\"train_t shape = \", train_t.shape, \"train_x shape = \", train_x.shape)\n",
    "    print(\"\\n Training features:\\n\")\n",
    "    print(train_x)\n",
    "    valid_t, valid_x = normal_split_t_x(\n",
    "        df=raw_valid_data, target=target, input_features=features\n",
    "    )\n",
    "    print(\"valid_t shape = \", valid_t.shape, \"valid_x shape = \", valid_x.shape)\n",
    "    test_t, test_x = normal_split_t_x(\n",
    "        df=raw_test_data, target=target, input_features=features\n",
    "    )\n",
    "    print(\"test_t shape = \", test_t.shape, \"test_x shape = \", test_x.shape)\n",
    "\n",
    "print(\"no need to train_test_split since we already have the split dataframes\")\n",
    "print(valid_x.mean(axis=0), valid_x.std(axis=0))\n",
    "print(train_x.mean(axis=0), train_x.std(axis=0))\n",
    "print(valid_t.mean(), valid_t.std())\n",
    "print(train_t.mean(), train_t.std())\n",
    "######################################################\n",
    "\n",
    "# Apply z scaling to features and targets\n",
    "# to features\n",
    "\n",
    "NFEATURES = train_x.shape[1]\n",
    "TRAIN_SCALE_DICT = get_train_scale_dict(USE_BRADEN_SCALING)\n",
    "# to features\n",
    "apply_z_generator = apply_z_to_features(TRAIN_SCALE_DICT, train_x, test_x, valid_x)\n",
    "train_x_z_scaled = next(apply_z_generator)\n",
    "test_x_z_scaled = next(apply_z_generator)\n",
    "valid_x_z_scaled = next(apply_z_generator)\n",
    "print(valid_x_z_scaled.mean(axis=0), valid_x_z_scaled.std(axis=0))\n",
    "print(train_x_z_scaled.mean(axis=0), train_x_z_scaled.std(axis=0))\n",
    "# to targets\n",
    "apply_z_to_targets_generator = apply_z_to_targets(train_t, test_t, valid_t)\n",
    "train_t_z_scaled = next(apply_z_to_targets_generator)\n",
    "test_t_z_scaled = next(apply_z_to_targets_generator)\n",
    "valid_t_z_scaled = next(apply_z_to_targets_generator)\n",
    "print(valid_t_z_scaled.mean(), valid_t_z_scaled.std())\n",
    "print(train_t_z_scaled.mean(), train_t_z_scaled.std())\n",
    "\n",
    "###########################################################\n",
    "# Get the  parameters for this model and training\n",
    "PARAMS_m = {\n",
    "\"n_layers\": int(4),\n",
    "\"hidden_size\": int(6),\n",
    "\"dropout_1\": float(0.6),\n",
    "\"dropout_2\": float(0.1),\n",
    "\"activation\": \"LeakyReLU\",\n",
    "    'optimizer_name':'NAdam',\n",
    "    'starting_learning_rate':float(0.7),\n",
    "    'momentum':float(0.6),\n",
    "    'batch_size':int(1024),\n",
    "    'n_iterations': int(2e6),\n",
    "}\n",
    "\n",
    "optimizer_name = PARAMS_m[\"optimizer_name\"]\n",
    "print(type(optimizer_name))\n",
    "# optimizer_name = BEST_PARAMS[\"optimizer_name\"].to_string().split()[1]\n",
    "NITERATIONS = PARAMS_m[\"n_iterations\"]\n",
    "BATCHSIZE = PARAMS_m[\"batch_size\"]\n",
    "comment = \"\"\n",
    "\n",
    "# N_epochs X N_train_examples = N_iterations X batch_size\n",
    "N_epochs = (NITERATIONS * BATCHSIZE) / int(train_x.shape[0])\n",
    "print(\n",
    "    f\"This model was trained for {NITERATIONS} iteration, which is  {N_epochs} epochs\"\n",
    ")\n",
    "\n",
    "# 'Trained_IQNx4_%s_TUNED.dict' % target\n",
    "filename_model = utils.get_model_filename(target, PARAMS_m)\n",
    "# OR, if you know a model filename directly, you can also specify it, \n",
    "# BUT, if you pull a trained model explicitly, you have to make sure its parameters in the PARAMS dictionary above match\n",
    "# Nominal one is 'Trained_IQNx4_RecoDatam_ 8_layer5_hiddenLeakyReLU_activation1024_batchsize300_Kiteration.dict', also in backup\n",
    "# filename_model='Trained_IQNx4_RecoDatam_ 8_layer5_hiddenLeakyReLU_activation1024_batchsize300_Kiteration.dict'\n",
    "# filename_model='Trained_IQNx4_RecoDatapT_10_layer6_hiddenLeakyReLU_activation512_batchsize300_Kiteration.dict'\n",
    "trained_models_dir = \"trained_models\"\n",
    "utils.mkdir(trained_models_dir)\n",
    "# on cluster, Im using another TRAIN directory\n",
    "PATH_model = os.path.join(\n",
    "    IQN_BASE,  # the loaction of the repo\n",
    "    \"JupyterBook\",  # up tp TRAIN could be combined in a srs dicretory\n",
    "    \"Cluster\",\n",
    "    \"TRAIN\",\n",
    "    trained_models_dir,  # /trained_models\n",
    "    filename_model,  # utils.get_model_filename has the saved file format\n",
    ")\n",
    "\n",
    "# Load trained model\n",
    "IQN_m = load_model(PATH_model, PARAMS_m)\n",
    "# Get predicted distribution\n",
    "p = simple_eval(IQN_m, test_x_z_scaled)\n",
    "\n",
    "range_ = (FIELDS[target][\"xmin\"], FIELDS[target][\"xmax\"])\n",
    "bins = 50\n",
    "REAL_RAW_DATA = raw_test_data\n",
    "\n",
    "YLIM = (0.8, 1.2)\n",
    "###########GET REAL DIST###########\n",
    "REAL_RAW_DATA = REAL_RAW_DATA[\n",
    "    [\"RecoDatapT\", \"RecoDataeta\", \"RecoDataphi\", \"RecoDatam\"]\n",
    "]\n",
    "REAL_RAW_DATA.columns = [\"realpT\", \"realeta\", \"realphi\", \"realm\"]\n",
    "REAL_DIST = REAL_RAW_DATA[\"realm\"]\n",
    "norm_data = REAL_RAW_DATA.shape[0]\n",
    "#############GET EVALUATION DIST#############\n",
    "raw_test_data.describe()\n",
    "m_reco = raw_test_data[\"RecoDatam\"]\n",
    "m_gen = raw_test_data[\"genDatam\"]\n",
    "# plt.hist(m_reco,label=r'$m_{gen}^{test \\ data}$');plt.legend();plt.show()\n",
    "\n",
    "\n",
    "def descale_Braden_scaled_prediction(label, p):\n",
    "    \"\"\"Label could be m. p is the outcome of the model evaluation, e.g. \n",
    "    IQN_m = load_model(PATH_model, PARAMS_m)\n",
    "    p = simple_eval(IQN_m, test_x_z_scaled)\n",
    "    \n",
    "    \"\"\"\n",
    "    # make sure you've set braden scaling global variable to use this function.\n",
    "    assert USE_BRADEN_SCALING==True\n",
    "    orig_ratio = T(label, scaled_df=scaled_train_data)\n",
    "    z_inv_f = z_inverse(xprime=p, mean=np.mean(orig_ratio), std=np.std(orig_ratio))\n",
    "    L_obs = L(orig_observable=m_gen, label=label)\n",
    "    z_inv_f = z_inv_f.flatten()\n",
    "    print(z_inv_f.shape)\n",
    "\n",
    "    factor = (z_inv_f * (L_obs + 10)) - 10\n",
    "    label_pred = L_inverse(L_observable=factor, label=label)\n",
    "    return label_pred\n",
    "    \n",
    "    \n",
    "m_pred = z_inverse2(\n",
    "    xprime=p,\n",
    "    train_mean=TRAIN_SCALE_DICT[target][\"mean\"],\n",
    "    train_std=TRAIN_SCALE_DICT[target][\"std\"],\n",
    ")\n",
    "m_pred = m_pred.flatten()\n",
    "\n",
    "# Get histogram of predicted distribution\n",
    "real_label_counts_m, predicted_label_counts_m, label_edges_m = get_hist_simple(\n",
    "    predicted_dist=m_pred, target=target\n",
    ")\n",
    "# eval_data=pd.read_csv(DATA_DIR+'/test_data_10M_2.csv')\n",
    "# Get evaluation data\n",
    "eval_data = pd.read_csv(DATA_DIR + \"/test_data_10M_2.csv\")\n",
    "ev_features = features\n",
    "eval_data = eval_data[ev_features]\n",
    "# save new distribution (m) in the eval data as autoregressive eval for next IQN\n",
    "eval_data[target] = m_pred\n",
    "\n",
    "new_cols = [target] + features\n",
    "eval_data = eval_data.reindex(columns=new_cols)\n",
    "print(\"EVALUATION DATA NEW INDEX\\n\", eval_data.head())\n",
    "\n",
    "eval_data.to_csv(\n",
    "    os.path.join(\n",
    "        IQN_BASE, \"JupyterBook\", \"Cluster\", \"EVALUATE\", AUTOREGRESSIVE_DIST_NAME\n",
    "    )\n",
    ")\n",
    "\n",
    "# Load this saved predited autoregressive distribution\n",
    "AUTOREGRESSIVE_DIST = pd.read_csv(\n",
    "    os.path.join(\n",
    "        IQN_BASE, \"JupyterBook\", \"Cluster\", \"EVALUATE\", AUTOREGRESSIVE_DIST_NAME\n",
    "    )\n",
    ")\n",
    "\n",
    "# norm_IQN=AUTOREGRESSIVE_DIST.shape[0]\n",
    "# get normalization values\n",
    "norm_autoregressive = AUTOREGRESSIVE_DIST.shape[0]\n",
    "norm_IQN = norm_autoregressive\n",
    "print(\n",
    "    \"norm_data\",\n",
    "    norm_data,\n",
    "    \"\\nnorm IQN\",\n",
    "    norm_IQN,\n",
    "    \"\\nnorm_autoregressive\",\n",
    "    norm_autoregressive,\n",
    ")\n",
    "\n",
    "# Finally, plot predicted distribution\n",
    "\n",
    "plot_one(\n",
    "    target=target,\n",
    "    real_edges=label_edges_m,\n",
    "    real_counts=real_label_counts_m,\n",
    "    predicted_counts=predicted_label_counts_m,\n",
    "    save_plot=True,\n",
    "    PARAMS=PARAMS_m\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df205105-a24d-4694-a182-ef84c08bfd4c",
   "metadata": {},
   "source": [
    "## 3.4: Evaluate $p_T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95d0ccc6-5576-4e09-9423-9ed7cb07fa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test (evaluation) Data is Autoregressive, loading AUTOREGRESSIVE_m_Prime.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RecoDatam</th>\n",
       "      <th>genDatapT</th>\n",
       "      <th>genDataeta</th>\n",
       "      <th>genDataphi</th>\n",
       "      <th>genDatam</th>\n",
       "      <th>tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.797721</td>\n",
       "      <td>43.6113</td>\n",
       "      <td>0.824891</td>\n",
       "      <td>-1.26949</td>\n",
       "      <td>5.93310</td>\n",
       "      <td>0.250046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6.829849</td>\n",
       "      <td>43.6113</td>\n",
       "      <td>0.824891</td>\n",
       "      <td>-1.26949</td>\n",
       "      <td>5.93310</td>\n",
       "      <td>0.847493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.645979</td>\n",
       "      <td>26.0153</td>\n",
       "      <td>3.529970</td>\n",
       "      <td>1.55495</td>\n",
       "      <td>7.41270</td>\n",
       "      <td>0.851995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.593726</td>\n",
       "      <td>28.4944</td>\n",
       "      <td>-1.159650</td>\n",
       "      <td>1.82602</td>\n",
       "      <td>7.84157</td>\n",
       "      <td>0.052378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.501870</td>\n",
       "      <td>21.9840</td>\n",
       "      <td>2.747660</td>\n",
       "      <td>2.03085</td>\n",
       "      <td>5.18315</td>\n",
       "      <td>0.542549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  RecoDatam  genDatapT  genDataeta  genDataphi  genDatam  \\\n",
       "0           0   4.797721    43.6113    0.824891    -1.26949   5.93310   \n",
       "1           1   6.829849    43.6113    0.824891    -1.26949   5.93310   \n",
       "2           2   5.645979    26.0153    3.529970     1.55495   7.41270   \n",
       "3           3   3.593726    28.4944   -1.159650     1.82602   7.84157   \n",
       "4           4   3.501870    21.9840    2.747660     2.03085   5.18315   \n",
       "\n",
       "        tau  \n",
       "0  0.250046  \n",
       "1  0.847493  \n",
       "2  0.851995  \n",
       "3  0.052378  \n",
       "4  0.542549  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data_df = get_previous_autoregressive_dist(AUTOREGRESSIVE_DIST_NAME=PREVIOUS_AUTOREGRESSIVE_DIST_NAME)\n",
    "eval_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed548cae-19f9-44d7-b30f-1328fd8fb454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features:\n",
      " ['RecoDatam', 'genDatapT', 'genDataeta', 'genDataphi', 'genDatam', 'tau']\n",
      "\n",
      "Target =  RecoDatapT\n",
      "USING NEW DATASET\n",
      "\n",
      "spliting autoregressive evaluation data for RecoDatapT\n",
      "train_t shape =  (8000000,) train_x shape =  (8000000, 6)\n",
      "\n",
      " Training features:\n",
      "\n",
      "[[ 2.59587    29.4452      0.828187    2.90213     2.85348     0.36130954]\n",
      " [ 5.35538    24.3193     -1.16351     0.636469    5.83685     0.12689925]\n",
      " [ 5.35538    24.3193     -1.16351     0.636469    5.83685     0.96230681]\n",
      " ...\n",
      " [ 6.25659    41.4192     -2.23358    -2.81921     7.19348     0.08421659]\n",
      " [ 6.11213    35.4637     -1.12318     0.356494    6.06597     0.05535172]\n",
      " [ 4.17483    26.5586     -1.09427    -1.49334     4.25409     0.07489863]]\n",
      "valid_t shape =  (1000000,) valid_x shape =  (1000000, 6)\n",
      "test_t shape =  (1000000,) test_x shape =  (1000000, 6)\n",
      "no need to train_test_split since we already have the split dataframes\n",
      "[ 5.55141126e+00  3.27223764e+01  6.98189368e-04 -8.95543973e-04\n",
      "  6.96116528e+00  5.00485136e-01] [ 2.66412454 15.19914133  2.20425356  1.81362773  2.78097831  0.28852734]\n",
      "[ 5.55556745e+00  3.26952341e+01 -1.78188172e-03 -3.83090331e-04\n",
      "  6.96299435e+00  4.99915289e-01] [ 2.66433986 14.93793254  2.20430976  1.81382516  2.78133203  0.28867295]\n",
      "32.881453465999996 16.02400426348493\n",
      "32.86720151648752 15.829355769531851\n",
      "NORMAL UNSCALED DICTIONARY\n",
      "{'genDatapT': {'mean': 32.695234084987476, 'std': 14.937932540562551}, 'genDataeta': {'mean': -0.0017818817154031672, 'std': 2.204309760627079}, 'genDataphi': {'mean': -0.0003830903308450233, 'std': 1.8138251604791067}, 'genDatam': {'mean': 6.962994352358474, 'std': 2.781332025286383}, 'RecoDatapT': {'mean': 32.86720151648752, 'std': 15.829355769531851}, 'RecoDataeta': {'mean': -0.0017898858568513964, 'std': 2.197968491495457}, 'RecoDataphi': {'mean': -0.0004719170328962474, 'std': 1.8144739820043825}, 'RecoDatam': {'mean': 5.555567451922438, 'std': 2.664339857066051}}\n",
      "\n",
      "\n",
      "\n",
      "[-1.81710707e+00  1.48455353e+01  5.96132264e-04 -2.50379668e+00\n",
      " -1.63658184e+00  5.00485136e-01] [0.17834627 6.89519305 1.2152514  0.65207164 0.17568487 0.28852734]\n",
      "[-1.81682884e+00  1.48332220e+01 -7.71183141e-04 -2.50361243e+00\n",
      " -1.63646629e+00  4.99915289e-01] [0.17836068 6.77669391 1.21528238 0.65214262 0.17570722 0.28867295]\n",
      "0.0009003493079555966 1.0122966781963252\n",
      "-1.2048033681821834e-15 1.0000000000000002\n",
      "<class 'str'>\n",
      "This model was trained for 2000000 iteration, which is  256.0 epochs\n",
      "RegularizedRegressionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.3)\n",
      "    (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.3)\n",
      "    (5): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (6): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.3)\n",
      "    (8): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Test (evaluation) Data is Autoregressive, loading AUTOREGRESSIVE_m_Prime.csv\n",
      "EVALUATION DATA NEW INDEX\n",
      "    RecoDatam  RecoDatapT  genDatapT  genDataeta  genDataphi  genDatam  \\\n",
      "0   4.840795   41.525097    43.6113    0.824891    -1.26949   5.93310   \n",
      "1   7.059293   49.677708    43.6113    0.824891    -1.26949   5.93310   \n",
      "2   5.725040   27.880127    26.0153    3.529970     1.55495   7.41270   \n",
      "3   3.605120   26.332504    28.4944   -1.159650     1.82602   7.84157   \n",
      "4   3.521224   22.635612    21.9840    2.747660     2.03085   5.18315   \n",
      "\n",
      "        tau  \n",
      "0  0.250046  \n",
      "1  0.847493  \n",
      "2  0.851995  \n",
      "3  0.052378  \n",
      "4  0.542549  \n",
      "norm_data 1000000 \n",
      "norm IQN 1000000 \n",
      "norm_autoregressive 1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_378619/3379445305.py:403: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax2.set_yticklabels([0.8, 1.0, 1.2])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 420x380 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target = \"RecoDatapT\"\n",
    "source = FIELDS[target]\n",
    "features = source[\"inputs\"]\n",
    "print(\"Training Features:\\n\", features)\n",
    "print(\"\\nTarget = \", target)\n",
    "PREVIOUS_AUTOREGRESSIVE_DIST_NAME = \"AUTOREGRESSIVE_m_Prime.csv\"\n",
    "AUTOREGRESSIVE_DIST_NAME = \"AUTOREGRESSIVE_m_Prime_pT_Prime.csv\"\n",
    "print(\"USING NEW DATASET\\n\")\n",
    "######################################\n",
    "USE_BRADEN_SCALING = False\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "raw_train_data, raw_test_data, raw_valid_data = load_raw_data()\n",
    "\n",
    "\n",
    "# Load scaled data\n",
    "# scaled_train_data, scaled_test_data, scaled_valid_data = load_scaled_dataframes()\n",
    "\n",
    "\n",
    "################################################## Load Evaluation Data\n",
    "#eval_data=pd.read_csv(DATA_DIR+'/test_data_10M_2.csv')\n",
    "# Or test on actual test (evaluation) data for development\n",
    "# eval_data=pd.read_csv(DATA_DIR+'/test_data_10M_2.csv')\n",
    "\n",
    "# Get targets and features\n",
    "if USE_BRADEN_SCALING == True:\n",
    "    print(f\"spliting data for {target}\")\n",
    "    train_t, train_x = split_t_x(\n",
    "        df=scaled_train_data, target=target, input_features=features\n",
    "    )\n",
    "    print(\"train_t shape = \", train_t.shape, \"train_x shape = \", train_x.shape)\n",
    "    print(\"\\n Training features:\\n\")\n",
    "    print(train_x)\n",
    "    valid_t, valid_x = split_t_x(\n",
    "        df=scaled_valid_data, target=target, input_features=features\n",
    "    )\n",
    "    print(\"valid_t shape = \", valid_t.shape, \"valid_x shape = \", valid_x.shape)\n",
    "        \n",
    "    ##### WHAT MATTERS IS TEST (EVALUATION)\n",
    "\n",
    "    test_t, test_x = split_t_x(\n",
    "        df=scaled_test_data, target=target, input_features=features\n",
    "    )\n",
    "    print(\"test_t shape = \", test_t.shape, \"test_x shape = \", test_x.shape)\n",
    "\n",
    "else:\n",
    "    print(f\"spliting autoregressive evaluation data for {target}\")\n",
    "    train_t, train_x = normal_split_t_x(\n",
    "            df=raw_train_data, target=target, input_features=features\n",
    "        )\n",
    "    print(\"train_t shape = \", train_t.shape, \"train_x shape = \", train_x.shape)\n",
    "    print(\"\\n Training features:\\n\")\n",
    "    print(train_x)\n",
    "    valid_t, valid_x = normal_split_t_x(\n",
    "        df=raw_valid_data, target=target, input_features=features\n",
    "    )\n",
    "    print(\"valid_t shape = \", valid_t.shape, \"valid_x shape = \", valid_x.shape)\n",
    "    ##### WHAT MATTERS IS TEST (EVALUATION)\n",
    "    test_t, test_x = normal_split_t_x(\n",
    "        df=raw_test_data, target=target, input_features=features\n",
    "    )\n",
    "    print(\"test_t shape = \", test_t.shape, \"test_x shape = \", test_x.shape)\n",
    "\n",
    "print(\"no need to train_test_split since we already have the split dataframes\")\n",
    "print(valid_x.mean(axis=0), valid_x.std(axis=0))\n",
    "print(train_x.mean(axis=0), train_x.std(axis=0))\n",
    "print(valid_t.mean(), valid_t.std())\n",
    "print(train_t.mean(), train_t.std())\n",
    "######################################################\n",
    "# Replace test_x with eval_data\n",
    "\n",
    "# ev_features = features\n",
    "# eval_data_df = eval_data[ev_features]\n",
    "# eval_data = np.array(eval_data_df)\n",
    "# test_x = eval_data\n",
    "\n",
    "# eval_data=pd.read_csv(DATA_DIR+'/test_data_10M_2.csv')\n",
    "    \n",
    "# eval_data=raw_train_data[:raw_test_data.shape[0]]\n",
    "# test_x = np.array\n",
    "\n",
    "# Apply z scaling to features and targets\n",
    "# to features\n",
    "#####################################################################\n",
    "NFEATURES = train_x.shape[1]\n",
    "# GET EVALUATION DATASET\n",
    "# eval_data= get_previous_autoregressive_dist(AUTOREGRESSIVE_DIST_NAME=PREVIOUS_AUTOREGRESSIVE_DIST_NAME)\n",
    "# test_x = np.array(eval_data[features])\n",
    "\n",
    "\n",
    "\n",
    "TRAIN_SCALE_DICT = get_train_scale_dict(USE_BRADEN_SCALING)\n",
    "# to features\n",
    "apply_z_generator = apply_z_to_features(TRAIN_SCALE_DICT, train_x, test_x, valid_x)\n",
    "train_x_z_scaled = next(apply_z_generator)\n",
    "test_x_z_scaled = next(apply_z_generator)\n",
    "valid_x_z_scaled = next(apply_z_generator)\n",
    "print(valid_x_z_scaled.mean(axis=0), valid_x_z_scaled.std(axis=0))\n",
    "print(train_x_z_scaled.mean(axis=0), train_x_z_scaled.std(axis=0))\n",
    "# to targets\n",
    "apply_z_to_targets_generator = apply_z_to_targets(train_t, test_t, valid_t)\n",
    "train_t_z_scaled = next(apply_z_to_targets_generator)\n",
    "test_t_z_scaled = next(apply_z_to_targets_generator)\n",
    "valid_t_z_scaled = next(apply_z_to_targets_generator)\n",
    "print(valid_t_z_scaled.mean(), valid_t_z_scaled.std())\n",
    "print(train_t_z_scaled.mean(), train_t_z_scaled.std())\n",
    "\n",
    "###########################################################\n",
    "# Get the  parameters for this model and training\n",
    "PARAMS_pT = {\n",
    "\"n_layers\": int(3),\n",
    "\"hidden_size\": int(16),\n",
    "\"dropout_1\": float(0.6),\n",
    "\"dropout_2\": float(0.1),\n",
    "\"activation\": \"LeakyReLU\",\n",
    "    'optimizer_name':'NAdam',\n",
    "    'starting_learning_rate':float(0.5),\n",
    "    'momentum':float(0.6),\n",
    "    'batch_size':int(1024),\n",
    "    'n_iterations': int(2e6),\n",
    "}\n",
    "\n",
    "optimizer_name = PARAMS_pT[\"optimizer_name\"]\n",
    "print(type(optimizer_name))\n",
    "# optimizer_name = BEST_PARAMS[\"optimizer_name\"].to_string().split()[1]\n",
    "NITERATIONS = PARAMS_pT[\"n_iterations\"]\n",
    "BATCHSIZE = PARAMS_pT[\"batch_size\"]\n",
    "comment = \"\"\n",
    "\n",
    "# N_epochs X N_train_examples = N_iterations X batch_size\n",
    "N_epochs = (NITERATIONS * BATCHSIZE) / int(train_x.shape[0])\n",
    "print(\n",
    "    f\"This model was trained for {NITERATIONS} iteration, which is  {N_epochs} epochs\"\n",
    ")\n",
    "\n",
    "\n",
    "filename_model = utils.get_model_filename(target, PARAMS_pT)\n",
    "# filename_model = 'Trained_IQNx4_RecoDatapT_ 13_layer6_hiddenLeakyReLU_activation1024_batchsize200_Kiteration.dict'\n",
    "# filename_model = 'Trained_IQNx4_RecoDatapT_10_layer6_hiddenLeakyReLU_activation512_batchsize300_Kiteration.dict'\n",
    "trained_models_dir = \"trained_models\"\n",
    "utils.mkdir(trained_models_dir)\n",
    "# on cluster, Im using another TRAIN directory\n",
    "PATH_model = os.path.join(\n",
    "    IQN_BASE,  # the loaction of the repo\n",
    "    \"JupyterBook\",  # up tp TRAIN could be combined in a srs dicretory\n",
    "    \"Cluster\",\n",
    "    \"TRAIN\",\n",
    "    trained_models_dir,  # /trained_models\n",
    "    filename_model,  # utils.get_model_filename has the saved file format\n",
    ")\n",
    "\n",
    "# Load trained model\n",
    "IQN_pT = load_model(PATH_model, PARAMS_pT)\n",
    "# Get predicted distribution\n",
    "p = simple_eval(IQN_pT, test_x_z_scaled)\n",
    "\n",
    "range_ = (FIELDS[target][\"xmin\"], FIELDS[target][\"xmax\"])\n",
    "bins = 50\n",
    "REAL_RAW_DATA = raw_test_data\n",
    "\n",
    "YLIM = (0.8, 1.2)\n",
    "###########GET REAL DIST###########\n",
    "REAL_RAW_DATA = REAL_RAW_DATA[\n",
    "    [\"RecoDatapT\", \"RecoDataeta\", \"RecoDataphi\", \"RecoDatam\"]\n",
    "]\n",
    "REAL_RAW_DATA.columns = [\"realpT\", \"realeta\", \"realphi\", \"realm\"]\n",
    "REAL_DIST = REAL_RAW_DATA[\"realpT\"]\n",
    "norm_data = REAL_RAW_DATA.shape[0]\n",
    "#############GET EVALUATION DIST#############\n",
    "raw_test_data.describe()\n",
    "pT_reco = raw_test_data[\"RecoDatapT\"]\n",
    "pT_gen = raw_test_data[\"genDatapT\"]\n",
    "# plt.hist(m_reco,label=r'$m_{gen}^{test \\ data}$');plt.legend();plt.show()\n",
    "\n",
    "def descale_Braden_scaled_prediction(label, p):\n",
    "    \"\"\"Label could be m. p is the outcome of the model evaluation, e.g. \n",
    "    IQN_m = load_model(PATH_model, PARAMS_m)\n",
    "    p = simple_eval(IQN_m, test_x_z_scaled)\n",
    "\n",
    "    \"\"\"\n",
    "    # make sure you've set braden scaling global variable to use this function.\n",
    "    assert USE_BRADEN_SCALING==True\n",
    "    orig_ratio = T(label, scaled_df=scaled_train_data)\n",
    "    z_inv_f = z_inverse(xprime=p, mean=np.mean(orig_ratio), std=np.std(orig_ratio))\n",
    "    L_obs = L(orig_observable=pT_gen, label=label)\n",
    "    z_inv_f = z_inv_f.flatten()\n",
    "    print(z_inv_f.shape)\n",
    "\n",
    "    factor = (z_inv_f * (L_obs + 10)) - 10\n",
    "    label_pred = L_inverse(L_observable=factor, label=label)\n",
    "    return label_pred\n",
    "\n",
    "\n",
    "pT_pred = z_inverse2(\n",
    "    xprime=p,\n",
    "    train_mean=TRAIN_SCALE_DICT[target][\"mean\"],\n",
    "    train_std=TRAIN_SCALE_DICT[target][\"std\"],\n",
    ")\n",
    "pT_pred = pT_pred.flatten()\n",
    "\n",
    "# Get histogram of predicted distribution\n",
    "real_label_counts_pT, predicted_label_counts_pT, label_edges_pT = get_hist_simple(\n",
    "    predicted_dist=pT_pred, target=target\n",
    ")\n",
    "\n",
    "# Get evaluation data as test data for development\n",
    "\n",
    "# eval_data_df=pd.read_csv(DATA_DIR+'/test_data_10M_2.csv')#[features]\n",
    "\n",
    "\n",
    "eval_data_df = get_previous_autoregressive_dist(AUTOREGRESSIVE_DIST_NAME=PREVIOUS_AUTOREGRESSIVE_DIST_NAME)\n",
    "\n",
    "ev_features = features\n",
    "eval_data = eval_data_df[ev_features]\n",
    "# save new distribution (pT) in the eval data as autoregressive eval for next IQN\n",
    "eval_data_df[target] = pT_pred\n",
    "#change order of columns\n",
    "new_cols = [\"RecoDatam\", target] + X\n",
    "eval_data_df = eval_data_df.reindex(columns=new_cols)\n",
    "print(\"EVALUATION DATA NEW INDEX\\n\", eval_data_df.head())\n",
    "# save \n",
    "eval_data_df.to_csv(\n",
    "    os.path.join(\n",
    "        IQN_BASE, \"JupyterBook\", \"Cluster\", \"EVALUATE\", AUTOREGRESSIVE_DIST_NAME\n",
    "    )\n",
    ")\n",
    "\n",
    "# Load this saved predited autoregressive distribution\n",
    "AUTOREGRESSIVE_DIST = pd.read_csv(\n",
    "    os.path.join(\n",
    "        IQN_BASE, \"JupyterBook\", \"Cluster\", \"EVALUATE\", AUTOREGRESSIVE_DIST_NAME\n",
    "    )\n",
    ")\n",
    "\n",
    "# norm_IQN=AUTOREGRESSIVE_DIST.shape[0]\n",
    "# get normalization values\n",
    "norm_autoregressive = AUTOREGRESSIVE_DIST.shape[0]\n",
    "norm_IQN = norm_autoregressive\n",
    "print(\n",
    "    \"norm_data\",\n",
    "    norm_data,\n",
    "    \"\\nnorm IQN\",\n",
    "    norm_IQN,\n",
    "    \"\\nnorm_autoregressive\",\n",
    "    norm_autoregressive,\n",
    ")\n",
    "\n",
    "# Finally, plot predicted distribution\n",
    "plot_one(\n",
    "    target=target,\n",
    "    real_edges=label_edges_pT,\n",
    "    real_counts=real_label_counts_pT,\n",
    "    predicted_counts=predicted_label_counts_pT,\n",
    "    save_plot=True,\n",
    "    PARAMS=PARAMS_pT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48801bd-6864-425d-b4cd-fbe5fdf89790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
