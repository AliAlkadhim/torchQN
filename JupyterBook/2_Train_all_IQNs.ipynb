{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de81fd7f-8c91-44e5-9b5e-878882120c1e",
   "metadata": {},
   "source": [
    "# IQNx4 Chapter 2: Train All Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ddfd24-43c6-44ac-b171-7269c28f4f93",
   "metadata": {},
   "source": [
    "# 2.1 Imports and Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faf410b4-9e3a-4b0d-9bac-fd65f3997d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using torch version 1.11.0.post2\n",
      "matplotlib version=  3.5.3\n",
      "using (optional) optuna version 3.0.0\n",
      "BASE directoy properly set =  /home/ali/Desktop/Pulled_Github_Repositories/torchQN\n",
      "using torch version 1.11.0.post2\n",
      "matplotlib version=  3.5.3\n",
      "using (optional) optuna version 3.0.0\n",
      "BASE directoy properly set =  /home/ali/Desktop/Pulled_Github_Repositories/torchQN\n",
      "DATA directory also properly set, in /home/ali/Desktop/Pulled_Github_Repositories/IQN_HEP/Davidson/data\n",
      "using DATA_DIR=/home/ali/Desktop/Pulled_Github_Repositories/IQN_HEP/Davidson/data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import scipy as sp; import scipy.stats as st\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "print(f\"using torch version {torch.__version__}\")#old torch version: 1.9.0\n",
    "# use numba's just-in-time compiler to speed things up\n",
    "# from numba import njit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib as mp\n",
    "\n",
    "print(\"matplotlib version= \", mp.__version__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# reset matplotlib stle/parameters\n",
    "import matplotlib as mpl\n",
    "\n",
    "# reset matplotlib parameters to their defaults\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "plt.style.use(\"seaborn-deep\")\n",
    "mp.rcParams[\"agg.path.chunksize\"] = 10000\n",
    "font_legend = 15\n",
    "font_axes = 15\n",
    "# %matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "#or use joblib for caching on disk\n",
    "from joblib import  Memory\n",
    "# from IPython.display import Image, display\n",
    "# from importlib import import_module\n",
    "# import plotly\n",
    "try:\n",
    "    import optuna\n",
    "\n",
    "    print(f\"using (optional) optuna version {optuna.__version__}\")\n",
    "except Exception:\n",
    "    print(\"optuna is only used for hyperparameter tuning, not critical!\")\n",
    "    pass\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "# import sympy as sy\n",
    "# import ipywidgets as wid;\n",
    "\n",
    "\n",
    "# try:\n",
    "#     IQN_BASE = os.environ[\"IQN_BASE\"]\n",
    "#     print(\"BASE directoy properly set = \", IQN_BASE)\n",
    "#     utils_dir = os.path.join(IQN_BASE, \"utils/\")\n",
    "#     sys.path.append(utils_dir)\n",
    "#     import utils\n",
    "\n",
    "#     # usually its not recommended to import everything from a module, but we know\n",
    "#     # whats in it so its fine\n",
    "#     from utils import *\n",
    "\n",
    "#     print(\"DATA directory also properly set, in %s\" % os.environ[\"DATA_DIR\"])\n",
    "# except Exception:\n",
    "#     # IQN_BASE=os.getcwd()\n",
    "#     print(\n",
    "#         \"\"\"\\nBASE directory not properly set. Read repo README.    If you need a function from utils, use the decorator below, or add utils to sys.path\\n\n",
    "#     You can also do \n",
    "#     os.environ['IQN_BASE']=<ABSOLUTE PATH FOR THE IQN REPO>\n",
    "#     or\n",
    "#     os.environ['IQN_BASE']=os.getcwd()\"\"\"\n",
    "#     )\n",
    "#     pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from IPython.core.magic import register_cell_magic\n",
    "\n",
    "\n",
    "# @debug\n",
    "# def get_model_params_simple():\n",
    "#     dropout=0.2\n",
    "#     n_layers = 2\n",
    "#     n_hidden=32\n",
    "#     starting_learning_rate=1e-3\n",
    "#     print('n_iterations, n_layers, n_hidden, starting_learning_rate, dropout')\n",
    "#     return n_iterations, n_layers, n_hidden, starting_learning_rate, dropout\n",
    "\n",
    "\n",
    "# update fonts\n",
    "FONTSIZE = 14\n",
    "font = {\"family\": \"serif\", \"weight\": \"normal\", \"size\": FONTSIZE}\n",
    "mp.rc(\"font\", **font)\n",
    "\n",
    "# set usetex = False if LaTex is not\n",
    "# available on your system or if the\n",
    "# rendering is too slow\n",
    "mp.rc(\"text\", usetex=True)\n",
    "\n",
    "# set a seed to ensure reproducibility\n",
    "# seed = 128\n",
    "# rnd  = np.random.RandomState(seed)\n",
    "# sometimes jupyter doesnt initialize MathJax automatically for latex, so do this:\n",
    "#######\n",
    "\n",
    "\n",
    "IQN_BASE = os.environ[\"IQN_BASE\"]\n",
    "print(\"BASE directoy properly set = \", IQN_BASE)\n",
    "utils_dir = os.path.join(IQN_BASE, \"utils/\")\n",
    "sys.path.append(utils_dir)\n",
    "import utils\n",
    "\n",
    "# usually its not recommended to import everything from a module, but we know\n",
    "# whats in it so its fine\n",
    "from utils import *\n",
    "\n",
    "\n",
    "DATA_DIR = os.environ[\"DATA_DIR\"]\n",
    "print(f\"using DATA_DIR={DATA_DIR}\")\n",
    "\n",
    "memory = Memory(DATA_DIR)\n",
    "################################### SET DATA CONFIGURATIONS ###################################\n",
    "\n",
    "y_label_dict = {\n",
    "    \"RecoDatapT\": \"$p(p_T)$\" + \" [ GeV\" + \"$^{-1} $\" + \"]\",\n",
    "    \"RecoDataeta\": \"$p(\\eta)$\",\n",
    "    \"RecoDataphi\": \"$p(\\phi)$\",\n",
    "    \"RecoDatam\": \"$p(m)$\" + \" [ GeV\" + \"$^{-1} $\" + \"]\",\n",
    "}\n",
    "\n",
    "loss_y_label_dict = {\n",
    "    \"RecoDatapT\": \"$p_T^{reco}$\",\n",
    "    \"RecoDataeta\": \"$\\eta^{reco}$\",\n",
    "    \"RecoDataphi\": \"$\\phi^{reco}$\",\n",
    "    \"RecoDatam\": \"$m^{reco}$\",\n",
    "}\n",
    "\n",
    "X = [\"genDatapT\", \"genDataeta\", \"genDataphi\", \"genDatam\", \"tau\"]\n",
    "\n",
    "# set order of training:\n",
    "# pT_first: pT->>m->eta->phi\n",
    "# m_first: m->pT->eta->phi\n",
    "\n",
    "\n",
    "ORDER = \"m_First\"\n",
    "\n",
    "if ORDER == \"m_First\":\n",
    "    FIELDS = {\n",
    "        \"RecoDatam\": {\n",
    "            \"inputs\": X,\n",
    "            \"xlabel\": r\"$m$ (GeV)\",\n",
    "            \"ylabel\": \"$m^{reco}$\",\n",
    "            \"xmin\": 0,\n",
    "            \"xmax\": 25,\n",
    "        },\n",
    "        \"RecoDatapT\": {\n",
    "            \"inputs\": [\"RecoDatam\"] + X,\n",
    "            \"xlabel\": r\"$p_T$ (GeV)\",\n",
    "            \"ylabel\": \"$p_T^{reco}$\",\n",
    "            \"xmin\": 20,\n",
    "            \"xmax\": 80,\n",
    "        },\n",
    "        \"RecoDataeta\": {\n",
    "            \"inputs\": [\"RecoDatam\", \"RecoDatapT\"] + X,\n",
    "            \"xlabel\": r\"$\\eta$\",\n",
    "            \"ylabel\": \"$\\eta^{reco}$\",\n",
    "            \"xmin\": -5,\n",
    "            \"xmax\": 5,\n",
    "        },\n",
    "        \"RecoDataphi\": {\n",
    "            \"inputs\": [\"RecoDatam\", \"RecoDatapT\", \"RecoDataeta\"] + X,\n",
    "            \"xlabel\": r\"$\\phi$\",\n",
    "            \"ylabel\": \"$\\phi^{reco}$\",\n",
    "            \"xmin\": -3.2,\n",
    "            \"xmax\": 3.2,\n",
    "        },\n",
    "    }\n",
    "elif ORDER== \"phi_first\":\n",
    "    FIELDS = {\n",
    "        \"RecoDataphi\": {\n",
    "        \"inputs\": X,\n",
    "        \"xlabel\": r\"$\\phi$\",\n",
    "        \"ylabel\": \"$\\phi^{reco}$\",\n",
    "        \"xmin\": -3.2,\n",
    "        \"xmax\": 3.2,\n",
    "    },\n",
    "\n",
    "    \"RecoDatam\": {\n",
    "        \"inputs\": ['RecoDataphi'] + X,\n",
    "        \"xlabel\": r\"$m$ (GeV)\",\n",
    "        \"ylabel\": \"$m^{reco}$\",\n",
    "        \"xmin\": 0,\n",
    "        \"xmax\": 25,\n",
    "    },\n",
    "    \"RecoDatapT\": {\n",
    "        \"inputs\": [\"RecoDataphi\", \"RecoDatam\"] + X,\n",
    "        \"xlabel\": r\"$p_T$ (GeV)\",\n",
    "        \"ylabel\": \"$p_T^{reco}$\",\n",
    "        \"xmin\": 20,\n",
    "        \"xmax\": 80,\n",
    "    },\n",
    "    \"RecoDataeta\": {\n",
    "        \"inputs\": [\"RecoDataphi\", \"RecoDatam\", \"RecoDatapT\"]  + X,\n",
    "        \"xlabel\": r\"$\\eta$\",\n",
    "        \"ylabel\": \"$\\eta^{reco}$\",\n",
    "        \"xmin\": -5,\n",
    "        \"xmax\": 5,\n",
    "    },\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "# Load and explore raw (unscaled) dataframes\n",
    "\n",
    "\n",
    "all_variable_cols = [\n",
    "    \"genDatapT\",\n",
    "    \"genDataeta\",\n",
    "    \"genDataphi\",\n",
    "    \"genDatam\",\n",
    "    \"RecoDatapT\",\n",
    "    \"RecoDataeta\",\n",
    "    \"RecoDataphi\",\n",
    "    \"RecoDatam\",\n",
    "]\n",
    "all_cols = [\n",
    "    \"genDatapT\",\n",
    "    \"genDataeta\",\n",
    "    \"genDataphi\",\n",
    "    \"genDatam\",\n",
    "    \"RecoDatapT\",\n",
    "    \"RecoDataeta\",\n",
    "    \"RecoDataphi\",\n",
    "    \"RecoDatam\",\n",
    "    \"tau\",\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9654c3-0337-4d13-b223-c9750abd0afc",
   "metadata": {},
   "source": [
    "# 2.2: Load Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90f34e6d-4f15-4e82-96ae-64d047b38eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LR_Cooler:\n",
    "    def __init__(self, starting_lr: float, total_iterations: int, iter_: int) -> float:\n",
    "        self.starting_lr=starting_lr\n",
    "        self.iter_=iter_\n",
    "        self.total_iterations= total_iterations\n",
    "    def exponential_decay(self):\n",
    "        return self.starting_lr * (np.exp(-  self.iter_/1e5 ))\n",
    "    def exponential_decay_2(self):\n",
    "        decay_rate=1e-3\n",
    "        return self.starting_lr * np.exp(- decay_rate* self.iter)\n",
    "    \n",
    "    def fractional_decay(self):\n",
    "        final_time = 1\n",
    "        return self.starting_lr/(self.iter + final_time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30f02bc1-6d36-44e8-b412-5356ef425eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LR_sched = LR_Cooler(1e-3, np.arange(1e6), np.arange(1e6))\n",
    "LR = LR_sched.exponential_decay()\n",
    "plt.plot(np.arange(1e6), LR);plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f9d1692-0259-40e5-8859-3fbbfc76f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### Load unscaled dataframes ###################################\n",
    "################################### Load unscaled dataframes ###################################\n",
    "@memory.cache\n",
    "def load_raw_data():\n",
    "    \"\"\"Load raw train, test, and validation raw (unscaled) dataframes, in that order.\n",
    "\n",
    "    Returns:\n",
    "        list(pandas.DataFrame): train, test, valid raw datafranes\n",
    "    \"\"\"\n",
    "    print(f'SUBSAMPLE = {SUBSAMPLE}')\n",
    "    raw_train_data=pd.read_csv(os.path.join(DATA_DIR,'train_data_10M_2.csv'),\n",
    "                        usecols=all_cols,\n",
    "                        nrows=SUBSAMPLE\n",
    "                        )\n",
    "\n",
    "    raw_test_data=pd.read_csv(os.path.join(DATA_DIR,'test_data_10M_2.csv'),\n",
    "                        usecols=all_cols,\n",
    "                        nrows=SUBSAMPLE\n",
    "                        )\n",
    "\n",
    "    raw_valid_data=pd.read_csv(os.path.join(DATA_DIR,'validation_data_10M_2.csv'),\n",
    "                        usecols=all_cols,\n",
    "                        nrows=SUBSAMPLE\n",
    "                        )\n",
    "\n",
    "\n",
    "    print('\\n RAW TRAIN DATA SHAPE\\n')\n",
    "    print(raw_train_data.shape)\n",
    "    print('\\n RAW TRAIN DATA\\n')\n",
    "    raw_train_data.describe()#unscaled\n",
    "    print('\\n RAW TEST DATA\\ SHAPEn')\n",
    "    print(raw_test_data.shape)\n",
    "    print('\\n RAW TEST DATA\\n')\n",
    "    raw_test_data.describe()#unscaled\n",
    "\n",
    "    return raw_train_data, raw_test_data, raw_valid_data\n",
    "\n",
    "\n",
    "########## Generate scaled data###############\n",
    "# scaled_train_data = L_scale_df(raw_train_data, title='scaled_train_data_10M_2.csv',\n",
    "#                              save=True)\n",
    "# print('\\n\\n')\n",
    "# scaled_test_data = L_scale_df(raw_test_data,  title='scaled_test_data_10M_2.csv',\n",
    "#                             save=True)\n",
    "# print('\\n\\n')\n",
    "\n",
    "# scaled_valid_data = L_scale_df(raw_valid_data,  title='scaled_valid_data_10M_2.csv',\n",
    "#                             save=True)\n",
    "\n",
    "# explore_data(df=scaled_train_data, title='Braden Kronheim-L-scaled Dataframe', scaled=True)\n",
    "\n",
    "################ Load scaled data##############\n",
    "@utils.time_type_of_func(tuning_or_training='loading')\n",
    "@memory.cache\n",
    "def load_scaled_dataframes():\n",
    "    \"\"\"Load L-scaled train, test and validation according to Braden scaling, in that order.\n",
    "\n",
    "    Returns:\n",
    "        list(pandas.DataFarme): L-scaled train, test, validation dataframes, in that order.\n",
    "    \"\"\"\n",
    "    # print(\"SCALED TRAIN DATA\")\n",
    "    scaled_train_data = pd.read_csv(\n",
    "        os.path.join(DATA_DIR, \"scaled_train_data_10M_2.csv\"),\n",
    "        usecols=all_cols,\n",
    "        nrows=SUBSAMPLE,\n",
    "    )\n",
    "\n",
    "    # print(\"TRAINING FEATURES\\n\", scaled_train_data.head())\n",
    "\n",
    "    scaled_test_data = pd.read_csv(\n",
    "        os.path.join(DATA_DIR, \"scaled_test_data_10M_2.csv\"),\n",
    "        usecols=all_cols,\n",
    "        nrows=SUBSAMPLE,\n",
    "    )\n",
    "\n",
    "    scaled_valid_data = pd.read_csv(\n",
    "        os.path.join(DATA_DIR, \"scaled_valid_data_10M_2.csv\"),\n",
    "        usecols=all_cols,\n",
    "        nrows=SUBSAMPLE,\n",
    "    )\n",
    "    return scaled_train_data, scaled_test_data, scaled_valid_data\n",
    "\n",
    "# print('\\nTESTING FEATURES\\n', test_data_m.head())\n",
    "\n",
    "# print('\\ntrain set shape:',  train_data_m.shape)\n",
    "# print('\\ntest set shape:  ', test_data_m.shape)\n",
    "# # print('validation set shape:', valid_data.shape)\n",
    "\n",
    "\n",
    "\n",
    "def get_train_scale_dict(USE_BRADEN_SCALING):\n",
    "    \"\"\"Get a dictionary containing mean and standard deviation of each gen and reco feature. \n",
    "\n",
    "    Args:\n",
    "        USE_BRADEN_SCALING (bool): Whether you wish to use the Braden scaling. If True, it uses the L-scaled train dataframe. If False, it uses the unscaled dataframe.\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary of floats containing mean and standard deviation of each gen and reco feature. \n",
    "    \"\"\"\n",
    "    if USE_BRADEN_SCALING==True:\n",
    "        TRAIN_SCALE_DICT = get_scaling_info(scaled_train_data)\n",
    "        print('BRADEN SCALING DICTIONARY')\n",
    "        print(TRAIN_SCALE_DICT)\n",
    "        print(\"\\n\\n\")\n",
    "        # TEST_SCALE_DICT = get_scaling_info(scaled_test_data)\n",
    "        # print(TEST_SCALE_DICT)\n",
    "    else:\n",
    "        print('NORMAL UNSCALED DICTIONARY')\n",
    "        TRAIN_SCALE_DICT = get_scaling_info(raw_train_data)\n",
    "        print(TRAIN_SCALE_DICT)\n",
    "        print(\"\\n\\n\")\n",
    "        # TEST_SCALE_DICT = get_scaling_info(scaled_test_data)\n",
    "        # print(TEST_SCALE_DICT)\n",
    "    return TRAIN_SCALE_DICT\n",
    "\n",
    "\n",
    "\n",
    "################################ SPLIT###########\n",
    "# Currently need the split function again here\n",
    "# @memory.cache\n",
    "def split_t_x(df, target, input_features):\n",
    "    \"\"\"Get the target as the ratio, according to the T equation.\n",
    "    \n",
    "    Returns:\n",
    "    list(numpy.array): list of numpy array of target and training features\"\"\"\n",
    "\n",
    "    if target == \"RecoDatam\":\n",
    "        t = T(\"m\", scaled_df=scaled_train_data)\n",
    "    if target == \"RecoDatapT\":\n",
    "        t = T(\"pT\", scaled_df=scaled_train_data)\n",
    "    if target == \"RecoDataeta\":\n",
    "        t = T(\"eta\", scaled_df=scaled_train_data)\n",
    "    if target == \"RecoDataphi\":\n",
    "        t = T(\"phi\", scaled_df=scaled_train_data)\n",
    "    x = np.array(df[input_features])\n",
    "    return np.array(t), x\n",
    "\n",
    "# @memory.cache\n",
    "def normal_split_t_x(df, target, input_features):\n",
    "    \"\"\"splot dataframe into targets and feature arrays.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): Dataframe of train, test or validation data.\n",
    "        target (str): Choice of \"RecoDatapT\", \"RecoDataeta\", \"RecoDataphi\",\"RecoDatam\" as target.\n",
    "        input_features (list(str)): list of training features labels\n",
    "\n",
    "    Returns:\n",
    "    list(numpy.array): list of numpy array of target and training features\n",
    " \"\"\"\n",
    "    # change from pandas dataframe format to a numpy \n",
    "    # array of the specified types\n",
    "    # t = np.array(df[target])\n",
    "    t = np.array(df[target])\n",
    "    x = np.array(df[input_features])\n",
    "    return t, x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################ Apply Z scaling############\n",
    "def z(x):\n",
    "    \"\"\"Simple z-score standardization. Used for targets\"\"\"\n",
    "    eps = 1e-20\n",
    "    return (x - np.mean(x)) / (np.std(x) + eps)\n",
    "def z_inverse(xprime, x):\n",
    "    return xprime * np.std(x) + np.mean(x)\n",
    "\n",
    "# @memory.cache\n",
    "def z2(x, mean, std):\n",
    "    \"\"\"\n",
    "    The main z score function. Args:\n",
    "        x (numpy.array): feature 1-D array\n",
    "        mean (float): mean of the feature (in the training set)\n",
    "        std (float): standard deviation of the feature (in the training set)\n",
    "\n",
    "    Returns:\n",
    "        numpy.array: z-score-scaled 1-D feature\n",
    "    \"\"\"\n",
    "    eps = 1e-20\n",
    "    scaled = (x - mean) / (std + eps)\n",
    "    return np.array(scaled, dtype=np.float64)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# @memory.cache\n",
    "def z_inverse2(xprime, train_mean, train_std):\n",
    "    \"\"\"\n",
    "        The main z score de-scaling function. \n",
    "        \n",
    "        Args:\n",
    "        xprime (numpy.array): z-score-scaled feature 1-D array\n",
    "        train_mean (float): mean of the feature (in the training set)\n",
    "        train_std (float): standard deviation of the feature (in the training set)\n",
    "        \"\"\"\n",
    "    return xprime * train_std + train_mean\n",
    "\n",
    "# @memory.cache\n",
    "def apply_z_to_features(TRAIN_SCALE_DICT, train_x, test_x, valid_x):\n",
    "    \"\"\"TO ensure this z scaling is only applied once to the training features, we use a generator.\n",
    "    This doesn't change the shapes of anything, just applies z to all the feature columns other than tau.\n",
    "    \n",
    "    Args:\n",
    "    TRAIN_SCALE_DICT (dict(float)): dictionary of train set mean and standard deviation values\n",
    "    train_x (numpy.array): 2-D numpy array of training features\n",
    "    test_x (numpy.array):  2-D numpy array of test features\n",
    "    valid_x (numpy.array):  2-D numpy array of validation features\n",
    "    \"\"\"\n",
    "    for i in range(NFEATURES - 1):\n",
    "        variable = list(TRAIN_SCALE_DICT)[i]\n",
    "        train_mean = float(TRAIN_SCALE_DICT[variable][\"mean\"])\n",
    "        train_std = float(TRAIN_SCALE_DICT[variable][\"std\"])\n",
    "        train_x[:, i] = z2(train_x[:, i], mean=train_mean, std=train_std)\n",
    "        test_x[:, i] = z2(test_x[:, i], mean=train_mean, std=train_std)\n",
    "        valid_x[:, i] = z2(valid_x[:, i], mean=train_mean, std=train_std)\n",
    "    yield train_x\n",
    "    yield test_x\n",
    "    yield valid_x\n",
    "\n",
    "\n",
    "# @memory.cache\n",
    "def apply_z_to_targets(train_t, test_t, valid_t):\n",
    "    \"\"\"apply z-score scaling to target columns\n",
    "\n",
    "    Args:\n",
    "        train_t (numpy.array): target column in the training set\n",
    "        test_t (numpy.array): target column in the test set\n",
    "        valid_t (numpy.array): target column in the validation set\n",
    "\n",
    "    Yields:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "    train_mean = np.mean(train_t)\n",
    "    train_std = np.std(train_t)\n",
    "    train_t_ = z2(train_t, mean=train_mean, std=train_std)\n",
    "    test_t_ = z2(test_t, mean=train_mean, std=train_std)\n",
    "    valid_t_ = z2(valid_t, mean=train_mean, std=train_std)\n",
    "\n",
    "    yield train_t_\n",
    "    yield test_t_\n",
    "    yield valid_t_\n",
    "\n",
    "\n",
    "\n",
    "# check that it looks correct\n",
    "# fig = plt.figure(figsize=(10, 4))\n",
    "# ax = fig.add_subplot(autoscale_on=True)\n",
    "# ax.grid()\n",
    "# for i in range(NFEATURES):\n",
    "#     ax.hist(train_x[:,i], alpha=0.35, label=f'feature {i}' )\n",
    "#     # set_axes(ax=ax, xlabel=\"Transformed features X' \",title=\"training features post-z score: X'=z(L(X))\")\n",
    "# ax.legend()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "######### Get beset hyperparameters\n",
    "# tuned_dir = os.path.join(IQN_BASE,'best_params')\n",
    "# tuned_filename=os.path.join(tuned_dir,'best_params_mass_%s_trials.csv' % str(int(n_trials)))\n",
    "# BEST_PARAMS = pd.read_csv(os.path.join(IQN_BASE, 'best_params','best_params_Test_Trials.csv'))\n",
    "# BEST_PARAMS=pd.read_csv(tuned_filename)\n",
    "# print(BEST_PARAMS)\n",
    "\n",
    "\n",
    "\n",
    "def load_untrained_model(PARAMS):\n",
    "    \"\"\"Load an untrained model (with weights initiatted) according to model paramateters in the \n",
    "    PARAMS dictionary\n",
    "\n",
    "    Args:\n",
    "        PARAMS (dict): dictionary of model/training parameters: i.e. hyperparameters and training parameters.\n",
    "\n",
    "    Returns:\n",
    "        utils.RegularizedRegressionModel object\n",
    "    \"\"\"\n",
    "    model = utils.RegularizedRegressionModel(\n",
    "        nfeatures=NFEATURES,\n",
    "        ntargets=1,\n",
    "        nlayers=PARAMS[\"n_layers\"],\n",
    "        hidden_size=PARAMS[\"hidden_size\"],\n",
    "        dropout_1=PARAMS[\"dropout_1\"],\n",
    "        dropout_2=PARAMS[\"dropout_2\"],\n",
    "        activation=PARAMS[\"activation\"],\n",
    "    )\n",
    "    # model.apply(initialize_weights)\n",
    "    print(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SaveModelCheckpoint:\n",
    "    \"\"\"Continuous model-checkpointing class. Updates the latest checkpoint of an object based o validation loss each time its called. \n",
    "    \"\"\"\n",
    "    def __init__(self, best_valid_loss=np.inf):\n",
    "        \"\"\"Initiate an instance of the class based on filename and best_valid_loss/\n",
    "\n",
    "        Args:\n",
    "            best_valid_loss (float, optional): Best possible validation loss of a checkpoint object. Defaults to np.inf.\n",
    "        \"\"\"\n",
    "        self.best_valid_loss = best_valid_loss\n",
    "        self.filename_model=filename_model\n",
    "\n",
    "    def __call__(self, model, current_valid_loss, filename_model):\n",
    "        \"\"\"When an object of the calss is called, its validation loss gets updated and the model based \n",
    "        on the latest validation loss is saved.\n",
    "\n",
    "        Args:\n",
    "            model: utils.RegularizedRegressionModel object.\n",
    "            current_valid_loss (float): current (latest) validation loss of this model during the training process.\n",
    "            filename_model (str): filename in which the latest model will be saved. Can be a relative or local path. \n",
    "        \"\"\"\n",
    "        if current_valid_loss < self.best_valid_loss:\n",
    "            # update the best loss\n",
    "            self.best_valid_loss = current_valid_loss\n",
    "            # filename_model='Trained_IQNx4_%s_%sK_iter.dict' % (target, str(int(n_iterations/1000)) )\n",
    "            # filename_model = \"Trained_IQNx4_%s_TUNED_2lin_with_noise.dict\" % target\n",
    "\n",
    "            # note that n_iterations is the total n_iterations, we dont want to save a million files for each iteration\n",
    "            trained_models_dir = \"trained_models\"\n",
    "            mkdir(trained_models_dir)\n",
    "            # on cluster, Im using another TRAIN directory\n",
    "            PATH_model = os.path.join(\n",
    "                IQN_BASE,\n",
    "                \"JupyterBook\",\n",
    "                \"Cluster\",\n",
    "                \"TRAIN\",\n",
    "                trained_models_dir,\n",
    "                filename_model,\n",
    "            )\n",
    "            torch.save(model.state_dict(), PATH_model)\n",
    "            print(\n",
    "                f\"\\nCurrent valid loss: {current_valid_loss};  saved better model at {PATH_model}\"\n",
    "            )\n",
    "            # save using .pth object which if a dictionary of dicionaries, so that I can have PARAMS saved in the same file\n",
    "\n",
    "\n",
    "def train(\n",
    "    target,\n",
    "    model,\n",
    "    avloss,\n",
    "    getbatch,\n",
    "    train_x,\n",
    "    train_t,\n",
    "    valid_x,\n",
    "    valid_t,\n",
    "    PARAMS,\n",
    "    traces,\n",
    "    step,\n",
    "    window,\n",
    "):\n",
    "    \"\"\"Training Function. \n",
    "\n",
    "    Args:\n",
    "        target (str): hoice of \"RecoDatapT\", \"RecoDataeta\", \"RecoDataphi\",\"RecoDatam\" as target.\n",
    "        model a torch NN model, e.g utils.RegularizedRegressionModel.\n",
    "        avloss (float): average training losss\n",
    "        getbatch (function): a get_batch function\n",
    "        train_x (numpy.DataFrame): 2-D numpy array of training features\n",
    "        train_t (numpy.DataFrame:  1-D numpy array of training targets\n",
    "        valid_x (numpy.DataFrame): 2-D numpy array of validation features\n",
    "        valid_t (numpy.DataFrame: 1-D numpy array of validation targets\n",
    "        PARAMS (dict): dictionary of model/training parameters \n",
    "        traces (tuple): tuple of  \n",
    "        (iteration, training accuracy, validation accuracy, running average of validation accuracy) \n",
    "        = (xx, yy_t, yy_v, yy_v_avg) \n",
    "        step (int): number of iterations to take a printout step of the traces\n",
    "        window (int): window of running average of validation loss  \n",
    "\n",
    "    Returns:\n",
    "        tuple: traces\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: obviously, for reference, the \"traces\" should be saved as a 2D numpy array\n",
    "    # with the same naming format as the \"model_filename\", so that it can be opened later and \n",
    "    # plot loss curves for different models.\n",
    "    \n",
    "    # TODO: decay the stepsize, such that steps (and hence checkpointing) are large in the beginnig to the learning\n",
    "    # process (which corresponds to high learning rates), and decrease as time steps increase.\n",
    "    batch_size = PARAMS['batch_size']\n",
    "    n_iterations = PARAMS['n_iterations']\n",
    "    # to keep track of average losses\n",
    "    xx, yy_t, yy_v, yy_v_avg = traces\n",
    "    model_checkpoint = SaveModelCheckpoint()\n",
    "    n = len(valid_x)\n",
    "    \n",
    "    print(\"Iteration vs average loss\")\n",
    "    print(\"%10s\\t%10s\\t%10s\" % (\"iteration\", \"train-set\", \"test-set\"))\n",
    "    \n",
    "    fifth_n_iterations=int(n_iterations//5)\n",
    "    starting_learning_rate = PARAMS['starting_learning_rate']\n",
    "    for ii in range(n_iterations):\n",
    "        #experiment with annealing LR from beginning\n",
    "\n",
    "#         # starting learning rate (first fifth)\n",
    "        Cutoff_from_initial_LR = 5000\n",
    "        if ii< Cutoff_from_initial_LR:\n",
    "            learning_rate= starting_learning_rate\n",
    "        \n",
    "#         #second fifth\n",
    "\n",
    "#         if 2* fifth_n_iterations < ii < 3*fifth_n_iterations:\n",
    "#             learning_rate=starting_learning_rate/10 #1e-2\n",
    "        if ii > Cutoff_from_initial_LR:\n",
    "            LR_sched=LR_Cooler(starting_lr=starting_learning_rate, total_iterations=n_iterations, iter_=ii)\n",
    "            learning_rate=LR_sched.exponential_decay()\n",
    "#         #third fifth\n",
    "#         if 3*fifth_n_iterations < ii < 4*fifth_n_iterations:\n",
    "#             learning_rate=starting_learning_rate/100 #1e-3\n",
    "#         #frouth fifth: stary decay LR\n",
    "#         if ii > 4*fifth_n_iterations:\n",
    "#             learning_rate = decay_LR(ii)\n",
    "            \n",
    "        \n",
    "        # add weight decay (important regularization to reduce overfitting)\n",
    "        L2 = 1\n",
    "        # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=L2)\n",
    "        #SGD allows for: momentum=0, dampening=0, weight_decay=0, nesterov=boolean, differentiable=boolean\n",
    "\n",
    "        optimizer = getattr(torch.optim, optimizer_name)(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "         # amsgrad=True, \n",
    "\n",
    "        #  weight_decay=L2,#\n",
    "        # differentiable=True,\n",
    "        #For SGD nesterov, it requires momentum and zero dampening\n",
    "        # dampening=0,\n",
    "        # momentum=momentum,\n",
    "        # nesterov=True\n",
    "        # BUT no one should ever use SGD in 2022! Adam converges much better and faster.\n",
    "        )\n",
    "        \n",
    "        #if ii > 1e4: learning_rate=1e-4\n",
    "        # set mode to training so that training specific\n",
    "        # operations such as dropout are enabled.\n",
    "        # time_p_start = time.perf_counter()\n",
    "        model.train()\n",
    "\n",
    "        # get a random sample (a batch) of data (as numpy arrays)\n",
    "        batch_x, batch_t = getbatch(train_x, train_t, batch_size)\n",
    "        # Take df/ dtau\n",
    "        # x = torch.from_numpy(batch_x).float()\n",
    "        # # print('x is leaf: ', x.is_leaf)\n",
    "        # x.requires_grad_(True)\n",
    "        # # x.retain_grad()\n",
    "        # # print('x is leaf after retain: ', x.is_leaf)\n",
    "        # # x.requires_grad_(True)\n",
    "        # # x.retain_grad()\n",
    "        # f = model(x)\n",
    "        # f = f.view(-1)\n",
    "        # #multiply the model by its ransverse, remember we can only take gradients of scalars\n",
    "        # #and f will be a vector before this\n",
    "        # f = f @ f.t()\n",
    "        # f.retain_grad()\n",
    "        # f.backward(gradient=torch.ones_like(f), retain_graph=True)\n",
    "        # df_dx = x.grad\n",
    "        # df_dtau = df_dx[:,-1]\n",
    "        # x.grad.zero_()\n",
    "        \n",
    "        #add noise to training data\n",
    "        # batch_x = add_noise(batch_x)\n",
    "        # batch_t = add_noise(batch_t)\n",
    "        \n",
    "        # Try torch scheduler\n",
    "        scheduler=torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)\n",
    "        scheduler.step()\n",
    "\n",
    "        with torch.no_grad():  # no need to compute gradients\n",
    "            # wrt. x and t\n",
    "            x = torch.from_numpy(batch_x).float()\n",
    "            t = torch.from_numpy(batch_t).float()\n",
    "\n",
    "        outputs = model(x).reshape(t.shape)\n",
    "\n",
    "        empirical_risk = avloss(outputs, t, x)\n",
    "\n",
    "        optimizer.zero_grad()  # clear previous gradients\n",
    "        empirical_risk.backward()  # compute gradients\n",
    "\n",
    "        optimizer.step()  # move one step towards the minimum of the loss function using an SGD-like algorithm.\n",
    "        \n",
    "        \n",
    "\n",
    "        if ii % step == 0:\n",
    "\n",
    "            print(f\"\\t\\tCURRENT LEARNING RATE: {learning_rate}\")\n",
    "            acc_t = validate(model, avloss, train_x[:n], train_t[:n])\n",
    "            #acc_t: list of training losses\n",
    "            acc_v = validate(model, avloss, valid_x[:n], valid_t[:n])\n",
    "            #acc_v: list of validation losses\n",
    "            yy_t.append(acc_t)\n",
    "            yy_v.append(acc_v)\n",
    "            previous_iter_valid_loss = yy_v[-1]\n",
    "            print(f'previous_iter_valid_loss : {previous_iter_valid_loss}\\n')\n",
    "            # save better models based on valid loss\n",
    "            # filename_model=\"Trained_IQNx4_%s_TUNED_0lin_with_high_noise3.dict\" % target\n",
    "            filename_model=get_model_filename(target, PARAMS)\n",
    "             \n",
    "            model_checkpoint(model=model, filename_model =filename_model ,current_valid_loss=acc_v)\n",
    "            # compute running average for validation data\n",
    "            len_yy_v = len(yy_v)\n",
    "            if len_yy_v < window:\n",
    "                yy_v_avg.append(yy_v[-1])\n",
    "            elif len_yy_v == window:\n",
    "                yy_v_avg.append(sum(yy_v) / window)\n",
    "            else:\n",
    "                acc_v_avg = yy_v_avg[-1] * window\n",
    "                acc_v_avg += yy_v[-1] - yy_v[-window - 1]\n",
    "                yy_v_avg.append(acc_v_avg / window)\n",
    "\n",
    "            if len(xx) < 1:\n",
    "                xx.append(0)\n",
    "                print(\"%10d\\t%10.6f\\t%10.6f\" % (xx[-1], yy_t[-1], yy_v[-1]))\n",
    "            else:\n",
    "                xx.append(xx[-1] + step)\n",
    "\n",
    "                print(\n",
    "                    \"\\r%10d\\t%10.6f\\t%10.6f\\t%10.6f\"\n",
    "                    % (xx[-1], yy_t[-1], yy_v[-1], yy_v_avg[-1]),\n",
    "                    end=\"\",\n",
    "                )\n",
    "        # time_p_end = time.perf_counter()\n",
    "        # time_for_this_iter = time_p_end-time_p_start\n",
    "        # time_per_example = time_for_this_iter/batch_size\n",
    "        # print(f'training time for one example: {time_per_example}')\n",
    "\n",
    "    print()\n",
    "    return (xx, yy_t, yy_v, yy_v_avg)\n",
    "\n",
    "\n",
    "@utils.time_type_of_func(tuning_or_training=\"training\")\n",
    "def run(\n",
    "    target,\n",
    "    model,\n",
    "    train_x,\n",
    "    train_t,\n",
    "    valid_x,\n",
    "    valid_t,\n",
    "    traces,\n",
    "    PARAMS,\n",
    "    traces_step,\n",
    "    traces_window,\n",
    "    save_model,\n",
    "):\n",
    "\n",
    "\n",
    "    traces = train(\n",
    "        target,\n",
    "        model,\n",
    "        average_quantile_loss,\n",
    "        get_batch,\n",
    "        train_x,\n",
    "        train_t,\n",
    "        valid_x,\n",
    "        valid_t,\n",
    "        PARAMS,\n",
    "        traces,\n",
    "        step=traces_step,\n",
    "        window=traces_window,\n",
    "    )\n",
    "\n",
    "    if save_model:\n",
    "        filename = \"Trained_IQNx4_%s_%sK_iter.dict\" % (\n",
    "            target,\n",
    "            str(int(n_iterations / 1000)),\n",
    "        )\n",
    "        PATH = os.path.join(IQN_BASE, \"trained_models\", filename)\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "        print(\"\\ntrained model dictionary saved in %s\" % PATH)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_train_scale_dict(USE_BRADEN_SCALING):\n",
    "    if USE_BRADEN_SCALING==True:\n",
    "        TRAIN_SCALE_DICT = utils.get_scaling_info(scaled_train_data)\n",
    "        print(\"BRADEN SCALING DICTIONARY\")\n",
    "        print(TRAIN_SCALE_DICT)\n",
    "        print(\"\\n\\n\")\n",
    "        # TEST_SCALE_DICT = get_scaling_info(scaled_test_data)\n",
    "        # print(TEST_SCALE_DICT)\n",
    "    else:\n",
    "        print(\"NORMAL UNSCALED DICTIONARY\")\n",
    "        TRAIN_SCALE_DICT = utils.get_scaling_info(raw_train_data)\n",
    "        print(TRAIN_SCALE_DICT)\n",
    "        print(\"\\n\\n\")\n",
    "        # TEST_SCALE_DICT = get_scaling_info(scaled_test_data)\n",
    "        # print(TEST_SCALE_DICT)\n",
    "    return TRAIN_SCALE_DICT\n",
    "\n",
    "\n",
    "@utils.debug\n",
    "def save_model(model, PATH):\n",
    "    print(model)\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    print(\"\\ntrained model dictionary saved in %s\" % PATH)\n",
    "\n",
    "\n",
    "@utils.debug\n",
    "def save_model_params(model, PATH):\n",
    "    print(model)\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    print(\"\\ntrained model dictionary saved in %s\" % PATH)\n",
    "\n",
    "\n",
    "@utils.debug\n",
    "def load_model(PATH):\n",
    "    # n_layers = int(BEST_PARAMS[\"n_layers\"])\n",
    "    # hidden_size = int(BEST_PARAMS[\"hidden_size\"])\n",
    "    # dropout = float(BEST_PARAMS[\"dropout\"])\n",
    "    # optimizer_name = BEST_PARAMS[\"optimizer_name\"].to_string().split()[1]\n",
    "    # learning_rate =  float(BEST_PARAMS[\"learning_rate\"])\n",
    "    # batch_size = int(BEST_PARAMS[\"batch_size\"])\n",
    "    model = utils.RegularizedRegressionModel(\n",
    "        nfeatures=train_x.shape[1],\n",
    "        ntargets=1,\n",
    "        nlayers=n_layers,\n",
    "        hidden_size=hidden_size,\n",
    "        dropout=dropout,\n",
    "    )\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    # OR\n",
    "    # model=torch.load(PATH)#BUT HERE IT WILL BE A DICT (CANT BE EVALUATED RIGHT AWAY) DISCOURAGED!\n",
    "    model.eval()\n",
    "    print(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_trained_model(PATH, PARAMS):\n",
    "    model = utils.RegularizedRegressionModel(\n",
    "        nfeatures=NFEATURES,\n",
    "        ntargets=1,\n",
    "        nlayers=PARAMS[\"n_layers\"],\n",
    "        hidden_size=PARAMS[\"hidden_size\"],\n",
    "        dropout_1=PARAMS[\"dropout_1\"],\n",
    "        dropout_2=PARAMS[\"dropout_2\"],\n",
    "        activation=PARAMS[\"activation\"],\n",
    "    )\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    print(model)\n",
    "    model.train()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891fa0d7-ee43-4ee0-8d25-eafa4fc40b02",
   "metadata": {},
   "source": [
    "# 2.3 Load Data, split, scale, and Train Mass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1b5168-4ef0-4d5f-b115-372c5bfd2609",
   "metadata": {},
   "source": [
    "#### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38a53649-0c88-4fb8-9052-1187751e3dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "USE_BRADEN_SCALING=False\n",
    "#####################################\n",
    "################################### CONFIGURATIONS ###################################\n",
    "\n",
    "JUPYTER = True\n",
    "use_subsample = False\n",
    "# use_subsample = True\n",
    "if use_subsample:\n",
    "    SUBSAMPLE = int(1e5)  # subsample use for development - in production use whole dataset\n",
    "else:\n",
    "    SUBSAMPLE = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c91935e-8f27-4a16-a568-9302c2f91f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__--tmp-ipykernel-1472050648.load_raw_data...\n",
      "load_raw_data()\n",
      "SUBSAMPLE = None\n",
      "\n",
      " RAW TRAIN DATA SHAPE\n",
      "\n",
      "(8000000, 9)\n",
      "\n",
      " RAW TRAIN DATA\n",
      "\n",
      "\n",
      " RAW TEST DATA\\ SHAPEn\n",
      "(1000000, 9)\n",
      "\n",
      " RAW TEST DATA\n",
      "\n",
      "___________________________________________________load_raw_data - 24.2s, 0.4min\n"
     ]
    }
   ],
   "source": [
    "########################################################################################\n",
    "# Load data only once, and with caching!\n",
    "raw_train_data, raw_test_data, raw_valid_data =load_raw_data()\n",
    "# Load scaled data\n",
    "# scaled_train_data, scaled_test_data, scaled_valid_data = load_scaled_dataframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a34491a-0c10-4e71-8967-c0514d211f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features:\n",
      " ['genDatapT', 'genDataeta', 'genDataphi', 'genDatam', 'tau']\n",
      "\n",
      "Target =  RecoDatam\n",
      "USING NEW DATASET\n",
      "\n",
      "spliting data for RecoDatam\n",
      "train_t shape =  (8000000,) train_x shape =  (8000000, 5)\n",
      "\n",
      " Training features:\n",
      "\n",
      "[[29.4452      0.828187    2.90213     2.85348     0.36130954]\n",
      " [24.3193     -1.16351     0.636469    5.83685     0.12689925]\n",
      " [24.3193     -1.16351     0.636469    5.83685     0.96230681]\n",
      " ...\n",
      " [41.4192     -2.23358    -2.81921     7.19348     0.08421659]\n",
      " [35.4637     -1.12318     0.356494    6.06597     0.05535172]\n",
      " [26.5586     -1.09427    -1.49334     4.25409     0.07489863]]\n",
      "valid_t shape =  (1000000,) valid_x shape =  (1000000, 5)\n",
      "test_t shape =  (1000000,) test_x shape =  (1000000, 5)\n",
      "no need to train_test_split since we already have the split dataframes\n",
      "[ 3.27223764e+01  6.98189368e-04 -8.95543973e-04  6.96116528e+00\n",
      "  5.00485136e-01] [15.19914133  2.20425356  1.81362773  2.78097831  0.28852734]\n",
      "[ 3.26952341e+01 -1.78188172e-03 -3.83090331e-04  6.96299435e+00\n",
      "  4.99915289e-01] [14.93793254  2.20430976  1.81382516  2.78133203  0.28867295]\n",
      "5.5514112643334546 2.664124544901276\n",
      "5.555567451922438 2.664339857066051\n",
      "NORMAL UNSCALED DICTIONARY\n",
      "{'genDatapT': {'mean': 32.695234084987476, 'std': 14.937932540562551}, 'genDataeta': {'mean': -0.0017818817154031672, 'std': 2.204309760627079}, 'genDataphi': {'mean': -0.0003830903308450233, 'std': 1.8138251604791067}, 'genDatam': {'mean': 6.962994352358474, 'std': 2.781332025286383}, 'RecoDatapT': {'mean': 32.86720151648752, 'std': 15.829355769531851}, 'RecoDataeta': {'mean': -0.0017898858568513964, 'std': 2.197968491495457}, 'RecoDataphi': {'mean': -0.0004719170328962474, 'std': 1.8144739820043825}, 'RecoDatam': {'mean': 5.555567451922438, 'std': 2.664339857066051}}\n",
      "\n",
      "\n",
      "\n",
      "[ 1.81700902e-03  1.12510099e-03 -2.82526482e-04 -6.57626105e-04\n",
      "  5.00485136e-01] [1.01748627 0.9999745  0.99989115 0.99987283 0.28852734]\n",
      "[ 1.61650249e-15 -1.10134124e-18 -3.12905257e-17  5.01036723e-15\n",
      "  4.99915289e-01] [1.         1.         1.         1.         0.28867295]\n",
      "-0.0015599314696879494 0.9999191874249058\n",
      "6.996216939114674e-16 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "target = \"RecoDatam\"\n",
    "source = FIELDS[target]\n",
    "features = source[\"inputs\"]\n",
    "print(\"Training Features:\\n\", features)\n",
    "print(\"\\nTarget = \", target)\n",
    "\n",
    "print(\"USING NEW DATASET\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get targets and features\n",
    "# if USE_BRADEN_SCALING==True:\n",
    "#     print(f\"spliting data for {target}\")\n",
    "#     train_t, train_x = split_t_x(\n",
    "#         df=scaled_train_data, target=target, input_features=features\n",
    "#     )\n",
    "#     print(\"train_t shape = \", train_t.shape, \"train_x shape = \", train_x.shape)\n",
    "#     print(\"\\n Training features:\\n\")\n",
    "#     print(train_x)\n",
    "#     valid_t, valid_x = split_t_x(\n",
    "#         df=scaled_valid_data, target=target, input_features=features\n",
    "#     )\n",
    "#     print(\"valid_t shape = \", valid_t.shape, \"valid_x shape = \", valid_x.shape)\n",
    "#     test_t, test_x = split_t_x(df=scaled_test_data, target=target, input_features=features)\n",
    "#     print(\"test_t shape = \", test_t.shape, \"test_x shape = \", test_x.shape)\n",
    "\n",
    "# else:\n",
    "#     print(f\"spliting data for {target}\")\n",
    "#     train_t, train_x = normal_split_t_x(\n",
    "#     df=raw_train_data, target=target, input_features=features\n",
    "#     )\n",
    "#     print(\"train_t shape = \", train_t.shape, \"train_x shape = \", train_x.shape)\n",
    "#     print(\"\\n Training features:\\n\")\n",
    "#     print(train_x)\n",
    "#     valid_t, valid_x = normal_split_t_x(\n",
    "#     df=raw_valid_data, target=target, input_features=features\n",
    "#     )\n",
    "#     print(\"valid_t shape = \", valid_t.shape, \"valid_x shape = \", valid_x.shape)\n",
    "#     test_t, test_x = normal_split_t_x(df=raw_test_data, target=target, input_features=features)\n",
    "#     print(\"test_t shape = \", test_t.shape, \"test_x shape = \", test_x.shape)\n",
    "\n",
    "\n",
    "print(f\"spliting data for {target}\")\n",
    "train_t, train_x = normal_split_t_x(\n",
    "df=raw_train_data, target=target, input_features=features\n",
    ")\n",
    "print(\"train_t shape = \", train_t.shape, \"train_x shape = \", train_x.shape)\n",
    "print(\"\\n Training features:\\n\")\n",
    "print(train_x)\n",
    "valid_t, valid_x = normal_split_t_x(\n",
    "df=raw_valid_data, target=target, input_features=features\n",
    ")\n",
    "print(\"valid_t shape = \", valid_t.shape, \"valid_x shape = \", valid_x.shape)\n",
    "test_t, test_x = normal_split_t_x(df=raw_test_data, target=target, input_features=features)\n",
    "print(\"test_t shape = \", test_t.shape, \"test_x shape = \", test_x.shape)\n",
    "\n",
    "\n",
    "print(\"no need to train_test_split since we already have the split dataframes\")\n",
    "print(valid_x.mean(axis=0), valid_x.std(axis=0))\n",
    "print(train_x.mean(axis=0), train_x.std(axis=0))\n",
    "print(valid_t.mean(), valid_t.std())\n",
    "print(train_t.mean(), train_t.std())\n",
    "NFEATURES = train_x.shape[1]\n",
    "######################################################\n",
    "\n",
    "# Apply z scaling to features and targets\n",
    "# to features\n",
    "TRAIN_SCALE_DICT=get_train_scale_dict(USE_BRADEN_SCALING)\n",
    "apply_z_generator = apply_z_to_features(TRAIN_SCALE_DICT, train_x, test_x, valid_x)\n",
    "train_x_z_scaled = next(apply_z_generator)\n",
    "test_x_z_scaled = next(apply_z_generator)\n",
    "valid_x_z_scaled = next(apply_z_generator)\n",
    "print(valid_x_z_scaled.mean(axis=0), valid_x_z_scaled.std(axis=0))\n",
    "print(train_x_z_scaled.mean(axis=0), train_x_z_scaled.std(axis=0))\n",
    "\n",
    "# to targets\n",
    "apply_z_to_targets_generator = apply_z_to_targets(\n",
    "    train_t, test_t, valid_t\n",
    ")\n",
    "train_t_z_scaled = next(apply_z_to_targets_generator)\n",
    "test_t_z_scaled = next(apply_z_to_targets_generator)\n",
    "valid_t_z_scaled = next(apply_z_to_targets_generator)\n",
    "print(valid_t_z_scaled.mean(), valid_t_z_scaled.std())\n",
    "print(train_t_z_scaled.mean(), train_t_z_scaled.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3087482e-fb15-4e02-a894-c5c6fc05638e",
   "metadata": {},
   "source": [
    "Decide Whether to use Braden Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d597bc6-64df-4427-b268-9f1aeb3cd183",
   "metadata": {},
   "source": [
    "# Define Mass Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b8a342c-6c66-4d39-aaeb-eb421bfa3b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# Decide on parameters for this model and training\n",
    "PARAMS_m = {\n",
    "\"n_layers\": int(4),\n",
    "\"hidden_size\": int(5),\n",
    "\"dropout_1\": float(0.6),\n",
    "\"dropout_2\": float(0.1),\n",
    "\"activation\": \"LeakyReLU\",\n",
    "    'optimizer_name':'NAdam',\n",
    "    'starting_learning_rate':float(0.5),\n",
    "    'momentum':float(0.6),\n",
    "    'batch_size':int(512),\n",
    "    'n_iterations': int(2e6),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708af01e-612a-405a-81c8-41a2e3739a07",
   "metadata": {},
   "source": [
    "## Train Mass\n",
    "\n",
    "### The model that needs the longest time in training is mass. Click here to scroll down to train $p_T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f695aaf2-a37e-4ba1-86aa-0563957f09dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "training for 500000 iteration, which is  32.0 epochs\n",
      "RegularizedRegressionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.3)\n",
      "    (2): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (3): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.3)\n",
      "    (5): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (6): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.3)\n",
      "    (8): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (9): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.3)\n",
      "    (11): Linear(in_features=5, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "training IQN \n",
      "Iteration vs average loss\n",
      " iteration\t train-set\t  test-set\n",
      "\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.34466463327407837\n",
      "\n",
      "\n",
      "Current valid loss: 0.34466463327407837;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "         0\t  0.344941\t  0.344665\n",
      "\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.1760653257369995\n",
      "\n",
      "\n",
      "Current valid loss: 0.1760653257369995;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "       200\t  0.176295\t  0.176065\t  0.176065\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.19366678595542908\n",
      "\n",
      "       400\t  0.194019\t  0.193667\t  0.193667\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.17708821594715118\n",
      "\n",
      "       600\t  0.177132\t  0.177088\t  0.177088\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.17682118713855743\n",
      "\n",
      "       800\t  0.177035\t  0.176821\t  0.176821\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.17116710543632507\n",
      "\n",
      "\n",
      "Current valid loss: 0.17116710543632507;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "      1000\t  0.171121\t  0.171167\t  0.171167\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.17148981988430023\n",
      "\n",
      "      1200\t  0.171570\t  0.171490\t  0.171490\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.17396743595600128\n",
      "\n",
      "      1400\t  0.173969\t  0.173967\t  0.173967\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.1690109223127365\n",
      "\n",
      "\n",
      "Current valid loss: 0.1690109223127365;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "      1600\t  0.169020\t  0.169011\t  0.169011\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.17037005722522736\n",
      "\n",
      "      1800\t  0.170389\t  0.170370\t  0.170370\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.1704281121492386\n",
      "\n",
      "      2000\t  0.170441\t  0.170428\t  0.170428\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.17227700352668762\n",
      "\n",
      "      2200\t  0.172112\t  0.172277\t  0.172277\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.1690891683101654\n",
      "\n",
      "      2400\t  0.169129\t  0.169089\t  0.169089\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.1732080727815628\n",
      "\n",
      "      2600\t  0.173192\t  0.173208\t  0.173208\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.16744056344032288\n",
      "\n",
      "\n",
      "Current valid loss: 0.16744056344032288;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "      2800\t  0.167546\t  0.167441\t  0.167441\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.17443381249904633\n",
      "\n",
      "      3000\t  0.174641\t  0.174434\t  0.174434\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.1721777766942978\n",
      "\n",
      "      3200\t  0.172150\t  0.172178\t  0.172178\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.17313727736473083\n",
      "\n",
      "      3400\t  0.173260\t  0.173137\t  0.173137\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.1714889258146286\n",
      "\n",
      "      3600\t  0.171466\t  0.171489\t  0.171489\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.17957670986652374\n",
      "\n",
      "      3800\t  0.179695\t  0.179577\t  0.179577\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.17059652507305145\n",
      "\n",
      "      4000\t  0.170744\t  0.170597\t  0.170597\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.17402960360050201\n",
      "\n",
      "      4200\t  0.174338\t  0.174030\t  0.174030\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.16973820328712463\n",
      "\n",
      "      4400\t  0.169843\t  0.169738\t  0.169738\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.16622024774551392\n",
      "\n",
      "\n",
      "Current valid loss: 0.16622024774551392;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "      4600\t  0.166258\t  0.166220\t  0.166220\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.1750408262014389\n",
      "\n",
      "      4800\t  0.175281\t  0.175041\t  0.175041\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.17104652523994446\n",
      "\n",
      "      5000\t  0.171321\t  0.171047\t  0.171047\t\tCURRENT LEARNING RATE: 0.47466443342144476\n",
      "previous_iter_valid_loss : 0.17399699985980988\n",
      "\n",
      "      5200\t  0.174022\t  0.173997\t  0.173997\t\tCURRENT LEARNING RATE: 0.47371605325089916\n",
      "previous_iter_valid_loss : 0.16805705428123474\n",
      "\n",
      "      5400\t  0.168279\t  0.168057\t  0.168057\t\tCURRENT LEARNING RATE: 0.47276956794519814\n",
      "previous_iter_valid_loss : 0.16900865733623505\n",
      "\n",
      "      5600\t  0.169199\t  0.169009\t  0.169009\t\tCURRENT LEARNING RATE: 0.47182497371839927\n",
      "previous_iter_valid_loss : 0.1703009307384491\n",
      "\n",
      "      5800\t  0.170547\t  0.170301\t  0.170301\t\tCURRENT LEARNING RATE: 0.47088226679212436\n",
      "previous_iter_valid_loss : 0.17189940810203552\n",
      "\n",
      "      6000\t  0.172057\t  0.171899\t  0.171899\t\tCURRENT LEARNING RATE: 0.46994144339554444\n",
      "previous_iter_valid_loss : 0.17370867729187012\n",
      "\n",
      "      6200\t  0.173919\t  0.173709\t  0.173709\t\tCURRENT LEARNING RATE: 0.46900249976536473\n",
      "previous_iter_valid_loss : 0.17092587053775787\n",
      "\n",
      "      6400\t  0.171041\t  0.170926\t  0.170926\t\tCURRENT LEARNING RATE: 0.4680654321458094\n",
      "previous_iter_valid_loss : 0.17532841861248016\n",
      "\n",
      "      6600\t  0.175615\t  0.175328\t  0.175328\t\tCURRENT LEARNING RATE: 0.46713023678860677\n",
      "previous_iter_valid_loss : 0.1653168797492981\n",
      "\n",
      "\n",
      "Current valid loss: 0.1653168797492981;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "      6800\t  0.165479\t  0.165317\t  0.165317\t\tCURRENT LEARNING RATE: 0.46619690995297414\n",
      "previous_iter_valid_loss : 0.17974960803985596\n",
      "\n",
      "      7000\t  0.180092\t  0.179750\t  0.179750\t\tCURRENT LEARNING RATE: 0.46526544790560287\n",
      "previous_iter_valid_loss : 0.16464421153068542\n",
      "\n",
      "\n",
      "Current valid loss: 0.16464421153068542;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "      7200\t  0.164892\t  0.164644\t  0.164644\t\tCURRENT LEARNING RATE: 0.4643358469206436\n",
      "previous_iter_valid_loss : 0.18450719118118286\n",
      "\n",
      "      7400\t  0.184866\t  0.184507\t  0.184507\t\tCURRENT LEARNING RATE: 0.4634081032796911\n",
      "previous_iter_valid_loss : 0.16626328229904175\n",
      "\n",
      "      7600\t  0.166397\t  0.166263\t  0.166263\t\tCURRENT LEARNING RATE: 0.46248221327176964\n",
      "previous_iter_valid_loss : 0.1740187257528305\n",
      "\n",
      "      7800\t  0.174313\t  0.174019\t  0.174019\t\tCURRENT LEARNING RATE: 0.4615581731933179\n",
      "previous_iter_valid_loss : 0.17600196599960327\n",
      "\n",
      "      8000\t  0.176295\t  0.176002\t  0.176002\t\tCURRENT LEARNING RATE: 0.46063597934817435\n",
      "previous_iter_valid_loss : 0.1852818876504898\n",
      "\n",
      "      8200\t  0.185400\t  0.185282\t  0.185282\t\tCURRENT LEARNING RATE: 0.45971562804756233\n",
      "previous_iter_valid_loss : 0.16584952175617218\n",
      "\n",
      "      8400\t  0.165983\t  0.165850\t  0.165850\t\tCURRENT LEARNING RATE: 0.45879711561007547\n",
      "previous_iter_valid_loss : 0.16665376722812653\n",
      "\n",
      "      8600\t  0.166825\t  0.166654\t  0.166654\t\tCURRENT LEARNING RATE: 0.4578804383616628\n",
      "previous_iter_valid_loss : 0.16855782270431519\n",
      "\n",
      "      8800\t  0.168701\t  0.168558\t  0.168558\t\tCURRENT LEARNING RATE: 0.4569655926356141\n",
      "previous_iter_valid_loss : 0.16735120117664337\n",
      "\n",
      "      9000\t  0.167435\t  0.167351\t  0.167351\t\tCURRENT LEARNING RATE: 0.4560525747725452\n",
      "previous_iter_valid_loss : 0.16469819843769073\n",
      "\n",
      "      9200\t  0.164842\t  0.164698\t  0.164698\t\tCURRENT LEARNING RATE: 0.4551413811203835\n",
      "previous_iter_valid_loss : 0.16581134498119354\n",
      "\n",
      "      9400\t  0.165902\t  0.165811\t  0.165811\t\tCURRENT LEARNING RATE: 0.4542320080343531\n",
      "previous_iter_valid_loss : 0.16710622608661652\n",
      "\n",
      "      9600\t  0.167250\t  0.167106\t  0.167106\t\tCURRENT LEARNING RATE: 0.45332445187696047\n",
      "previous_iter_valid_loss : 0.16906611621379852\n",
      "\n",
      "      9800\t  0.169383\t  0.169066\t  0.169066\t\tCURRENT LEARNING RATE: 0.45241870901797976\n",
      "previous_iter_valid_loss : 0.170145183801651\n",
      "\n",
      "     10000\t  0.170431\t  0.170145\t  0.170145\t\tCURRENT LEARNING RATE: 0.4515147758344384\n",
      "previous_iter_valid_loss : 0.1646515130996704\n",
      "\n",
      "     10200\t  0.164878\t  0.164652\t  0.164652\t\tCURRENT LEARNING RATE: 0.4506126487106024\n",
      "previous_iter_valid_loss : 0.16736100614070892\n",
      "\n",
      "     10400\t  0.167409\t  0.167361\t  0.167361\t\tCURRENT LEARNING RATE: 0.449712324037962\n",
      "previous_iter_valid_loss : 0.1671299934387207\n",
      "\n",
      "     10600\t  0.167359\t  0.167130\t  0.167130\t\tCURRENT LEARNING RATE: 0.44881379821521744\n",
      "previous_iter_valid_loss : 0.16500872373580933\n",
      "\n",
      "     10800\t  0.165244\t  0.165009\t  0.165009\t\tCURRENT LEARNING RATE: 0.4479170676482641\n",
      "previous_iter_valid_loss : 0.170308455824852\n",
      "\n",
      "     11000\t  0.170539\t  0.170308\t  0.170308\t\tCURRENT LEARNING RATE: 0.4470221287501786\n",
      "previous_iter_valid_loss : 0.16751308739185333\n",
      "\n",
      "     11200\t  0.167719\t  0.167513\t  0.167513\t\tCURRENT LEARNING RATE: 0.44612897794120415\n",
      "previous_iter_valid_loss : 0.16637387871742249\n",
      "\n",
      "     11400\t  0.166557\t  0.166374\t  0.166374\t\tCURRENT LEARNING RATE: 0.4452376116487363\n",
      "previous_iter_valid_loss : 0.17866940796375275\n",
      "\n",
      "     11600\t  0.178952\t  0.178669\t  0.178669\t\tCURRENT LEARNING RATE: 0.4443480263073087\n",
      "previous_iter_valid_loss : 0.17822308838367462\n",
      "\n",
      "     11800\t  0.178252\t  0.178223\t  0.178223\t\tCURRENT LEARNING RATE: 0.44346021835857874\n",
      "previous_iter_valid_loss : 0.16852378845214844\n",
      "\n",
      "     12000\t  0.168579\t  0.168524\t  0.168524\t\tCURRENT LEARNING RATE: 0.44257418425131356\n",
      "previous_iter_valid_loss : 0.1651621311903\n",
      "\n",
      "     12200\t  0.165319\t  0.165162\t  0.165162\t\tCURRENT LEARNING RATE: 0.44168992044137545\n",
      "previous_iter_valid_loss : 0.1675209403038025\n",
      "\n",
      "     12400\t  0.167715\t  0.167521\t  0.167521\t\tCURRENT LEARNING RATE: 0.44080742339170803\n",
      "previous_iter_valid_loss : 0.1698734313249588\n",
      "\n",
      "     12600\t  0.170162\t  0.169873\t  0.169873\t\tCURRENT LEARNING RATE: 0.4399266895723219\n",
      "previous_iter_valid_loss : 0.16748130321502686\n",
      "\n",
      "     12800\t  0.167512\t  0.167481\t  0.167481\t\tCURRENT LEARNING RATE: 0.43904771546028065\n",
      "previous_iter_valid_loss : 0.17067056894302368\n",
      "\n",
      "     13000\t  0.170743\t  0.170671\t  0.170671\t\tCURRENT LEARNING RATE: 0.4381704975396866\n",
      "previous_iter_valid_loss : 0.17058037221431732\n",
      "\n",
      "     13200\t  0.170745\t  0.170580\t  0.170580\t\tCURRENT LEARNING RATE: 0.437295032301667\n",
      "previous_iter_valid_loss : 0.16829149425029755\n",
      "\n",
      "     13400\t  0.168554\t  0.168291\t  0.168291\t\tCURRENT LEARNING RATE: 0.43642131624435965\n",
      "previous_iter_valid_loss : 0.17045657336711884\n",
      "\n",
      "     13600\t  0.170663\t  0.170457\t  0.170457\t\tCURRENT LEARNING RATE: 0.4355493458728992\n",
      "previous_iter_valid_loss : 0.16973109543323517\n",
      "\n",
      "     13800\t  0.169959\t  0.169731\t  0.169731\t\tCURRENT LEARNING RATE: 0.43467911769940293\n",
      "previous_iter_valid_loss : 0.1655919998884201\n",
      "\n",
      "     14000\t  0.165795\t  0.165592\t  0.165592\t\tCURRENT LEARNING RATE: 0.433810628242957\n",
      "previous_iter_valid_loss : 0.1708456128835678\n",
      "\n",
      "     14200\t  0.171063\t  0.170846\t  0.170846\t\tCURRENT LEARNING RATE: 0.4329438740296025\n",
      "previous_iter_valid_loss : 0.16450639069080353\n",
      "\n",
      "\n",
      "Current valid loss: 0.16450639069080353;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "     14400\t  0.164626\t  0.164506\t  0.164506\t\tCURRENT LEARNING RATE: 0.4320788515923214\n",
      "previous_iter_valid_loss : 0.16372571885585785\n",
      "\n",
      "\n",
      "Current valid loss: 0.16372571885585785;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "     14600\t  0.163947\t  0.163726\t  0.163726\t\tCURRENT LEARNING RATE: 0.43121555747102275\n",
      "previous_iter_valid_loss : 0.16406874358654022\n",
      "\n",
      "     14800\t  0.164326\t  0.164069\t  0.164069\t\tCURRENT LEARNING RATE: 0.4303539882125289\n",
      "previous_iter_valid_loss : 0.168100506067276\n",
      "\n",
      "     15000\t  0.168310\t  0.168101\t  0.168101\t\tCURRENT LEARNING RATE: 0.4294941403705617\n",
      "previous_iter_valid_loss : 0.16798058152198792\n",
      "\n",
      "     15200\t  0.168197\t  0.167981\t  0.167981\t\tCURRENT LEARNING RATE: 0.42863601050572875\n",
      "previous_iter_valid_loss : 0.16435971856117249\n",
      "\n",
      "     15400\t  0.164495\t  0.164360\t  0.164360\t\tCURRENT LEARNING RATE: 0.42777959518550923\n",
      "previous_iter_valid_loss : 0.1661955863237381\n",
      "\n",
      "     15600\t  0.166422\t  0.166196\t  0.166196\t\tCURRENT LEARNING RATE: 0.42692489098424086\n",
      "previous_iter_valid_loss : 0.1649206280708313\n",
      "\n",
      "     15800\t  0.165063\t  0.164921\t  0.164921\t\tCURRENT LEARNING RATE: 0.4260718944831057\n",
      "previous_iter_valid_loss : 0.16873982548713684\n",
      "\n",
      "     16000\t  0.168838\t  0.168740\t  0.168740\t\tCURRENT LEARNING RATE: 0.4252206022701165\n",
      "previous_iter_valid_loss : 0.16942192614078522\n",
      "\n",
      "     16200\t  0.169641\t  0.169422\t  0.169422\t\tCURRENT LEARNING RATE: 0.4243710109401034\n",
      "previous_iter_valid_loss : 0.164626345038414\n",
      "\n",
      "     16400\t  0.164783\t  0.164626\t  0.164626\t\tCURRENT LEARNING RATE: 0.4235231170946998\n",
      "previous_iter_valid_loss : 0.17259228229522705\n",
      "\n",
      "     16600\t  0.172764\t  0.172592\t  0.172592\t\tCURRENT LEARNING RATE: 0.4226769173423294\n",
      "previous_iter_valid_loss : 0.1716335415840149\n",
      "\n",
      "     16800\t  0.171792\t  0.171634\t  0.171634\t\tCURRENT LEARNING RATE: 0.42183240829819185\n",
      "previous_iter_valid_loss : 0.170531764626503\n",
      "\n",
      "     17000\t  0.170683\t  0.170532\t  0.170532\t\tCURRENT LEARNING RATE: 0.42098958658424995\n",
      "previous_iter_valid_loss : 0.17431993782520294\n",
      "\n",
      "     17200\t  0.174484\t  0.174320\t  0.174320\t\tCURRENT LEARNING RATE: 0.4201484488292157\n",
      "previous_iter_valid_loss : 0.1690942347049713\n",
      "\n",
      "     17400\t  0.169278\t  0.169094\t  0.169094\t\tCURRENT LEARNING RATE: 0.419308991668537\n",
      "previous_iter_valid_loss : 0.172032430768013\n",
      "\n",
      "     17600\t  0.172202\t  0.172032\t  0.172032\t\tCURRENT LEARNING RATE: 0.41847121174438406\n",
      "previous_iter_valid_loss : 0.1715475618839264\n",
      "\n",
      "     17800\t  0.171719\t  0.171548\t  0.171548\t\tCURRENT LEARNING RATE: 0.417635105705636\n",
      "previous_iter_valid_loss : 0.16957694292068481\n",
      "\n",
      "     18000\t  0.169709\t  0.169577\t  0.169577\t\tCURRENT LEARNING RATE: 0.41680067020786765\n",
      "previous_iter_valid_loss : 0.17330540716648102\n",
      "\n",
      "     18200\t  0.173455\t  0.173305\t  0.173305\t\tCURRENT LEARNING RATE: 0.4159679019133359\n",
      "previous_iter_valid_loss : 0.17397169768810272\n",
      "\n",
      "     18400\t  0.174216\t  0.173972\t  0.173972\t\tCURRENT LEARNING RATE: 0.4151367974909663\n",
      "previous_iter_valid_loss : 0.16430005431175232\n",
      "\n",
      "     18600\t  0.164392\t  0.164300\t  0.164300\t\tCURRENT LEARNING RATE: 0.4143073536163403\n",
      "previous_iter_valid_loss : 0.17117944359779358\n",
      "\n",
      "     18800\t  0.171312\t  0.171179\t  0.171179\t\tCURRENT LEARNING RATE: 0.41347956697168115\n",
      "previous_iter_valid_loss : 0.16513502597808838\n",
      "\n",
      "     19000\t  0.165360\t  0.165135\t  0.165135\t\tCURRENT LEARNING RATE: 0.41265343424584117\n",
      "previous_iter_valid_loss : 0.17444156110286713\n",
      "\n",
      "     19200\t  0.174732\t  0.174442\t  0.174442\t\tCURRENT LEARNING RATE: 0.41182895213428844\n",
      "previous_iter_valid_loss : 0.16723836958408356\n",
      "\n",
      "     19400\t  0.167273\t  0.167238\t  0.167238\t\tCURRENT LEARNING RATE: 0.41100611733909326\n",
      "previous_iter_valid_loss : 0.16496065258979797\n",
      "\n",
      "     19600\t  0.165105\t  0.164961\t  0.164961\t\tCURRENT LEARNING RATE: 0.41018492656891553\n",
      "previous_iter_valid_loss : 0.16455601155757904\n",
      "\n",
      "     19800\t  0.164621\t  0.164556\t  0.164556\t\tCURRENT LEARNING RATE: 0.4093653765389909\n",
      "previous_iter_valid_loss : 0.16542859375476837\n",
      "\n",
      "     20000\t  0.165531\t  0.165429\t  0.165429\t\tCURRENT LEARNING RATE: 0.4085474639711183\n",
      "previous_iter_valid_loss : 0.16488796472549438\n",
      "\n",
      "     20200\t  0.165091\t  0.164888\t  0.164888\t\tCURRENT LEARNING RATE: 0.40773118559364635\n",
      "previous_iter_valid_loss : 0.1673518419265747\n",
      "\n",
      "     20400\t  0.167421\t  0.167352\t  0.167352\t\tCURRENT LEARNING RATE: 0.40691653814146034\n",
      "previous_iter_valid_loss : 0.16353830695152283\n",
      "\n",
      "\n",
      "Current valid loss: 0.16353830695152283;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "     20600\t  0.163613\t  0.163538\t  0.163538\t\tCURRENT LEARNING RATE: 0.40610351835596953\n",
      "previous_iter_valid_loss : 0.16639767587184906\n",
      "\n",
      "     20800\t  0.166492\t  0.166398\t  0.166398\t\tCURRENT LEARNING RATE: 0.40529212298509354\n",
      "previous_iter_valid_loss : 0.17605523765087128\n",
      "\n",
      "     21000\t  0.176139\t  0.176055\t  0.176055\t\tCURRENT LEARNING RATE: 0.4044823487832499\n",
      "previous_iter_valid_loss : 0.1733189821243286\n",
      "\n",
      "     21200\t  0.173436\t  0.173319\t  0.173319\t\tCURRENT LEARNING RATE: 0.40367419251134073\n",
      "previous_iter_valid_loss : 0.16549068689346313\n",
      "\n",
      "     21400\t  0.165625\t  0.165491\t  0.165491\t\tCURRENT LEARNING RATE: 0.4028676509367398\n",
      "previous_iter_valid_loss : 0.165224090218544\n",
      "\n",
      "     21600\t  0.165427\t  0.165224\t  0.165224\t\tCURRENT LEARNING RATE: 0.4020627208332798\n",
      "previous_iter_valid_loss : 0.16579900681972504\n",
      "\n",
      "     21800\t  0.165909\t  0.165799\t  0.165799\t\tCURRENT LEARNING RATE: 0.40125939898123925\n",
      "previous_iter_valid_loss : 0.17142868041992188\n",
      "\n",
      "     22000\t  0.171595\t  0.171429\t  0.171429\t\tCURRENT LEARNING RATE: 0.4004576821673296\n",
      "previous_iter_valid_loss : 0.17190897464752197\n",
      "\n",
      "     22200\t  0.171996\t  0.171909\t  0.171909\t\tCURRENT LEARNING RATE: 0.39965756718468254\n",
      "previous_iter_valid_loss : 0.1651468724012375\n",
      "\n",
      "     22400\t  0.165294\t  0.165147\t  0.165147\t\tCURRENT LEARNING RATE: 0.3988590508328371\n",
      "previous_iter_valid_loss : 0.16496184468269348\n",
      "\n",
      "     22600\t  0.165005\t  0.164962\t  0.164962\t\tCURRENT LEARNING RATE: 0.3980621299177269\n",
      "previous_iter_valid_loss : 0.16649669408798218\n",
      "\n",
      "     22800\t  0.166720\t  0.166497\t  0.166497\t\tCURRENT LEARNING RATE: 0.397266801251667\n",
      "previous_iter_valid_loss : 0.16876649856567383\n",
      "\n",
      "     23000\t  0.168984\t  0.168766\t  0.168766\t\tCURRENT LEARNING RATE: 0.39647306165334184\n",
      "previous_iter_valid_loss : 0.17556455731391907\n",
      "\n",
      "     23200\t  0.175816\t  0.175565\t  0.175565\t\tCURRENT LEARNING RATE: 0.3956809079477919\n",
      "previous_iter_valid_loss : 0.19370143115520477\n",
      "\n",
      "     23400\t  0.194072\t  0.193701\t  0.193701\t\tCURRENT LEARNING RATE: 0.39489033696640136\n",
      "previous_iter_valid_loss : 0.17406144738197327\n",
      "\n",
      "     23600\t  0.174381\t  0.174061\t  0.174061\t\tCURRENT LEARNING RATE: 0.3941013455468852\n",
      "previous_iter_valid_loss : 0.17274685204029083\n",
      "\n",
      "     23800\t  0.172950\t  0.172747\t  0.172747\t\tCURRENT LEARNING RATE: 0.39331393053327673\n",
      "previous_iter_valid_loss : 0.17239752411842346\n",
      "\n",
      "     24000\t  0.172564\t  0.172398\t  0.172398\t\tCURRENT LEARNING RATE: 0.3925280887759148\n",
      "previous_iter_valid_loss : 0.16901923716068268\n",
      "\n",
      "     24200\t  0.169243\t  0.169019\t  0.169019\t\tCURRENT LEARNING RATE: 0.39174381713143125\n",
      "previous_iter_valid_loss : 0.1722026914358139\n",
      "\n",
      "     24400\t  0.172478\t  0.172203\t  0.172203\t\tCURRENT LEARNING RATE: 0.3909611124627386\n",
      "previous_iter_valid_loss : 0.1895473599433899\n",
      "\n",
      "     24600\t  0.189853\t  0.189547\t  0.189547\t\tCURRENT LEARNING RATE: 0.39017997163901713\n",
      "previous_iter_valid_loss : 0.17441369593143463\n",
      "\n",
      "     24800\t  0.174487\t  0.174414\t  0.174414\t\tCURRENT LEARNING RATE: 0.38940039153570244\n",
      "previous_iter_valid_loss : 0.17625480890274048\n",
      "\n",
      "     25000\t  0.176296\t  0.176255\t  0.176255\t\tCURRENT LEARNING RATE: 0.38862236903447306\n",
      "previous_iter_valid_loss : 0.17792126536369324\n",
      "\n",
      "     25200\t  0.177994\t  0.177921\t  0.177921\t\tCURRENT LEARNING RATE: 0.387845901023238\n",
      "previous_iter_valid_loss : 0.18227353692054749\n",
      "\n",
      "     25400\t  0.182508\t  0.182274\t  0.182274\t\tCURRENT LEARNING RATE: 0.3870709843961242\n",
      "previous_iter_valid_loss : 0.17274397611618042\n",
      "\n",
      "     25600\t  0.172848\t  0.172744\t  0.172744\t\tCURRENT LEARNING RATE: 0.386297616053464\n",
      "previous_iter_valid_loss : 0.17117774486541748\n",
      "\n",
      "     25800\t  0.171336\t  0.171178\t  0.171178\t\tCURRENT LEARNING RATE: 0.3855257929017831\n",
      "previous_iter_valid_loss : 0.17340326309204102\n",
      "\n",
      "     26000\t  0.173640\t  0.173403\t  0.173403\t\tCURRENT LEARNING RATE: 0.3847555118537879\n",
      "previous_iter_valid_loss : 0.1720987856388092\n",
      "\n",
      "     26200\t  0.172329\t  0.172099\t  0.172099\t\tCURRENT LEARNING RATE: 0.38398676982835306\n",
      "previous_iter_valid_loss : 0.16791878640651703\n",
      "\n",
      "     26400\t  0.168082\t  0.167919\t  0.167919\t\tCURRENT LEARNING RATE: 0.3832195637505096\n",
      "previous_iter_valid_loss : 0.1855320930480957\n",
      "\n",
      "     26600\t  0.185673\t  0.185532\t  0.185532\t\tCURRENT LEARNING RATE: 0.382453890551432\n",
      "previous_iter_valid_loss : 0.17818157374858856\n",
      "\n",
      "     26800\t  0.178252\t  0.178182\t  0.178182\t\tCURRENT LEARNING RATE: 0.3816897471684266\n",
      "previous_iter_valid_loss : 0.174829363822937\n",
      "\n",
      "     27000\t  0.174928\t  0.174829\t  0.174829\t\tCURRENT LEARNING RATE: 0.3809271305449188\n",
      "previous_iter_valid_loss : 0.17565381526947021\n",
      "\n",
      "     27200\t  0.175835\t  0.175654\t  0.175654\t\tCURRENT LEARNING RATE: 0.38016603763044104\n",
      "previous_iter_valid_loss : 0.17445671558380127\n",
      "\n",
      "     27400\t  0.174599\t  0.174457\t  0.174457\t\tCURRENT LEARNING RATE: 0.37940646538062067\n",
      "previous_iter_valid_loss : 0.1760406792163849\n",
      "\n",
      "     27600\t  0.176101\t  0.176041\t  0.176041\t\tCURRENT LEARNING RATE: 0.37864841075716776\n",
      "previous_iter_valid_loss : 0.17965668439865112\n",
      "\n",
      "     27800\t  0.179761\t  0.179657\t  0.179657\t\tCURRENT LEARNING RATE: 0.37789187072786273\n",
      "previous_iter_valid_loss : 0.1764509528875351\n",
      "\n",
      "     28000\t  0.176542\t  0.176451\t  0.176451\t\tCURRENT LEARNING RATE: 0.3771368422665445\n",
      "previous_iter_valid_loss : 0.1739293336868286\n",
      "\n",
      "     28200\t  0.174115\t  0.173929\t  0.173929\t\tCURRENT LEARNING RATE: 0.3763833223530981\n",
      "previous_iter_valid_loss : 0.17476493120193481\n",
      "\n",
      "     28400\t  0.174794\t  0.174765\t  0.174765\t\tCURRENT LEARNING RATE: 0.375631307973443\n",
      "previous_iter_valid_loss : 0.19267284870147705\n",
      "\n",
      "     28600\t  0.192700\t  0.192673\t  0.192673\t\tCURRENT LEARNING RATE: 0.37488079611952063\n",
      "previous_iter_valid_loss : 0.17615991830825806\n",
      "\n",
      "     28800\t  0.176377\t  0.176160\t  0.176160\t\tCURRENT LEARNING RATE: 0.37413178378928263\n",
      "previous_iter_valid_loss : 0.17174306511878967\n",
      "\n",
      "     29000\t  0.171847\t  0.171743\t  0.171743\t\tCURRENT LEARNING RATE: 0.37338426798667856\n",
      "previous_iter_valid_loss : 0.16575592756271362\n",
      "\n",
      "     29200\t  0.165802\t  0.165756\t  0.165756\t\tCURRENT LEARNING RATE: 0.37263824572164433\n",
      "previous_iter_valid_loss : 0.17400361597537994\n",
      "\n",
      "     29400\t  0.174216\t  0.174004\t  0.174004\t\tCURRENT LEARNING RATE: 0.3718937140100898\n",
      "previous_iter_valid_loss : 0.16898265480995178\n",
      "\n",
      "     29600\t  0.169152\t  0.168983\t  0.168983\t\tCURRENT LEARNING RATE: 0.3711506698738872\n",
      "previous_iter_valid_loss : 0.16578543186187744\n",
      "\n",
      "     29800\t  0.166008\t  0.165785\t  0.165785\t\tCURRENT LEARNING RATE: 0.37040911034085894\n",
      "previous_iter_valid_loss : 0.16688556969165802\n",
      "\n",
      "     30000\t  0.166915\t  0.166886\t  0.166886\t\tCURRENT LEARNING RATE: 0.36966903244476595\n",
      "previous_iter_valid_loss : 0.1683308482170105\n",
      "\n",
      "     30200\t  0.168321\t  0.168331\t  0.168331\t\tCURRENT LEARNING RATE: 0.36893043322529556\n",
      "previous_iter_valid_loss : 0.18650060892105103\n",
      "\n",
      "     30400\t  0.186607\t  0.186501\t  0.186501\t\tCURRENT LEARNING RATE: 0.36819330972805003\n",
      "previous_iter_valid_loss : 0.1748056858778\n",
      "\n",
      "     30600\t  0.174831\t  0.174806\t  0.174806\t\tCURRENT LEARNING RATE: 0.36745765900453436\n",
      "previous_iter_valid_loss : 0.16567055881023407\n",
      "\n",
      "     30800\t  0.165671\t  0.165671\t  0.165671\t\tCURRENT LEARNING RATE: 0.3667234781121446\n",
      "previous_iter_valid_loss : 0.1777692437171936\n",
      "\n",
      "     31000\t  0.177652\t  0.177769\t  0.177769\t\tCURRENT LEARNING RATE: 0.3659907641141563\n",
      "previous_iter_valid_loss : 0.16585546731948853\n",
      "\n",
      "     31200\t  0.165860\t  0.165855\t  0.165855\t\tCURRENT LEARNING RATE: 0.36525951407971247\n",
      "previous_iter_valid_loss : 0.1749654859304428\n",
      "\n",
      "     31400\t  0.175173\t  0.174965\t  0.174965\t\tCURRENT LEARNING RATE: 0.3645297250838119\n",
      "previous_iter_valid_loss : 0.18069452047348022\n",
      "\n",
      "     31600\t  0.180859\t  0.180695\t  0.180695\t\tCURRENT LEARNING RATE: 0.36380139420729773\n",
      "previous_iter_valid_loss : 0.1645471304655075\n",
      "\n",
      "     31800\t  0.164514\t  0.164547\t  0.164547\t\tCURRENT LEARNING RATE: 0.36307451853684547\n",
      "previous_iter_valid_loss : 0.17336629331111908\n",
      "\n",
      "     32000\t  0.173430\t  0.173366\t  0.173366\t\tCURRENT LEARNING RATE: 0.36234909516495145\n",
      "previous_iter_valid_loss : 0.16724424064159393\n",
      "\n",
      "     32200\t  0.167199\t  0.167244\t  0.167244\t\tCURRENT LEARNING RATE: 0.3616251211899212\n",
      "previous_iter_valid_loss : 0.17201510071754456\n",
      "\n",
      "     32400\t  0.172134\t  0.172015\t  0.172015\t\tCURRENT LEARNING RATE: 0.3609025937158579\n",
      "previous_iter_valid_loss : 0.16417977213859558\n",
      "\n",
      "     32600\t  0.164269\t  0.164180\t  0.164180\t\tCURRENT LEARNING RATE: 0.3601815098526507\n",
      "previous_iter_valid_loss : 0.1691184639930725\n",
      "\n",
      "     32800\t  0.169240\t  0.169118\t  0.169118\t\tCURRENT LEARNING RATE: 0.3594618667159631\n",
      "previous_iter_valid_loss : 0.1737615168094635\n",
      "\n",
      "     33000\t  0.173883\t  0.173762\t  0.173762\t\tCURRENT LEARNING RATE: 0.35874366142722164\n",
      "previous_iter_valid_loss : 0.17507153749465942\n",
      "\n",
      "     33200\t  0.175221\t  0.175072\t  0.175072\t\tCURRENT LEARNING RATE: 0.35802689111360425\n",
      "previous_iter_valid_loss : 0.17291727662086487\n",
      "\n",
      "     33400\t  0.173014\t  0.172917\t  0.172917\t\tCURRENT LEARNING RATE: 0.35731155290802863\n",
      "previous_iter_valid_loss : 0.16607898473739624\n",
      "\n",
      "     33600\t  0.166142\t  0.166079\t  0.166079\t\tCURRENT LEARNING RATE: 0.3565976439491411\n",
      "previous_iter_valid_loss : 0.16876113414764404\n",
      "\n",
      "     33800\t  0.168894\t  0.168761\t  0.168761\t\tCURRENT LEARNING RATE: 0.3558851613813048\n",
      "previous_iter_valid_loss : 0.1742030829191208\n",
      "\n",
      "     34000\t  0.174406\t  0.174203\t  0.174203\t\tCURRENT LEARNING RATE: 0.35517410235458863\n",
      "previous_iter_valid_loss : 0.16685019433498383\n",
      "\n",
      "     34200\t  0.167054\t  0.166850\t  0.166850\t\tCURRENT LEARNING RATE: 0.3544644640247554\n",
      "previous_iter_valid_loss : 0.17227855324745178\n",
      "\n",
      "     34400\t  0.172417\t  0.172279\t  0.172279\t\tCURRENT LEARNING RATE: 0.35375624355325086\n",
      "previous_iter_valid_loss : 0.1705026477575302\n",
      "\n",
      "     34600\t  0.170592\t  0.170503\t  0.170503\t\tCURRENT LEARNING RATE: 0.3530494381071922\n",
      "previous_iter_valid_loss : 0.16611313819885254\n",
      "\n",
      "     34800\t  0.166465\t  0.166113\t  0.166113\t\tCURRENT LEARNING RATE: 0.3523440448593567\n",
      "previous_iter_valid_loss : 0.16582506895065308\n",
      "\n",
      "     35000\t  0.166111\t  0.165825\t  0.165825\t\tCURRENT LEARNING RATE: 0.35164006098817047\n",
      "previous_iter_valid_loss : 0.17162327468395233\n",
      "\n",
      "     35200\t  0.172016\t  0.171623\t  0.171623\t\tCURRENT LEARNING RATE: 0.350937483677697\n",
      "previous_iter_valid_loss : 0.16436141729354858\n",
      "\n",
      "     35400\t  0.164692\t  0.164361\t  0.164361\t\tCURRENT LEARNING RATE: 0.3502363101176262\n",
      "previous_iter_valid_loss : 0.16683132946491241\n",
      "\n",
      "     35600\t  0.167029\t  0.166831\t  0.166831\t\tCURRENT LEARNING RATE: 0.34953653750326286\n",
      "previous_iter_valid_loss : 0.17285415530204773\n",
      "\n",
      "     35800\t  0.173220\t  0.172854\t  0.172854\t\tCURRENT LEARNING RATE: 0.3488381630355155\n",
      "previous_iter_valid_loss : 0.16425442695617676\n",
      "\n",
      "     36000\t  0.164361\t  0.164254\t  0.164254\t\tCURRENT LEARNING RATE: 0.3481411839208855\n",
      "previous_iter_valid_loss : 0.16624529659748077\n",
      "\n",
      "     36200\t  0.166406\t  0.166245\t  0.166245\t\tCURRENT LEARNING RATE: 0.3474455973714553\n",
      "previous_iter_valid_loss : 0.1657441109418869\n",
      "\n",
      "     36400\t  0.165989\t  0.165744\t  0.165744\t\tCURRENT LEARNING RATE: 0.3467514006048779\n",
      "previous_iter_valid_loss : 0.1730290800333023\n",
      "\n",
      "     36600\t  0.173340\t  0.173029\t  0.173029\t\tCURRENT LEARNING RATE: 0.3460585908443652\n",
      "previous_iter_valid_loss : 0.16447043418884277\n",
      "\n",
      "     36800\t  0.164624\t  0.164470\t  0.164470\t\tCURRENT LEARNING RATE: 0.34536716531867734\n",
      "previous_iter_valid_loss : 0.16575662791728973\n",
      "\n",
      "     37000\t  0.166000\t  0.165757\t  0.165757\t\tCURRENT LEARNING RATE: 0.3446771212621112\n",
      "previous_iter_valid_loss : 0.1804250031709671\n",
      "\n",
      "     37200\t  0.180636\t  0.180425\t  0.180425\t\tCURRENT LEARNING RATE: 0.34398845591448973\n",
      "previous_iter_valid_loss : 0.16619350016117096\n",
      "\n",
      "     37400\t  0.166223\t  0.166194\t  0.166194\t\tCURRENT LEARNING RATE: 0.3433011665211505\n",
      "previous_iter_valid_loss : 0.16455991566181183\n",
      "\n",
      "     37600\t  0.164613\t  0.164560\t  0.164560\t\tCURRENT LEARNING RATE: 0.34261525033293516\n",
      "previous_iter_valid_loss : 0.16330699622631073\n",
      "\n",
      "\n",
      "Current valid loss: 0.16330699622631073;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "     37800\t  0.163485\t  0.163307\t  0.163307\t\tCURRENT LEARNING RATE: 0.3419307046061779\n",
      "previous_iter_valid_loss : 0.17093801498413086\n",
      "\n",
      "     38000\t  0.171006\t  0.170938\t  0.170938\t\tCURRENT LEARNING RATE: 0.34124752660269503\n",
      "previous_iter_valid_loss : 0.16444621980190277\n",
      "\n",
      "     38200\t  0.164589\t  0.164446\t  0.164446\t\tCURRENT LEARNING RATE: 0.34056571358977356\n",
      "previous_iter_valid_loss : 0.16368073225021362\n",
      "\n",
      "     38400\t  0.163786\t  0.163681\t  0.163681\t\tCURRENT LEARNING RATE: 0.3398852628401605\n",
      "previous_iter_valid_loss : 0.16997388005256653\n",
      "\n",
      "     38600\t  0.170119\t  0.169974\t  0.169974\t\tCURRENT LEARNING RATE: 0.339206171632052\n",
      "previous_iter_valid_loss : 0.1662924438714981\n",
      "\n",
      "     38800\t  0.166559\t  0.166292\t  0.166292\t\tCURRENT LEARNING RATE: 0.3385284372490823\n",
      "previous_iter_valid_loss : 0.16391712427139282\n",
      "\n",
      "     39000\t  0.164069\t  0.163917\t  0.163917\t\tCURRENT LEARNING RATE: 0.337852056980313\n",
      "previous_iter_valid_loss : 0.16561083495616913\n",
      "\n",
      "     39200\t  0.165808\t  0.165611\t  0.165611\t\tCURRENT LEARNING RATE: 0.3371770281202221\n",
      "previous_iter_valid_loss : 0.16537438333034515\n",
      "\n",
      "     39400\t  0.165498\t  0.165374\t  0.165374\t\tCURRENT LEARNING RATE: 0.3365033479686932\n",
      "previous_iter_valid_loss : 0.16482190787792206\n",
      "\n",
      "     39600\t  0.164899\t  0.164822\t  0.164822\t\tCURRENT LEARNING RATE: 0.3358310138310049\n",
      "previous_iter_valid_loss : 0.16875456273555756\n",
      "\n",
      "     39800\t  0.168930\t  0.168755\t  0.171638\t\tCURRENT LEARNING RATE: 0.33516002301781966\n",
      "previous_iter_valid_loss : 0.16438814997673035\n",
      "\n",
      "     40000\t  0.164475\t  0.164388\t  0.170736\t\tCURRENT LEARNING RATE: 0.33449037284517336\n",
      "previous_iter_valid_loss : 0.1629648506641388\n",
      "\n",
      "\n",
      "Current valid loss: 0.1629648506641388;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "     40200\t  0.163039\t  0.162965\t  0.170671\t\tCURRENT LEARNING RATE: 0.33382206063446446\n",
      "previous_iter_valid_loss : 0.16280430555343628\n",
      "\n",
      "\n",
      "Current valid loss: 0.16280430555343628;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "     40400\t  0.162997\t  0.162804\t  0.170517\t\tCURRENT LEARNING RATE: 0.3331550837124432\n",
      "previous_iter_valid_loss : 0.17428478598594666\n",
      "\n",
      "     40600\t  0.174384\t  0.174285\t  0.170503\t\tCURRENT LEARNING RATE: 0.33248943941120096\n",
      "previous_iter_valid_loss : 0.1638869047164917\n",
      "\n",
      "     40800\t  0.164019\t  0.163887\t  0.170438\t\tCURRENT LEARNING RATE: 0.3318251250681597\n",
      "previous_iter_valid_loss : 0.1640591025352478\n",
      "\n",
      "     41000\t  0.164146\t  0.164059\t  0.170402\t\tCURRENT LEARNING RATE: 0.33116213802606115\n",
      "previous_iter_valid_loss : 0.163298100233078\n",
      "\n",
      "     41200\t  0.163480\t  0.163298\t  0.170361\t\tCURRENT LEARNING RATE: 0.33050047563295626\n",
      "previous_iter_valid_loss : 0.1655752807855606\n",
      "\n",
      "     41400\t  0.165723\t  0.165575\t  0.170319\t\tCURRENT LEARNING RATE: 0.3298401352421945\n",
      "previous_iter_valid_loss : 0.16484583914279938\n",
      "\n",
      "     41600\t  0.164942\t  0.164846\t  0.170299\t\tCURRENT LEARNING RATE: 0.3291811142124136\n",
      "previous_iter_valid_loss : 0.1692795306444168\n",
      "\n",
      "     41800\t  0.169336\t  0.169280\t  0.170293\t\tCURRENT LEARNING RATE: 0.3285234099075284\n",
      "previous_iter_valid_loss : 0.1661115437746048\n",
      "\n",
      "     42000\t  0.166236\t  0.166112\t  0.170272\t\tCURRENT LEARNING RATE: 0.3278670196967209\n",
      "previous_iter_valid_loss : 0.16376034915447235\n",
      "\n",
      "     42200\t  0.163920\t  0.163760\t  0.170229\t\tCURRENT LEARNING RATE: 0.3272119409544293\n",
      "previous_iter_valid_loss : 0.16727472841739655\n",
      "\n",
      "     42400\t  0.167444\t  0.167275\t  0.170220\t\tCURRENT LEARNING RATE: 0.3265581710603378\n",
      "previous_iter_valid_loss : 0.16311386227607727\n",
      "\n",
      "     42600\t  0.163222\t  0.163114\t  0.170169\t\tCURRENT LEARNING RATE: 0.325905707399366\n",
      "previous_iter_valid_loss : 0.16310907900333405\n",
      "\n",
      "     42800\t  0.163298\t  0.163109\t  0.170148\t\tCURRENT LEARNING RATE: 0.32525454736165826\n",
      "previous_iter_valid_loss : 0.1697595715522766\n",
      "\n",
      "     43000\t  0.169978\t  0.169760\t  0.170124\t\tCURRENT LEARNING RATE: 0.3246046883425737\n",
      "previous_iter_valid_loss : 0.16600759327411652\n",
      "\n",
      "     43200\t  0.166143\t  0.166008\t  0.170094\t\tCURRENT LEARNING RATE: 0.3239561277426753\n",
      "previous_iter_valid_loss : 0.16468918323516846\n",
      "\n",
      "     43400\t  0.164873\t  0.164689\t  0.170051\t\tCURRENT LEARNING RATE: 0.3233088629677198\n",
      "previous_iter_valid_loss : 0.1648971140384674\n",
      "\n",
      "     43600\t  0.165062\t  0.164897\t  0.170018\t\tCURRENT LEARNING RATE: 0.3226628914286473\n",
      "previous_iter_valid_loss : 0.17312367260456085\n",
      "\n",
      "     43800\t  0.173377\t  0.173124\t  0.169986\t\tCURRENT LEARNING RATE: 0.3220182105415707\n",
      "previous_iter_valid_loss : 0.163072869181633\n",
      "\n",
      "     44000\t  0.163240\t  0.163073\t  0.169948\t\tCURRENT LEARNING RATE: 0.3213748177277656\n",
      "previous_iter_valid_loss : 0.16307300329208374\n",
      "\n",
      "     44200\t  0.163177\t  0.163073\t  0.169894\t\tCURRENT LEARNING RATE: 0.3207327104136599\n",
      "previous_iter_valid_loss : 0.1733551323413849\n",
      "\n",
      "     44400\t  0.173598\t  0.173355\t  0.169912\t\tCURRENT LEARNING RATE: 0.32009188603082356\n",
      "previous_iter_valid_loss : 0.16355808079242706\n",
      "\n",
      "     44600\t  0.163772\t  0.163558\t  0.169898\t\tCURRENT LEARNING RATE: 0.3194523420159581\n",
      "previous_iter_valid_loss : 0.16286958754062653\n",
      "\n",
      "     44800\t  0.163107\t  0.162870\t  0.169838\t\tCURRENT LEARNING RATE: 0.31881407581088667\n",
      "previous_iter_valid_loss : 0.1688571274280548\n",
      "\n",
      "     45000\t  0.169023\t  0.168857\t  0.169827\t\tCURRENT LEARNING RATE: 0.31817708486254354\n",
      "previous_iter_valid_loss : 0.16352462768554688\n",
      "\n",
      "     45200\t  0.163686\t  0.163525\t  0.169774\t\tCURRENT LEARNING RATE: 0.31754136662296406\n",
      "previous_iter_valid_loss : 0.16442008316516876\n",
      "\n",
      "     45400\t  0.164478\t  0.164420\t  0.169756\t\tCURRENT LEARNING RATE: 0.3169069185492745\n",
      "previous_iter_valid_loss : 0.1645660251379013\n",
      "\n",
      "     45600\t  0.164703\t  0.164566\t  0.169734\t\tCURRENT LEARNING RATE: 0.3162737381036817\n",
      "previous_iter_valid_loss : 0.16538390517234802\n",
      "\n",
      "     45800\t  0.165533\t  0.165384\t  0.169709\t\tCURRENT LEARNING RATE: 0.315641822753463\n",
      "previous_iter_valid_loss : 0.1832072138786316\n",
      "\n",
      "     46000\t  0.183375\t  0.183207\t  0.169766\t\tCURRENT LEARNING RATE: 0.31501116997095613\n",
      "previous_iter_valid_loss : 0.16577354073524475\n",
      "\n",
      "     46200\t  0.165975\t  0.165774\t  0.169726\t\tCURRENT LEARNING RATE: 0.3143817772335492\n",
      "previous_iter_valid_loss : 0.16301719844341278\n",
      "\n",
      "     46400\t  0.163084\t  0.163017\t  0.169687\t\tCURRENT LEARNING RATE: 0.31375364202367034\n",
      "previous_iter_valid_loss : 0.16511276364326477\n",
      "\n",
      "     46600\t  0.165243\t  0.165113\t  0.169636\t\tCURRENT LEARNING RATE: 0.31312676182877797\n",
      "previous_iter_valid_loss : 0.16414831578731537\n",
      "\n",
      "     46800\t  0.164249\t  0.164148\t  0.169630\t\tCURRENT LEARNING RATE: 0.3125011341413504\n",
      "previous_iter_valid_loss : 0.1628260463476181\n",
      "\n",
      "     47000\t  0.162921\t  0.162826\t  0.169545\t\tCURRENT LEARNING RATE: 0.3118767564588761\n",
      "previous_iter_valid_loss : 0.1642487645149231\n",
      "\n",
      "     47200\t  0.164321\t  0.164249\t  0.169543\t\tCURRENT LEARNING RATE: 0.3112536262838434\n",
      "previous_iter_valid_loss : 0.16418105363845825\n",
      "\n",
      "     47400\t  0.164338\t  0.164181\t  0.169441\t\tCURRENT LEARNING RATE: 0.3106317411237309\n",
      "previous_iter_valid_loss : 0.16316722333431244\n",
      "\n",
      "     47600\t  0.163282\t  0.163167\t  0.169426\t\tCURRENT LEARNING RATE: 0.310011098490997\n",
      "previous_iter_valid_loss : 0.1692003309726715\n",
      "\n",
      "     47800\t  0.169350\t  0.169200\t  0.169402\t\tCURRENT LEARNING RATE: 0.3093916959030704\n",
      "previous_iter_valid_loss : 0.16520504653453827\n",
      "\n",
      "     48000\t  0.165357\t  0.165205\t  0.169348\t\tCURRENT LEARNING RATE: 0.30877353088234\n",
      "previous_iter_valid_loss : 0.1638718545436859\n",
      "\n",
      "     48200\t  0.164069\t  0.163872\t  0.169241\t\tCURRENT LEARNING RATE: 0.30815660095614483\n",
      "previous_iter_valid_loss : 0.16362594068050385\n",
      "\n",
      "     48400\t  0.163746\t  0.163626\t  0.169230\t\tCURRENT LEARNING RATE: 0.30754090365676434\n",
      "previous_iter_valid_loss : 0.17304305732250214\n",
      "\n",
      "     48600\t  0.173131\t  0.173043\t  0.169262\t\tCURRENT LEARNING RATE: 0.30692643652140855\n",
      "previous_iter_valid_loss : 0.16370068490505219\n",
      "\n",
      "     48800\t  0.163845\t  0.163701\t  0.169237\t\tCURRENT LEARNING RATE: 0.30631319709220806\n",
      "previous_iter_valid_loss : 0.16512678563594818\n",
      "\n",
      "     49000\t  0.165285\t  0.165127\t  0.169226\t\tCURRENT LEARNING RATE: 0.30570118291620435\n",
      "previous_iter_valid_loss : 0.16347196698188782\n",
      "\n",
      "     49200\t  0.163540\t  0.163472\t  0.169220\t\tCURRENT LEARNING RATE: 0.3050903915453399\n",
      "previous_iter_valid_loss : 0.16478762030601501\n",
      "\n",
      "     49400\t  0.164882\t  0.164788\t  0.169215\t\tCURRENT LEARNING RATE: 0.3044808205364484\n",
      "previous_iter_valid_loss : 0.1630302369594574\n",
      "\n",
      "     49600\t  0.163086\t  0.163030\t  0.169195\t\tCURRENT LEARNING RATE: 0.3038724674512451\n",
      "previous_iter_valid_loss : 0.1672133505344391\n",
      "\n",
      "     49800\t  0.167280\t  0.167213\t  0.169185\t\tCURRENT LEARNING RATE: 0.3032653298563167\n",
      "previous_iter_valid_loss : 0.16701090335845947\n",
      "\n",
      "     50000\t  0.167101\t  0.167011\t  0.169170\t\tCURRENT LEARNING RATE: 0.30265940532311214\n",
      "previous_iter_valid_loss : 0.16516686975955963\n",
      "\n",
      "     50200\t  0.165266\t  0.165167\t  0.169172\t\tCURRENT LEARNING RATE: 0.30205469142793234\n",
      "previous_iter_valid_loss : 0.16300556063652039\n",
      "\n",
      "     50400\t  0.163106\t  0.163006\t  0.169151\t\tCURRENT LEARNING RATE: 0.30145118575192104\n",
      "previous_iter_valid_loss : 0.1620464324951172\n",
      "\n",
      "\n",
      "Current valid loss: 0.1620464324951172;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "     50600\t  0.162181\t  0.162046\t  0.169125\t\tCURRENT LEARNING RATE: 0.3008488858810547\n",
      "previous_iter_valid_loss : 0.16688750684261322\n",
      "\n",
      "     50800\t  0.167082\t  0.166888\t  0.169135\t\tCURRENT LEARNING RATE: 0.30024778940613295\n",
      "previous_iter_valid_loss : 0.1627301424741745\n",
      "\n",
      "     51000\t  0.162932\t  0.162730\t  0.169097\t\tCURRENT LEARNING RATE: 0.2996478939227692\n",
      "previous_iter_valid_loss : 0.16297462582588196\n",
      "\n",
      "     51200\t  0.163153\t  0.162975\t  0.169074\t\tCURRENT LEARNING RATE: 0.29904919703138066\n",
      "previous_iter_valid_loss : 0.16242599487304688\n",
      "\n",
      "     51400\t  0.162588\t  0.162426\t  0.169054\t\tCURRENT LEARNING RATE: 0.298451696337179\n",
      "previous_iter_valid_loss : 0.16346214711666107\n",
      "\n",
      "     51600\t  0.163713\t  0.163462\t  0.168978\t\tCURRENT LEARNING RATE: 0.2978553894501606\n",
      "previous_iter_valid_loss : 0.17260105907917023\n",
      "\n",
      "     51800\t  0.172722\t  0.172601\t  0.168950\t\tCURRENT LEARNING RATE: 0.2972602739850972\n",
      "previous_iter_valid_loss : 0.16504649817943573\n",
      "\n",
      "     52000\t  0.165147\t  0.165046\t  0.168933\t\tCURRENT LEARNING RATE: 0.296666347561526\n",
      "previous_iter_valid_loss : 0.1645069718360901\n",
      "\n",
      "     52200\t  0.164696\t  0.164507\t  0.168929\t\tCURRENT LEARNING RATE: 0.29607360780374065\n",
      "previous_iter_valid_loss : 0.16558893024921417\n",
      "\n",
      "     52400\t  0.165778\t  0.165589\t  0.168920\t\tCURRENT LEARNING RATE: 0.2954820523407813\n",
      "previous_iter_valid_loss : 0.16306430101394653\n",
      "\n",
      "     52600\t  0.163193\t  0.163064\t  0.168886\t\tCURRENT LEARNING RATE: 0.2948916788064252\n",
      "previous_iter_valid_loss : 0.16430407762527466\n",
      "\n",
      "     52800\t  0.164430\t  0.164304\t  0.168870\t\tCURRENT LEARNING RATE: 0.2943024848391776\n",
      "previous_iter_valid_loss : 0.16630317270755768\n",
      "\n",
      "     53000\t  0.166557\t  0.166303\t  0.168848\t\tCURRENT LEARNING RATE: 0.2937144680822617\n",
      "previous_iter_valid_loss : 0.1659117192029953\n",
      "\n",
      "     53200\t  0.166169\t  0.165912\t  0.168825\t\tCURRENT LEARNING RATE: 0.2931276261836098\n",
      "previous_iter_valid_loss : 0.16369794309139252\n",
      "\n",
      "     53400\t  0.163802\t  0.163698\t  0.168802\t\tCURRENT LEARNING RATE: 0.29254195679585343\n",
      "previous_iter_valid_loss : 0.16313065588474274\n",
      "\n",
      "     53600\t  0.163262\t  0.163131\t  0.168765\t\tCURRENT LEARNING RATE: 0.29195745757631436\n",
      "previous_iter_valid_loss : 0.1651071310043335\n",
      "\n",
      "     53800\t  0.165227\t  0.165107\t  0.168742\t\tCURRENT LEARNING RATE: 0.2913741261869948\n",
      "previous_iter_valid_loss : 0.16291439533233643\n",
      "\n",
      "     54000\t  0.163051\t  0.162914\t  0.168729\t\tCURRENT LEARNING RATE: 0.29079196029456855\n",
      "previous_iter_valid_loss : 0.1635572761297226\n",
      "\n",
      "     54200\t  0.163711\t  0.163557\t  0.168692\t\tCURRENT LEARNING RATE: 0.2902109575703712\n",
      "previous_iter_valid_loss : 0.16997049748897552\n",
      "\n",
      "     54400\t  0.170214\t  0.169970\t  0.168719\t\tCURRENT LEARNING RATE: 0.289631115690391\n",
      "previous_iter_valid_loss : 0.1631082147359848\n",
      "\n",
      "     54600\t  0.163266\t  0.163108\t  0.168716\t\tCURRENT LEARNING RATE: 0.2890524323352598\n",
      "previous_iter_valid_loss : 0.16451506316661835\n",
      "\n",
      "     54800\t  0.164594\t  0.164515\t  0.168719\t\tCURRENT LEARNING RATE: 0.2884749051902433\n",
      "previous_iter_valid_loss : 0.1626279205083847\n",
      "\n",
      "     55000\t  0.162745\t  0.162628\t  0.168691\t\tCURRENT LEARNING RATE: 0.28789853194523224\n",
      "previous_iter_valid_loss : 0.16204100847244263\n",
      "\n",
      "\n",
      "Current valid loss: 0.16204100847244263;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "     55200\t  0.162161\t  0.162041\t  0.168661\t\tCURRENT LEARNING RATE: 0.28732331029473285\n",
      "previous_iter_valid_loss : 0.16338256001472473\n",
      "\n",
      "     55400\t  0.163517\t  0.163383\t  0.168657\t\tCURRENT LEARNING RATE: 0.28674923793785767\n",
      "previous_iter_valid_loss : 0.16234470903873444\n",
      "\n",
      "     55600\t  0.162421\t  0.162345\t  0.168637\t\tCURRENT LEARNING RATE: 0.2861763125783166\n",
      "previous_iter_valid_loss : 0.16780871152877808\n",
      "\n",
      "     55800\t  0.167990\t  0.167809\t  0.168652\t\tCURRENT LEARNING RATE: 0.28560453192440743\n",
      "previous_iter_valid_loss : 0.16209624707698822\n",
      "\n",
      "     56000\t  0.162268\t  0.162096\t  0.168619\t\tCURRENT LEARNING RATE: 0.2850338936890067\n",
      "previous_iter_valid_loss : 0.1628962904214859\n",
      "\n",
      "     56200\t  0.163066\t  0.162896\t  0.168586\t\tCURRENT LEARNING RATE: 0.2844643955895609\n",
      "previous_iter_valid_loss : 0.1630626618862152\n",
      "\n",
      "     56400\t  0.163241\t  0.163063\t  0.168578\t\tCURRENT LEARNING RATE: 0.28389603534807667\n",
      "previous_iter_valid_loss : 0.16338811814785004\n",
      "\n",
      "     56600\t  0.163549\t  0.163388\t  0.168532\t\tCURRENT LEARNING RATE: 0.2833288106911123\n",
      "previous_iter_valid_loss : 0.1617761254310608\n",
      "\n",
      "\n",
      "Current valid loss: 0.1617761254310608;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "     56800\t  0.161928\t  0.161776\t  0.168483\t\tCURRENT LEARNING RATE: 0.28276271934976854\n",
      "previous_iter_valid_loss : 0.16599467396736145\n",
      "\n",
      "     57000\t  0.166207\t  0.165995\t  0.168460\t\tCURRENT LEARNING RATE: 0.2821977590596792\n",
      "previous_iter_valid_loss : 0.1622190624475479\n",
      "\n",
      "     57200\t  0.162394\t  0.162219\t  0.168400\t\tCURRENT LEARNING RATE: 0.28163392756100236\n",
      "previous_iter_valid_loss : 0.16361217200756073\n",
      "\n",
      "     57400\t  0.163793\t  0.163612\t  0.168372\t\tCURRENT LEARNING RATE: 0.2810712225984112\n",
      "previous_iter_valid_loss : 0.16497178375720978\n",
      "\n",
      "     57600\t  0.165200\t  0.164972\t  0.168337\t\tCURRENT LEARNING RATE: 0.2805096419210853\n",
      "previous_iter_valid_loss : 0.1629941612482071\n",
      "\n",
      "     57800\t  0.163116\t  0.162994\t  0.168294\t\tCURRENT LEARNING RATE: 0.279949183282701\n",
      "previous_iter_valid_loss : 0.16200150549411774\n",
      "\n",
      "     58000\t  0.162134\t  0.162002\t  0.168256\t\tCURRENT LEARNING RATE: 0.2793898444414232\n",
      "previous_iter_valid_loss : 0.16262730956077576\n",
      "\n",
      "     58200\t  0.162737\t  0.162627\t  0.168203\t\tCURRENT LEARNING RATE: 0.2788316231598956\n",
      "previous_iter_valid_loss : 0.16569584608078003\n",
      "\n",
      "     58400\t  0.165850\t  0.165696\t  0.168161\t\tCURRENT LEARNING RATE: 0.27827451720523244\n",
      "previous_iter_valid_loss : 0.16307619214057922\n",
      "\n",
      "     58600\t  0.163217\t  0.163076\t  0.168155\t\tCURRENT LEARNING RATE: 0.2777185243490091\n",
      "previous_iter_valid_loss : 0.1648280918598175\n",
      "\n",
      "     58800\t  0.164968\t  0.164828\t  0.168124\t\tCURRENT LEARNING RATE: 0.27716364236725355\n",
      "previous_iter_valid_loss : 0.16363337635993958\n",
      "\n",
      "     59000\t  0.163798\t  0.163633\t  0.168116\t\tCURRENT LEARNING RATE: 0.27660986904043694\n",
      "previous_iter_valid_loss : 0.16344007849693298\n",
      "\n",
      "     59200\t  0.163584\t  0.163440\t  0.168061\t\tCURRENT LEARNING RATE: 0.2760572021534653\n",
      "previous_iter_valid_loss : 0.165048748254776\n",
      "\n",
      "     59400\t  0.165177\t  0.165049\t  0.168050\t\tCURRENT LEARNING RATE: 0.27550563949567036\n",
      "previous_iter_valid_loss : 0.16328029334545135\n",
      "\n",
      "     59600\t  0.163459\t  0.163280\t  0.168042\t\tCURRENT LEARNING RATE: 0.2749551788608008\n",
      "previous_iter_valid_loss : 0.16175784170627594\n",
      "\n",
      "\n",
      "Current valid loss: 0.16175784170627594;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "     59800\t  0.161868\t  0.161758\t  0.168028\t\tCURRENT LEARNING RATE: 0.2744058180470132\n",
      "previous_iter_valid_loss : 0.16190853714942932\n",
      "\n",
      "     60000\t  0.162086\t  0.161909\t  0.168010\t\tCURRENT LEARNING RATE: 0.27385755485686375\n",
      "previous_iter_valid_loss : 0.1634439080953598\n",
      "\n",
      "     60200\t  0.163655\t  0.163444\t  0.168003\t\tCURRENT LEARNING RATE: 0.2733103870972988\n",
      "previous_iter_valid_loss : 0.16527216136455536\n",
      "\n",
      "     60400\t  0.165522\t  0.165272\t  0.167993\t\tCURRENT LEARNING RATE: 0.2727643125796467\n",
      "previous_iter_valid_loss : 0.16217267513275146\n",
      "\n",
      "     60600\t  0.162375\t  0.162173\t  0.167986\t\tCURRENT LEARNING RATE: 0.27221932911960856\n",
      "previous_iter_valid_loss : 0.1640000194311142\n",
      "\n",
      "     60800\t  0.164242\t  0.164000\t  0.167974\t\tCURRENT LEARNING RATE: 0.2716754345372499\n",
      "previous_iter_valid_loss : 0.16464048624038696\n",
      "\n",
      "     61000\t  0.164932\t  0.164640\t  0.167917\t\tCURRENT LEARNING RATE: 0.2711326266569916\n",
      "previous_iter_valid_loss : 0.16279837489128113\n",
      "\n",
      "     61200\t  0.163089\t  0.162798\t  0.167864\t\tCURRENT LEARNING RATE: 0.27059090330760144\n",
      "previous_iter_valid_loss : 0.16204094886779785\n",
      "\n",
      "     61400\t  0.162301\t  0.162041\t  0.167847\t\tCURRENT LEARNING RATE: 0.2700502623221853\n",
      "previous_iter_valid_loss : 0.16253717243671417\n",
      "\n",
      "     61600\t  0.162814\t  0.162537\t  0.167833\t\tCURRENT LEARNING RATE: 0.2695107015381785\n",
      "previous_iter_valid_loss : 0.16772116720676422\n",
      "\n",
      "     61800\t  0.167988\t  0.167721\t  0.167843\t\tCURRENT LEARNING RATE: 0.26897221879733724\n",
      "previous_iter_valid_loss : 0.16401825845241547\n",
      "\n",
      "     62000\t  0.164305\t  0.164018\t  0.167806\t\tCURRENT LEARNING RATE: 0.26843481194572977\n",
      "previous_iter_valid_loss : 0.1641656458377838\n",
      "\n",
      "     62200\t  0.164455\t  0.164166\t  0.167767\t\tCURRENT LEARNING RATE: 0.267898478833728\n",
      "previous_iter_valid_loss : 0.16856490075588226\n",
      "\n",
      "     62400\t  0.168703\t  0.168565\t  0.167784\t\tCURRENT LEARNING RATE: 0.26736321731599877\n",
      "previous_iter_valid_loss : 0.17212024331092834\n",
      "\n",
      "     62600\t  0.172345\t  0.172120\t  0.167820\t\tCURRENT LEARNING RATE: 0.2668290252514953\n",
      "previous_iter_valid_loss : 0.16511690616607666\n",
      "\n",
      "     62800\t  0.165265\t  0.165117\t  0.167813\t\tCURRENT LEARNING RATE: 0.2662959005034486\n",
      "previous_iter_valid_loss : 0.16280902922153473\n",
      "\n",
      "     63000\t  0.162985\t  0.162809\t  0.167783\t\tCURRENT LEARNING RATE: 0.26576384093935895\n",
      "previous_iter_valid_loss : 0.16230230033397675\n",
      "\n",
      "     63200\t  0.162507\t  0.162302\t  0.167717\t\tCURRENT LEARNING RATE: 0.26523284443098744\n",
      "previous_iter_valid_loss : 0.16340458393096924\n",
      "\n",
      "     63400\t  0.163620\t  0.163405\t  0.167566\t\tCURRENT LEARNING RATE: 0.2647029088543473\n",
      "previous_iter_valid_loss : 0.16498437523841858\n",
      "\n",
      "     63600\t  0.165216\t  0.164984\t  0.167520\t\tCURRENT LEARNING RATE: 0.2641740320896955\n",
      "previous_iter_valid_loss : 0.16478349268436432\n",
      "\n",
      "     63800\t  0.165041\t  0.164783\t  0.167480\t\tCURRENT LEARNING RATE: 0.2636462120215243\n",
      "previous_iter_valid_loss : 0.16703356802463531\n",
      "\n",
      "     64000\t  0.167302\t  0.167034\t  0.167454\t\tCURRENT LEARNING RATE: 0.2631194465385527\n",
      "previous_iter_valid_loss : 0.17389044165611267\n",
      "\n",
      "     64200\t  0.174051\t  0.173890\t  0.167478\t\tCURRENT LEARNING RATE: 0.26259373353371807\n",
      "previous_iter_valid_loss : 0.1660689413547516\n",
      "\n",
      "     64400\t  0.166238\t  0.166069\t  0.167447\t\tCURRENT LEARNING RATE: 0.2620690709041677\n",
      "previous_iter_valid_loss : 0.16578409075737\n",
      "\n",
      "     64600\t  0.165983\t  0.165784\t  0.167328\t\tCURRENT LEARNING RATE: 0.2615454565512504\n",
      "previous_iter_valid_loss : 0.1683405488729477\n",
      "\n",
      "     64800\t  0.168440\t  0.168341\t  0.167298\t\tCURRENT LEARNING RATE: 0.261022888380508\n",
      "previous_iter_valid_loss : 0.16289715468883514\n",
      "\n",
      "     65000\t  0.163087\t  0.162897\t  0.167231\t\tCURRENT LEARNING RATE: 0.2605013643016672\n",
      "previous_iter_valid_loss : 0.16470496356487274\n",
      "\n",
      "     65200\t  0.164873\t  0.164705\t  0.167165\t\tCURRENT LEARNING RATE: 0.2599808822286309\n",
      "previous_iter_valid_loss : 0.16371649503707886\n",
      "\n",
      "     65400\t  0.163927\t  0.163716\t  0.167072\t\tCURRENT LEARNING RATE: 0.2594614400794702\n",
      "previous_iter_valid_loss : 0.17068137228488922\n",
      "\n",
      "     65600\t  0.170919\t  0.170681\t  0.167062\t\tCURRENT LEARNING RATE: 0.2589430357764157\n",
      "previous_iter_valid_loss : 0.1625441163778305\n",
      "\n",
      "     65800\t  0.162768\t  0.162544\t  0.167019\t\tCURRENT LEARNING RATE: 0.2584256672458496\n",
      "previous_iter_valid_loss : 0.1699042171239853\n",
      "\n",
      "     66000\t  0.170077\t  0.169904\t  0.167001\t\tCURRENT LEARNING RATE: 0.25790933241829705\n",
      "previous_iter_valid_loss : 0.17119649052619934\n",
      "\n",
      "     66200\t  0.171450\t  0.171196\t  0.166997\t\tCURRENT LEARNING RATE: 0.2573940292284181\n",
      "previous_iter_valid_loss : 0.1808442324399948\n",
      "\n",
      "     66400\t  0.181150\t  0.180844\t  0.167062\t\tCURRENT LEARNING RATE: 0.25687975561499915\n",
      "previous_iter_valid_loss : 0.16706018149852753\n",
      "\n",
      "     66600\t  0.167235\t  0.167060\t  0.166969\t\tCURRENT LEARNING RATE: 0.25636650952094525\n",
      "previous_iter_valid_loss : 0.16736844182014465\n",
      "\n",
      "     66800\t  0.167539\t  0.167368\t  0.166915\t\tCURRENT LEARNING RATE: 0.2558542888932712\n",
      "previous_iter_valid_loss : 0.16721834242343903\n",
      "\n",
      "     67000\t  0.167545\t  0.167218\t  0.166877\t\tCURRENT LEARNING RATE: 0.25534309168309394\n",
      "previous_iter_valid_loss : 0.163753941655159\n",
      "\n",
      "     67200\t  0.163956\t  0.163754\t  0.166818\t\tCURRENT LEARNING RATE: 0.2548329158456238\n",
      "previous_iter_valid_loss : 0.16435113549232483\n",
      "\n",
      "     67400\t  0.164454\t  0.164351\t  0.166767\t\tCURRENT LEARNING RATE: 0.25432375934015683\n",
      "previous_iter_valid_loss : 0.16300642490386963\n",
      "\n",
      "     67600\t  0.163143\t  0.163006\t  0.166702\t\tCURRENT LEARNING RATE: 0.25381562013006637\n",
      "previous_iter_valid_loss : 0.17491252720355988\n",
      "\n",
      "     67800\t  0.175035\t  0.174913\t  0.166678\t\tCURRENT LEARNING RATE: 0.2533084961827948\n",
      "previous_iter_valid_loss : 0.16476085782051086\n",
      "\n",
      "     68000\t  0.164894\t  0.164761\t  0.166620\t\tCURRENT LEARNING RATE: 0.25280238546984574\n",
      "previous_iter_valid_loss : 0.1643161028623581\n",
      "\n",
      "     68200\t  0.164460\t  0.164316\t  0.166572\t\tCURRENT LEARNING RATE: 0.2522972859667756\n",
      "previous_iter_valid_loss : 0.16441617906093597\n",
      "\n",
      "     68400\t  0.164550\t  0.164416\t  0.166520\t\tCURRENT LEARNING RATE: 0.2517931956531857\n",
      "previous_iter_valid_loss : 0.1651294082403183\n",
      "\n",
      "     68600\t  0.165348\t  0.165129\t  0.166382\t\tCURRENT LEARNING RATE: 0.2512901125127142\n",
      "previous_iter_valid_loss : 0.1646905541419983\n",
      "\n",
      "     68800\t  0.164764\t  0.164691\t  0.166325\t\tCURRENT LEARNING RATE: 0.2507880345330278\n",
      "previous_iter_valid_loss : 0.16938146948814392\n",
      "\n",
      "     69000\t  0.169402\t  0.169381\t  0.166313\t\tCURRENT LEARNING RATE: 0.2502869597058139\n",
      "previous_iter_valid_loss : 0.16795729100704193\n",
      "\n",
      "     69200\t  0.168064\t  0.167957\t  0.166324\t\tCURRENT LEARNING RATE: 0.2497868860267725\n",
      "previous_iter_valid_loss : 0.18096362054347992\n",
      "\n",
      "     69400\t  0.180993\t  0.180964\t  0.166359\t\tCURRENT LEARNING RATE: 0.24928781149560827\n",
      "previous_iter_valid_loss : 0.1651277244091034\n",
      "\n",
      "     69600\t  0.165229\t  0.165128\t  0.166340\t\tCURRENT LEARNING RATE: 0.24878973411602243\n",
      "previous_iter_valid_loss : 0.17018702626228333\n",
      "\n",
      "     69800\t  0.170215\t  0.170187\t  0.166362\t\tCURRENT LEARNING RATE: 0.24829265189570476\n",
      "previous_iter_valid_loss : 0.1762414127588272\n",
      "\n",
      "     70000\t  0.176375\t  0.176241\t  0.166408\t\tCURRENT LEARNING RATE: 0.24779656284632573\n",
      "previous_iter_valid_loss : 0.18677373230457306\n",
      "\n",
      "     70200\t  0.186911\t  0.186774\t  0.166501\t\tCURRENT LEARNING RATE: 0.2473014649835285\n",
      "previous_iter_valid_loss : 0.1696012169122696\n",
      "\n",
      "     70400\t  0.169713\t  0.169601\t  0.166416\t\tCURRENT LEARNING RATE: 0.2468073563269209\n",
      "previous_iter_valid_loss : 0.16834111511707306\n",
      "\n",
      "     70600\t  0.168469\t  0.168341\t  0.166384\t\tCURRENT LEARNING RATE: 0.24631423490006774\n",
      "previous_iter_valid_loss : 0.16841769218444824\n",
      "\n",
      "     70800\t  0.168546\t  0.168418\t  0.166397\t\tCURRENT LEARNING RATE: 0.24582209873048255\n",
      "previous_iter_valid_loss : 0.16834671795368195\n",
      "\n",
      "     71000\t  0.168562\t  0.168347\t  0.166350\t\tCURRENT LEARNING RATE: 0.24533094584962006\n",
      "previous_iter_valid_loss : 0.17099975049495697\n",
      "\n",
      "     71200\t  0.171240\t  0.171000\t  0.166376\t\tCURRENT LEARNING RATE: 0.2448407742928681\n",
      "previous_iter_valid_loss : 0.1737910509109497\n",
      "\n",
      "     71400\t  0.174018\t  0.173791\t  0.166370\t\tCURRENT LEARNING RATE: 0.24435158209953975\n",
      "previous_iter_valid_loss : 0.16499505937099457\n",
      "\n",
      "     71600\t  0.165186\t  0.164995\t  0.166292\t\tCURRENT LEARNING RATE: 0.2438633673128656\n",
      "previous_iter_valid_loss : 0.19014684855937958\n",
      "\n",
      "     71800\t  0.190359\t  0.190147\t  0.166420\t\tCURRENT LEARNING RATE: 0.24337612797998584\n",
      "previous_iter_valid_loss : 0.1637006253004074\n",
      "\n",
      "     72000\t  0.163939\t  0.163701\t  0.166371\t\tCURRENT LEARNING RATE: 0.2428898621519425\n",
      "previous_iter_valid_loss : 0.18317574262619019\n",
      "\n",
      "     72200\t  0.183559\t  0.183176\t  0.166451\t\tCURRENT LEARNING RATE: 0.24240456788367162\n",
      "previous_iter_valid_loss : 0.16613516211509705\n",
      "\n",
      "     72400\t  0.166412\t  0.166135\t  0.166422\t\tCURRENT LEARNING RATE: 0.2419202432339955\n",
      "previous_iter_valid_loss : 0.172057643532753\n",
      "\n",
      "     72600\t  0.172408\t  0.172058\t  0.166461\t\tCURRENT LEARNING RATE: 0.24143688626561488\n",
      "previous_iter_valid_loss : 0.17916694283485413\n",
      "\n",
      "     72800\t  0.179585\t  0.179167\t  0.166511\t\tCURRENT LEARNING RATE: 0.24095449504510122\n",
      "previous_iter_valid_loss : 0.16424649953842163\n",
      "\n",
      "     73000\t  0.164618\t  0.164246\t  0.166464\t\tCURRENT LEARNING RATE: 0.240473067642889\n",
      "previous_iter_valid_loss : 0.16621133685112\n",
      "\n",
      "     73200\t  0.166637\t  0.166211\t  0.166419\t\tCURRENT LEARNING RATE: 0.239992602133268\n",
      "previous_iter_valid_loss : 0.17426802217960358\n",
      "\n",
      "     73400\t  0.174621\t  0.174268\t  0.166426\t\tCURRENT LEARNING RATE: 0.23951309659437556\n",
      "previous_iter_valid_loss : 0.17369039356708527\n",
      "\n",
      "     73600\t  0.174095\t  0.173690\t  0.166464\t\tCURRENT LEARNING RATE: 0.2390345491081888\n",
      "previous_iter_valid_loss : 0.16883456707000732\n",
      "\n",
      "     73800\t  0.169123\t  0.168835\t  0.166465\t\tCURRENT LEARNING RATE: 0.2385569577605172\n",
      "previous_iter_valid_loss : 0.16543202102184296\n",
      "\n",
      "     74000\t  0.165742\t  0.165432\t  0.166421\t\tCURRENT LEARNING RATE: 0.2380803206409947\n",
      "previous_iter_valid_loss : 0.1640583574771881\n",
      "\n",
      "     74200\t  0.164378\t  0.164058\t  0.166407\t\tCURRENT LEARNING RATE: 0.23760463584307223\n",
      "previous_iter_valid_loss : 0.1898428052663803\n",
      "\n",
      "     74400\t  0.190232\t  0.189843\t  0.166495\t\tCURRENT LEARNING RATE: 0.23712990146400995\n",
      "previous_iter_valid_loss : 0.16816899180412292\n",
      "\n",
      "     74600\t  0.168552\t  0.168169\t  0.166483\t\tCURRENT LEARNING RATE: 0.23665611560486965\n",
      "previous_iter_valid_loss : 0.16837207973003387\n",
      "\n",
      "     74800\t  0.168667\t  0.168372\t  0.166494\t\tCURRENT LEARNING RATE: 0.23618327637050734\n",
      "previous_iter_valid_loss : 0.16486339271068573\n",
      "\n",
      "     75000\t  0.165215\t  0.164863\t  0.166489\t\tCURRENT LEARNING RATE: 0.23571138186956545\n",
      "previous_iter_valid_loss : 0.16485150158405304\n",
      "\n",
      "     75200\t  0.165145\t  0.164852\t  0.166455\t\tCURRENT LEARNING RATE: 0.23524043021446528\n",
      "previous_iter_valid_loss : 0.1652204692363739\n",
      "\n",
      "     75400\t  0.165561\t  0.165220\t  0.166460\t\tCURRENT LEARNING RATE: 0.23477041952139963\n",
      "previous_iter_valid_loss : 0.16920824348926544\n",
      "\n",
      "     75600\t  0.169528\t  0.169208\t  0.166472\t\tCURRENT LEARNING RATE: 0.23430134791032511\n",
      "previous_iter_valid_loss : 0.17200051248073578\n",
      "\n",
      "     75800\t  0.172189\t  0.172001\t  0.166467\t\tCURRENT LEARNING RATE: 0.23383321350495462\n",
      "previous_iter_valid_loss : 0.16376662254333496\n",
      "\n",
      "     76000\t  0.164045\t  0.163767\t  0.166465\t\tCURRENT LEARNING RATE: 0.23336601443274993\n",
      "previous_iter_valid_loss : 0.16522230207920074\n",
      "\n",
      "     76200\t  0.165413\t  0.165222\t  0.166460\t\tCURRENT LEARNING RATE: 0.23289974882491413\n",
      "previous_iter_valid_loss : 0.16386687755584717\n",
      "\n",
      "     76400\t  0.164060\t  0.163867\t  0.166450\t\tCURRENT LEARNING RATE: 0.23243441481638413\n",
      "previous_iter_valid_loss : 0.1691165417432785\n",
      "\n",
      "     76600\t  0.169360\t  0.169117\t  0.166431\t\tCURRENT LEARNING RATE: 0.23197001054582336\n",
      "previous_iter_valid_loss : 0.1654784232378006\n",
      "\n",
      "     76800\t  0.165755\t  0.165478\t  0.166436\t\tCURRENT LEARNING RATE: 0.23150653415561404\n",
      "previous_iter_valid_loss : 0.16998139023780823\n",
      "\n",
      "     77000\t  0.170189\t  0.169981\t  0.166457\t\tCURRENT LEARNING RATE: 0.23104398379185\n",
      "previous_iter_valid_loss : 0.16413547098636627\n",
      "\n",
      "     77200\t  0.164300\t  0.164135\t  0.166376\t\tCURRENT LEARNING RATE: 0.2305823576043292\n",
      "previous_iter_valid_loss : 0.1673763245344162\n",
      "\n",
      "     77400\t  0.167505\t  0.167376\t  0.166381\t\tCURRENT LEARNING RATE: 0.23012165374654628\n",
      "previous_iter_valid_loss : 0.16403940320014954\n",
      "\n",
      "     77600\t  0.164228\t  0.164039\t  0.166379\t\tCURRENT LEARNING RATE: 0.22966187037568517\n",
      "previous_iter_valid_loss : 0.16386380791664124\n",
      "\n",
      "     77800\t  0.164021\t  0.163864\t  0.166382\t\tCURRENT LEARNING RATE: 0.22920300565261176\n",
      "previous_iter_valid_loss : 0.16317984461784363\n",
      "\n",
      "     78000\t  0.163337\t  0.163180\t  0.166343\t\tCURRENT LEARNING RATE: 0.22874505774186657\n",
      "previous_iter_valid_loss : 0.16225740313529968\n",
      "\n",
      "     78200\t  0.162425\t  0.162257\t  0.166332\t\tCURRENT LEARNING RATE: 0.22828802481165736\n",
      "previous_iter_valid_loss : 0.16316404938697815\n",
      "\n",
      "     78400\t  0.163264\t  0.163164\t  0.166329\t\tCURRENT LEARNING RATE: 0.22783190503385176\n",
      "previous_iter_valid_loss : 0.16723206639289856\n",
      "\n",
      "     78600\t  0.167493\t  0.167232\t  0.166316\t\tCURRENT LEARNING RATE: 0.22737669658397008\n",
      "previous_iter_valid_loss : 0.16338464617729187\n",
      "\n",
      "     78800\t  0.163574\t  0.163385\t  0.166301\t\tCURRENT LEARNING RATE: 0.22692239764117791\n",
      "previous_iter_valid_loss : 0.16520684957504272\n",
      "\n",
      "     79000\t  0.165432\t  0.165207\t  0.166308\t\tCURRENT LEARNING RATE: 0.22646900638827885\n",
      "previous_iter_valid_loss : 0.16221019625663757\n",
      "\n",
      "     79200\t  0.162318\t  0.162210\t  0.166291\t\tCURRENT LEARNING RATE: 0.22601652101170733\n",
      "previous_iter_valid_loss : 0.1636635661125183\n",
      "\n",
      "     79400\t  0.163889\t  0.163664\t  0.166282\t\tCURRENT LEARNING RATE: 0.22556493970152117\n",
      "previous_iter_valid_loss : 0.16649597883224487\n",
      "\n",
      "     79600\t  0.166724\t  0.166496\t  0.166290\t\tCURRENT LEARNING RATE: 0.22511426065139462\n",
      "previous_iter_valid_loss : 0.16368234157562256\n",
      "\n",
      "     79800\t  0.163902\t  0.163682\t  0.166265\t\tCURRENT LEARNING RATE: 0.22466448205861078\n",
      "previous_iter_valid_loss : 0.16426591575145721\n",
      "\n",
      "     80000\t  0.164502\t  0.164266\t  0.166264\t\tCURRENT LEARNING RATE: 0.22421560212405475\n",
      "previous_iter_valid_loss : 0.16426332294940948\n",
      "\n",
      "     80200\t  0.164418\t  0.164263\t  0.166271\t\tCURRENT LEARNING RATE: 0.22376761905220618\n",
      "previous_iter_valid_loss : 0.1638309210538864\n",
      "\n",
      "     80400\t  0.163973\t  0.163831\t  0.166276\t\tCURRENT LEARNING RATE: 0.22332053105113217\n",
      "previous_iter_valid_loss : 0.16218781471252441\n",
      "\n",
      "     80600\t  0.162340\t  0.162188\t  0.166216\t\tCURRENT LEARNING RATE: 0.2228743363324801\n",
      "previous_iter_valid_loss : 0.16271474957466125\n",
      "\n",
      "     80800\t  0.162894\t  0.162715\t  0.166210\t\tCURRENT LEARNING RATE: 0.22242903311147055\n",
      "previous_iter_valid_loss : 0.16199339926242828\n",
      "\n",
      "     81000\t  0.162129\t  0.161993\t  0.166199\t\tCURRENT LEARNING RATE: 0.22198461960689003\n",
      "previous_iter_valid_loss : 0.16219846904277802\n",
      "\n",
      "     81200\t  0.162387\t  0.162198\t  0.166194\t\tCURRENT LEARNING RATE: 0.2215410940410839\n",
      "previous_iter_valid_loss : 0.16446062922477722\n",
      "\n",
      "     81400\t  0.164692\t  0.164461\t  0.166188\t\tCURRENT LEARNING RATE: 0.22109845463994934\n",
      "previous_iter_valid_loss : 0.1651621162891388\n",
      "\n",
      "     81600\t  0.165330\t  0.165162\t  0.166190\t\tCURRENT LEARNING RATE: 0.2206566996329281\n",
      "previous_iter_valid_loss : 0.16407765448093414\n",
      "\n",
      "     81800\t  0.164244\t  0.164078\t  0.166164\t\tCURRENT LEARNING RATE: 0.22021582725299965\n",
      "previous_iter_valid_loss : 0.16670353710651398\n",
      "\n",
      "     82000\t  0.166804\t  0.166704\t  0.166167\t\tCURRENT LEARNING RATE: 0.2197758357366738\n",
      "previous_iter_valid_loss : 0.16427874565124512\n",
      "\n",
      "     82200\t  0.164419\t  0.164279\t  0.166169\t\tCURRENT LEARNING RATE: 0.21933672332398393\n",
      "previous_iter_valid_loss : 0.16345925629138947\n",
      "\n",
      "     82400\t  0.163622\t  0.163459\t  0.166150\t\tCURRENT LEARNING RATE: 0.21889848825847982\n",
      "previous_iter_valid_loss : 0.1643114984035492\n",
      "\n",
      "     82600\t  0.164516\t  0.164311\t  0.166156\t\tCURRENT LEARNING RATE: 0.2184611287872206\n",
      "previous_iter_valid_loss : 0.16209776699543\n",
      "\n",
      "     82800\t  0.162324\t  0.162098\t  0.166151\t\tCURRENT LEARNING RATE: 0.2180246431607678\n",
      "previous_iter_valid_loss : 0.1653279960155487\n",
      "\n",
      "     83000\t  0.165493\t  0.165328\t  0.166129\t\tCURRENT LEARNING RATE: 0.21758902963317836\n",
      "previous_iter_valid_loss : 0.16252124309539795\n",
      "\n",
      "     83200\t  0.162700\t  0.162521\t  0.166112\t\tCURRENT LEARNING RATE: 0.21715428646199755\n",
      "previous_iter_valid_loss : 0.16243509948253632\n",
      "\n",
      "     83400\t  0.162627\t  0.162435\t  0.166100\t\tCURRENT LEARNING RATE: 0.21672041190825214\n",
      "previous_iter_valid_loss : 0.16223306953907013\n",
      "\n",
      "     83600\t  0.162376\t  0.162233\t  0.166087\t\tCURRENT LEARNING RATE: 0.21628740423644333\n",
      "previous_iter_valid_loss : 0.1644413322210312\n",
      "\n",
      "     83800\t  0.164597\t  0.164441\t  0.166044\t\tCURRENT LEARNING RATE: 0.21585526171453986\n",
      "previous_iter_valid_loss : 0.16277416050434113\n",
      "\n",
      "     84000\t  0.162940\t  0.162774\t  0.166042\t\tCURRENT LEARNING RATE: 0.21542398261397103\n",
      "previous_iter_valid_loss : 0.16688172519207\n",
      "\n",
      "     84200\t  0.167049\t  0.166882\t  0.166061\t\tCURRENT LEARNING RATE: 0.2149935652096199\n",
      "previous_iter_valid_loss : 0.16648779809474945\n",
      "\n",
      "     84400\t  0.166703\t  0.166488\t  0.166027\t\tCURRENT LEARNING RATE: 0.21456400777981627\n",
      "previous_iter_valid_loss : 0.16524821519851685\n",
      "\n",
      "     84600\t  0.165442\t  0.165248\t  0.166035\t\tCURRENT LEARNING RATE: 0.21413530860632984\n",
      "previous_iter_valid_loss : 0.1631169319152832\n",
      "\n",
      "     84800\t  0.163306\t  0.163117\t  0.166037\t\tCURRENT LEARNING RATE: 0.21370746597436335\n",
      "previous_iter_valid_loss : 0.16292034089565277\n",
      "\n",
      "     85000\t  0.163119\t  0.162920\t  0.166007\t\tCURRENT LEARNING RATE: 0.2132804781725457\n",
      "previous_iter_valid_loss : 0.16343474388122559\n",
      "\n",
      "     85200\t  0.163697\t  0.163435\t  0.166006\t\tCURRENT LEARNING RATE: 0.2128543434929251\n",
      "previous_iter_valid_loss : 0.16333475708961487\n",
      "\n",
      "     85400\t  0.163587\t  0.163335\t  0.166001\t\tCURRENT LEARNING RATE: 0.21242906023096228\n",
      "previous_iter_valid_loss : 0.16644610464572906\n",
      "\n",
      "     85600\t  0.166677\t  0.166446\t  0.166010\t\tCURRENT LEARNING RATE: 0.21200462668552364\n",
      "previous_iter_valid_loss : 0.1630096286535263\n",
      "\n",
      "     85800\t  0.163252\t  0.163010\t  0.165999\t\tCURRENT LEARNING RATE: 0.2115810411588744\n",
      "previous_iter_valid_loss : 0.1624426245689392\n",
      "\n",
      "     86000\t  0.162662\t  0.162443\t  0.165895\t\tCURRENT LEARNING RATE: 0.21115830195667193\n",
      "previous_iter_valid_loss : 0.16146112978458405\n",
      "\n",
      "\n",
      "Current valid loss: 0.16146112978458405;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "     86200\t  0.161632\t  0.161461\t  0.165873\t\tCURRENT LEARNING RATE: 0.21073640738795882\n",
      "previous_iter_valid_loss : 0.16359083354473114\n",
      "\n",
      "     86400\t  0.163797\t  0.163591\t  0.165876\t\tCURRENT LEARNING RATE: 0.21031535576515623\n",
      "previous_iter_valid_loss : 0.16227327287197113\n",
      "\n",
      "     86600\t  0.162481\t  0.162273\t  0.165862\t\tCURRENT LEARNING RATE: 0.20989514540405713\n",
      "previous_iter_valid_loss : 0.1622285097837448\n",
      "\n",
      "     86800\t  0.162445\t  0.162229\t  0.165852\t\tCURRENT LEARNING RATE: 0.2094757746238195\n",
      "previous_iter_valid_loss : 0.1645948886871338\n",
      "\n",
      "     87000\t  0.164740\t  0.164595\t  0.165861\t\tCURRENT LEARNING RATE: 0.20905724174695967\n",
      "previous_iter_valid_loss : 0.16325728595256805\n",
      "\n",
      "     87200\t  0.163385\t  0.163257\t  0.165856\t\tCURRENT LEARNING RATE: 0.20863954509934557\n",
      "previous_iter_valid_loss : 0.16402234137058258\n",
      "\n",
      "     87400\t  0.164222\t  0.164022\t  0.165855\t\tCURRENT LEARNING RATE: 0.20822268301019004\n",
      "previous_iter_valid_loss : 0.16490519046783447\n",
      "\n",
      "     87600\t  0.165124\t  0.164905\t  0.165864\t\tCURRENT LEARNING RATE: 0.2078066538120442\n",
      "previous_iter_valid_loss : 0.16144534945487976\n",
      "\n",
      "\n",
      "Current valid loss: 0.16144534945487976;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "     87800\t  0.161657\t  0.161445\t  0.165825\t\tCURRENT LEARNING RATE: 0.2073914558407907\n",
      "previous_iter_valid_loss : 0.16226691007614136\n",
      "\n",
      "     88000\t  0.162498\t  0.162267\t  0.165811\t\tCURRENT LEARNING RATE: 0.20697708743563706\n",
      "previous_iter_valid_loss : 0.16425569355487823\n",
      "\n",
      "     88200\t  0.164468\t  0.164256\t  0.165813\t\tCURRENT LEARNING RATE: 0.2065635469391091\n",
      "previous_iter_valid_loss : 0.16549165546894073\n",
      "\n",
      "     88400\t  0.165759\t  0.165492\t  0.165822\t\tCURRENT LEARNING RATE: 0.20615083269704437\n",
      "previous_iter_valid_loss : 0.16697673499584198\n",
      "\n",
      "     88600\t  0.167173\t  0.166977\t  0.165792\t\tCURRENT LEARNING RATE: 0.20573894305858528\n",
      "previous_iter_valid_loss : 0.16676455736160278\n",
      "\n",
      "     88800\t  0.166988\t  0.166765\t  0.165807\t\tCURRENT LEARNING RATE: 0.20532787637617275\n",
      "previous_iter_valid_loss : 0.16279900074005127\n",
      "\n",
      "     89000\t  0.163074\t  0.162799\t  0.165795\t\tCURRENT LEARNING RATE: 0.20491763100553947\n",
      "previous_iter_valid_loss : 0.16361472010612488\n",
      "\n",
      "     89200\t  0.163929\t  0.163615\t  0.165796\t\tCURRENT LEARNING RATE: 0.20450820530570346\n",
      "previous_iter_valid_loss : 0.16258357465267181\n",
      "\n",
      "     89400\t  0.162880\t  0.162584\t  0.165785\t\tCURRENT LEARNING RATE: 0.20409959763896135\n",
      "previous_iter_valid_loss : 0.162626713514328\n",
      "\n",
      "     89600\t  0.162859\t  0.162627\t  0.165783\t\tCURRENT LEARNING RATE: 0.2036918063708819\n",
      "previous_iter_valid_loss : 0.1646411269903183\n",
      "\n",
      "     89800\t  0.164958\t  0.164641\t  0.165770\t\tCURRENT LEARNING RATE: 0.20328482987029955\n",
      "previous_iter_valid_loss : 0.16281378269195557\n",
      "\n",
      "     90000\t  0.163068\t  0.162814\t  0.165749\t\tCURRENT LEARNING RATE: 0.20287866650930772\n",
      "previous_iter_valid_loss : 0.16393333673477173\n",
      "\n",
      "     90200\t  0.164271\t  0.163933\t  0.165743\t\tCURRENT LEARNING RATE: 0.20247331466325244\n",
      "previous_iter_valid_loss : 0.16169172525405884\n",
      "\n",
      "     90400\t  0.161948\t  0.161692\t  0.165736\t\tCURRENT LEARNING RATE: 0.20206877271072576\n",
      "previous_iter_valid_loss : 0.1615552306175232\n",
      "\n",
      "     90600\t  0.161843\t  0.161555\t  0.165734\t\tCURRENT LEARNING RATE: 0.20166503903355937\n",
      "previous_iter_valid_loss : 0.1625046730041504\n",
      "\n",
      "     90800\t  0.162798\t  0.162505\t  0.165712\t\tCURRENT LEARNING RATE: 0.20126211201681798\n",
      "previous_iter_valid_loss : 0.1657157987356186\n",
      "\n",
      "     91000\t  0.165928\t  0.165716\t  0.165727\t\tCURRENT LEARNING RATE: 0.200859990048793\n",
      "previous_iter_valid_loss : 0.1616891622543335\n",
      "\n",
      "     91200\t  0.161934\t  0.161689\t  0.165720\t\tCURRENT LEARNING RATE: 0.20045867152099606\n",
      "previous_iter_valid_loss : 0.16713790595531464\n",
      "\n",
      "     91400\t  0.167355\t  0.167138\t  0.165744\t\tCURRENT LEARNING RATE: 0.20005815482815248\n",
      "previous_iter_valid_loss : 0.16362857818603516\n",
      "\n",
      "     91600\t  0.163839\t  0.163629\t  0.165745\t\tCURRENT LEARNING RATE: 0.19965843836819494\n",
      "previous_iter_valid_loss : 0.1635248064994812\n",
      "\n",
      "     91800\t  0.163748\t  0.163525\t  0.165699\t\tCURRENT LEARNING RATE: 0.19925952054225707\n",
      "previous_iter_valid_loss : 0.16311824321746826\n",
      "\n",
      "     92000\t  0.163395\t  0.163118\t  0.165690\t\tCURRENT LEARNING RATE: 0.19886139975466707\n",
      "previous_iter_valid_loss : 0.16245095431804657\n",
      "\n",
      "     92200\t  0.162687\t  0.162451\t  0.165680\t\tCURRENT LEARNING RATE: 0.19846407441294123\n",
      "previous_iter_valid_loss : 0.163318932056427\n",
      "\n",
      "     92400\t  0.163588\t  0.163319\t  0.165668\t\tCURRENT LEARNING RATE: 0.19806754292777767\n",
      "previous_iter_valid_loss : 0.16460846364498138\n",
      "\n",
      "     92600\t  0.164838\t  0.164608\t  0.165676\t\tCURRENT LEARNING RATE: 0.1976718037130499\n",
      "previous_iter_valid_loss : 0.16145871579647064\n",
      "\n",
      "     92800\t  0.161702\t  0.161459\t  0.165662\t\tCURRENT LEARNING RATE: 0.19727685518580054\n",
      "previous_iter_valid_loss : 0.16244244575500488\n",
      "\n",
      "     93000\t  0.162641\t  0.162442\t  0.165642\t\tCURRENT LEARNING RATE: 0.196882695766235\n",
      "previous_iter_valid_loss : 0.1623549908399582\n",
      "\n",
      "     93200\t  0.162569\t  0.162355\t  0.165625\t\tCURRENT LEARNING RATE: 0.19648932387771498\n",
      "previous_iter_valid_loss : 0.16175413131713867\n",
      "\n",
      "     93400\t  0.161989\t  0.161754\t  0.165615\t\tCURRENT LEARNING RATE: 0.19609673794675248\n",
      "previous_iter_valid_loss : 0.16520990431308746\n",
      "\n",
      "     93600\t  0.165430\t  0.165210\t  0.165625\t\tCURRENT LEARNING RATE: 0.19570493640300327\n",
      "previous_iter_valid_loss : 0.16203846037387848\n",
      "\n",
      "     93800\t  0.162296\t  0.162038\t  0.165610\t\tCURRENT LEARNING RATE: 0.19531391767926057\n",
      "previous_iter_valid_loss : 0.16176243126392365\n",
      "\n",
      "     94000\t  0.162022\t  0.161762\t  0.165604\t\tCURRENT LEARNING RATE: 0.19492368021144899\n",
      "previous_iter_valid_loss : 0.16308580338954926\n",
      "\n",
      "     94200\t  0.163348\t  0.163086\t  0.165602\t\tCURRENT LEARNING RATE: 0.19453422243861818\n",
      "previous_iter_valid_loss : 0.16127853095531464\n",
      "\n",
      "\n",
      "Current valid loss: 0.16127853095531464;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "     94400\t  0.161557\t  0.161279\t  0.165558\t\tCURRENT LEARNING RATE: 0.1941455428029365\n",
      "previous_iter_valid_loss : 0.1622506082057953\n",
      "\n",
      "     94600\t  0.162556\t  0.162251\t  0.165554\t\tCURRENT LEARNING RATE: 0.19375763974968488\n",
      "previous_iter_valid_loss : 0.1639861911535263\n",
      "\n",
      "     94800\t  0.164194\t  0.163986\t  0.165551\t\tCURRENT LEARNING RATE: 0.19337051172725062\n",
      "previous_iter_valid_loss : 0.16366201639175415\n",
      "\n",
      "     95000\t  0.163953\t  0.163662\t  0.165557\t\tCURRENT LEARNING RATE: 0.19298415718712109\n",
      "previous_iter_valid_loss : 0.1648998260498047\n",
      "\n",
      "     95200\t  0.165193\t  0.164900\t  0.165571\t\tCURRENT LEARNING RATE: 0.1925985745838776\n",
      "previous_iter_valid_loss : 0.16134370863437653\n",
      "\n",
      "     95400\t  0.161575\t  0.161344\t  0.165561\t\tCURRENT LEARNING RATE: 0.19221376237518928\n",
      "previous_iter_valid_loss : 0.16670295596122742\n",
      "\n",
      "     95600\t  0.167018\t  0.166703\t  0.165582\t\tCURRENT LEARNING RATE: 0.1918297190218067\n",
      "previous_iter_valid_loss : 0.1636534184217453\n",
      "\n",
      "     95800\t  0.163959\t  0.163653\t  0.165562\t\tCURRENT LEARNING RATE: 0.19144644298755603\n",
      "previous_iter_valid_loss : 0.16183766722679138\n",
      "\n",
      "     96000\t  0.162104\t  0.161838\t  0.165560\t\tCURRENT LEARNING RATE: 0.19106393273933253\n",
      "previous_iter_valid_loss : 0.16330356895923615\n",
      "\n",
      "     96200\t  0.163614\t  0.163304\t  0.165562\t\tCURRENT LEARNING RATE: 0.19068218674709478\n",
      "previous_iter_valid_loss : 0.16218668222427368\n",
      "\n",
      "     96400\t  0.162496\t  0.162187\t  0.165558\t\tCURRENT LEARNING RATE: 0.19030120348385823\n",
      "previous_iter_valid_loss : 0.16328105330467224\n",
      "\n",
      "     96600\t  0.163515\t  0.163281\t  0.165558\t\tCURRENT LEARNING RATE: 0.18992098142568936\n",
      "previous_iter_valid_loss : 0.1634404957294464\n",
      "\n",
      "     96800\t  0.163715\t  0.163440\t  0.165566\t\tCURRENT LEARNING RATE: 0.18954151905169941\n",
      "previous_iter_valid_loss : 0.1619487851858139\n",
      "\n",
      "     97000\t  0.162210\t  0.161949\t  0.165546\t\tCURRENT LEARNING RATE: 0.1891628148440384\n",
      "previous_iter_valid_loss : 0.16427551209926605\n",
      "\n",
      "     97200\t  0.164547\t  0.164276\t  0.165556\t\tCURRENT LEARNING RATE: 0.18878486728788899\n",
      "previous_iter_valid_loss : 0.16383224725723267\n",
      "\n",
      "     97400\t  0.164126\t  0.163832\t  0.165557\t\tCURRENT LEARNING RATE: 0.18840767487146043\n",
      "previous_iter_valid_loss : 0.1669836938381195\n",
      "\n",
      "     97600\t  0.167265\t  0.166984\t  0.165567\t\tCURRENT LEARNING RATE: 0.18803123608598257\n",
      "previous_iter_valid_loss : 0.1618606448173523\n",
      "\n",
      "     97800\t  0.162091\t  0.161861\t  0.165561\t\tCURRENT LEARNING RATE: 0.18765554942569979\n",
      "previous_iter_valid_loss : 0.1611613780260086\n",
      "\n",
      "\n",
      "Current valid loss: 0.1611613780260086;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "     98000\t  0.161435\t  0.161161\t  0.165557\t\tCURRENT LEARNING RATE: 0.1872806133878649\n",
      "previous_iter_valid_loss : 0.16126392781734467\n",
      "\n",
      "     98200\t  0.161569\t  0.161264\t  0.165550\t\tCURRENT LEARNING RATE: 0.18690642647273326\n",
      "previous_iter_valid_loss : 0.16249537467956543\n",
      "\n",
      "     98400\t  0.162786\t  0.162495\t  0.165534\t\tCURRENT LEARNING RATE: 0.1865329871835567\n",
      "previous_iter_valid_loss : 0.1632809191942215\n",
      "\n",
      "     98600\t  0.163579\t  0.163281\t  0.165535\t\tCURRENT LEARNING RATE: 0.1861602940265776\n",
      "previous_iter_valid_loss : 0.165176123380661\n",
      "\n",
      "     98800\t  0.165429\t  0.165176\t  0.165537\t\tCURRENT LEARNING RATE: 0.18578834551102286\n",
      "previous_iter_valid_loss : 0.163349911570549\n",
      "\n",
      "     99000\t  0.163541\t  0.163350\t  0.165536\t\tCURRENT LEARNING RATE: 0.18541714014909783\n",
      "previous_iter_valid_loss : 0.16205276548862457\n",
      "\n",
      "     99200\t  0.162283\t  0.162053\t  0.165529\t\tCURRENT LEARNING RATE: 0.18504667645598064\n",
      "previous_iter_valid_loss : 0.1617029756307602\n",
      "\n",
      "     99400\t  0.161895\t  0.161703\t  0.165512\t\tCURRENT LEARNING RATE: 0.184676952949816\n",
      "previous_iter_valid_loss : 0.16640783846378326\n",
      "\n",
      "     99600\t  0.166628\t  0.166408\t  0.165528\t\tCURRENT LEARNING RATE: 0.1843079681517094\n",
      "previous_iter_valid_loss : 0.16248667240142822\n",
      "\n",
      "     99800\t  0.162664\t  0.162487\t  0.165531\t\tCURRENT LEARNING RATE: 0.18393972058572117\n",
      "previous_iter_valid_loss : 0.16216298937797546\n",
      "\n",
      "    100000\t  0.162371\t  0.162163\t  0.165533\t\tCURRENT LEARNING RATE: 0.18357220877886052\n",
      "previous_iter_valid_loss : 0.16168183088302612\n",
      "\n",
      "    100200\t  0.161896\t  0.161682\t  0.165524\t\tCURRENT LEARNING RATE: 0.18320543126107974\n",
      "previous_iter_valid_loss : 0.1624724417924881\n",
      "\n",
      "    100400\t  0.162686\t  0.162472\t  0.165510\t\tCURRENT LEARNING RATE: 0.18283938656526827\n",
      "previous_iter_valid_loss : 0.16284164786338806\n",
      "\n",
      "    100600\t  0.163019\t  0.162842\t  0.165513\t\tCURRENT LEARNING RATE: 0.18247407322724687\n",
      "previous_iter_valid_loss : 0.16617928445339203\n",
      "\n",
      "    100800\t  0.166435\t  0.166179\t  0.165524\t\tCURRENT LEARNING RATE: 0.18210948978576166\n",
      "previous_iter_valid_loss : 0.1632474958896637\n",
      "\n",
      "    101000\t  0.163527\t  0.163247\t  0.165517\t\tCURRENT LEARNING RATE: 0.1817456347824784\n",
      "previous_iter_valid_loss : 0.16415558755397797\n",
      "\n",
      "    101200\t  0.164399\t  0.164156\t  0.165524\t\tCURRENT LEARNING RATE: 0.18138250676197662\n",
      "previous_iter_valid_loss : 0.1654820591211319\n",
      "\n",
      "    101400\t  0.165646\t  0.165482\t  0.165541\t\tCURRENT LEARNING RATE: 0.18102010427174373\n",
      "previous_iter_valid_loss : 0.16352224349975586\n",
      "\n",
      "    101600\t  0.163671\t  0.163522\t  0.165546\t\tCURRENT LEARNING RATE: 0.18065842586216926\n",
      "previous_iter_valid_loss : 0.16763629019260406\n",
      "\n",
      "    101800\t  0.167740\t  0.167636\t  0.165546\t\tCURRENT LEARNING RATE: 0.18029747008653915\n",
      "previous_iter_valid_loss : 0.1629638820886612\n",
      "\n",
      "    102000\t  0.163105\t  0.162964\t  0.165540\t\tCURRENT LEARNING RATE: 0.17993723550102977\n",
      "previous_iter_valid_loss : 0.16326658427715302\n",
      "\n",
      "    102200\t  0.163486\t  0.163267\t  0.165536\t\tCURRENT LEARNING RATE: 0.1795777206647023\n",
      "previous_iter_valid_loss : 0.16849203407764435\n",
      "\n",
      "    102400\t  0.168737\t  0.168492\t  0.165535\t\tCURRENT LEARNING RATE: 0.17921892413949694\n",
      "previous_iter_valid_loss : 0.16178634762763977\n",
      "\n",
      "    102600\t  0.162022\t  0.161786\t  0.165484\t\tCURRENT LEARNING RATE: 0.1788608444902271\n",
      "previous_iter_valid_loss : 0.16242292523384094\n",
      "\n",
      "    102800\t  0.162643\t  0.162423\t  0.165470\t\tCURRENT LEARNING RATE: 0.1785034802845737\n",
      "previous_iter_valid_loss : 0.16223612427711487\n",
      "\n",
      "    103000\t  0.162466\t  0.162236\t  0.165467\t\tCURRENT LEARNING RATE: 0.1781468300930794\n",
      "previous_iter_valid_loss : 0.16363340616226196\n",
      "\n",
      "    103200\t  0.163765\t  0.163633\t  0.165474\t\tCURRENT LEARNING RATE: 0.17779089248914307\n",
      "previous_iter_valid_loss : 0.16349433362483978\n",
      "\n",
      "    103400\t  0.163743\t  0.163494\t  0.165475\t\tCURRENT LEARNING RATE: 0.1774356660490137\n",
      "previous_iter_valid_loss : 0.16297252476215363\n",
      "\n",
      "    103600\t  0.163206\t  0.162973\t  0.165464\t\tCURRENT LEARNING RATE: 0.17708114935178512\n",
      "previous_iter_valid_loss : 0.16273024678230286\n",
      "\n",
      "    103800\t  0.162984\t  0.162730\t  0.165454\t\tCURRENT LEARNING RATE: 0.17672734097939008\n",
      "previous_iter_valid_loss : 0.16186009347438812\n",
      "\n",
      "    104000\t  0.162100\t  0.161860\t  0.165428\t\tCURRENT LEARNING RATE: 0.17637423951659456\n",
      "previous_iter_valid_loss : 0.1618228256702423\n",
      "\n",
      "    104200\t  0.161998\t  0.161823\t  0.165368\t\tCURRENT LEARNING RATE: 0.1760218435509923\n",
      "previous_iter_valid_loss : 0.16387467086315155\n",
      "\n",
      "    104400\t  0.164064\t  0.163875\t  0.165357\t\tCURRENT LEARNING RATE: 0.1756701516729989\n",
      "previous_iter_valid_loss : 0.16510109603405\n",
      "\n",
      "    104600\t  0.165337\t  0.165101\t  0.165354\t\tCURRENT LEARNING RATE: 0.17531916247584647\n",
      "previous_iter_valid_loss : 0.16511476039886475\n",
      "\n",
      "    104800\t  0.165378\t  0.165115\t  0.165338\t\tCURRENT LEARNING RATE: 0.17496887455557766\n",
      "previous_iter_valid_loss : 0.16488981246948242\n",
      "\n",
      "    105000\t  0.165162\t  0.164890\t  0.165347\t\tCURRENT LEARNING RATE: 0.1746192865110404\n",
      "previous_iter_valid_loss : 0.1650082767009735\n",
      "\n",
      "    105200\t  0.165205\t  0.165008\t  0.165349\t\tCURRENT LEARNING RATE: 0.174270396943882\n",
      "previous_iter_valid_loss : 0.16660869121551514\n",
      "\n",
      "    105400\t  0.166819\t  0.166609\t  0.165363\t\tCURRENT LEARNING RATE: 0.1739222044585437\n",
      "previous_iter_valid_loss : 0.16218283772468567\n",
      "\n",
      "    105600\t  0.162391\t  0.162183\t  0.165321\t\tCURRENT LEARNING RATE: 0.17357470766225516\n",
      "previous_iter_valid_loss : 0.1634082943201065\n",
      "\n",
      "    105800\t  0.163645\t  0.163408\t  0.165325\t\tCURRENT LEARNING RATE: 0.1732279051650287\n",
      "previous_iter_valid_loss : 0.16235460340976715\n",
      "\n",
      "    106000\t  0.162581\t  0.162355\t  0.165288\t\tCURRENT LEARNING RATE: 0.17288179557965389\n",
      "previous_iter_valid_loss : 0.16417409479618073\n",
      "\n",
      "    106200\t  0.164420\t  0.164174\t  0.165252\t\tCURRENT LEARNING RATE: 0.17253637752169187\n",
      "previous_iter_valid_loss : 0.16160696744918823\n",
      "\n",
      "    106400\t  0.161812\t  0.161607\t  0.165156\t\tCURRENT LEARNING RATE: 0.17219164960947\n",
      "previous_iter_valid_loss : 0.1638740450143814\n",
      "\n",
      "    106600\t  0.164155\t  0.163874\t  0.165140\t\tCURRENT LEARNING RATE: 0.17184761046407618\n",
      "previous_iter_valid_loss : 0.16428285837173462\n",
      "\n",
      "    106800\t  0.164563\t  0.164283\t  0.165125\t\tCURRENT LEARNING RATE: 0.17150425870935332\n",
      "previous_iter_valid_loss : 0.16182896494865417\n",
      "\n",
      "    107000\t  0.162059\t  0.161829\t  0.165098\t\tCURRENT LEARNING RATE: 0.17116159297189398\n",
      "previous_iter_valid_loss : 0.161855548620224\n",
      "\n",
      "    107200\t  0.162062\t  0.161856\t  0.165088\t\tCURRENT LEARNING RATE: 0.17081961188103473\n",
      "previous_iter_valid_loss : 0.16207529604434967\n",
      "\n",
      "    107400\t  0.162293\t  0.162075\t  0.165077\t\tCURRENT LEARNING RATE: 0.17047831406885078\n",
      "previous_iter_valid_loss : 0.16388466954231262\n",
      "\n",
      "    107600\t  0.164098\t  0.163885\t  0.165081\t\tCURRENT LEARNING RATE: 0.1701376981701504\n",
      "previous_iter_valid_loss : 0.1627773493528366\n",
      "\n",
      "    107800\t  0.162999\t  0.162777\t  0.165021\t\tCURRENT LEARNING RATE: 0.16979776282246956\n",
      "previous_iter_valid_loss : 0.1644642949104309\n",
      "\n",
      "    108000\t  0.164714\t  0.164464\t  0.165019\t\tCURRENT LEARNING RATE: 0.1694585066660664\n",
      "previous_iter_valid_loss : 0.16393353044986725\n",
      "\n",
      "    108200\t  0.164189\t  0.163934\t  0.165017\t\tCURRENT LEARNING RATE: 0.16911992834391584\n",
      "previous_iter_valid_loss : 0.16177918016910553\n",
      "\n",
      "    108400\t  0.161980\t  0.161779\t  0.165004\t\tCURRENT LEARNING RATE: 0.16878202650170418\n",
      "previous_iter_valid_loss : 0.1665673702955246\n",
      "\n",
      "    108600\t  0.166833\t  0.166567\t  0.165011\t\tCURRENT LEARNING RATE: 0.16844479978782353\n",
      "previous_iter_valid_loss : 0.1612187772989273\n",
      "\n",
      "    108800\t  0.161421\t  0.161219\t  0.164994\t\tCURRENT LEARNING RATE: 0.16810824685336667\n",
      "previous_iter_valid_loss : 0.16380636394023895\n",
      "\n",
      "    109000\t  0.163989\t  0.163806\t  0.164966\t\tCURRENT LEARNING RATE: 0.16777236635212134\n",
      "previous_iter_valid_loss : 0.16486787796020508\n",
      "\n",
      "    109200\t  0.165073\t  0.164868\t  0.164951\t\tCURRENT LEARNING RATE: 0.1674371569405651\n",
      "previous_iter_valid_loss : 0.16210781037807465\n",
      "\n",
      "    109400\t  0.162332\t  0.162108\t  0.164856\t\tCURRENT LEARNING RATE: 0.16710261727785988\n",
      "previous_iter_valid_loss : 0.16275450587272644\n",
      "\n",
      "    109600\t  0.162921\t  0.162755\t  0.164845\t\tCURRENT LEARNING RATE: 0.1667687460258466\n",
      "previous_iter_valid_loss : 0.16262921690940857\n",
      "\n",
      "    109800\t  0.162785\t  0.162629\t  0.164807\t\tCURRENT LEARNING RATE: 0.16643554184903978\n",
      "previous_iter_valid_loss : 0.16221894323825836\n",
      "\n",
      "    110000\t  0.162412\t  0.162219\t  0.164737\t\tCURRENT LEARNING RATE: 0.16610300341462222\n",
      "previous_iter_valid_loss : 0.16272936761379242\n",
      "\n",
      "    110200\t  0.162925\t  0.162729\t  0.164616\t\tCURRENT LEARNING RATE: 0.16577112939243985\n",
      "previous_iter_valid_loss : 0.16475409269332886\n",
      "\n",
      "    110400\t  0.164956\t  0.164754\t  0.164592\t\tCURRENT LEARNING RATE: 0.16543991845499603\n",
      "previous_iter_valid_loss : 0.16222664713859558\n",
      "\n",
      "    110600\t  0.162393\t  0.162227\t  0.164562\t\tCURRENT LEARNING RATE: 0.16510936927744665\n",
      "previous_iter_valid_loss : 0.1623285412788391\n",
      "\n",
      "    110800\t  0.162466\t  0.162329\t  0.164531\t\tCURRENT LEARNING RATE: 0.16477948053759453\n",
      "previous_iter_valid_loss : 0.165882870554924\n",
      "\n",
      "    111000\t  0.166028\t  0.165883\t  0.164519\t\tCURRENT LEARNING RATE: 0.16445025091588425\n",
      "previous_iter_valid_loss : 0.16387709975242615\n",
      "\n",
      "    111200\t  0.164109\t  0.163877\t  0.164483\t\tCURRENT LEARNING RATE: 0.16412167909539688\n",
      "previous_iter_valid_loss : 0.16269512474536896\n",
      "\n",
      "    111400\t  0.162888\t  0.162695\t  0.164428\t\tCURRENT LEARNING RATE: 0.16379376376184476\n",
      "previous_iter_valid_loss : 0.16141003370285034\n",
      "\n",
      "    111600\t  0.161562\t  0.161410\t  0.164410\t\tCURRENT LEARNING RATE: 0.16346650360356604\n",
      "previous_iter_valid_loss : 0.16511552035808563\n",
      "\n",
      "    111800\t  0.165341\t  0.165116\t  0.164285\t\tCURRENT LEARNING RATE: 0.16313989731151973\n",
      "previous_iter_valid_loss : 0.16345062851905823\n",
      "\n",
      "    112000\t  0.163645\t  0.163451\t  0.164283\t\tCURRENT LEARNING RATE: 0.16281394357928017\n",
      "previous_iter_valid_loss : 0.16200357675552368\n",
      "\n",
      "    112200\t  0.162151\t  0.162004\t  0.164178\t\tCURRENT LEARNING RATE: 0.162488641103032\n",
      "previous_iter_valid_loss : 0.1614156812429428\n",
      "\n",
      "    112400\t  0.161557\t  0.161416\t  0.164154\t\tCURRENT LEARNING RATE: 0.16216398858156494\n",
      "previous_iter_valid_loss : 0.16453969478607178\n",
      "\n",
      "    112600\t  0.164683\t  0.164540\t  0.164116\t\tCURRENT LEARNING RATE: 0.1618399847162684\n",
      "previous_iter_valid_loss : 0.16186510026454926\n",
      "\n",
      "    112800\t  0.162021\t  0.161865\t  0.164030\t\tCURRENT LEARNING RATE: 0.16151662821112647\n",
      "previous_iter_valid_loss : 0.16353653371334076\n",
      "\n",
      "    113000\t  0.163721\t  0.163537\t  0.164026\t\tCURRENT LEARNING RATE: 0.16119391777271277\n",
      "previous_iter_valid_loss : 0.16366331279277802\n",
      "\n",
      "    113200\t  0.163784\t  0.163663\t  0.164014\t\tCURRENT LEARNING RATE: 0.1608718521101851\n",
      "previous_iter_valid_loss : 0.1632036566734314\n",
      "\n",
      "    113400\t  0.163374\t  0.163204\t  0.163958\t\tCURRENT LEARNING RATE: 0.16055042993528035\n",
      "previous_iter_valid_loss : 0.16588424146175385\n",
      "\n",
      "    113600\t  0.166104\t  0.165884\t  0.163919\t\tCURRENT LEARNING RATE: 0.1602296499623094\n",
      "previous_iter_valid_loss : 0.1635940670967102\n",
      "\n",
      "    113800\t  0.163816\t  0.163594\t  0.163893\t\tCURRENT LEARNING RATE: 0.15990951090815197\n",
      "previous_iter_valid_loss : 0.16414649784564972\n",
      "\n",
      "    114000\t  0.164381\t  0.164146\t  0.163887\t\tCURRENT LEARNING RATE: 0.15959001149225135\n",
      "previous_iter_valid_loss : 0.16155844926834106\n",
      "\n",
      "    114200\t  0.161731\t  0.161558\t  0.163874\t\tCURRENT LEARNING RATE: 0.1592711504366095\n",
      "previous_iter_valid_loss : 0.16365066170692444\n",
      "\n",
      "    114400\t  0.163800\t  0.163651\t  0.163743\t\tCURRENT LEARNING RATE: 0.15895292646578177\n",
      "previous_iter_valid_loss : 0.16518013179302216\n",
      "\n",
      "    114600\t  0.165315\t  0.165180\t  0.163728\t\tCURRENT LEARNING RATE: 0.15863533830687182\n",
      "previous_iter_valid_loss : 0.16376850008964539\n",
      "\n",
      "    114800\t  0.163971\t  0.163769\t  0.163705\t\tCURRENT LEARNING RATE: 0.15831838468952664\n",
      "previous_iter_valid_loss : 0.16265618801116943\n",
      "\n",
      "    115000\t  0.162811\t  0.162656\t  0.163694\t\tCURRENT LEARNING RATE: 0.15800206434593128\n",
      "previous_iter_valid_loss : 0.16350896656513214\n",
      "\n",
      "    115200\t  0.163725\t  0.163509\t  0.163687\t\tCURRENT LEARNING RATE: 0.15768637601080399\n",
      "previous_iter_valid_loss : 0.16161911189556122\n",
      "\n",
      "    115400\t  0.161854\t  0.161619\t  0.163669\t\tCURRENT LEARNING RATE: 0.15737131842139096\n",
      "previous_iter_valid_loss : 0.16121122241020203\n",
      "\n",
      "    115600\t  0.161394\t  0.161211\t  0.163629\t\tCURRENT LEARNING RATE: 0.15705689031746148\n",
      "previous_iter_valid_loss : 0.1631380319595337\n",
      "\n",
      "    115800\t  0.163353\t  0.163138\t  0.163585\t\tCURRENT LEARNING RATE: 0.15674309044130266\n",
      "previous_iter_valid_loss : 0.16463825106620789\n",
      "\n",
      "    116000\t  0.164843\t  0.164638\t  0.163589\t\tCURRENT LEARNING RATE: 0.1564299175377146\n",
      "previous_iter_valid_loss : 0.16235284507274628\n",
      "\n",
      "    116200\t  0.162537\t  0.162353\t  0.163575\t\tCURRENT LEARNING RATE: 0.15611737035400527\n",
      "previous_iter_valid_loss : 0.16207747161388397\n",
      "\n",
      "    116400\t  0.162316\t  0.162077\t  0.163566\t\tCURRENT LEARNING RATE: 0.15580544763998552\n",
      "previous_iter_valid_loss : 0.1620386391878128\n",
      "\n",
      "    116600\t  0.162246\t  0.162039\t  0.163531\t\tCURRENT LEARNING RATE: 0.15549414814796406\n",
      "previous_iter_valid_loss : 0.16135413944721222\n",
      "\n",
      "    116800\t  0.161508\t  0.161354\t  0.163510\t\tCURRENT LEARNING RATE: 0.15518347063274252\n",
      "previous_iter_valid_loss : 0.1678115427494049\n",
      "\n",
      "    117000\t  0.168082\t  0.167812\t  0.163499\t\tCURRENT LEARNING RATE: 0.1548734138516104\n",
      "previous_iter_valid_loss : 0.1671174019575119\n",
      "\n",
      "    117200\t  0.167291\t  0.167117\t  0.163514\t\tCURRENT LEARNING RATE: 0.1545639765643402\n",
      "previous_iter_valid_loss : 0.16304297745227814\n",
      "\n",
      "    117400\t  0.163265\t  0.163043\t  0.163493\t\tCURRENT LEARNING RATE: 0.15425515753318236\n",
      "previous_iter_valid_loss : 0.16305959224700928\n",
      "\n",
      "    117600\t  0.163285\t  0.163060\t  0.163488\t\tCURRENT LEARNING RATE: 0.1539469555228603\n",
      "previous_iter_valid_loss : 0.1616469770669937\n",
      "\n",
      "    117800\t  0.161814\t  0.161647\t  0.163477\t\tCURRENT LEARNING RATE: 0.15363936930056563\n",
      "previous_iter_valid_loss : 0.16423369944095612\n",
      "\n",
      "    118000\t  0.164432\t  0.164234\t  0.163482\t\tCURRENT LEARNING RATE: 0.153332397635953\n",
      "previous_iter_valid_loss : 0.1630595326423645\n",
      "\n",
      "    118200\t  0.163268\t  0.163060\t  0.163486\t\tCURRENT LEARNING RATE: 0.15302603930113534\n",
      "previous_iter_valid_loss : 0.1631217747926712\n",
      "\n",
      "    118400\t  0.163365\t  0.163122\t  0.163486\t\tCURRENT LEARNING RATE: 0.15272029307067894\n",
      "previous_iter_valid_loss : 0.16267827153205872\n",
      "\n",
      "    118600\t  0.162907\t  0.162678\t  0.163463\t\tCURRENT LEARNING RATE: 0.15241515772159842\n",
      "previous_iter_valid_loss : 0.16131000220775604\n",
      "\n",
      "    118800\t  0.161563\t  0.161310\t  0.163452\t\tCURRENT LEARNING RATE: 0.15211063203335204\n",
      "previous_iter_valid_loss : 0.1640470027923584\n",
      "\n",
      "    119000\t  0.164238\t  0.164047\t  0.163447\t\tCURRENT LEARNING RATE: 0.15180671478783658\n",
      "previous_iter_valid_loss : 0.16157931089401245\n",
      "\n",
      "    119200\t  0.161849\t  0.161579\t  0.163444\t\tCURRENT LEARNING RATE: 0.1515034047693827\n",
      "previous_iter_valid_loss : 0.16206325590610504\n",
      "\n",
      "    119400\t  0.162325\t  0.162063\t  0.163436\t\tCURRENT LEARNING RATE: 0.1512007007647499\n",
      "previous_iter_valid_loss : 0.16423912346363068\n",
      "\n",
      "    119600\t  0.164528\t  0.164239\t  0.163424\t\tCURRENT LEARNING RATE: 0.15089860156312174\n",
      "previous_iter_valid_loss : 0.16231277585029602\n",
      "\n",
      "    119800\t  0.162519\t  0.162313\t  0.163417\t\tCURRENT LEARNING RATE: 0.15059710595610107\n",
      "previous_iter_valid_loss : 0.16320115327835083\n",
      "\n",
      "    120000\t  0.163460\t  0.163201\t  0.163412\t\tCURRENT LEARNING RATE: 0.150296212737705\n",
      "previous_iter_valid_loss : 0.16123318672180176\n",
      "\n",
      "    120200\t  0.161452\t  0.161233\t  0.163397\t\tCURRENT LEARNING RATE: 0.14999592070436024\n",
      "previous_iter_valid_loss : 0.16143770515918732\n",
      "\n",
      "    120400\t  0.161665\t  0.161438\t  0.163385\t\tCURRENT LEARNING RATE: 0.14969622865489834\n",
      "previous_iter_valid_loss : 0.16184337437152863\n",
      "\n",
      "    120600\t  0.162078\t  0.161843\t  0.163383\t\tCURRENT LEARNING RATE: 0.14939713539055063\n",
      "previous_iter_valid_loss : 0.16254843771457672\n",
      "\n",
      "    120800\t  0.162792\t  0.162548\t  0.163382\t\tCURRENT LEARNING RATE: 0.1490986397149437\n",
      "previous_iter_valid_loss : 0.16284380853176117\n",
      "\n",
      "    121000\t  0.163037\t  0.162844\t  0.163387\t\tCURRENT LEARNING RATE: 0.14880074043409441\n",
      "previous_iter_valid_loss : 0.17134876549243927\n",
      "\n",
      "    121200\t  0.171611\t  0.171349\t  0.163432\t\tCURRENT LEARNING RATE: 0.14850343635640526\n",
      "previous_iter_valid_loss : 0.16246049106121063\n",
      "\n",
      "    121400\t  0.162743\t  0.162460\t  0.163422\t\tCURRENT LEARNING RATE: 0.14820672629265955\n",
      "previous_iter_valid_loss : 0.16495372354984283\n",
      "\n",
      "    121600\t  0.165221\t  0.164954\t  0.163421\t\tCURRENT LEARNING RATE: 0.1479106090560166\n",
      "previous_iter_valid_loss : 0.16425375640392303\n",
      "\n",
      "    121800\t  0.164543\t  0.164254\t  0.163422\t\tCURRENT LEARNING RATE: 0.1476150834620071\n",
      "previous_iter_valid_loss : 0.1630474478006363\n",
      "\n",
      "    122000\t  0.163322\t  0.163047\t  0.163404\t\tCURRENT LEARNING RATE: 0.14732014832852827\n",
      "previous_iter_valid_loss : 0.16366128623485565\n",
      "\n",
      "    122200\t  0.163901\t  0.163661\t  0.163401\t\tCURRENT LEARNING RATE: 0.14702580247583918\n",
      "previous_iter_valid_loss : 0.16309072077274323\n",
      "\n",
      "    122400\t  0.163343\t  0.163091\t  0.163399\t\tCURRENT LEARNING RATE: 0.14673204472655604\n",
      "previous_iter_valid_loss : 0.16228093206882477\n",
      "\n",
      "    122600\t  0.162473\t  0.162281\t  0.163389\t\tCURRENT LEARNING RATE: 0.14643887390564744\n",
      "previous_iter_valid_loss : 0.16367566585540771\n",
      "\n",
      "    122800\t  0.163905\t  0.163676\t  0.163397\t\tCURRENT LEARNING RATE: 0.1461462888404297\n",
      "previous_iter_valid_loss : 0.16254784166812897\n",
      "\n",
      "    123000\t  0.162722\t  0.162548\t  0.163383\t\tCURRENT LEARNING RATE: 0.1458542883605622\n",
      "previous_iter_valid_loss : 0.16151146590709686\n",
      "\n",
      "    123200\t  0.161767\t  0.161511\t  0.163378\t\tCURRENT LEARNING RATE: 0.1455628712980426\n",
      "previous_iter_valid_loss : 0.16478781402111053\n",
      "\n",
      "    123400\t  0.165021\t  0.164788\t  0.163390\t\tCURRENT LEARNING RATE: 0.1452720364872023\n",
      "previous_iter_valid_loss : 0.16302256286144257\n",
      "\n",
      "    123600\t  0.163260\t  0.163023\t  0.163394\t\tCURRENT LEARNING RATE: 0.1449817827647016\n",
      "previous_iter_valid_loss : 0.16280710697174072\n",
      "\n",
      "    123800\t  0.163039\t  0.162807\t  0.163385\t\tCURRENT LEARNING RATE: 0.1446921089695253\n",
      "previous_iter_valid_loss : 0.16171060502529144\n",
      "\n",
      "    124000\t  0.161966\t  0.161711\t  0.163380\t\tCURRENT LEARNING RATE: 0.14440301394297783\n",
      "previous_iter_valid_loss : 0.16162540018558502\n",
      "\n",
      "    124200\t  0.161847\t  0.161625\t  0.163354\t\tCURRENT LEARNING RATE: 0.14411449652867864\n",
      "previous_iter_valid_loss : 0.1616305112838745\n",
      "\n",
      "    124400\t  0.161836\t  0.161631\t  0.163330\t\tCURRENT LEARNING RATE: 0.1438265555725577\n",
      "previous_iter_valid_loss : 0.16208304464817047\n",
      "\n",
      "    124600\t  0.162287\t  0.162083\t  0.163314\t\tCURRENT LEARNING RATE: 0.14353918992285084\n",
      "previous_iter_valid_loss : 0.1618179827928543\n",
      "\n",
      "    124800\t  0.161995\t  0.161818\t  0.163307\t\tCURRENT LEARNING RATE: 0.14325239843009505\n",
      "previous_iter_valid_loss : 0.16271694004535675\n",
      "\n",
      "    125000\t  0.162926\t  0.162717\t  0.163306\t\tCURRENT LEARNING RATE: 0.142966179947124\n",
      "previous_iter_valid_loss : 0.16180044412612915\n",
      "\n",
      "    125200\t  0.162009\t  0.161800\t  0.163298\t\tCURRENT LEARNING RATE: 0.14268053332906333\n",
      "previous_iter_valid_loss : 0.16224387288093567\n",
      "\n",
      "    125400\t  0.162478\t  0.162244\t  0.163293\t\tCURRENT LEARNING RATE: 0.14239545743332624\n",
      "previous_iter_valid_loss : 0.16400673985481262\n",
      "\n",
      "    125600\t  0.164256\t  0.164007\t  0.163280\t\tCURRENT LEARNING RATE: 0.14211095111960872\n",
      "previous_iter_valid_loss : 0.16135931015014648\n",
      "\n",
      "    125800\t  0.161639\t  0.161359\t  0.163272\t\tCURRENT LEARNING RATE: 0.1418270132498852\n",
      "previous_iter_valid_loss : 0.16358190774917603\n",
      "\n",
      "    126000\t  0.163882\t  0.163582\t  0.163278\t\tCURRENT LEARNING RATE: 0.14154364268840375\n",
      "previous_iter_valid_loss : 0.16153928637504578\n",
      "\n",
      "    126200\t  0.161772\t  0.161539\t  0.163278\t\tCURRENT LEARNING RATE: 0.1412608383016818\n",
      "previous_iter_valid_loss : 0.1621425598859787\n",
      "\n",
      "    126400\t  0.162405\t  0.162143\t  0.163271\t\tCURRENT LEARNING RATE: 0.14097859895850137\n",
      "previous_iter_valid_loss : 0.16469097137451172\n",
      "\n",
      "    126600\t  0.164955\t  0.164691\t  0.163283\t\tCURRENT LEARNING RATE: 0.14069692352990476\n",
      "previous_iter_valid_loss : 0.1633494645357132\n",
      "\n",
      "    126800\t  0.163560\t  0.163349\t  0.163289\t\tCURRENT LEARNING RATE: 0.1404158108891899\n",
      "previous_iter_valid_loss : 0.16261565685272217\n",
      "\n",
      "    127000\t  0.162825\t  0.162616\t  0.163279\t\tCURRENT LEARNING RATE: 0.14013525991190579\n",
      "previous_iter_valid_loss : 0.16161419451236725\n",
      "\n",
      "    127200\t  0.161847\t  0.161614\t  0.163271\t\tCURRENT LEARNING RATE: 0.13985526947584817\n",
      "previous_iter_valid_loss : 0.16168177127838135\n",
      "\n",
      "    127400\t  0.161841\t  0.161682\t  0.163259\t\tCURRENT LEARNING RATE: 0.13957583846105492\n",
      "previous_iter_valid_loss : 0.16151976585388184\n",
      "\n",
      "    127600\t  0.161665\t  0.161520\t  0.163242\t\tCURRENT LEARNING RATE: 0.13929696574980163\n",
      "previous_iter_valid_loss : 0.1627415269613266\n",
      "\n",
      "    127800\t  0.162932\t  0.162742\t  0.163248\t\tCURRENT LEARNING RATE: 0.13901865022659707\n",
      "previous_iter_valid_loss : 0.1623857617378235\n",
      "\n",
      "    128000\t  0.162656\t  0.162386\t  0.163249\t\tCURRENT LEARNING RATE: 0.13874089077817875\n",
      "previous_iter_valid_loss : 0.16154728829860687\n",
      "\n",
      "    128200\t  0.161741\t  0.161547\t  0.163235\t\tCURRENT LEARNING RATE: 0.13846368629350855\n",
      "previous_iter_valid_loss : 0.1616944521665573\n",
      "\n",
      "    128400\t  0.161873\t  0.161694\t  0.163216\t\tCURRENT LEARNING RATE: 0.13818703566376817\n",
      "previous_iter_valid_loss : 0.16208791732788086\n",
      "\n",
      "    128600\t  0.162304\t  0.162088\t  0.163192\t\tCURRENT LEARNING RATE: 0.13791093778235466\n",
      "previous_iter_valid_loss : 0.16470567882061005\n",
      "\n",
      "    128800\t  0.164958\t  0.164706\t  0.163182\t\tCURRENT LEARNING RATE: 0.13763539154487617\n",
      "previous_iter_valid_loss : 0.16258934140205383\n",
      "\n",
      "    129000\t  0.162760\t  0.162589\t  0.163181\t\tCURRENT LEARNING RATE: 0.13736039584914736\n",
      "previous_iter_valid_loss : 0.1677134931087494\n",
      "\n",
      "    129200\t  0.167927\t  0.167713\t  0.163201\t\tCURRENT LEARNING RATE: 0.1370859495951851\n",
      "previous_iter_valid_loss : 0.16192568838596344\n",
      "\n",
      "    129400\t  0.162124\t  0.161926\t  0.163198\t\tCURRENT LEARNING RATE: 0.13681205168520402\n",
      "previous_iter_valid_loss : 0.16261860728263855\n",
      "\n",
      "    129600\t  0.162802\t  0.162619\t  0.163198\t\tCURRENT LEARNING RATE: 0.1365387010236121\n",
      "previous_iter_valid_loss : 0.16188457608222961\n",
      "\n",
      "    129800\t  0.162095\t  0.161885\t  0.163184\t\tCURRENT LEARNING RATE: 0.1362658965170063\n",
      "previous_iter_valid_loss : 0.16250629723072052\n",
      "\n",
      "    130000\t  0.162717\t  0.162506\t  0.163182\t\tCURRENT LEARNING RATE: 0.13599363707416826\n",
      "previous_iter_valid_loss : 0.16178084909915924\n",
      "\n",
      "    130200\t  0.162017\t  0.161781\t  0.163172\t\tCURRENT LEARNING RATE: 0.13572192160605986\n",
      "previous_iter_valid_loss : 0.16182300448417664\n",
      "\n",
      "    130400\t  0.162000\t  0.161823\t  0.163172\t\tCURRENT LEARNING RATE: 0.13545074902581883\n",
      "previous_iter_valid_loss : 0.16164487600326538\n",
      "\n",
      "    130600\t  0.161824\t  0.161645\t  0.163173\t\tCURRENT LEARNING RATE: 0.1351801182487545\n",
      "previous_iter_valid_loss : 0.16519372165203094\n",
      "\n",
      "    130800\t  0.165422\t  0.165194\t  0.163186\t\tCURRENT LEARNING RATE: 0.1349100281923434\n",
      "previous_iter_valid_loss : 0.16298730671405792\n",
      "\n",
      "    131000\t  0.163143\t  0.162987\t  0.163173\t\tCURRENT LEARNING RATE: 0.13464047777622498\n",
      "previous_iter_valid_loss : 0.16425800323486328\n",
      "\n",
      "    131200\t  0.164459\t  0.164258\t  0.163185\t\tCURRENT LEARNING RATE: 0.13437146592219718\n",
      "previous_iter_valid_loss : 0.16375380754470825\n",
      "\n",
      "    131400\t  0.164008\t  0.163754\t  0.163169\t\tCURRENT LEARNING RATE: 0.1341029915542122\n",
      "previous_iter_valid_loss : 0.1621059626340866\n",
      "\n",
      "    131600\t  0.162308\t  0.162106\t  0.163161\t\tCURRENT LEARNING RATE: 0.13383505359837228\n",
      "previous_iter_valid_loss : 0.16152843832969666\n",
      "\n",
      "    131800\t  0.161661\t  0.161528\t  0.163151\t\tCURRENT LEARNING RATE: 0.13356765098292517\n",
      "previous_iter_valid_loss : 0.16227424144744873\n",
      "\n",
      "    132000\t  0.162499\t  0.162274\t  0.163147\t\tCURRENT LEARNING RATE: 0.1333007826382601\n",
      "previous_iter_valid_loss : 0.16120752692222595\n",
      "\n",
      "    132200\t  0.161388\t  0.161208\t  0.163141\t\tCURRENT LEARNING RATE: 0.13303444749690332\n",
      "previous_iter_valid_loss : 0.1614180952310562\n",
      "\n",
      "    132400\t  0.161598\t  0.161418\t  0.163131\t\tCURRENT LEARNING RATE: 0.1327686444935139\n",
      "previous_iter_valid_loss : 0.16128161549568176\n",
      "\n",
      "    132600\t  0.161472\t  0.161282\t  0.163114\t\tCURRENT LEARNING RATE: 0.13250337256487946\n",
      "previous_iter_valid_loss : 0.16283202171325684\n",
      "\n",
      "    132800\t  0.163025\t  0.162832\t  0.163121\t\tCURRENT LEARNING RATE: 0.13223863064991198\n",
      "previous_iter_valid_loss : 0.16431842744350433\n",
      "\n",
      "    133000\t  0.164544\t  0.164318\t  0.163131\t\tCURRENT LEARNING RATE: 0.1319744176896434\n",
      "previous_iter_valid_loss : 0.16231346130371094\n",
      "\n",
      "    133200\t  0.162534\t  0.162313\t  0.163130\t\tCURRENT LEARNING RATE: 0.13171073262722155\n",
      "previous_iter_valid_loss : 0.16189612448215485\n",
      "\n",
      "    133400\t  0.162086\t  0.161896\t  0.163131\t\tCURRENT LEARNING RATE: 0.13144757440790583\n",
      "previous_iter_valid_loss : 0.1630619466304779\n",
      "\n",
      "    133600\t  0.163213\t  0.163062\t  0.163120\t\tCURRENT LEARNING RATE: 0.131184941979063\n",
      "previous_iter_valid_loss : 0.1629360020160675\n",
      "\n",
      "    133800\t  0.163087\t  0.162936\t  0.163125\t\tCURRENT LEARNING RATE: 0.130922834290163\n",
      "previous_iter_valid_loss : 0.16148819029331207\n",
      "\n",
      "    134000\t  0.161685\t  0.161488\t  0.163123\t\tCURRENT LEARNING RATE: 0.1306612502927747\n",
      "previous_iter_valid_loss : 0.16234932839870453\n",
      "\n",
      "    134200\t  0.162566\t  0.162349\t  0.163120\t\tCURRENT LEARNING RATE: 0.13040018894056182\n",
      "previous_iter_valid_loss : 0.16172060370445251\n",
      "\n",
      "    134400\t  0.161887\t  0.161721\t  0.163122\t\tCURRENT LEARNING RATE: 0.13013964918927856\n",
      "previous_iter_valid_loss : 0.16200336813926697\n",
      "\n",
      "    134600\t  0.162172\t  0.162003\t  0.163121\t\tCURRENT LEARNING RATE: 0.12987962999676556\n",
      "previous_iter_valid_loss : 0.16152043640613556\n",
      "\n",
      "    134800\t  0.161684\t  0.161520\t  0.163108\t\tCURRENT LEARNING RATE: 0.12962013032294575\n",
      "previous_iter_valid_loss : 0.16487281024456024\n",
      "\n",
      "    135000\t  0.165099\t  0.164873\t  0.163115\t\tCURRENT LEARNING RATE: 0.12936114912982002\n",
      "previous_iter_valid_loss : 0.16326352953910828\n",
      "\n",
      "    135200\t  0.163465\t  0.163264\t  0.163106\t\tCURRENT LEARNING RATE: 0.12910268538146333\n",
      "previous_iter_valid_loss : 0.16290147602558136\n",
      "\n",
      "    135400\t  0.163051\t  0.162901\t  0.163114\t\tCURRENT LEARNING RATE: 0.12884473804402027\n",
      "previous_iter_valid_loss : 0.16256007552146912\n",
      "\n",
      "    135600\t  0.162734\t  0.162560\t  0.163093\t\tCURRENT LEARNING RATE: 0.1285873060857012\n",
      "previous_iter_valid_loss : 0.1655200570821762\n",
      "\n",
      "    135800\t  0.165754\t  0.165520\t  0.163103\t\tCURRENT LEARNING RATE: 0.12833038847677794\n",
      "previous_iter_valid_loss : 0.16244055330753326\n",
      "\n",
      "    136000\t  0.162605\t  0.162441\t  0.163106\t\tCURRENT LEARNING RATE: 0.12807398418957966\n",
      "previous_iter_valid_loss : 0.16426481306552887\n",
      "\n",
      "    136200\t  0.164506\t  0.164265\t  0.163111\t\tCURRENT LEARNING RATE: 0.12781809219848891\n",
      "previous_iter_valid_loss : 0.16116850078105927\n",
      "\n",
      "    136400\t  0.161344\t  0.161169\t  0.163105\t\tCURRENT LEARNING RATE: 0.1275627114799374\n",
      "previous_iter_valid_loss : 0.16258563101291656\n",
      "\n",
      "    136600\t  0.162751\t  0.162586\t  0.163102\t\tCURRENT LEARNING RATE: 0.12730784101240186\n",
      "previous_iter_valid_loss : 0.1617189347743988\n",
      "\n",
      "    136800\t  0.161876\t  0.161719\t  0.163093\t\tCURRENT LEARNING RATE: 0.12705347977640014\n",
      "previous_iter_valid_loss : 0.16361063718795776\n",
      "\n",
      "    137000\t  0.163747\t  0.163611\t  0.163102\t\tCURRENT LEARNING RATE: 0.12679962675448692\n",
      "previous_iter_valid_loss : 0.16217859089374542\n",
      "\n",
      "    137200\t  0.162408\t  0.162179\t  0.163091\t\tCURRENT LEARNING RATE: 0.12654628093124978\n",
      "previous_iter_valid_loss : 0.16210255026817322\n",
      "\n",
      "    137400\t  0.162294\t  0.162103\t  0.163083\t\tCURRENT LEARNING RATE: 0.12629344129330514\n",
      "previous_iter_valid_loss : 0.16411036252975464\n",
      "\n",
      "    137600\t  0.164234\t  0.164110\t  0.163068\t\tCURRENT LEARNING RATE: 0.126041106829294\n",
      "previous_iter_valid_loss : 0.16152149438858032\n",
      "\n",
      "    137800\t  0.161706\t  0.161521\t  0.163067\t\tCURRENT LEARNING RATE: 0.12578927652987826\n",
      "previous_iter_valid_loss : 0.16199570894241333\n",
      "\n",
      "    138000\t  0.162151\t  0.161996\t  0.163071\t\tCURRENT LEARNING RATE: 0.12553794938773635\n",
      "previous_iter_valid_loss : 0.16518017649650574\n",
      "\n",
      "    138200\t  0.165443\t  0.165180\t  0.163090\t\tCURRENT LEARNING RATE: 0.1252871243975594\n",
      "previous_iter_valid_loss : 0.16257934272289276\n",
      "\n",
      "    138400\t  0.162731\t  0.162579\t  0.163091\t\tCURRENT LEARNING RATE: 0.12503680055604707\n",
      "previous_iter_valid_loss : 0.16329079866409302\n",
      "\n",
      "    138600\t  0.163456\t  0.163291\t  0.163091\t\tCURRENT LEARNING RATE: 0.12478697686190367\n",
      "previous_iter_valid_loss : 0.16329945623874664\n",
      "\n",
      "    138800\t  0.163516\t  0.163299\t  0.163081\t\tCURRENT LEARNING RATE: 0.12453765231583411\n",
      "previous_iter_valid_loss : 0.1638811230659485\n",
      "\n",
      "    139000\t  0.164064\t  0.163881\t  0.163084\t\tCURRENT LEARNING RATE: 0.12428882592053986\n",
      "previous_iter_valid_loss : 0.1637042909860611\n",
      "\n",
      "    139200\t  0.163923\t  0.163704\t  0.163092\t\tCURRENT LEARNING RATE: 0.12404049668071501\n",
      "previous_iter_valid_loss : 0.16260620951652527\n",
      "\n",
      "    139400\t  0.162780\t  0.162606\t  0.163097\t\tCURRENT LEARNING RATE: 0.12379266360304228\n",
      "previous_iter_valid_loss : 0.16199783980846405\n",
      "\n",
      "    139600\t  0.162197\t  0.161998\t  0.163075\t\tCURRENT LEARNING RATE: 0.123545325696189\n",
      "previous_iter_valid_loss : 0.16119162738323212\n",
      "\n",
      "    139800\t  0.161343\t  0.161192\t  0.163068\t\tCURRENT LEARNING RATE: 0.12329848197080324\n",
      "previous_iter_valid_loss : 0.16262978315353394\n",
      "\n",
      "    140000\t  0.162819\t  0.162630\t  0.163071\t\tCURRENT LEARNING RATE: 0.12305213143950977\n",
      "previous_iter_valid_loss : 0.16182512044906616\n",
      "\n",
      "    140200\t  0.162012\t  0.161825\t  0.163071\t\tCURRENT LEARNING RATE: 0.12280627311690613\n",
      "previous_iter_valid_loss : 0.16527310013771057\n",
      "\n",
      "    140400\t  0.165511\t  0.165273\t  0.163085\t\tCURRENT LEARNING RATE: 0.12256090601955869\n",
      "previous_iter_valid_loss : 0.1618606001138687\n",
      "\n",
      "    140600\t  0.162031\t  0.161861\t  0.163080\t\tCURRENT LEARNING RATE: 0.12231602916599875\n",
      "previous_iter_valid_loss : 0.16218651831150055\n",
      "\n",
      "    140800\t  0.162310\t  0.162187\t  0.163060\t\tCURRENT LEARNING RATE: 0.12207164157671856\n",
      "previous_iter_valid_loss : 0.1611662060022354\n",
      "\n",
      "    141000\t  0.161291\t  0.161166\t  0.163050\t\tCURRENT LEARNING RATE: 0.12182774227416743\n",
      "previous_iter_valid_loss : 0.1623363196849823\n",
      "\n",
      "    141200\t  0.162528\t  0.162336\t  0.163041\t\tCURRENT LEARNING RATE: 0.12158433028274783\n",
      "previous_iter_valid_loss : 0.16249814629554749\n",
      "\n",
      "    141400\t  0.162645\t  0.162498\t  0.163026\t\tCURRENT LEARNING RATE: 0.12134140462881149\n",
      "previous_iter_valid_loss : 0.16279420256614685\n",
      "\n",
      "    141600\t  0.162946\t  0.162794\t  0.163022\t\tCURRENT LEARNING RATE: 0.12109896434065545\n",
      "previous_iter_valid_loss : 0.16280819475650787\n",
      "\n",
      "    141800\t  0.163048\t  0.162808\t  0.162998\t\tCURRENT LEARNING RATE: 0.12085700844851822\n",
      "previous_iter_valid_loss : 0.1618065983057022\n",
      "\n",
      "    142000\t  0.162017\t  0.161807\t  0.162992\t\tCURRENT LEARNING RATE: 0.12061553598457596\n",
      "previous_iter_valid_loss : 0.16171158850193024\n",
      "\n",
      "    142200\t  0.161914\t  0.161712\t  0.162985\t\tCURRENT LEARNING RATE: 0.12037454598293844\n",
      "previous_iter_valid_loss : 0.1619151085615158\n",
      "\n",
      "    142400\t  0.162090\t  0.161915\t  0.162952\t\tCURRENT LEARNING RATE: 0.12013403747964535\n",
      "previous_iter_valid_loss : 0.16189785301685333\n",
      "\n",
      "    142600\t  0.162112\t  0.161898\t  0.162952\t\tCURRENT LEARNING RATE: 0.11989400951266235\n",
      "previous_iter_valid_loss : 0.16391772031784058\n",
      "\n",
      "    142800\t  0.164169\t  0.163918\t  0.162960\t\tCURRENT LEARNING RATE: 0.11965446112187728\n",
      "previous_iter_valid_loss : 0.1621197611093521\n",
      "\n",
      "    143000\t  0.162373\t  0.162120\t  0.162959\t\tCURRENT LEARNING RATE: 0.11941539134909622\n",
      "previous_iter_valid_loss : 0.16138416528701782\n",
      "\n",
      "    143200\t  0.161592\t  0.161384\t  0.162948\t\tCURRENT LEARNING RATE: 0.11917679923803978\n",
      "previous_iter_valid_loss : 0.1644180566072464\n",
      "\n",
      "    143400\t  0.164656\t  0.164418\t  0.162953\t\tCURRENT LEARNING RATE: 0.1189386838343392\n",
      "previous_iter_valid_loss : 0.16157019138336182\n",
      "\n",
      "    143600\t  0.161767\t  0.161570\t  0.162946\t\tCURRENT LEARNING RATE: 0.11870104418553254\n",
      "previous_iter_valid_loss : 0.1615089625120163\n",
      "\n",
      "    143800\t  0.161718\t  0.161509\t  0.162939\t\tCURRENT LEARNING RATE: 0.11846387934106088\n",
      "previous_iter_valid_loss : 0.16175800561904907\n",
      "\n",
      "    144000\t  0.161949\t  0.161758\t  0.162939\t\tCURRENT LEARNING RATE: 0.11822718835226455\n",
      "previous_iter_valid_loss : 0.16304439306259155\n",
      "\n",
      "    144200\t  0.163233\t  0.163044\t  0.162945\t\tCURRENT LEARNING RATE: 0.11799097027237926\n",
      "previous_iter_valid_loss : 0.16235864162445068\n",
      "\n",
      "    144400\t  0.162552\t  0.162359\t  0.162937\t\tCURRENT LEARNING RATE: 0.11775522415653238\n",
      "previous_iter_valid_loss : 0.16290758550167084\n",
      "\n",
      "    144600\t  0.163157\t  0.162908\t  0.162927\t\tCURRENT LEARNING RATE: 0.11751994906173914\n",
      "previous_iter_valid_loss : 0.162164568901062\n",
      "\n",
      "    144800\t  0.162401\t  0.162165\t  0.162912\t\tCURRENT LEARNING RATE: 0.11728514404689883\n",
      "previous_iter_valid_loss : 0.16141147911548615\n",
      "\n",
      "    145000\t  0.161623\t  0.161411\t  0.162894\t\tCURRENT LEARNING RATE: 0.1170508081727911\n",
      "previous_iter_valid_loss : 0.1646271049976349\n",
      "\n",
      "    145200\t  0.164819\t  0.164627\t  0.162892\t\tCURRENT LEARNING RATE: 0.11681694050207211\n",
      "previous_iter_valid_loss : 0.16179139912128448\n",
      "\n",
      "    145400\t  0.161978\t  0.161791\t  0.162868\t\tCURRENT LEARNING RATE: 0.1165835400992709\n",
      "previous_iter_valid_loss : 0.16136766970157623\n",
      "\n",
      "    145600\t  0.161551\t  0.161368\t  0.162864\t\tCURRENT LEARNING RATE: 0.11635060603078554\n",
      "previous_iter_valid_loss : 0.16217847168445587\n",
      "\n",
      "    145800\t  0.162335\t  0.162178\t  0.162858\t\tCURRENT LEARNING RATE: 0.11611813736487941\n",
      "previous_iter_valid_loss : 0.16431406140327454\n",
      "\n",
      "    146000\t  0.164541\t  0.164314\t  0.162868\t\tCURRENT LEARNING RATE: 0.11588613317167758\n",
      "previous_iter_valid_loss : 0.16166436672210693\n",
      "\n",
      "    146200\t  0.161858\t  0.161664\t  0.162855\t\tCURRENT LEARNING RATE: 0.11565459252316296\n",
      "previous_iter_valid_loss : 0.16189822554588318\n",
      "\n",
      "    146400\t  0.162064\t  0.161898\t  0.162857\t\tCURRENT LEARNING RATE: 0.11542351449317262\n",
      "previous_iter_valid_loss : 0.1615031361579895\n",
      "\n",
      "    146600\t  0.161649\t  0.161503\t  0.162845\t\tCURRENT LEARNING RATE: 0.11519289815739417\n",
      "previous_iter_valid_loss : 0.16178591549396515\n",
      "\n",
      "    146800\t  0.161953\t  0.161786\t  0.162833\t\tCURRENT LEARNING RATE: 0.11496274259336192\n",
      "previous_iter_valid_loss : 0.1616518497467041\n",
      "\n",
      "    147000\t  0.161835\t  0.161652\t  0.162832\t\tCURRENT LEARNING RATE: 0.11473304688045334\n",
      "previous_iter_valid_loss : 0.16161014139652252\n",
      "\n",
      "    147200\t  0.161811\t  0.161610\t  0.162830\t\tCURRENT LEARNING RATE: 0.11450381009988525\n",
      "previous_iter_valid_loss : 0.16284340620040894\n",
      "\n",
      "    147400\t  0.162996\t  0.162843\t  0.162834\t\tCURRENT LEARNING RATE: 0.11427503133471024\n",
      "previous_iter_valid_loss : 0.1618630737066269\n",
      "\n",
      "    147600\t  0.162016\t  0.161863\t  0.162824\t\tCURRENT LEARNING RATE: 0.11404670966981294\n",
      "previous_iter_valid_loss : 0.16180002689361572\n",
      "\n",
      "    147800\t  0.161948\t  0.161800\t  0.162819\t\tCURRENT LEARNING RATE: 0.11381884419190637\n",
      "previous_iter_valid_loss : 0.1616823822259903\n",
      "\n",
      "    148000\t  0.161825\t  0.161682\t  0.162805\t\tCURRENT LEARNING RATE: 0.11359143398952833\n",
      "previous_iter_valid_loss : 0.16144615411758423\n",
      "\n",
      "    148200\t  0.161595\t  0.161446\t  0.162793\t\tCURRENT LEARNING RATE: 0.11336447815303771\n",
      "previous_iter_valid_loss : 0.16152985394001007\n",
      "\n",
      "    148400\t  0.161637\t  0.161530\t  0.162792\t\tCURRENT LEARNING RATE: 0.11313797577461085\n",
      "previous_iter_valid_loss : 0.16249501705169678\n",
      "\n",
      "    148600\t  0.162671\t  0.162495\t  0.162771\t\tCURRENT LEARNING RATE: 0.11291192594823793\n",
      "previous_iter_valid_loss : 0.16627395153045654\n",
      "\n",
      "    148800\t  0.166390\t  0.166274\t  0.162797\t\tCURRENT LEARNING RATE: 0.11268632776971936\n",
      "previous_iter_valid_loss : 0.16112875938415527\n",
      "\n",
      "\n",
      "Current valid loss: 0.16112875938415527;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "    149000\t  0.161298\t  0.161129\t  0.162783\t\tCURRENT LEARNING RATE: 0.11246118033666212\n",
      "previous_iter_valid_loss : 0.16144458949565887\n",
      "\n",
      "    149200\t  0.161619\t  0.161445\t  0.162766\t\tCURRENT LEARNING RATE: 0.11223648274847617\n",
      "previous_iter_valid_loss : 0.16261142492294312\n",
      "\n",
      "    149400\t  0.162798\t  0.162611\t  0.162769\t\tCURRENT LEARNING RATE: 0.11201223410637087\n",
      "previous_iter_valid_loss : 0.16170379519462585\n",
      "\n",
      "    149600\t  0.161885\t  0.161704\t  0.162763\t\tCURRENT LEARNING RATE: 0.11178843351335134\n",
      "previous_iter_valid_loss : 0.16201025247573853\n",
      "\n",
      "    149800\t  0.162221\t  0.162010\t  0.162760\t\tCURRENT LEARNING RATE: 0.11156508007421491\n",
      "previous_iter_valid_loss : 0.16225291788578033\n",
      "\n",
      "    150000\t  0.162445\t  0.162253\t  0.162760\t\tCURRENT LEARNING RATE: 0.11134217289554754\n",
      "previous_iter_valid_loss : 0.16164255142211914\n",
      "\n",
      "    150200\t  0.161884\t  0.161643\t  0.162755\t\tCURRENT LEARNING RATE: 0.1111197110857202\n",
      "previous_iter_valid_loss : 0.16136930882930756\n",
      "\n",
      "    150400\t  0.161572\t  0.161369\t  0.162738\t\tCURRENT LEARNING RATE: 0.11089769375488537\n",
      "previous_iter_valid_loss : 0.16119997203350067\n",
      "\n",
      "    150600\t  0.161433\t  0.161200\t  0.162733\t\tCURRENT LEARNING RATE: 0.11067612001497341\n",
      "previous_iter_valid_loss : 0.161928191781044\n",
      "\n",
      "    150800\t  0.162133\t  0.161928\t  0.162731\t\tCURRENT LEARNING RATE: 0.1104549889796891\n",
      "previous_iter_valid_loss : 0.16160383820533752\n",
      "\n",
      "    151000\t  0.161817\t  0.161604\t  0.162710\t\tCURRENT LEARNING RATE: 0.11023429976450796\n",
      "previous_iter_valid_loss : 0.16277053952217102\n",
      "\n",
      "    151200\t  0.162999\t  0.162771\t  0.162704\t\tCURRENT LEARNING RATE: 0.11001405148667287\n",
      "previous_iter_valid_loss : 0.16421599686145782\n",
      "\n",
      "    151400\t  0.164453\t  0.164216\t  0.162712\t\tCURRENT LEARNING RATE: 0.10979424326519041\n",
      "previous_iter_valid_loss : 0.16516566276550293\n",
      "\n",
      "    151600\t  0.165408\t  0.165166\t  0.162730\t\tCURRENT LEARNING RATE: 0.1095748742208274\n",
      "previous_iter_valid_loss : 0.16342546045780182\n",
      "\n",
      "    151800\t  0.163620\t  0.163425\t  0.162722\t\tCURRENT LEARNING RATE: 0.10935594347610737\n",
      "previous_iter_valid_loss : 0.1618267446756363\n",
      "\n",
      "    152000\t  0.162016\t  0.161827\t  0.162714\t\tCURRENT LEARNING RATE: 0.10913745015530707\n",
      "previous_iter_valid_loss : 0.16297827661037445\n",
      "\n",
      "    152200\t  0.163164\t  0.162978\t  0.162719\t\tCURRENT LEARNING RATE: 0.10891939338445289\n",
      "previous_iter_valid_loss : 0.1614561825990677\n",
      "\n",
      "    152400\t  0.161651\t  0.161456\t  0.162719\t\tCURRENT LEARNING RATE: 0.10870177229131749\n",
      "previous_iter_valid_loss : 0.16288165748119354\n",
      "\n",
      "    152600\t  0.163060\t  0.162882\t  0.162711\t\tCURRENT LEARNING RATE: 0.10848458600541618\n",
      "previous_iter_valid_loss : 0.161298006772995\n",
      "\n",
      "    152800\t  0.161475\t  0.161298\t  0.162708\t\tCURRENT LEARNING RATE: 0.10826783365800353\n",
      "previous_iter_valid_loss : 0.16162538528442383\n",
      "\n",
      "    153000\t  0.161754\t  0.161625\t  0.162698\t\tCURRENT LEARNING RATE: 0.10805151438206988\n",
      "previous_iter_valid_loss : 0.16213358938694\n",
      "\n",
      "    153200\t  0.162327\t  0.162134\t  0.162691\t\tCURRENT LEARNING RATE: 0.10783562731233783\n",
      "previous_iter_valid_loss : 0.16294650733470917\n",
      "\n",
      "    153400\t  0.163153\t  0.162947\t  0.162689\t\tCURRENT LEARNING RATE: 0.10762017158525879\n",
      "previous_iter_valid_loss : 0.1628132313489914\n",
      "\n",
      "    153600\t  0.163002\t  0.162813\t  0.162674\t\tCURRENT LEARNING RATE: 0.1074051463390096\n",
      "previous_iter_valid_loss : 0.1621650904417038\n",
      "\n",
      "    153800\t  0.162378\t  0.162165\t  0.162667\t\tCURRENT LEARNING RATE: 0.10719055071348897\n",
      "previous_iter_valid_loss : 0.16190923750400543\n",
      "\n",
      "    154000\t  0.162069\t  0.161909\t  0.162656\t\tCURRENT LEARNING RATE: 0.10697638385031412\n",
      "previous_iter_valid_loss : 0.16226671636104584\n",
      "\n",
      "    154200\t  0.162510\t  0.162267\t  0.162659\t\tCURRENT LEARNING RATE: 0.1067626448928173\n",
      "previous_iter_valid_loss : 0.16139554977416992\n",
      "\n",
      "    154400\t  0.161595\t  0.161396\t  0.162648\t\tCURRENT LEARNING RATE: 0.10654933298604241\n",
      "previous_iter_valid_loss : 0.16251978278160095\n",
      "\n",
      "    154600\t  0.162764\t  0.162520\t  0.162635\t\tCURRENT LEARNING RATE: 0.10633644727674152\n",
      "previous_iter_valid_loss : 0.161496102809906\n",
      "\n",
      "    154800\t  0.161708\t  0.161496\t  0.162623\t\tCURRENT LEARNING RATE: 0.10612398691337152\n",
      "previous_iter_valid_loss : 0.16161790490150452\n",
      "\n",
      "    155000\t  0.161843\t  0.161618\t  0.162618\t\tCURRENT LEARNING RATE: 0.10591195104609068\n",
      "previous_iter_valid_loss : 0.1623660922050476\n",
      "\n",
      "    155200\t  0.162563\t  0.162366\t  0.162612\t\tCURRENT LEARNING RATE: 0.10570033882675524\n",
      "previous_iter_valid_loss : 0.16362805664539337\n",
      "\n",
      "    155400\t  0.163833\t  0.163628\t  0.162622\t\tCURRENT LEARNING RATE: 0.10548914940891603\n",
      "previous_iter_valid_loss : 0.16177566349506378\n",
      "\n",
      "    155600\t  0.161936\t  0.161776\t  0.162625\t\tCURRENT LEARNING RATE: 0.10527838194781512\n",
      "previous_iter_valid_loss : 0.1617496907711029\n",
      "\n",
      "    155800\t  0.161919\t  0.161750\t  0.162618\t\tCURRENT LEARNING RATE: 0.10506803560038236\n",
      "previous_iter_valid_loss : 0.1615661382675171\n",
      "\n",
      "    156000\t  0.161745\t  0.161566\t  0.162603\t\tCURRENT LEARNING RATE: 0.1048581095252321\n",
      "previous_iter_valid_loss : 0.16213560104370117\n",
      "\n",
      "    156200\t  0.162349\t  0.162136\t  0.162602\t\tCURRENT LEARNING RATE: 0.10464860288265976\n",
      "previous_iter_valid_loss : 0.16143783926963806\n",
      "\n",
      "    156400\t  0.161634\t  0.161438\t  0.162599\t\tCURRENT LEARNING RATE: 0.10443951483463847\n",
      "previous_iter_valid_loss : 0.16340982913970947\n",
      "\n",
      "    156600\t  0.163637\t  0.163410\t  0.162605\t\tCURRENT LEARNING RATE: 0.10423084454481576\n",
      "previous_iter_valid_loss : 0.1619562953710556\n",
      "\n",
      "    156800\t  0.162141\t  0.161956\t  0.162608\t\tCURRENT LEARNING RATE: 0.10402259117851023\n",
      "previous_iter_valid_loss : 0.16147267818450928\n",
      "\n",
      "    157000\t  0.161666\t  0.161473\t  0.162577\t\tCURRENT LEARNING RATE: 0.1038147539027081\n",
      "previous_iter_valid_loss : 0.16174852848052979\n",
      "\n",
      "    157200\t  0.161925\t  0.161749\t  0.162550\t\tCURRENT LEARNING RATE: 0.10360733188606\n",
      "previous_iter_valid_loss : 0.16175580024719238\n",
      "\n",
      "    157400\t  0.161930\t  0.161756\t  0.162544\t\tCURRENT LEARNING RATE: 0.10340032429887758\n",
      "previous_iter_valid_loss : 0.16472414135932922\n",
      "\n",
      "    157600\t  0.164911\t  0.164724\t  0.162552\t\tCURRENT LEARNING RATE: 0.10319373031313023\n",
      "previous_iter_valid_loss : 0.16208961606025696\n",
      "\n",
      "    157800\t  0.162282\t  0.162090\t  0.162554\t\tCURRENT LEARNING RATE: 0.10298754910244172\n",
      "previous_iter_valid_loss : 0.16184358298778534\n",
      "\n",
      "    158000\t  0.162023\t  0.161844\t  0.162542\t\tCURRENT LEARNING RATE: 0.10278177984208695\n",
      "previous_iter_valid_loss : 0.16255152225494385\n",
      "\n",
      "    158200\t  0.162705\t  0.162552\t  0.162540\t\tCURRENT LEARNING RATE: 0.10257642170898858\n",
      "previous_iter_valid_loss : 0.1619395762681961\n",
      "\n",
      "    158400\t  0.162073\t  0.161940\t  0.162534\t\tCURRENT LEARNING RATE: 0.10237147388171382\n",
      "previous_iter_valid_loss : 0.1614474058151245\n",
      "\n",
      "    158600\t  0.161607\t  0.161447\t  0.162527\t\tCURRENT LEARNING RATE: 0.10216693554047107\n",
      "previous_iter_valid_loss : 0.16410274803638458\n",
      "\n",
      "    158800\t  0.164190\t  0.164103\t  0.162541\t\tCURRENT LEARNING RATE: 0.10196280586710671\n",
      "previous_iter_valid_loss : 0.16224732995033264\n",
      "\n",
      "    159000\t  0.162413\t  0.162247\t  0.162532\t\tCURRENT LEARNING RATE: 0.10175908404510177\n",
      "previous_iter_valid_loss : 0.16289527714252472\n",
      "\n",
      "    159200\t  0.163114\t  0.162895\t  0.162539\t\tCURRENT LEARNING RATE: 0.10155576925956869\n",
      "previous_iter_valid_loss : 0.16280131042003632\n",
      "\n",
      "    159400\t  0.162985\t  0.162801\t  0.162543\t\tCURRENT LEARNING RATE: 0.10135286069724805\n",
      "previous_iter_valid_loss : 0.16163718700408936\n",
      "\n",
      "    159600\t  0.161847\t  0.161637\t  0.162530\t\tCURRENT LEARNING RATE: 0.10115035754650535\n",
      "previous_iter_valid_loss : 0.1635551154613495\n",
      "\n",
      "    159800\t  0.163780\t  0.163555\t  0.162536\t\tCURRENT LEARNING RATE: 0.10094825899732769\n",
      "previous_iter_valid_loss : 0.16117192804813385\n",
      "\n",
      "    160000\t  0.161349\t  0.161172\t  0.162526\t\tCURRENT LEARNING RATE: 0.10074656424132063\n",
      "previous_iter_valid_loss : 0.16119331121444702\n",
      "\n",
      "    160200\t  0.161358\t  0.161193\t  0.162526\t\tCURRENT LEARNING RATE: 0.10054527247170486\n",
      "previous_iter_valid_loss : 0.16257479786872864\n",
      "\n",
      "    160400\t  0.162698\t  0.162575\t  0.162531\t\tCURRENT LEARNING RATE: 0.10034438288331303\n",
      "previous_iter_valid_loss : 0.16181403398513794\n",
      "\n",
      "    160600\t  0.161974\t  0.161814\t  0.162531\t\tCURRENT LEARNING RATE: 0.10014389467258653\n",
      "previous_iter_valid_loss : 0.16170953214168549\n",
      "\n",
      "    160800\t  0.161856\t  0.161710\t  0.162527\t\tCURRENT LEARNING RATE: 0.09994380703757225\n",
      "previous_iter_valid_loss : 0.16668689250946045\n",
      "\n",
      "    161000\t  0.166833\t  0.166687\t  0.162546\t\tCURRENT LEARNING RATE: 0.09974411917791937\n",
      "previous_iter_valid_loss : 0.16159021854400635\n",
      "\n",
      "    161200\t  0.161768\t  0.161590\t  0.162497\t\tCURRENT LEARNING RATE: 0.0995448302948762\n",
      "previous_iter_valid_loss : 0.16329090297222137\n",
      "\n",
      "    161400\t  0.163462\t  0.163291\t  0.162501\t\tCURRENT LEARNING RATE: 0.09934593959128693\n",
      "previous_iter_valid_loss : 0.16463203728199005\n",
      "\n",
      "    161600\t  0.164789\t  0.164632\t  0.162500\t\tCURRENT LEARNING RATE: 0.09914744627158849\n",
      "previous_iter_valid_loss : 0.16118091344833374\n",
      "\n",
      "    161800\t  0.161388\t  0.161181\t  0.162484\t\tCURRENT LEARNING RATE: 0.09894934954180733\n",
      "previous_iter_valid_loss : 0.16147208213806152\n",
      "\n",
      "    162000\t  0.161669\t  0.161472\t  0.162477\t\tCURRENT LEARNING RATE: 0.09875164860955628\n",
      "previous_iter_valid_loss : 0.1636616587638855\n",
      "\n",
      "    162200\t  0.163897\t  0.163662\t  0.162477\t\tCURRENT LEARNING RATE: 0.09855434268403132\n",
      "previous_iter_valid_loss : 0.16508406400680542\n",
      "\n",
      "    162400\t  0.165300\t  0.165084\t  0.162487\t\tCURRENT LEARNING RATE: 0.09835743097600853\n",
      "previous_iter_valid_loss : 0.16194503009319305\n",
      "\n",
      "    162600\t  0.162181\t  0.161945\t  0.162485\t\tCURRENT LEARNING RATE: 0.09816091269784077\n",
      "previous_iter_valid_loss : 0.1623203158378601\n",
      "\n",
      "    162800\t  0.162532\t  0.162320\t  0.162478\t\tCURRENT LEARNING RATE: 0.09796478706345468\n",
      "previous_iter_valid_loss : 0.16227781772613525\n",
      "\n",
      "    163000\t  0.162466\t  0.162278\t  0.162477\t\tCURRENT LEARNING RATE: 0.09776905328834747\n",
      "previous_iter_valid_loss : 0.16206277906894684\n",
      "\n",
      "    163200\t  0.162221\t  0.162063\t  0.162480\t\tCURRENT LEARNING RATE: 0.09757371058958376\n",
      "previous_iter_valid_loss : 0.16153764724731445\n",
      "\n",
      "    163400\t  0.161731\t  0.161538\t  0.162463\t\tCURRENT LEARNING RATE: 0.09737875818579252\n",
      "previous_iter_valid_loss : 0.16503340005874634\n",
      "\n",
      "    163600\t  0.165240\t  0.165033\t  0.162473\t\tCURRENT LEARNING RATE: 0.09718419529716385\n",
      "previous_iter_valid_loss : 0.16140691936016083\n",
      "\n",
      "    163800\t  0.161585\t  0.161407\t  0.162466\t\tCURRENT LEARNING RATE: 0.09699002114544596\n",
      "previous_iter_valid_loss : 0.163772314786911\n",
      "\n",
      "    164000\t  0.163950\t  0.163772\t  0.162477\t\tCURRENT LEARNING RATE: 0.09679623495394196\n",
      "previous_iter_valid_loss : 0.1617068350315094\n",
      "\n",
      "    164200\t  0.161879\t  0.161707\t  0.162477\t\tCURRENT LEARNING RATE: 0.09660283594750685\n",
      "previous_iter_valid_loss : 0.1619029939174652\n",
      "\n",
      "    164400\t  0.162061\t  0.161903\t  0.162478\t\tCURRENT LEARNING RATE: 0.09640982335254432\n",
      "previous_iter_valid_loss : 0.16149254143238068\n",
      "\n",
      "    164600\t  0.161624\t  0.161493\t  0.162475\t\tCURRENT LEARNING RATE: 0.09621719639700375\n",
      "previous_iter_valid_loss : 0.16155682504177094\n",
      "\n",
      "    164800\t  0.161682\t  0.161557\t  0.162474\t\tCURRENT LEARNING RATE: 0.09602495431037707\n",
      "previous_iter_valid_loss : 0.16238655149936676\n",
      "\n",
      "    165000\t  0.162533\t  0.162387\t  0.162473\t\tCURRENT LEARNING RATE: 0.09583309632369565\n",
      "previous_iter_valid_loss : 0.16166718304157257\n",
      "\n",
      "    165200\t  0.161812\t  0.161667\t  0.162472\t\tCURRENT LEARNING RATE: 0.0956416216695273\n",
      "previous_iter_valid_loss : 0.1624062955379486\n",
      "\n",
      "    165400\t  0.162558\t  0.162406\t  0.162473\t\tCURRENT LEARNING RATE: 0.09545052958197317\n",
      "previous_iter_valid_loss : 0.16142550110816956\n",
      "\n",
      "    165600\t  0.161598\t  0.161426\t  0.162460\t\tCURRENT LEARNING RATE: 0.09525981929666462\n",
      "previous_iter_valid_loss : 0.16154661774635315\n",
      "\n",
      "    165800\t  0.161706\t  0.161547\t  0.162461\t\tCURRENT LEARNING RATE: 0.09506949005076028\n",
      "previous_iter_valid_loss : 0.16197940707206726\n",
      "\n",
      "    166000\t  0.162133\t  0.161979\t  0.162453\t\tCURRENT LEARNING RATE: 0.09487954108294289\n",
      "previous_iter_valid_loss : 0.1614733189344406\n",
      "\n",
      "    166200\t  0.161655\t  0.161473\t  0.162452\t\tCURRENT LEARNING RATE: 0.09468997163341634\n",
      "previous_iter_valid_loss : 0.16132254898548126\n",
      "\n",
      "    166400\t  0.161495\t  0.161323\t  0.162448\t\tCURRENT LEARNING RATE: 0.09450078094390257\n",
      "previous_iter_valid_loss : 0.16268570721149445\n",
      "\n",
      "    166600\t  0.162894\t  0.162686\t  0.162438\t\tCURRENT LEARNING RATE: 0.0943119682576386\n",
      "previous_iter_valid_loss : 0.163856640458107\n",
      "\n",
      "    166800\t  0.164057\t  0.163857\t  0.162441\t\tCURRENT LEARNING RATE: 0.0941235328193734\n",
      "previous_iter_valid_loss : 0.16138972342014313\n",
      "\n",
      "    167000\t  0.161554\t  0.161390\t  0.162435\t\tCURRENT LEARNING RATE: 0.09393547387536497\n",
      "previous_iter_valid_loss : 0.16518014669418335\n",
      "\n",
      "    167200\t  0.165422\t  0.165180\t  0.162452\t\tCURRENT LEARNING RATE: 0.09374779067337728\n",
      "previous_iter_valid_loss : 0.16215039789676666\n",
      "\n",
      "    167400\t  0.162305\t  0.162150\t  0.162455\t\tCURRENT LEARNING RATE: 0.0935604824626773\n",
      "previous_iter_valid_loss : 0.16188699007034302\n",
      "\n",
      "    167600\t  0.162008\t  0.161887\t  0.162457\t\tCURRENT LEARNING RATE: 0.0933735484940319\n",
      "previous_iter_valid_loss : 0.16437150537967682\n",
      "\n",
      "    167800\t  0.164533\t  0.164372\t  0.162465\t\tCURRENT LEARNING RATE: 0.09318698801970499\n",
      "previous_iter_valid_loss : 0.16167686879634857\n",
      "\n",
      "    168000\t  0.161854\t  0.161677\t  0.162461\t\tCURRENT LEARNING RATE: 0.0930008002934544\n",
      "previous_iter_valid_loss : 0.1627497673034668\n",
      "\n",
      "    168200\t  0.162934\t  0.162750\t  0.162467\t\tCURRENT LEARNING RATE: 0.09281498457052899\n",
      "previous_iter_valid_loss : 0.16438931226730347\n",
      "\n",
      "    168400\t  0.164577\t  0.164389\t  0.162481\t\tCURRENT LEARNING RATE: 0.09262954010766561\n",
      "previous_iter_valid_loss : 0.16237756609916687\n",
      "\n",
      "    168600\t  0.162557\t  0.162378\t  0.162482\t\tCURRENT LEARNING RATE: 0.09244446616308617\n",
      "previous_iter_valid_loss : 0.16201399266719818\n",
      "\n",
      "    168800\t  0.162148\t  0.162014\t  0.162469\t\tCURRENT LEARNING RATE: 0.09225976199649463\n",
      "previous_iter_valid_loss : 0.16138435900211334\n",
      "\n",
      "    169000\t  0.161563\t  0.161384\t  0.162463\t\tCURRENT LEARNING RATE: 0.0920754268690741\n",
      "previous_iter_valid_loss : 0.16117309033870697\n",
      "\n",
      "    169200\t  0.161355\t  0.161173\t  0.162430\t\tCURRENT LEARNING RATE: 0.09189146004348382\n",
      "previous_iter_valid_loss : 0.1614009290933609\n",
      "\n",
      "    169400\t  0.161576\t  0.161401\t  0.162427\t\tCURRENT LEARNING RATE: 0.09170786078385623\n",
      "previous_iter_valid_loss : 0.1613398790359497\n",
      "\n",
      "    169600\t  0.161482\t  0.161340\t  0.162421\t\tCURRENT LEARNING RATE: 0.09152462835579406\n",
      "previous_iter_valid_loss : 0.16121302545070648\n",
      "\n",
      "    169800\t  0.161362\t  0.161213\t  0.162418\t\tCURRENT LEARNING RATE: 0.09134176202636733\n",
      "previous_iter_valid_loss : 0.16237324476242065\n",
      "\n",
      "    170000\t  0.162506\t  0.162373\t  0.162417\t\tCURRENT LEARNING RATE: 0.0911592610641105\n",
      "previous_iter_valid_loss : 0.16181081533432007\n",
      "\n",
      "    170200\t  0.161979\t  0.161811\t  0.162417\t\tCURRENT LEARNING RATE: 0.09097712473901948\n",
      "previous_iter_valid_loss : 0.16195371747016907\n",
      "\n",
      "    170400\t  0.162098\t  0.161954\t  0.162418\t\tCURRENT LEARNING RATE: 0.0907953523225487\n",
      "previous_iter_valid_loss : 0.1617659032344818\n",
      "\n",
      "    170600\t  0.161895\t  0.161766\t  0.162418\t\tCURRENT LEARNING RATE: 0.0906139430876083\n",
      "previous_iter_valid_loss : 0.16412246227264404\n",
      "\n",
      "    170800\t  0.164234\t  0.164122\t  0.162413\t\tCURRENT LEARNING RATE: 0.09043289630856105\n",
      "previous_iter_valid_loss : 0.1636039912700653\n",
      "\n",
      "    171000\t  0.163724\t  0.163604\t  0.162416\t\tCURRENT LEARNING RATE: 0.09025221126121961\n",
      "previous_iter_valid_loss : 0.16138705611228943\n",
      "\n",
      "    171200\t  0.161520\t  0.161387\t  0.162402\t\tCURRENT LEARNING RATE: 0.09007188722284355\n",
      "previous_iter_valid_loss : 0.16149908304214478\n",
      "\n",
      "    171400\t  0.161641\t  0.161499\t  0.162390\t\tCURRENT LEARNING RATE: 0.08989192347213648\n",
      "previous_iter_valid_loss : 0.16459651291370392\n",
      "\n",
      "    171600\t  0.164798\t  0.164597\t  0.162403\t\tCURRENT LEARNING RATE: 0.08971231928924317\n",
      "previous_iter_valid_loss : 0.16406580805778503\n",
      "\n",
      "    171800\t  0.164207\t  0.164066\t  0.162416\t\tCURRENT LEARNING RATE: 0.08953307395574661\n",
      "previous_iter_valid_loss : 0.1613885760307312\n",
      "\n",
      "    172000\t  0.161556\t  0.161389\t  0.162411\t\tCURRENT LEARNING RATE: 0.08935418675466526\n",
      "previous_iter_valid_loss : 0.16405925154685974\n",
      "\n",
      "    172200\t  0.164230\t  0.164059\t  0.162425\t\tCURRENT LEARNING RATE: 0.08917565697045007\n",
      "previous_iter_valid_loss : 0.16229261457920074\n",
      "\n",
      "    172400\t  0.162506\t  0.162293\t  0.162430\t\tCURRENT LEARNING RATE: 0.08899748388898167\n",
      "previous_iter_valid_loss : 0.16136300563812256\n",
      "\n",
      "    172600\t  0.161547\t  0.161363\t  0.162430\t\tCURRENT LEARNING RATE: 0.08881966679756748\n",
      "previous_iter_valid_loss : 0.163424551486969\n",
      "\n",
      "    172800\t  0.163551\t  0.163425\t  0.162433\t\tCURRENT LEARNING RATE: 0.08864220498493891\n",
      "previous_iter_valid_loss : 0.16202694177627563\n",
      "\n",
      "    173000\t  0.162214\t  0.162027\t  0.162422\t\tCURRENT LEARNING RATE: 0.08846509774124846\n",
      "previous_iter_valid_loss : 0.1633157730102539\n",
      "\n",
      "    173200\t  0.163471\t  0.163316\t  0.162427\t\tCURRENT LEARNING RATE: 0.08828834435806694\n",
      "previous_iter_valid_loss : 0.16173040866851807\n",
      "\n",
      "    173400\t  0.161933\t  0.161730\t  0.162426\t\tCURRENT LEARNING RATE: 0.08811194412838055\n",
      "previous_iter_valid_loss : 0.16159725189208984\n",
      "\n",
      "    173600\t  0.161783\t  0.161597\t  0.162419\t\tCURRENT LEARNING RATE: 0.08793589634658819\n",
      "previous_iter_valid_loss : 0.16318963468074799\n",
      "\n",
      "    173800\t  0.163350\t  0.163190\t  0.162420\t\tCURRENT LEARNING RATE: 0.08776020030849843\n",
      "previous_iter_valid_loss : 0.16159173846244812\n",
      "\n",
      "    174000\t  0.161827\t  0.161592\t  0.162420\t\tCURRENT LEARNING RATE: 0.08758485531132694\n",
      "previous_iter_valid_loss : 0.16257068514823914\n",
      "\n",
      "    174200\t  0.162744\t  0.162571\t  0.162421\t\tCURRENT LEARNING RATE: 0.08740986065369347\n",
      "previous_iter_valid_loss : 0.16139400005340576\n",
      "\n",
      "    174400\t  0.161586\t  0.161394\t  0.162420\t\tCURRENT LEARNING RATE: 0.08723521563561916\n",
      "previous_iter_valid_loss : 0.16199971735477448\n",
      "\n",
      "    174600\t  0.162200\t  0.162000\t  0.162420\t\tCURRENT LEARNING RATE: 0.0870609195585237\n",
      "previous_iter_valid_loss : 0.16469764709472656\n",
      "\n",
      "    174800\t  0.164825\t  0.164698\t  0.162436\t\tCURRENT LEARNING RATE: 0.08688697172522257\n",
      "previous_iter_valid_loss : 0.1614050269126892\n",
      "\n",
      "    175000\t  0.161570\t  0.161405\t  0.162418\t\tCURRENT LEARNING RATE: 0.08671337143992418\n",
      "previous_iter_valid_loss : 0.1617630273103714\n",
      "\n",
      "    175200\t  0.161920\t  0.161763\t  0.162411\t\tCURRENT LEARNING RATE: 0.08654011800822717\n",
      "previous_iter_valid_loss : 0.16484752297401428\n",
      "\n",
      "    175400\t  0.165086\t  0.164848\t  0.162421\t\tCURRENT LEARNING RATE: 0.08636721073711758\n",
      "previous_iter_valid_loss : 0.16153988242149353\n",
      "\n",
      "    175600\t  0.161701\t  0.161540\t  0.162415\t\tCURRENT LEARNING RATE: 0.08619464893496609\n",
      "previous_iter_valid_loss : 0.16245824098587036\n",
      "\n",
      "    175800\t  0.162604\t  0.162458\t  0.162400\t\tCURRENT LEARNING RATE: 0.08602243191152527\n",
      "previous_iter_valid_loss : 0.16186392307281494\n",
      "\n",
      "    176000\t  0.162083\t  0.161864\t  0.162397\t\tCURRENT LEARNING RATE: 0.08585055897792679\n",
      "previous_iter_valid_loss : 0.16177166998386383\n",
      "\n",
      "    176200\t  0.161975\t  0.161772\t  0.162385\t\tCURRENT LEARNING RATE: 0.08567902944667868\n",
      "previous_iter_valid_loss : 0.16230033338069916\n",
      "\n",
      "    176400\t  0.162438\t  0.162300\t  0.162390\t\tCURRENT LEARNING RATE: 0.08550784263166261\n",
      "previous_iter_valid_loss : 0.16295203566551208\n",
      "\n",
      "    176600\t  0.163130\t  0.162952\t  0.162392\t\tCURRENT LEARNING RATE: 0.08533699784813108\n",
      "previous_iter_valid_loss : 0.1614008992910385\n",
      "\n",
      "    176800\t  0.161578\t  0.161401\t  0.162391\t\tCURRENT LEARNING RATE: 0.08516649441270471\n",
      "previous_iter_valid_loss : 0.16141816973686218\n",
      "\n",
      "    177000\t  0.161576\t  0.161418\t  0.162380\t\tCURRENT LEARNING RATE: 0.08499633164336956\n",
      "previous_iter_valid_loss : 0.16215258836746216\n",
      "\n",
      "    177200\t  0.162388\t  0.162153\t  0.162380\t\tCURRENT LEARNING RATE: 0.0848265088594743\n",
      "previous_iter_valid_loss : 0.16192010045051575\n",
      "\n",
      "    177400\t  0.162033\t  0.161920\t  0.162379\t\tCURRENT LEARNING RATE: 0.08465702538172759\n",
      "previous_iter_valid_loss : 0.1645495444536209\n",
      "\n",
      "    177600\t  0.164719\t  0.164550\t  0.162381\t\tCURRENT LEARNING RATE: 0.08448788053219529\n",
      "previous_iter_valid_loss : 0.16206878423690796\n",
      "\n",
      "    177800\t  0.162272\t  0.162069\t  0.162384\t\tCURRENT LEARNING RATE: 0.08431907363429775\n",
      "previous_iter_valid_loss : 0.16169680655002594\n",
      "\n",
      "    178000\t  0.161873\t  0.161697\t  0.162382\t\tCURRENT LEARNING RATE: 0.08415060401280719\n",
      "previous_iter_valid_loss : 0.1620575338602066\n",
      "\n",
      "    178200\t  0.162190\t  0.162058\t  0.162366\t\tCURRENT LEARNING RATE: 0.08398247099384487\n",
      "previous_iter_valid_loss : 0.161810964345932\n",
      "\n",
      "    178400\t  0.161928\t  0.161811\t  0.162363\t\tCURRENT LEARNING RATE: 0.0838146739048785\n",
      "previous_iter_valid_loss : 0.1614135205745697\n",
      "\n",
      "    178600\t  0.161558\t  0.161414\t  0.162353\t\tCURRENT LEARNING RATE: 0.0836472120747195\n",
      "previous_iter_valid_loss : 0.16189244389533997\n",
      "\n",
      "    178800\t  0.162053\t  0.161892\t  0.162346\t\tCURRENT LEARNING RATE: 0.08348008483352035\n",
      "previous_iter_valid_loss : 0.1611785590648651\n",
      "\n",
      "    179000\t  0.161360\t  0.161179\t  0.162333\t\tCURRENT LEARNING RATE: 0.08331329151277182\n",
      "previous_iter_valid_loss : 0.16241084039211273\n",
      "\n",
      "    179200\t  0.162605\t  0.162411\t  0.162326\t\tCURRENT LEARNING RATE: 0.08314683144530044\n",
      "previous_iter_valid_loss : 0.16162872314453125\n",
      "\n",
      "    179400\t  0.161816\t  0.161629\t  0.162321\t\tCURRENT LEARNING RATE: 0.08298070396526569\n",
      "previous_iter_valid_loss : 0.16176718473434448\n",
      "\n",
      "    179600\t  0.161965\t  0.161767\t  0.162320\t\tCURRENT LEARNING RATE: 0.08281490840815746\n",
      "previous_iter_valid_loss : 0.16130851209163666\n",
      "\n",
      "    179800\t  0.161487\t  0.161309\t  0.162321\t\tCURRENT LEARNING RATE: 0.08264944411079327\n",
      "previous_iter_valid_loss : 0.16236372292041779\n",
      "\n",
      "    180000\t  0.162516\t  0.162364\t  0.162319\t\tCURRENT LEARNING RATE: 0.08248431041131572\n",
      "previous_iter_valid_loss : 0.16353802382946014\n",
      "\n",
      "    180200\t  0.163721\t  0.163538\t  0.162328\t\tCURRENT LEARNING RATE: 0.0823195066491898\n",
      "previous_iter_valid_loss : 0.16145296394824982\n",
      "\n",
      "    180400\t  0.161606\t  0.161453\t  0.162309\t\tCURRENT LEARNING RATE: 0.08215503216520023\n",
      "previous_iter_valid_loss : 0.16197052597999573\n",
      "\n",
      "    180600\t  0.162089\t  0.161971\t  0.162309\t\tCURRENT LEARNING RATE: 0.08199088630144886\n",
      "previous_iter_valid_loss : 0.16193409264087677\n",
      "\n",
      "    180800\t  0.162094\t  0.161934\t  0.162308\t\tCURRENT LEARNING RATE: 0.08182706840135202\n",
      "previous_iter_valid_loss : 0.16176024079322815\n",
      "\n",
      "    181000\t  0.161929\t  0.161760\t  0.162311\t\tCURRENT LEARNING RATE: 0.0816635778096379\n",
      "previous_iter_valid_loss : 0.16135339438915253\n",
      "\n",
      "    181200\t  0.161534\t  0.161353\t  0.162306\t\tCURRENT LEARNING RATE: 0.08150041387234389\n",
      "previous_iter_valid_loss : 0.16154125332832336\n",
      "\n",
      "    181400\t  0.161660\t  0.161541\t  0.162301\t\tCURRENT LEARNING RATE: 0.08133757593681404\n",
      "previous_iter_valid_loss : 0.16335681080818176\n",
      "\n",
      "    181600\t  0.163454\t  0.163357\t  0.162304\t\tCURRENT LEARNING RATE: 0.08117506335169639\n",
      "previous_iter_valid_loss : 0.16312111914157867\n",
      "\n",
      "    181800\t  0.163247\t  0.163121\t  0.162306\t\tCURRENT LEARNING RATE: 0.08101287546694037\n",
      "previous_iter_valid_loss : 0.16230528056621552\n",
      "\n",
      "    182000\t  0.162445\t  0.162305\t  0.162308\t\tCURRENT LEARNING RATE: 0.08085101163379425\n",
      "previous_iter_valid_loss : 0.16169723868370056\n",
      "\n",
      "    182200\t  0.161848\t  0.161697\t  0.162308\t\tCURRENT LEARNING RATE: 0.08068947120480247\n",
      "previous_iter_valid_loss : 0.16174840927124023\n",
      "\n",
      "    182400\t  0.161910\t  0.161748\t  0.162307\t\tCURRENT LEARNING RATE: 0.08052825353380308\n",
      "previous_iter_valid_loss : 0.16114430129528046\n",
      "\n",
      "    182600\t  0.161328\t  0.161144\t  0.162304\t\tCURRENT LEARNING RATE: 0.08036735797592519\n",
      "previous_iter_valid_loss : 0.1628623753786087\n",
      "\n",
      "    182800\t  0.163083\t  0.162862\t  0.162298\t\tCURRENT LEARNING RATE: 0.08020678388758637\n",
      "previous_iter_valid_loss : 0.16117247939109802\n",
      "\n",
      "    183000\t  0.161416\t  0.161172\t  0.162294\t\tCURRENT LEARNING RATE: 0.08004653062649005\n",
      "previous_iter_valid_loss : 0.16171303391456604\n",
      "\n",
      "    183200\t  0.161901\t  0.161713\t  0.162295\t\tCURRENT LEARNING RATE: 0.07988659755162296\n",
      "previous_iter_valid_loss : 0.16304916143417358\n",
      "\n",
      "    183400\t  0.163218\t  0.163049\t  0.162288\t\tCURRENT LEARNING RATE: 0.07972698402325258\n",
      "previous_iter_valid_loss : 0.16167159378528595\n",
      "\n",
      "    183600\t  0.161866\t  0.161672\t  0.162289\t\tCURRENT LEARNING RATE: 0.07956768940292461\n",
      "previous_iter_valid_loss : 0.1640959233045578\n",
      "\n",
      "    183800\t  0.164325\t  0.164096\t  0.162302\t\tCURRENT LEARNING RATE: 0.07940871305346034\n",
      "previous_iter_valid_loss : 0.16209562122821808\n",
      "\n",
      "    184000\t  0.162286\t  0.162096\t  0.162304\t\tCURRENT LEARNING RATE: 0.07925005433895416\n",
      "previous_iter_valid_loss : 0.16222232580184937\n",
      "\n",
      "    184200\t  0.162454\t  0.162222\t  0.162299\t\tCURRENT LEARNING RATE: 0.07909171262477101\n",
      "previous_iter_valid_loss : 0.1613365262746811\n",
      "\n",
      "    184400\t  0.161490\t  0.161337\t  0.162294\t\tCURRENT LEARNING RATE: 0.0789336872775438\n",
      "previous_iter_valid_loss : 0.16144013404846191\n",
      "\n",
      "    184600\t  0.161642\t  0.161440\t  0.162287\t\tCURRENT LEARNING RATE: 0.07877597766517096\n",
      "previous_iter_valid_loss : 0.16126205027103424\n",
      "\n",
      "    184800\t  0.161434\t  0.161262\t  0.162283\t\tCURRENT LEARNING RATE: 0.0786185831568138\n",
      "previous_iter_valid_loss : 0.16182707250118256\n",
      "\n",
      "    185000\t  0.162032\t  0.161827\t  0.162285\t\tCURRENT LEARNING RATE: 0.0784615031228941\n",
      "previous_iter_valid_loss : 0.16129139065742493\n",
      "\n",
      "    185200\t  0.161455\t  0.161291\t  0.162268\t\tCURRENT LEARNING RATE: 0.0783047369350915\n",
      "previous_iter_valid_loss : 0.16143937408924103\n",
      "\n",
      "    185400\t  0.161581\t  0.161439\t  0.162266\t\tCURRENT LEARNING RATE: 0.07814828396634106\n",
      "previous_iter_valid_loss : 0.16158916056156158\n",
      "\n",
      "    185600\t  0.161801\t  0.161589\t  0.162267\t\tCURRENT LEARNING RATE: 0.07799214359083068\n",
      "previous_iter_valid_loss : 0.16145019233226776\n",
      "\n",
      "    185800\t  0.161637\t  0.161450\t  0.162264\t\tCURRENT LEARNING RATE: 0.07783631518399865\n",
      "previous_iter_valid_loss : 0.16157159209251404\n",
      "\n",
      "    186000\t  0.161705\t  0.161572\t  0.162250\t\tCURRENT LEARNING RATE: 0.07768079812253113\n",
      "previous_iter_valid_loss : 0.16173015534877777\n",
      "\n",
      "    186200\t  0.161907\t  0.161730\t  0.162250\t\tCURRENT LEARNING RATE: 0.07752559178435968\n",
      "previous_iter_valid_loss : 0.16172069311141968\n",
      "\n",
      "    186400\t  0.161874\t  0.161721\t  0.162249\t\tCURRENT LEARNING RATE: 0.07737069554865875\n",
      "previous_iter_valid_loss : 0.16122664511203766\n",
      "\n",
      "    186600\t  0.161377\t  0.161227\t  0.162248\t\tCURRENT LEARNING RATE: 0.07721610879584316\n",
      "previous_iter_valid_loss : 0.16134272515773773\n",
      "\n",
      "    186800\t  0.161457\t  0.161343\t  0.162246\t\tCURRENT LEARNING RATE: 0.0770618309075657\n",
      "previous_iter_valid_loss : 0.16296759247779846\n",
      "\n",
      "    187000\t  0.163139\t  0.162968\t  0.162252\t\tCURRENT LEARNING RATE: 0.07690786126671463\n",
      "previous_iter_valid_loss : 0.16236962378025055\n",
      "\n",
      "    187200\t  0.162497\t  0.162370\t  0.162256\t\tCURRENT LEARNING RATE: 0.07675419925741117\n",
      "previous_iter_valid_loss : 0.1611882448196411\n",
      "\n",
      "    187400\t  0.161343\t  0.161188\t  0.162248\t\tCURRENT LEARNING RATE: 0.0766008442650071\n",
      "previous_iter_valid_loss : 0.16334985196590424\n",
      "\n",
      "    187600\t  0.163480\t  0.163350\t  0.162255\t\tCURRENT LEARNING RATE: 0.0764477956760822\n",
      "previous_iter_valid_loss : 0.1614515632390976\n",
      "\n",
      "    187800\t  0.161595\t  0.161452\t  0.162254\t\tCURRENT LEARNING RATE: 0.07629505287844195\n",
      "previous_iter_valid_loss : 0.1628304272890091\n",
      "\n",
      "    188000\t  0.163039\t  0.162830\t  0.162259\t\tCURRENT LEARNING RATE: 0.07614261526111492\n",
      "previous_iter_valid_loss : 0.161429300904274\n",
      "\n",
      "    188200\t  0.161590\t  0.161429\t  0.162259\t\tCURRENT LEARNING RATE: 0.07599048221435047\n",
      "previous_iter_valid_loss : 0.1613202840089798\n",
      "\n",
      "    188400\t  0.161476\t  0.161320\t  0.162258\t\tCURRENT LEARNING RATE: 0.0758386531296162\n",
      "previous_iter_valid_loss : 0.16259759664535522\n",
      "\n",
      "    188600\t  0.162796\t  0.162598\t  0.162259\t\tCURRENT LEARNING RATE: 0.07568712739959556\n",
      "previous_iter_valid_loss : 0.1611611694097519\n",
      "\n",
      "    188800\t  0.161317\t  0.161161\t  0.162233\t\tCURRENT LEARNING RATE: 0.07553590441818543\n",
      "previous_iter_valid_loss : 0.1614065319299698\n",
      "\n",
      "    189000\t  0.161553\t  0.161407\t  0.162235\t\tCURRENT LEARNING RATE: 0.0753849835804937\n",
      "previous_iter_valid_loss : 0.1624697595834732\n",
      "\n",
      "    189200\t  0.162621\t  0.162470\t  0.162240\t\tCURRENT LEARNING RATE: 0.0752343642828368\n",
      "previous_iter_valid_loss : 0.16186590492725372\n",
      "\n",
      "    189400\t  0.162017\t  0.161866\t  0.162236\t\tCURRENT LEARNING RATE: 0.07508404592273733\n",
      "previous_iter_valid_loss : 0.1625775694847107\n",
      "\n",
      "    189600\t  0.162735\t  0.162578\t  0.162240\t\tCURRENT LEARNING RATE: 0.07493402789892167\n",
      "previous_iter_valid_loss : 0.16196191310882568\n",
      "\n",
      "    189800\t  0.162077\t  0.161962\t  0.162240\t\tCURRENT LEARNING RATE: 0.07478430961131753\n",
      "previous_iter_valid_loss : 0.16120316088199615\n",
      "\n",
      "    190000\t  0.161329\t  0.161203\t  0.162235\t\tCURRENT LEARNING RATE: 0.07463489046105154\n",
      "previous_iter_valid_loss : 0.16148914396762848\n",
      "\n",
      "    190200\t  0.161606\t  0.161489\t  0.162234\t\tCURRENT LEARNING RATE: 0.07448576985044691\n",
      "previous_iter_valid_loss : 0.1612166464328766\n",
      "\n",
      "    190400\t  0.161332\t  0.161217\t  0.162233\t\tCURRENT LEARNING RATE: 0.074336947183021\n",
      "previous_iter_valid_loss : 0.16148024797439575\n",
      "\n",
      "    190600\t  0.161625\t  0.161480\t  0.162235\t\tCURRENT LEARNING RATE: 0.07418842186348293\n",
      "previous_iter_valid_loss : 0.16124241054058075\n",
      "\n",
      "    190800\t  0.161395\t  0.161242\t  0.162231\t\tCURRENT LEARNING RATE: 0.07404019329773123\n",
      "previous_iter_valid_loss : 0.16190384328365326\n",
      "\n",
      "    191000\t  0.162063\t  0.161904\t  0.162233\t\tCURRENT LEARNING RATE: 0.07389226089285145\n",
      "previous_iter_valid_loss : 0.16124728322029114\n",
      "\n",
      "    191200\t  0.161386\t  0.161247\t  0.162225\t\tCURRENT LEARNING RATE: 0.07374462405711375\n",
      "previous_iter_valid_loss : 0.16163834929466248\n",
      "\n",
      "    191400\t  0.161792\t  0.161638\t  0.162212\t\tCURRENT LEARNING RATE: 0.07359728219997062\n",
      "previous_iter_valid_loss : 0.1617600917816162\n",
      "\n",
      "    191600\t  0.161868\t  0.161760\t  0.162195\t\tCURRENT LEARNING RATE: 0.07345023473205442\n",
      "previous_iter_valid_loss : 0.1617896556854248\n",
      "\n",
      "    191800\t  0.161896\t  0.161790\t  0.162187\t\tCURRENT LEARNING RATE: 0.07330348106517508\n",
      "previous_iter_valid_loss : 0.16245000064373016\n",
      "\n",
      "    192000\t  0.162611\t  0.162450\t  0.162190\t\tCURRENT LEARNING RATE: 0.07315702061231773\n",
      "previous_iter_valid_loss : 0.16381731629371643\n",
      "\n",
      "    192200\t  0.163960\t  0.163817\t  0.162194\t\tCURRENT LEARNING RATE: 0.07301085278764037\n",
      "previous_iter_valid_loss : 0.16177667677402496\n",
      "\n",
      "    192400\t  0.161913\t  0.161777\t  0.162196\t\tCURRENT LEARNING RATE: 0.07286497700647152\n",
      "previous_iter_valid_loss : 0.16193953156471252\n",
      "\n",
      "    192600\t  0.162067\t  0.161940\t  0.162191\t\tCURRENT LEARNING RATE: 0.07271939268530785\n",
      "previous_iter_valid_loss : 0.1624712347984314\n",
      "\n",
      "    192800\t  0.162615\t  0.162471\t  0.162197\t\tCURRENT LEARNING RATE: 0.07257409924181187\n",
      "previous_iter_valid_loss : 0.16257834434509277\n",
      "\n",
      "    193000\t  0.162685\t  0.162578\t  0.162202\t\tCURRENT LEARNING RATE: 0.07242909609480963\n",
      "previous_iter_valid_loss : 0.16209416091442108\n",
      "\n",
      "    193200\t  0.162222\t  0.162094\t  0.162202\t\tCURRENT LEARNING RATE: 0.07228438266428834\n",
      "previous_iter_valid_loss : 0.16308386623859406\n",
      "\n",
      "    193400\t  0.163244\t  0.163084\t  0.162202\t\tCURRENT LEARNING RATE: 0.07213995837139409\n",
      "previous_iter_valid_loss : 0.16140031814575195\n",
      "\n",
      "    193600\t  0.161553\t  0.161400\t  0.162195\t\tCURRENT LEARNING RATE: 0.0719958226384295\n",
      "previous_iter_valid_loss : 0.16201891005039215\n",
      "\n",
      "    193800\t  0.162168\t  0.162019\t  0.162195\t\tCURRENT LEARNING RATE: 0.07185197488885146\n",
      "previous_iter_valid_loss : 0.16253973543643951\n",
      "\n",
      "    194000\t  0.162687\t  0.162540\t  0.162198\t\tCURRENT LEARNING RATE: 0.07170841454726878\n",
      "previous_iter_valid_loss : 0.1615317463874817\n",
      "\n",
      "    194200\t  0.161646\t  0.161532\t  0.162194\t\tCURRENT LEARNING RATE: 0.07156514103943991\n",
      "previous_iter_valid_loss : 0.16141006350517273\n",
      "\n",
      "    194400\t  0.161548\t  0.161410\t  0.162194\t\tCURRENT LEARNING RATE: 0.07142215379227061\n",
      "previous_iter_valid_loss : 0.1642899364233017\n",
      "\n",
      "    194600\t  0.164443\t  0.164290\t  0.162203\t\tCURRENT LEARNING RATE: 0.07127945223381171\n",
      "previous_iter_valid_loss : 0.16206757724285126\n",
      "\n",
      "    194800\t  0.162226\t  0.162068\t  0.162206\t\tCURRENT LEARNING RATE: 0.0711370357932568\n",
      "previous_iter_valid_loss : 0.16358265280723572\n",
      "\n",
      "    195000\t  0.163735\t  0.163583\t  0.162216\t\tCURRENT LEARNING RATE: 0.07099490390093989\n",
      "previous_iter_valid_loss : 0.16198036074638367\n",
      "\n",
      "    195200\t  0.162122\t  0.161980\t  0.162214\t\tCURRENT LEARNING RATE: 0.07085305598833325\n",
      "previous_iter_valid_loss : 0.16137583553791046\n",
      "\n",
      "    195400\t  0.161491\t  0.161376\t  0.162202\t\tCURRENT LEARNING RATE: 0.07071149148804504\n",
      "previous_iter_valid_loss : 0.16273550689220428\n",
      "\n",
      "    195600\t  0.162851\t  0.162736\t  0.162207\t\tCURRENT LEARNING RATE: 0.07057020983381705\n",
      "previous_iter_valid_loss : 0.16152596473693848\n",
      "\n",
      "    195800\t  0.161649\t  0.161526\t  0.162206\t\tCURRENT LEARNING RATE: 0.0704292104605225\n",
      "previous_iter_valid_loss : 0.16345350444316864\n",
      "\n",
      "    196000\t  0.163608\t  0.163454\t  0.162216\t\tCURRENT LEARNING RATE: 0.0702884928041637\n",
      "previous_iter_valid_loss : 0.16139169037342072\n",
      "\n",
      "    196200\t  0.161504\t  0.161392\t  0.162212\t\tCURRENT LEARNING RATE: 0.07014805630186982\n",
      "previous_iter_valid_loss : 0.16135402023792267\n",
      "\n",
      "    196400\t  0.161460\t  0.161354\t  0.162211\t\tCURRENT LEARNING RATE: 0.0700079003918947\n",
      "previous_iter_valid_loss : 0.1621711105108261\n",
      "\n",
      "    196600\t  0.162276\t  0.162171\t  0.162205\t\tCURRENT LEARNING RATE: 0.06986802451361447\n",
      "previous_iter_valid_loss : 0.16167980432510376\n",
      "\n",
      "    196800\t  0.161815\t  0.161680\t  0.162204\t\tCURRENT LEARNING RATE: 0.06972842810752547\n",
      "previous_iter_valid_loss : 0.16128841042518616\n",
      "\n",
      "    197000\t  0.161415\t  0.161288\t  0.162203\t\tCURRENT LEARNING RATE: 0.06958911061524187\n",
      "previous_iter_valid_loss : 0.1616133451461792\n",
      "\n",
      "    197200\t  0.161710\t  0.161613\t  0.162202\t\tCURRENT LEARNING RATE: 0.0694500714794935\n",
      "previous_iter_valid_loss : 0.16275835037231445\n",
      "\n",
      "    197400\t  0.162902\t  0.162758\t  0.162207\t\tCURRENT LEARNING RATE: 0.06931131014412366\n",
      "previous_iter_valid_loss : 0.16189663112163544\n",
      "\n",
      "    197600\t  0.161998\t  0.161897\t  0.162193\t\tCURRENT LEARNING RATE: 0.06917282605408681\n",
      "previous_iter_valid_loss : 0.162852942943573\n",
      "\n",
      "    197800\t  0.162976\t  0.162853\t  0.162197\t\tCURRENT LEARNING RATE: 0.06903461865544641\n",
      "previous_iter_valid_loss : 0.16145355999469757\n",
      "\n",
      "    198000\t  0.161567\t  0.161454\t  0.162195\t\tCURRENT LEARNING RATE: 0.06889668739537268\n",
      "previous_iter_valid_loss : 0.1613243967294693\n",
      "\n",
      "    198200\t  0.161412\t  0.161324\t  0.162189\t\tCURRENT LEARNING RATE: 0.06875903172214037\n",
      "previous_iter_valid_loss : 0.1616184264421463\n",
      "\n",
      "    198400\t  0.161764\t  0.161618\t  0.162187\t\tCURRENT LEARNING RATE: 0.06862165108512666\n",
      "previous_iter_valid_loss : 0.16265787184238434\n",
      "\n",
      "    198600\t  0.162802\t  0.162658\t  0.162193\t\tCURRENT LEARNING RATE: 0.06848454493480877\n",
      "previous_iter_valid_loss : 0.1619226187467575\n",
      "\n",
      "    198800\t  0.162027\t  0.161923\t  0.162182\t\tCURRENT LEARNING RATE: 0.06834771272276192\n",
      "previous_iter_valid_loss : 0.16114366054534912\n",
      "\n",
      "    199000\t  0.161252\t  0.161144\t  0.162177\t\tCURRENT LEARNING RATE: 0.06821115390165712\n",
      "previous_iter_valid_loss : 0.16186144948005676\n",
      "\n",
      "    199200\t  0.161984\t  0.161861\t  0.162172\t\tCURRENT LEARNING RATE: 0.06807486792525885\n",
      "previous_iter_valid_loss : 0.16275730729103088\n",
      "\n",
      "    199400\t  0.162909\t  0.162757\t  0.162172\t\tCURRENT LEARNING RATE: 0.06793885424842307\n",
      "previous_iter_valid_loss : 0.1633472442626953\n",
      "\n",
      "    199600\t  0.163509\t  0.163347\t  0.162180\t\tCURRENT LEARNING RATE: 0.06780311232709485\n",
      "previous_iter_valid_loss : 0.16228437423706055\n",
      "\n",
      "    199800\t  0.162427\t  0.162284\t  0.162174\t\tCURRENT LEARNING RATE: 0.06766764161830635\n",
      "previous_iter_valid_loss : 0.16130408644676208\n",
      "\n",
      "    200000\t  0.161430\t  0.161304\t  0.162174\t\tCURRENT LEARNING RATE: 0.06753244158017456\n",
      "previous_iter_valid_loss : 0.16168008744716644\n",
      "\n",
      "    200200\t  0.161791\t  0.161680\t  0.162177\t\tCURRENT LEARNING RATE: 0.0673975116718991\n",
      "previous_iter_valid_loss : 0.16137978434562683\n",
      "\n",
      "    200400\t  0.161490\t  0.161380\t  0.162171\t\tCURRENT LEARNING RATE: 0.06726285135376023\n",
      "previous_iter_valid_loss : 0.161560520529747\n",
      "\n",
      "    200600\t  0.161658\t  0.161561\t  0.162170\t\tCURRENT LEARNING RATE: 0.06712846008711643\n",
      "previous_iter_valid_loss : 0.16185271739959717\n",
      "\n",
      "    200800\t  0.161961\t  0.161853\t  0.162170\t\tCURRENT LEARNING RATE: 0.06699433733440249\n",
      "previous_iter_valid_loss : 0.16144457459449768\n",
      "\n",
      "    201000\t  0.161554\t  0.161445\t  0.162144\t\tCURRENT LEARNING RATE: 0.0668604825591272\n",
      "previous_iter_valid_loss : 0.16178946197032928\n",
      "\n",
      "    201200\t  0.161895\t  0.161789\t  0.162145\t\tCURRENT LEARNING RATE: 0.06672689522587133\n",
      "previous_iter_valid_loss : 0.16337566077709198\n",
      "\n",
      "    201400\t  0.163490\t  0.163376\t  0.162146\t\tCURRENT LEARNING RATE: 0.0665935748002853\n",
      "previous_iter_valid_loss : 0.16233554482460022\n",
      "\n",
      "    201600\t  0.162434\t  0.162336\t  0.162134\t\tCURRENT LEARNING RATE: 0.06646052074908729\n",
      "previous_iter_valid_loss : 0.16149534285068512\n",
      "\n",
      "    201800\t  0.161601\t  0.161495\t  0.162136\t\tCURRENT LEARNING RATE: 0.06632773254006086\n",
      "previous_iter_valid_loss : 0.1612309366464615\n",
      "\n",
      "    202000\t  0.161315\t  0.161231\t  0.162134\t\tCURRENT LEARNING RATE: 0.06619520964205305\n",
      "previous_iter_valid_loss : 0.16144922375679016\n",
      "\n",
      "    202200\t  0.161531\t  0.161449\t  0.162123\t\tCURRENT LEARNING RATE: 0.06606295152497205\n",
      "previous_iter_valid_loss : 0.16221165657043457\n",
      "\n",
      "    202400\t  0.162304\t  0.162212\t  0.162109\t\tCURRENT LEARNING RATE: 0.06593095765978527\n",
      "previous_iter_valid_loss : 0.1632956713438034\n",
      "\n",
      "    202600\t  0.163392\t  0.163296\t  0.162116\t\tCURRENT LEARNING RATE: 0.065799227518517\n",
      "previous_iter_valid_loss : 0.16244713962078094\n",
      "\n",
      "    202800\t  0.162548\t  0.162447\t  0.162116\t\tCURRENT LEARNING RATE: 0.06566776057424656\n",
      "previous_iter_valid_loss : 0.16133937239646912\n",
      "\n",
      "    203000\t  0.161444\t  0.161339\t  0.162112\t\tCURRENT LEARNING RATE: 0.06553655630110594\n",
      "previous_iter_valid_loss : 0.16307592391967773\n",
      "\n",
      "    203200\t  0.163176\t  0.163076\t  0.162117\t\tCURRENT LEARNING RATE: 0.06540561417427794\n",
      "previous_iter_valid_loss : 0.16446581482887268\n",
      "\n",
      "    203400\t  0.164606\t  0.164466\t  0.162131\t\tCURRENT LEARNING RATE: 0.06527493366999382\n",
      "previous_iter_valid_loss : 0.16288481652736664\n",
      "\n",
      "    203600\t  0.163022\t  0.162885\t  0.162121\t\tCURRENT LEARNING RATE: 0.06514451426553144\n",
      "previous_iter_valid_loss : 0.16162937879562378\n",
      "\n",
      "    203800\t  0.161722\t  0.161629\t  0.162122\t\tCURRENT LEARNING RATE: 0.06501435543921295\n",
      "previous_iter_valid_loss : 0.1613352745771408\n",
      "\n",
      "    204000\t  0.161440\t  0.161335\t  0.162110\t\tCURRENT LEARNING RATE: 0.06488445667040293\n",
      "previous_iter_valid_loss : 0.16148920357227325\n",
      "\n",
      "    204200\t  0.161596\t  0.161489\t  0.162109\t\tCURRENT LEARNING RATE: 0.06475481743950609\n",
      "previous_iter_valid_loss : 0.16180157661437988\n",
      "\n",
      "    204400\t  0.161943\t  0.161802\t  0.162108\t\tCURRENT LEARNING RATE: 0.06462543722796536\n",
      "previous_iter_valid_loss : 0.16172175109386444\n",
      "\n",
      "    204600\t  0.161834\t  0.161722\t  0.162109\t\tCURRENT LEARNING RATE: 0.0644963155182597\n",
      "previous_iter_valid_loss : 0.16176781058311462\n",
      "\n",
      "    204800\t  0.161896\t  0.161768\t  0.162110\t\tCURRENT LEARNING RATE: 0.06436745179390212\n",
      "previous_iter_valid_loss : 0.1613219827413559\n",
      "\n",
      "    205000\t  0.161443\t  0.161322\t  0.162105\t\tCURRENT LEARNING RATE: 0.06423884553943751\n",
      "previous_iter_valid_loss : 0.16155996918678284\n",
      "\n",
      "    205200\t  0.161698\t  0.161560\t  0.162104\t\tCURRENT LEARNING RATE: 0.06411049624044075\n",
      "previous_iter_valid_loss : 0.16152553260326385\n",
      "\n",
      "    205400\t  0.161612\t  0.161526\t  0.162100\t\tCURRENT LEARNING RATE: 0.0639824033835144\n",
      "previous_iter_valid_loss : 0.1612713485956192\n",
      "\n",
      "    205600\t  0.161362\t  0.161271\t  0.162099\t\tCURRENT LEARNING RATE: 0.06385456645628691\n",
      "previous_iter_valid_loss : 0.16335056722164154\n",
      "\n",
      "    205800\t  0.163485\t  0.163351\t  0.162108\t\tCURRENT LEARNING RATE: 0.06372698494741037\n",
      "previous_iter_valid_loss : 0.16136899590492249\n",
      "\n",
      "    206000\t  0.161477\t  0.161369\t  0.162105\t\tCURRENT LEARNING RATE: 0.0635996583465586\n",
      "previous_iter_valid_loss : 0.16124506294727325\n",
      "\n",
      "    206200\t  0.161331\t  0.161245\t  0.162104\t\tCURRENT LEARNING RATE: 0.06347258614442501\n",
      "previous_iter_valid_loss : 0.1617787927389145\n",
      "\n",
      "    206400\t  0.161904\t  0.161779\t  0.162106\t\tCURRENT LEARNING RATE: 0.06334576783272065\n",
      "previous_iter_valid_loss : 0.1612551361322403\n",
      "\n",
      "    206600\t  0.161371\t  0.161255\t  0.162099\t\tCURRENT LEARNING RATE: 0.06321920290417204\n",
      "previous_iter_valid_loss : 0.16385069489479065\n",
      "\n",
      "    206800\t  0.164033\t  0.163851\t  0.162099\t\tCURRENT LEARNING RATE: 0.06309289085251939\n",
      "previous_iter_valid_loss : 0.16206493973731995\n",
      "\n",
      "    207000\t  0.162206\t  0.162065\t  0.162102\t\tCURRENT LEARNING RATE: 0.06296683117251423\n",
      "previous_iter_valid_loss : 0.1620984971523285\n",
      "\n",
      "    207200\t  0.162215\t  0.162098\t  0.162087\t\tCURRENT LEARNING RATE: 0.06284102335991774\n",
      "previous_iter_valid_loss : 0.1614917814731598\n",
      "\n",
      "    207400\t  0.161582\t  0.161492\t  0.162084\t\tCURRENT LEARNING RATE: 0.06271546691149846\n",
      "previous_iter_valid_loss : 0.16158512234687805\n",
      "\n",
      "    207600\t  0.161678\t  0.161585\t  0.162082\t\tCURRENT LEARNING RATE: 0.06259016132503047\n",
      "previous_iter_valid_loss : 0.16247843205928802\n",
      "\n",
      "    207800\t  0.162590\t  0.162478\t  0.162073\t\tCURRENT LEARNING RATE: 0.06246510609929121\n",
      "previous_iter_valid_loss : 0.16151855885982513\n",
      "\n",
      "    208000\t  0.161642\t  0.161519\t  0.162072\t\tCURRENT LEARNING RATE: 0.062340300734059655\n",
      "previous_iter_valid_loss : 0.16252733767032623\n",
      "\n",
      "    208200\t  0.162640\t  0.162527\t  0.162071\t\tCURRENT LEARNING RATE: 0.06221574473011413\n",
      "previous_iter_valid_loss : 0.16152967512607574\n",
      "\n",
      "    208400\t  0.161660\t  0.161530\t  0.162057\t\tCURRENT LEARNING RATE: 0.06209143758923051\n",
      "previous_iter_valid_loss : 0.16128821671009064\n",
      "\n",
      "    208600\t  0.161387\t  0.161288\t  0.162051\t\tCURRENT LEARNING RATE: 0.06196737881418001\n",
      "previous_iter_valid_loss : 0.16146184504032135\n",
      "\n",
      "    208800\t  0.161571\t  0.161462\t  0.162048\t\tCURRENT LEARNING RATE: 0.061843567908727415\n",
      "previous_iter_valid_loss : 0.16253280639648438\n",
      "\n",
      "    209000\t  0.162642\t  0.162533\t  0.162054\t\tCURRENT LEARNING RATE: 0.06172000437762889\n",
      "previous_iter_valid_loss : 0.16141416132450104\n",
      "\n",
      "    209200\t  0.161522\t  0.161414\t  0.162055\t\tCURRENT LEARNING RATE: 0.06159668772663019\n",
      "previous_iter_valid_loss : 0.16279751062393188\n",
      "\n",
      "    209400\t  0.162875\t  0.162798\t  0.162062\t\tCURRENT LEARNING RATE: 0.0614736174624645\n",
      "previous_iter_valid_loss : 0.16215337812900543\n",
      "\n",
      "    209600\t  0.162231\t  0.162153\t  0.162066\t\tCURRENT LEARNING RATE: 0.06135079309285065\n",
      "previous_iter_valid_loss : 0.1645517200231552\n",
      "\n",
      "    209800\t  0.164675\t  0.164552\t  0.162083\t\tCURRENT LEARNING RATE: 0.06122821412649095\n",
      "previous_iter_valid_loss : 0.16273829340934753\n",
      "\n",
      "    210000\t  0.162877\t  0.162738\t  0.162085\t\tCURRENT LEARNING RATE: 0.06110588007306942\n",
      "previous_iter_valid_loss : 0.1616145819425583\n",
      "\n",
      "    210200\t  0.161720\t  0.161615\t  0.162084\t\tCURRENT LEARNING RATE: 0.06098379044324963\n",
      "previous_iter_valid_loss : 0.16244256496429443\n",
      "\n",
      "    210400\t  0.162510\t  0.162443\t  0.162086\t\tCURRENT LEARNING RATE: 0.060861944748672944\n",
      "previous_iter_valid_loss : 0.16173630952835083\n",
      "\n",
      "    210600\t  0.161785\t  0.161736\t  0.162086\t\tCURRENT LEARNING RATE: 0.06074034250195638\n",
      "previous_iter_valid_loss : 0.16157476603984833\n",
      "\n",
      "    210800\t  0.161650\t  0.161575\t  0.162073\t\tCURRENT LEARNING RATE: 0.06061898321669084\n",
      "previous_iter_valid_loss : 0.16223689913749695\n",
      "\n",
      "    211000\t  0.162365\t  0.162237\t  0.162067\t\tCURRENT LEARNING RATE: 0.06049786640743896\n",
      "previous_iter_valid_loss : 0.1613047569990158\n",
      "\n",
      "    211200\t  0.161415\t  0.161305\t  0.162066\t\tCURRENT LEARNING RATE: 0.060376991589733406\n",
      "previous_iter_valid_loss : 0.1652703732252121\n",
      "\n",
      "    211400\t  0.165372\t  0.165270\t  0.162085\t\tCURRENT LEARNING RATE: 0.06025635828007469\n",
      "previous_iter_valid_loss : 0.1612273007631302\n",
      "\n",
      "    211600\t  0.161327\t  0.161227\t  0.162068\t\tCURRENT LEARNING RATE: 0.060135965995929457\n",
      "previous_iter_valid_loss : 0.16226314008235931\n",
      "\n",
      "    211800\t  0.162376\t  0.162263\t  0.162059\t\tCURRENT LEARNING RATE: 0.06001581425572836\n",
      "previous_iter_valid_loss : 0.1624070107936859\n",
      "\n",
      "    212000\t  0.162557\t  0.162407\t  0.162064\t\tCURRENT LEARNING RATE: 0.05989590257886434\n",
      "previous_iter_valid_loss : 0.16186799108982086\n",
      "\n",
      "    212200\t  0.161967\t  0.161868\t  0.162053\t\tCURRENT LEARNING RATE: 0.05977623048569047\n",
      "previous_iter_valid_loss : 0.16144993901252747\n",
      "\n",
      "    212400\t  0.161576\t  0.161450\t  0.162049\t\tCURRENT LEARNING RATE: 0.05965679749751826\n",
      "previous_iter_valid_loss : 0.1613353192806244\n",
      "\n",
      "    212600\t  0.161492\t  0.161335\t  0.162049\t\tCURRENT LEARNING RATE: 0.05953760313661557\n",
      "previous_iter_valid_loss : 0.1629757136106491\n",
      "\n",
      "    212800\t  0.163124\t  0.162976\t  0.162047\t\tCURRENT LEARNING RATE: 0.05941864692620483\n",
      "previous_iter_valid_loss : 0.16200736165046692\n",
      "\n",
      "    213000\t  0.162133\t  0.162007\t  0.162047\t\tCURRENT LEARNING RATE: 0.05929992839046099\n",
      "previous_iter_valid_loss : 0.16135358810424805\n",
      "\n",
      "    213200\t  0.161480\t  0.161354\t  0.162037\t\tCURRENT LEARNING RATE: 0.05918144705450981\n",
      "previous_iter_valid_loss : 0.16210873425006866\n",
      "\n",
      "    213400\t  0.162225\t  0.162109\t  0.162039\t\tCURRENT LEARNING RATE: 0.05906320244442573\n",
      "previous_iter_valid_loss : 0.16171325743198395\n",
      "\n",
      "    213600\t  0.161819\t  0.161713\t  0.162039\t\tCURRENT LEARNING RATE: 0.0589451940872302\n",
      "previous_iter_valid_loss : 0.16219814121723175\n",
      "\n",
      "    213800\t  0.162306\t  0.162198\t  0.162034\t\tCURRENT LEARNING RATE: 0.05882742151088959\n",
      "previous_iter_valid_loss : 0.16257654130458832\n",
      "\n",
      "    214000\t  0.162697\t  0.162577\t  0.162039\t\tCURRENT LEARNING RATE: 0.05870988424431349\n",
      "previous_iter_valid_loss : 0.1615157127380371\n",
      "\n",
      "    214200\t  0.161626\t  0.161516\t  0.162034\t\tCURRENT LEARNING RATE: 0.058592581817352614\n",
      "previous_iter_valid_loss : 0.16237470507621765\n",
      "\n",
      "    214400\t  0.162463\t  0.162375\t  0.162039\t\tCURRENT LEARNING RATE: 0.05847551376079716\n",
      "previous_iter_valid_loss : 0.1616632044315338\n",
      "\n",
      "    214600\t  0.161747\t  0.161663\t  0.162037\t\tCURRENT LEARNING RATE: 0.05835867960637469\n",
      "previous_iter_valid_loss : 0.161918044090271\n",
      "\n",
      "    214800\t  0.162012\t  0.161918\t  0.162023\t\tCURRENT LEARNING RATE: 0.05824207888674848\n",
      "previous_iter_valid_loss : 0.16273081302642822\n",
      "\n",
      "    215000\t  0.162820\t  0.162731\t  0.162030\t\tCURRENT LEARNING RATE: 0.05812571113551546\n",
      "previous_iter_valid_loss : 0.1619124561548233\n",
      "\n",
      "    215200\t  0.162061\t  0.161912\t  0.162031\t\tCURRENT LEARNING RATE: 0.0580095758872045\n",
      "previous_iter_valid_loss : 0.16195012629032135\n",
      "\n",
      "    215400\t  0.162075\t  0.161950\t  0.162016\t\tCURRENT LEARNING RATE: 0.0578936726772744\n",
      "previous_iter_valid_loss : 0.16197220981121063\n",
      "\n",
      "    215600\t  0.162135\t  0.161972\t  0.162018\t\tCURRENT LEARNING RATE: 0.05777800104211224\n",
      "previous_iter_valid_loss : 0.16233165562152863\n",
      "\n",
      "    215800\t  0.162478\t  0.162332\t  0.162018\t\tCURRENT LEARNING RATE: 0.05766256051903126\n",
      "previous_iter_valid_loss : 0.16143912076950073\n",
      "\n",
      "    216000\t  0.161558\t  0.161439\t  0.162016\t\tCURRENT LEARNING RATE: 0.05754735064626926\n",
      "previous_iter_valid_loss : 0.16475394368171692\n",
      "\n",
      "    216200\t  0.164868\t  0.164754\t  0.162031\t\tCURRENT LEARNING RATE: 0.05743237096298654\n",
      "previous_iter_valid_loss : 0.16156597435474396\n",
      "\n",
      "    216400\t  0.161697\t  0.161566\t  0.162027\t\tCURRENT LEARNING RATE: 0.05731762100926429\n",
      "previous_iter_valid_loss : 0.1616690754890442\n",
      "\n",
      "    216600\t  0.161804\t  0.161669\t  0.162020\t\tCURRENT LEARNING RATE: 0.057203100326102464\n",
      "previous_iter_valid_loss : 0.1614857017993927\n",
      "\n",
      "    216800\t  0.161611\t  0.161486\t  0.162021\t\tCURRENT LEARNING RATE: 0.05708880845541825\n",
      "previous_iter_valid_loss : 0.16281908750534058\n",
      "\n",
      "    217000\t  0.162951\t  0.162819\t  0.162028\t\tCURRENT LEARNING RATE: 0.05697474494004394\n",
      "previous_iter_valid_loss : 0.1615757942199707\n",
      "\n",
      "    217200\t  0.161680\t  0.161576\t  0.162025\t\tCURRENT LEARNING RATE: 0.05686090932372539\n",
      "previous_iter_valid_loss : 0.16127684712409973\n",
      "\n",
      "    217400\t  0.161384\t  0.161277\t  0.162022\t\tCURRENT LEARNING RATE: 0.056747301151119915\n",
      "previous_iter_valid_loss : 0.16231031715869904\n",
      "\n",
      "    217600\t  0.162424\t  0.162310\t  0.162011\t\tCURRENT LEARNING RATE: 0.05663391996779474\n",
      "previous_iter_valid_loss : 0.16162070631980896\n",
      "\n",
      "    217800\t  0.161768\t  0.161621\t  0.162008\t\tCURRENT LEARNING RATE: 0.056520765320224924\n",
      "previous_iter_valid_loss : 0.16230840981006622\n",
      "\n",
      "    218000\t  0.162443\t  0.162308\t  0.162011\t\tCURRENT LEARNING RATE: 0.05640783675579177\n",
      "previous_iter_valid_loss : 0.16146956384181976\n",
      "\n",
      "    218200\t  0.161610\t  0.161470\t  0.162008\t\tCURRENT LEARNING RATE: 0.05629513382278083\n",
      "previous_iter_valid_loss : 0.1617865264415741\n",
      "\n",
      "    218400\t  0.161927\t  0.161787\t  0.162008\t\tCURRENT LEARNING RATE: 0.05618265607038026\n",
      "previous_iter_valid_loss : 0.16178424656391144\n",
      "\n",
      "    218600\t  0.161879\t  0.161784\t  0.162010\t\tCURRENT LEARNING RATE: 0.05607040304867886\n",
      "previous_iter_valid_loss : 0.16164134442806244\n",
      "\n",
      "    218800\t  0.161774\t  0.161641\t  0.162009\t\tCURRENT LEARNING RATE: 0.05595837430866444\n",
      "previous_iter_valid_loss : 0.16204196214675903\n",
      "\n",
      "    219000\t  0.162138\t  0.162042\t  0.162013\t\tCURRENT LEARNING RATE: 0.05584656940222184\n",
      "previous_iter_valid_loss : 0.1615268588066101\n",
      "\n",
      "    219200\t  0.161634\t  0.161527\t  0.162009\t\tCURRENT LEARNING RATE: 0.05573498788213134\n",
      "previous_iter_valid_loss : 0.1627625674009323\n",
      "\n",
      "    219400\t  0.162899\t  0.162763\t  0.162014\t\tCURRENT LEARNING RATE: 0.05562362930206665\n",
      "previous_iter_valid_loss : 0.16200566291809082\n",
      "\n",
      "    219600\t  0.162163\t  0.162006\t  0.162016\t\tCURRENT LEARNING RATE: 0.055512493216593364\n",
      "previous_iter_valid_loss : 0.16151945292949677\n",
      "\n",
      "    219800\t  0.161665\t  0.161519\t  0.162017\t\tCURRENT LEARNING RATE: 0.055401579181166935\n",
      "previous_iter_valid_loss : 0.16152456402778625\n",
      "\n",
      "    220000\t  0.161652\t  0.161525\t  0.162013\t\tCURRENT LEARNING RATE: 0.05529088675213112\n",
      "previous_iter_valid_loss : 0.16290292143821716\n",
      "\n",
      "    220200\t  0.163054\t  0.162903\t  0.162009\t\tCURRENT LEARNING RATE: 0.05518041548671601\n",
      "previous_iter_valid_loss : 0.16206470131874084\n",
      "\n",
      "    220400\t  0.162218\t  0.162065\t  0.162012\t\tCURRENT LEARNING RATE: 0.05507016494303645\n",
      "previous_iter_valid_loss : 0.16272574663162231\n",
      "\n",
      "    220600\t  0.162871\t  0.162726\t  0.162016\t\tCURRENT LEARNING RATE: 0.05496013468009006\n",
      "previous_iter_valid_loss : 0.1618652194738388\n",
      "\n",
      "    220800\t  0.162012\t  0.161865\t  0.162016\t\tCURRENT LEARNING RATE: 0.054850324257755705\n",
      "previous_iter_valid_loss : 0.1613970696926117\n",
      "\n",
      "    221000\t  0.161547\t  0.161397\t  0.162014\t\tCURRENT LEARNING RATE: 0.05474073323679148\n",
      "previous_iter_valid_loss : 0.16133011877536774\n",
      "\n",
      "    221200\t  0.161482\t  0.161330\t  0.162014\t\tCURRENT LEARNING RATE: 0.054631361178833215\n",
      "previous_iter_valid_loss : 0.16169562935829163\n",
      "\n",
      "    221400\t  0.161873\t  0.161696\t  0.162015\t\tCURRENT LEARNING RATE: 0.05452220764639249\n",
      "previous_iter_valid_loss : 0.16280116140842438\n",
      "\n",
      "    221600\t  0.162965\t  0.162801\t  0.162012\t\tCURRENT LEARNING RATE: 0.054413272202855065\n",
      "previous_iter_valid_loss : 0.16181352734565735\n",
      "\n",
      "    221800\t  0.162019\t  0.161814\t  0.162005\t\tCURRENT LEARNING RATE: 0.05430455441247898\n",
      "previous_iter_valid_loss : 0.16137051582336426\n",
      "\n",
      "    222000\t  0.161488\t  0.161371\t  0.162001\t\tCURRENT LEARNING RATE: 0.05419605384039298\n",
      "previous_iter_valid_loss : 0.16148924827575684\n",
      "\n",
      "    222200\t  0.161674\t  0.161489\t  0.162000\t\tCURRENT LEARNING RATE: 0.05408777005259457\n",
      "previous_iter_valid_loss : 0.1615547388792038\n",
      "\n",
      "    222400\t  0.161697\t  0.161555\t  0.161999\t\tCURRENT LEARNING RATE: 0.05397970261594851\n",
      "previous_iter_valid_loss : 0.1625896841287613\n",
      "\n",
      "    222600\t  0.162732\t  0.162590\t  0.162006\t\tCURRENT LEARNING RATE: 0.053871851098184875\n",
      "previous_iter_valid_loss : 0.16190427541732788\n",
      "\n",
      "    222800\t  0.162051\t  0.161904\t  0.162001\t\tCURRENT LEARNING RATE: 0.053764215067897476\n",
      "previous_iter_valid_loss : 0.16135506331920624\n",
      "\n",
      "    223000\t  0.161500\t  0.161355\t  0.162002\t\tCURRENT LEARNING RATE: 0.053656794094542014\n",
      "previous_iter_valid_loss : 0.16167622804641724\n",
      "\n",
      "    223200\t  0.161779\t  0.161676\t  0.162002\t\tCURRENT LEARNING RATE: 0.0535495877484345\n",
      "previous_iter_valid_loss : 0.16172465682029724\n",
      "\n",
      "    223400\t  0.161902\t  0.161725\t  0.161995\t\tCURRENT LEARNING RATE: 0.05344259560074935\n",
      "previous_iter_valid_loss : 0.16184768080711365\n",
      "\n",
      "    223600\t  0.162026\t  0.161848\t  0.161996\t\tCURRENT LEARNING RATE: 0.05333581722351788\n",
      "previous_iter_valid_loss : 0.161469966173172\n",
      "\n",
      "    223800\t  0.161682\t  0.161470\t  0.161983\t\tCURRENT LEARNING RATE: 0.0532292521896264\n",
      "previous_iter_valid_loss : 0.1618688702583313\n",
      "\n",
      "    224000\t  0.162022\t  0.161869\t  0.161982\t\tCURRENT LEARNING RATE: 0.05312290007281467\n",
      "previous_iter_valid_loss : 0.16168594360351562\n",
      "\n",
      "    224200\t  0.161849\t  0.161686\t  0.161979\t\tCURRENT LEARNING RATE: 0.05301676044767405\n",
      "previous_iter_valid_loss : 0.16227585077285767\n",
      "\n",
      "    224400\t  0.162458\t  0.162276\t  0.161984\t\tCURRENT LEARNING RATE: 0.052910832889645924\n",
      "previous_iter_valid_loss : 0.16173391044139862\n",
      "\n",
      "    224600\t  0.161825\t  0.161734\t  0.161985\t\tCURRENT LEARNING RATE: 0.052805116975019877\n",
      "previous_iter_valid_loss : 0.16141530871391296\n",
      "\n",
      "    224800\t  0.161543\t  0.161415\t  0.161986\t\tCURRENT LEARNING RATE: 0.052699612280932166\n",
      "previous_iter_valid_loss : 0.16143402457237244\n",
      "\n",
      "    225000\t  0.161527\t  0.161434\t  0.161984\t\tCURRENT LEARNING RATE: 0.052594318385363846\n",
      "previous_iter_valid_loss : 0.16151849925518036\n",
      "\n",
      "    225200\t  0.161629\t  0.161518\t  0.161985\t\tCURRENT LEARNING RATE: 0.05248923486713917\n",
      "previous_iter_valid_loss : 0.16218163073062897\n",
      "\n",
      "    225400\t  0.162259\t  0.162182\t  0.161989\t\tCURRENT LEARNING RATE: 0.05238436130592397\n",
      "previous_iter_valid_loss : 0.16123837232589722\n",
      "\n",
      "    225600\t  0.161376\t  0.161238\t  0.161987\t\tCURRENT LEARNING RATE: 0.052279697282223814\n",
      "previous_iter_valid_loss : 0.16144795715808868\n",
      "\n",
      "    225800\t  0.161548\t  0.161448\t  0.161987\t\tCURRENT LEARNING RATE: 0.05217524237738252\n",
      "previous_iter_valid_loss : 0.16165661811828613\n",
      "\n",
      "    226000\t  0.161752\t  0.161657\t  0.161988\t\tCURRENT LEARNING RATE: 0.052070996173580276\n",
      "previous_iter_valid_loss : 0.16189050674438477\n",
      "\n",
      "    226200\t  0.162006\t  0.161891\t  0.161988\t\tCURRENT LEARNING RATE: 0.05196695825383218\n",
      "previous_iter_valid_loss : 0.16180995106697083\n",
      "\n",
      "    226400\t  0.161915\t  0.161810\t  0.161989\t\tCURRENT LEARNING RATE: 0.051863128201986367\n",
      "previous_iter_valid_loss : 0.16155600547790527\n",
      "\n",
      "    226600\t  0.161679\t  0.161556\t  0.161990\t\tCURRENT LEARNING RATE: 0.05175950560272253\n",
      "previous_iter_valid_loss : 0.16171090304851532\n",
      "\n",
      "    226800\t  0.161815\t  0.161711\t  0.161992\t\tCURRENT LEARNING RATE: 0.0516560900415501\n",
      "previous_iter_valid_loss : 0.1631172150373459\n",
      "\n",
      "    227000\t  0.163247\t  0.163117\t  0.161993\t\tCURRENT LEARNING RATE: 0.05155288110480673\n",
      "previous_iter_valid_loss : 0.16123884916305542\n",
      "\n",
      "    227200\t  0.161356\t  0.161239\t  0.161987\t\tCURRENT LEARNING RATE: 0.0514498783796565\n",
      "previous_iter_valid_loss : 0.16144078969955444\n",
      "\n",
      "    227400\t  0.161574\t  0.161441\t  0.161989\t\tCURRENT LEARNING RATE: 0.0513470814540884\n",
      "previous_iter_valid_loss : 0.16127052903175354\n",
      "\n",
      "    227600\t  0.161361\t  0.161271\t  0.161978\t\tCURRENT LEARNING RATE: 0.05124448991691456\n",
      "previous_iter_valid_loss : 0.1624155193567276\n",
      "\n",
      "    227800\t  0.162574\t  0.162416\t  0.161983\t\tCURRENT LEARNING RATE: 0.05114210335776874\n",
      "previous_iter_valid_loss : 0.1615932583808899\n",
      "\n",
      "    228000\t  0.161717\t  0.161593\t  0.161977\t\tCURRENT LEARNING RATE: 0.051039921367104515\n",
      "previous_iter_valid_loss : 0.16120316088199615\n",
      "\n",
      "    228200\t  0.161323\t  0.161203\t  0.161976\t\tCURRENT LEARNING RATE: 0.05093794353619384\n",
      "previous_iter_valid_loss : 0.16247853636741638\n",
      "\n",
      "    228400\t  0.162609\t  0.162479\t  0.161982\t\tCURRENT LEARNING RATE: 0.0508361694571252\n",
      "previous_iter_valid_loss : 0.1630041003227234\n",
      "\n",
      "    228600\t  0.163165\t  0.163004\t  0.161984\t\tCURRENT LEARNING RATE: 0.05073459872280219\n",
      "previous_iter_valid_loss : 0.16173484921455383\n",
      "\n",
      "    228800\t  0.161890\t  0.161735\t  0.161987\t\tCURRENT LEARNING RATE: 0.0506332309269417\n",
      "previous_iter_valid_loss : 0.16242806613445282\n",
      "\n",
      "    229000\t  0.162609\t  0.162428\t  0.161992\t\tCURRENT LEARNING RATE: 0.05053206566407245\n",
      "previous_iter_valid_loss : 0.1613299697637558\n",
      "\n",
      "    229200\t  0.161478\t  0.161330\t  0.161986\t\tCURRENT LEARNING RATE: 0.05043110252953321\n",
      "previous_iter_valid_loss : 0.1616261601448059\n",
      "\n",
      "    229400\t  0.161767\t  0.161626\t  0.161985\t\tCURRENT LEARNING RATE: 0.05033034111947135\n",
      "previous_iter_valid_loss : 0.16165143251419067\n",
      "\n",
      "    229600\t  0.161805\t  0.161651\t  0.161980\t\tCURRENT LEARNING RATE: 0.05022978103084105\n",
      "previous_iter_valid_loss : 0.16150926053524017\n",
      "\n",
      "    229800\t  0.161645\t  0.161509\t  0.161978\t\tCURRENT LEARNING RATE: 0.050129421861401874\n",
      "previous_iter_valid_loss : 0.16224084794521332\n",
      "\n",
      "    230000\t  0.162426\t  0.162241\t  0.161983\t\tCURRENT LEARNING RATE: 0.05002926320971696\n",
      "previous_iter_valid_loss : 0.1618393212556839\n",
      "\n",
      "    230200\t  0.161985\t  0.161839\t  0.161985\t\tCURRENT LEARNING RATE: 0.049929304675151616\n",
      "previous_iter_valid_loss : 0.1619124710559845\n",
      "\n",
      "    230400\t  0.162105\t  0.161912\t  0.161988\t\tCURRENT LEARNING RATE: 0.04982954585787151\n",
      "previous_iter_valid_loss : 0.16153991222381592\n",
      "\n",
      "    230600\t  0.161632\t  0.161540\t  0.161989\t\tCURRENT LEARNING RATE: 0.04972998635884131\n",
      "previous_iter_valid_loss : 0.16129016876220703\n",
      "\n",
      "    230800\t  0.161404\t  0.161290\t  0.161989\t\tCURRENT LEARNING RATE: 0.04963062577982283\n",
      "previous_iter_valid_loss : 0.16152770817279816\n",
      "\n",
      "    231000\t  0.161635\t  0.161528\t  0.161987\t\tCURRENT LEARNING RATE: 0.04953146372337366\n",
      "previous_iter_valid_loss : 0.16231755912303925\n",
      "\n",
      "    231200\t  0.162421\t  0.162318\t  0.161992\t\tCURRENT LEARNING RATE: 0.049432499792845405\n",
      "previous_iter_valid_loss : 0.16155903041362762\n",
      "\n",
      "    231400\t  0.161681\t  0.161559\t  0.161992\t\tCURRENT LEARNING RATE: 0.04933373359238225\n",
      "previous_iter_valid_loss : 0.1624489426612854\n",
      "\n",
      "    231600\t  0.162550\t  0.162449\t  0.161995\t\tCURRENT LEARNING RATE: 0.049235164726919224\n",
      "previous_iter_valid_loss : 0.16192509233951569\n",
      "\n",
      "    231800\t  0.162035\t  0.161925\t  0.161996\t\tCURRENT LEARNING RATE: 0.04913679280218077\n",
      "previous_iter_valid_loss : 0.16153225302696228\n",
      "\n",
      "    232000\t  0.161669\t  0.161532\t  0.161991\t\tCURRENT LEARNING RATE: 0.04903861742467903\n",
      "previous_iter_valid_loss : 0.16198711097240448\n",
      "\n",
      "    232200\t  0.162113\t  0.161987\t  0.161982\t\tCURRENT LEARNING RATE: 0.048940638201712384\n",
      "previous_iter_valid_loss : 0.16114650666713715\n",
      "\n",
      "    232400\t  0.161255\t  0.161147\t  0.161979\t\tCURRENT LEARNING RATE: 0.04884285474136378\n",
      "previous_iter_valid_loss : 0.16191554069519043\n",
      "\n",
      "    232600\t  0.162059\t  0.161916\t  0.161979\t\tCURRENT LEARNING RATE: 0.04874526665249929\n",
      "previous_iter_valid_loss : 0.16224737465381622\n",
      "\n",
      "    232800\t  0.162380\t  0.162247\t  0.161978\t\tCURRENT LEARNING RATE: 0.04864787354476638\n",
      "previous_iter_valid_loss : 0.1616213172674179\n",
      "\n",
      "    233000\t  0.161723\t  0.161621\t  0.161973\t\tCURRENT LEARNING RATE: 0.04855067502859254\n",
      "previous_iter_valid_loss : 0.16296082735061646\n",
      "\n",
      "    233200\t  0.163067\t  0.162961\t  0.161977\t\tCURRENT LEARNING RATE: 0.04845367071518352\n",
      "previous_iter_valid_loss : 0.1619240641593933\n",
      "\n",
      "    233400\t  0.162033\t  0.161924\t  0.161972\t\tCURRENT LEARNING RATE: 0.04835686021652199\n",
      "previous_iter_valid_loss : 0.16138096153736115\n",
      "\n",
      "    233600\t  0.161503\t  0.161381\t  0.161971\t\tCURRENT LEARNING RATE: 0.048260243145365776\n",
      "previous_iter_valid_loss : 0.1619711071252823\n",
      "\n",
      "    233800\t  0.162067\t  0.161971\t  0.161971\t\tCURRENT LEARNING RATE: 0.04816381911524652\n",
      "previous_iter_valid_loss : 0.16126832365989685\n",
      "\n",
      "    234000\t  0.161397\t  0.161268\t  0.161965\t\tCURRENT LEARNING RATE: 0.04806758774046791\n",
      "previous_iter_valid_loss : 0.16217349469661713\n",
      "\n",
      "    234200\t  0.162309\t  0.162173\t  0.161968\t\tCURRENT LEARNING RATE: 0.04797154863610439\n",
      "previous_iter_valid_loss : 0.16124363243579865\n",
      "\n",
      "    234400\t  0.161339\t  0.161244\t  0.161967\t\tCURRENT LEARNING RATE: 0.04787570141799934\n",
      "previous_iter_valid_loss : 0.1613646000623703\n",
      "\n",
      "    234600\t  0.161494\t  0.161365\t  0.161953\t\tCURRENT LEARNING RATE: 0.047780045702763826\n",
      "previous_iter_valid_loss : 0.16216756403446198\n",
      "\n",
      "    234800\t  0.162251\t  0.162168\t  0.161953\t\tCURRENT LEARNING RATE: 0.04768458110777481\n",
      "previous_iter_valid_loss : 0.16191603243350983\n",
      "\n",
      "    235000\t  0.161996\t  0.161916\t  0.161945\t\tCURRENT LEARNING RATE: 0.047589307251173815\n",
      "previous_iter_valid_loss : 0.16141477227210999\n",
      "\n",
      "    235200\t  0.161538\t  0.161415\t  0.161942\t\tCURRENT LEARNING RATE: 0.04749422375186527\n",
      "previous_iter_valid_loss : 0.16176293790340424\n",
      "\n",
      "    235400\t  0.161935\t  0.161763\t  0.161944\t\tCURRENT LEARNING RATE: 0.04739933022951507\n",
      "previous_iter_valid_loss : 0.16210637986660004\n",
      "\n",
      "    235600\t  0.162212\t  0.162106\t  0.161941\t\tCURRENT LEARNING RATE: 0.047304626304548965\n",
      "previous_iter_valid_loss : 0.16205213963985443\n",
      "\n",
      "    235800\t  0.162217\t  0.162052\t  0.161943\t\tCURRENT LEARNING RATE: 0.047210111598151173\n",
      "previous_iter_valid_loss : 0.16163356602191925\n",
      "\n",
      "    236000\t  0.161736\t  0.161634\t  0.161934\t\tCURRENT LEARNING RATE: 0.0471157857322627\n",
      "previous_iter_valid_loss : 0.16174128651618958\n",
      "\n",
      "    236200\t  0.161902\t  0.161741\t  0.161936\t\tCURRENT LEARNING RATE: 0.04702164832958\n",
      "previous_iter_valid_loss : 0.16127358376979828\n",
      "\n",
      "    236400\t  0.161409\t  0.161274\t  0.161936\t\tCURRENT LEARNING RATE: 0.046927699013553294\n",
      "previous_iter_valid_loss : 0.16159574687480927\n",
      "\n",
      "    236600\t  0.161731\t  0.161596\t  0.161933\t\tCURRENT LEARNING RATE: 0.046833937408385234\n",
      "previous_iter_valid_loss : 0.16185633838176727\n",
      "\n",
      "    236800\t  0.161983\t  0.161856\t  0.161934\t\tCURRENT LEARNING RATE: 0.04674036313902923\n",
      "previous_iter_valid_loss : 0.161641463637352\n",
      "\n",
      "    237000\t  0.161823\t  0.161641\t  0.161935\t\tCURRENT LEARNING RATE: 0.046646975831188126\n",
      "previous_iter_valid_loss : 0.16180190443992615\n",
      "\n",
      "    237200\t  0.161929\t  0.161802\t  0.161936\t\tCURRENT LEARNING RATE: 0.04655377511131252\n",
      "previous_iter_valid_loss : 0.16120150685310364\n",
      "\n",
      "    237400\t  0.161323\t  0.161202\t  0.161929\t\tCURRENT LEARNING RATE: 0.04646076060659945\n",
      "previous_iter_valid_loss : 0.16135334968566895\n",
      "\n",
      "    237600\t  0.161462\t  0.161353\t  0.161926\t\tCURRENT LEARNING RATE: 0.04636793194499073\n",
      "previous_iter_valid_loss : 0.16149306297302246\n",
      "\n",
      "    237800\t  0.161660\t  0.161493\t  0.161919\t\tCURRENT LEARNING RATE: 0.046275288755171645\n",
      "previous_iter_valid_loss : 0.16160652041435242\n",
      "\n",
      "    238000\t  0.161746\t  0.161607\t  0.161920\t\tCURRENT LEARNING RATE: 0.04618283066656925\n",
      "previous_iter_valid_loss : 0.16167859733104706\n",
      "\n",
      "    238200\t  0.161815\t  0.161679\t  0.161922\t\tCURRENT LEARNING RATE: 0.046090557309351125\n",
      "previous_iter_valid_loss : 0.1614661067724228\n",
      "\n",
      "    238400\t  0.161553\t  0.161466\t  0.161921\t\tCURRENT LEARNING RATE: 0.04599846831442367\n",
      "previous_iter_valid_loss : 0.1617828607559204\n",
      "\n",
      "    238600\t  0.161939\t  0.161783\t  0.161916\t\tCURRENT LEARNING RATE: 0.04590656331343083\n",
      "previous_iter_valid_loss : 0.16146999597549438\n",
      "\n",
      "    238800\t  0.161612\t  0.161470\t  0.161914\t\tCURRENT LEARNING RATE: 0.04581484193875242\n",
      "previous_iter_valid_loss : 0.16140106320381165\n",
      "\n",
      "    239000\t  0.161515\t  0.161401\t  0.161915\t\tCURRENT LEARNING RATE: 0.04572330382350288\n",
      "previous_iter_valid_loss : 0.16137290000915527\n",
      "\n",
      "    239200\t  0.161479\t  0.161373\t  0.161913\t\tCURRENT LEARNING RATE: 0.045631948601529575\n",
      "previous_iter_valid_loss : 0.16156770288944244\n",
      "\n",
      "    239400\t  0.161682\t  0.161568\t  0.161907\t\tCURRENT LEARNING RATE: 0.04554077590741154\n",
      "previous_iter_valid_loss : 0.16124892234802246\n",
      "\n",
      "    239600\t  0.161341\t  0.161249\t  0.161897\t\tCURRENT LEARNING RATE: 0.04544978537645784\n",
      "previous_iter_valid_loss : 0.16124649345874786\n",
      "\n",
      "    239800\t  0.161342\t  0.161246\t  0.161891\t\tCURRENT LEARNING RATE: 0.045358976644706256\n",
      "previous_iter_valid_loss : 0.16148144006729126\n",
      "\n",
      "    240000\t  0.161549\t  0.161481\t  0.161892\t\tCURRENT LEARNING RATE: 0.04526834934892172\n",
      "previous_iter_valid_loss : 0.1615201234817505\n",
      "\n",
      "    240200\t  0.161644\t  0.161520\t  0.161891\t\tCURRENT LEARNING RATE: 0.04517790312659495\n",
      "previous_iter_valid_loss : 0.1615697741508484\n",
      "\n",
      "    240400\t  0.161720\t  0.161570\t  0.161892\t\tCURRENT LEARNING RATE: 0.0450876376159409\n",
      "previous_iter_valid_loss : 0.16203299164772034\n",
      "\n",
      "    240600\t  0.162140\t  0.162033\t  0.161895\t\tCURRENT LEARNING RATE: 0.044997552455897455\n",
      "previous_iter_valid_loss : 0.1612914651632309\n",
      "\n",
      "    240800\t  0.161440\t  0.161291\t  0.161892\t\tCURRENT LEARNING RATE: 0.044907647286123814\n",
      "previous_iter_valid_loss : 0.16119959950447083\n",
      "\n",
      "    241000\t  0.161328\t  0.161200\t  0.161891\t\tCURRENT LEARNING RATE: 0.04481792174699921\n",
      "previous_iter_valid_loss : 0.16141873598098755\n",
      "\n",
      "    241200\t  0.161562\t  0.161419\t  0.161889\t\tCURRENT LEARNING RATE: 0.044728375479621336\n",
      "previous_iter_valid_loss : 0.16133925318717957\n",
      "\n",
      "    241400\t  0.161488\t  0.161339\t  0.161879\t\tCURRENT LEARNING RATE: 0.044639008125805034\n",
      "previous_iter_valid_loss : 0.16200588643550873\n",
      "\n",
      "    241600\t  0.162175\t  0.162006\t  0.161877\t\tCURRENT LEARNING RATE: 0.044549819328080734\n",
      "previous_iter_valid_loss : 0.1611485481262207\n",
      "\n",
      "    241800\t  0.161274\t  0.161149\t  0.161875\t\tCURRENT LEARNING RATE: 0.04446080872969317\n",
      "previous_iter_valid_loss : 0.16126661002635956\n",
      "\n",
      "    242000\t  0.161375\t  0.161267\t  0.161876\t\tCURRENT LEARNING RATE: 0.044371975974599784\n",
      "previous_iter_valid_loss : 0.1616101861000061\n",
      "\n",
      "    242200\t  0.161762\t  0.161610\t  0.161876\t\tCURRENT LEARNING RATE: 0.04428332070746948\n",
      "previous_iter_valid_loss : 0.161778062582016\n",
      "\n",
      "    242400\t  0.161892\t  0.161778\t  0.161874\t\tCURRENT LEARNING RATE: 0.044194842573681024\n",
      "previous_iter_valid_loss : 0.1617242842912674\n",
      "\n",
      "    242600\t  0.161861\t  0.161724\t  0.161866\t\tCURRENT LEARNING RATE: 0.04410654121932182\n",
      "previous_iter_valid_loss : 0.16299228370189667\n",
      "\n",
      "    242800\t  0.163165\t  0.162992\t  0.161869\t\tCURRENT LEARNING RATE: 0.044018416291186274\n",
      "previous_iter_valid_loss : 0.16149264574050903\n",
      "\n",
      "    243000\t  0.161654\t  0.161493\t  0.161870\t\tCURRENT LEARNING RATE: 0.0439304674367746\n",
      "previous_iter_valid_loss : 0.16166849434375763\n",
      "\n",
      "    243200\t  0.161848\t  0.161668\t  0.161863\t\tCURRENT LEARNING RATE: 0.04384269430429124\n",
      "previous_iter_valid_loss : 0.16297632455825806\n",
      "\n",
      "    243400\t  0.163123\t  0.162976\t  0.161855\t\tCURRENT LEARNING RATE: 0.04375509654264356\n",
      "previous_iter_valid_loss : 0.16123303771018982\n",
      "\n",
      "    243600\t  0.161393\t  0.161233\t  0.161847\t\tCURRENT LEARNING RATE: 0.04366767380144038\n",
      "previous_iter_valid_loss : 0.16151872277259827\n",
      "\n",
      "    243800\t  0.161617\t  0.161519\t  0.161847\t\tCURRENT LEARNING RATE: 0.04358042573099065\n",
      "previous_iter_valid_loss : 0.16264218091964722\n",
      "\n",
      "    244000\t  0.162816\t  0.162642\t  0.161853\t\tCURRENT LEARNING RATE: 0.04349335198230193\n",
      "previous_iter_valid_loss : 0.16141314804553986\n",
      "\n",
      "    244200\t  0.161549\t  0.161413\t  0.161853\t\tCURRENT LEARNING RATE: 0.043406452207079144\n",
      "previous_iter_valid_loss : 0.16135358810424805\n",
      "\n",
      "    244400\t  0.161498\t  0.161354\t  0.161850\t\tCURRENT LEARNING RATE: 0.04331972605772305\n",
      "previous_iter_valid_loss : 0.16211755573749542\n",
      "\n",
      "    244600\t  0.162336\t  0.162118\t  0.161852\t\tCURRENT LEARNING RATE: 0.04323317318732896\n",
      "previous_iter_valid_loss : 0.16143687069416046\n",
      "\n",
      "    244800\t  0.161594\t  0.161437\t  0.161851\t\tCURRENT LEARNING RATE: 0.04314679324968525\n",
      "previous_iter_valid_loss : 0.16144633293151855\n",
      "\n",
      "    245000\t  0.161595\t  0.161446\t  0.161851\t\tCURRENT LEARNING RATE: 0.04306058589927208\n",
      "previous_iter_valid_loss : 0.16208961606025696\n",
      "\n",
      "    245200\t  0.162277\t  0.162090\t  0.161854\t\tCURRENT LEARNING RATE: 0.042974550791259905\n",
      "previous_iter_valid_loss : 0.1611522138118744\n",
      "\n",
      "    245400\t  0.161268\t  0.161152\t  0.161852\t\tCURRENT LEARNING RATE: 0.04288868758150822\n",
      "previous_iter_valid_loss : 0.1616513729095459\n",
      "\n",
      "    245600\t  0.161804\t  0.161651\t  0.161854\t\tCURRENT LEARNING RATE: 0.042802995926564016\n",
      "previous_iter_valid_loss : 0.16162912547588348\n",
      "\n",
      "    245800\t  0.161747\t  0.161629\t  0.161845\t\tCURRENT LEARNING RATE: 0.042717475483660616\n",
      "previous_iter_valid_loss : 0.16150522232055664\n",
      "\n",
      "    246000\t  0.161614\t  0.161505\t  0.161846\t\tCURRENT LEARNING RATE: 0.042632125910716086\n",
      "previous_iter_valid_loss : 0.16126616299152374\n",
      "\n",
      "    246200\t  0.161423\t  0.161266\t  0.161846\t\tCURRENT LEARNING RATE: 0.04254694686633206\n",
      "previous_iter_valid_loss : 0.16157890856266022\n",
      "\n",
      "    246400\t  0.161713\t  0.161579\t  0.161845\t\tCURRENT LEARNING RATE: 0.042461938009792206\n",
      "previous_iter_valid_loss : 0.16196368634700775\n",
      "\n",
      "    246600\t  0.162087\t  0.161964\t  0.161849\t\tCURRENT LEARNING RATE: 0.042377099001061035\n",
      "previous_iter_valid_loss : 0.16135244071483612\n",
      "\n",
      "    246800\t  0.161474\t  0.161352\t  0.161836\t\tCURRENT LEARNING RATE: 0.042292429500782346\n",
      "previous_iter_valid_loss : 0.1614474356174469\n",
      "\n",
      "    247000\t  0.161570\t  0.161447\t  0.161833\t\tCURRENT LEARNING RATE: 0.04220792917027807\n",
      "previous_iter_valid_loss : 0.16221670806407928\n",
      "\n",
      "    247200\t  0.162350\t  0.162217\t  0.161834\t\tCURRENT LEARNING RATE: 0.042123597671546734\n",
      "previous_iter_valid_loss : 0.1614052951335907\n",
      "\n",
      "    247400\t  0.161504\t  0.161405\t  0.161833\t\tCURRENT LEARNING RATE: 0.04203943466726227\n",
      "previous_iter_valid_loss : 0.16116368770599365\n",
      "\n",
      "    247600\t  0.161251\t  0.161164\t  0.161831\t\tCURRENT LEARNING RATE: 0.0419554398207725\n",
      "previous_iter_valid_loss : 0.16158519685268402\n",
      "\n",
      "    247800\t  0.161669\t  0.161585\t  0.161827\t\tCURRENT LEARNING RATE: 0.04187161279609798\n",
      "previous_iter_valid_loss : 0.16294117271900177\n",
      "\n",
      "    248000\t  0.163069\t  0.162941\t  0.161834\t\tCURRENT LEARNING RATE: 0.04178795325793045\n",
      "previous_iter_valid_loss : 0.1629718840122223\n",
      "\n",
      "    248200\t  0.163112\t  0.162972\t  0.161836\t\tCURRENT LEARNING RATE: 0.041704460871631696\n",
      "previous_iter_valid_loss : 0.16128459572792053\n",
      "\n",
      "    248400\t  0.161398\t  0.161285\t  0.161835\t\tCURRENT LEARNING RATE: 0.041621135303232006\n",
      "previous_iter_valid_loss : 0.16251124441623688\n",
      "\n",
      "    248600\t  0.162683\t  0.162511\t  0.161841\t\tCURRENT LEARNING RATE: 0.04153797621942905\n",
      "previous_iter_valid_loss : 0.16193655133247375\n",
      "\n",
      "    248800\t  0.162111\t  0.161937\t  0.161843\t\tCURRENT LEARNING RATE: 0.04145498328758633\n",
      "previous_iter_valid_loss : 0.16124726831912994\n",
      "\n",
      "    249000\t  0.161355\t  0.161247\t  0.161837\t\tCURRENT LEARNING RATE: 0.04137215617573206\n",
      "previous_iter_valid_loss : 0.1611727923154831\n",
      "\n",
      "    249200\t  0.161304\t  0.161173\t  0.161836\t\tCURRENT LEARNING RATE: 0.041289494552557635\n",
      "previous_iter_valid_loss : 0.16151951253414154\n",
      "\n",
      "    249400\t  0.161666\t  0.161520\t  0.161829\t\tCURRENT LEARNING RATE: 0.041206998087416485\n",
      "previous_iter_valid_loss : 0.1616048365831375\n",
      "\n",
      "    249600\t  0.161722\t  0.161605\t  0.161827\t\tCURRENT LEARNING RATE: 0.04112466645032262\n",
      "previous_iter_valid_loss : 0.16118407249450684\n",
      "\n",
      "    249800\t  0.161280\t  0.161184\t  0.161810\t\tCURRENT LEARNING RATE: 0.0410424993119494\n",
      "previous_iter_valid_loss : 0.16256673634052277\n",
      "\n",
      "    250000\t  0.162696\t  0.162567\t  0.161809\t\tCURRENT LEARNING RATE: 0.04096049634362815\n",
      "previous_iter_valid_loss : 0.16240620613098145\n",
      "\n",
      "    250200\t  0.162543\t  0.162406\t  0.161813\t\tCURRENT LEARNING RATE: 0.040878657217346875\n",
      "previous_iter_valid_loss : 0.16321434080600739\n",
      "\n",
      "    250400\t  0.163345\t  0.163214\t  0.161817\t\tCURRENT LEARNING RATE: 0.04079698160574899\n",
      "previous_iter_valid_loss : 0.1622374802827835\n",
      "\n",
      "    250600\t  0.162368\t  0.162237\t  0.161819\t\tCURRENT LEARNING RATE: 0.040715469182131904\n",
      "previous_iter_valid_loss : 0.1616470068693161\n",
      "\n",
      "    250800\t  0.161809\t  0.161647\t  0.161820\t\tCURRENT LEARNING RATE: 0.04063411962044585\n",
      "previous_iter_valid_loss : 0.1614115983247757\n",
      "\n",
      "    251000\t  0.161444\t  0.161412\t  0.161816\t\tCURRENT LEARNING RATE: 0.04055293259529245\n",
      "previous_iter_valid_loss : 0.1621396541595459\n",
      "\n",
      "    251200\t  0.162316\t  0.162140\t  0.161820\t\tCURRENT LEARNING RATE: 0.040471907781923507\n",
      "previous_iter_valid_loss : 0.1613289713859558\n",
      "\n",
      "    251400\t  0.161434\t  0.161329\t  0.161800\t\tCURRENT LEARNING RATE: 0.04039104485623964\n",
      "previous_iter_valid_loss : 0.16180415451526642\n",
      "\n",
      "    251600\t  0.161892\t  0.161804\t  0.161803\t\tCURRENT LEARNING RATE: 0.040310343494789076\n",
      "previous_iter_valid_loss : 0.16134671866893768\n",
      "\n",
      "    251800\t  0.161482\t  0.161347\t  0.161798\t\tCURRENT LEARNING RATE: 0.04022980337476622\n",
      "previous_iter_valid_loss : 0.16133420169353485\n",
      "\n",
      "    252000\t  0.161413\t  0.161334\t  0.161793\t\tCURRENT LEARNING RATE: 0.04014942417401051\n",
      "previous_iter_valid_loss : 0.16219837963581085\n",
      "\n",
      "    252200\t  0.162276\t  0.162198\t  0.161795\t\tCURRENT LEARNING RATE: 0.040069205571005025\n",
      "previous_iter_valid_loss : 0.16131946444511414\n",
      "\n",
      "    252400\t  0.161405\t  0.161319\t  0.161794\t\tCURRENT LEARNING RATE: 0.039989147244875255\n",
      "previous_iter_valid_loss : 0.16121231019496918\n",
      "\n",
      "    252600\t  0.161359\t  0.161212\t  0.161793\t\tCURRENT LEARNING RATE: 0.03990924887538777\n",
      "previous_iter_valid_loss : 0.16141080856323242\n",
      "\n",
      "    252800\t  0.161517\t  0.161411\t  0.161786\t\tCURRENT LEARNING RATE: 0.03982951014294902\n",
      "previous_iter_valid_loss : 0.16271430253982544\n",
      "\n",
      "    253000\t  0.162915\t  0.162714\t  0.161789\t\tCURRENT LEARNING RATE: 0.03974993072860393\n",
      "previous_iter_valid_loss : 0.1614333689212799\n",
      "\n",
      "    253200\t  0.161527\t  0.161433\t  0.161789\t\tCURRENT LEARNING RATE: 0.03967051031403477\n",
      "previous_iter_valid_loss : 0.16176655888557434\n",
      "\n",
      "    253400\t  0.161834\t  0.161767\t  0.161788\t\tCURRENT LEARNING RATE: 0.03959124858155974\n",
      "previous_iter_valid_loss : 0.16128644347190857\n",
      "\n",
      "    253600\t  0.161451\t  0.161286\t  0.161786\t\tCURRENT LEARNING RATE: 0.03951214521413184\n",
      "previous_iter_valid_loss : 0.1616324633359909\n",
      "\n",
      "    253800\t  0.161690\t  0.161632\t  0.161783\t\tCURRENT LEARNING RATE: 0.03943319989533747\n",
      "previous_iter_valid_loss : 0.1617388129234314\n",
      "\n",
      "    254000\t  0.161899\t  0.161739\t  0.161779\t\tCURRENT LEARNING RATE: 0.03935441230939527\n",
      "previous_iter_valid_loss : 0.1617300659418106\n",
      "\n",
      "    254200\t  0.161888\t  0.161730\t  0.161780\t\tCURRENT LEARNING RATE: 0.03927578214115477\n",
      "previous_iter_valid_loss : 0.1616208851337433\n",
      "\n",
      "    254400\t  0.161777\t  0.161621\t  0.161776\t\tCURRENT LEARNING RATE: 0.03919730907609521\n",
      "previous_iter_valid_loss : 0.16123972833156586\n",
      "\n",
      "    254600\t  0.161356\t  0.161240\t  0.161774\t\tCURRENT LEARNING RATE: 0.03911899280032421\n",
      "previous_iter_valid_loss : 0.16142696142196655\n",
      "\n",
      "    254800\t  0.161563\t  0.161427\t  0.161771\t\tCURRENT LEARNING RATE: 0.039040833000576584\n",
      "previous_iter_valid_loss : 0.16125881671905518\n",
      "\n",
      "    255000\t  0.161387\t  0.161259\t  0.161764\t\tCURRENT LEARNING RATE: 0.038962829364213\n",
      "previous_iter_valid_loss : 0.16162559390068054\n",
      "\n",
      "    255200\t  0.161787\t  0.161626\t  0.161763\t\tCURRENT LEARNING RATE: 0.03888498157921883\n",
      "previous_iter_valid_loss : 0.16140012443065643\n",
      "\n",
      "    255400\t  0.161569\t  0.161400\t  0.161760\t\tCURRENT LEARNING RATE: 0.03880728933420281\n",
      "previous_iter_valid_loss : 0.1613265424966812\n",
      "\n",
      "    255600\t  0.161508\t  0.161327\t  0.161757\t\tCURRENT LEARNING RATE: 0.03872975231839589\n",
      "previous_iter_valid_loss : 0.16164030134677887\n",
      "\n",
      "    255800\t  0.161813\t  0.161640\t  0.161753\t\tCURRENT LEARNING RATE: 0.03865237022164987\n",
      "previous_iter_valid_loss : 0.16146749258041382\n",
      "\n",
      "    256000\t  0.161686\t  0.161467\t  0.161753\t\tCURRENT LEARNING RATE: 0.03857514273443629\n",
      "previous_iter_valid_loss : 0.16157233715057373\n",
      "\n",
      "    256200\t  0.161743\t  0.161572\t  0.161737\t\tCURRENT LEARNING RATE: 0.03849806954784506\n",
      "previous_iter_valid_loss : 0.16176415979862213\n",
      "\n",
      "    256400\t  0.161918\t  0.161764\t  0.161738\t\tCURRENT LEARNING RATE: 0.038421150353583365\n",
      "previous_iter_valid_loss : 0.1616145819425583\n",
      "\n",
      "    256600\t  0.161728\t  0.161615\t  0.161738\t\tCURRENT LEARNING RATE: 0.0383443848439743\n",
      "previous_iter_valid_loss : 0.1614321917295456\n",
      "\n",
      "    256800\t  0.161524\t  0.161432\t  0.161738\t\tCURRENT LEARNING RATE: 0.03826777271195576\n",
      "previous_iter_valid_loss : 0.1620243638753891\n",
      "\n",
      "    257000\t  0.162144\t  0.162024\t  0.161734\t\tCURRENT LEARNING RATE: 0.03819131365107906\n",
      "previous_iter_valid_loss : 0.16139209270477295\n",
      "\n",
      "    257200\t  0.161581\t  0.161392\t  0.161733\t\tCURRENT LEARNING RATE: 0.038115007355507914\n",
      "previous_iter_valid_loss : 0.16125743091106415\n",
      "\n",
      "    257400\t  0.161399\t  0.161257\t  0.161733\t\tCURRENT LEARNING RATE: 0.03803885352001699\n",
      "previous_iter_valid_loss : 0.161225363612175\n",
      "\n",
      "    257600\t  0.161375\t  0.161225\t  0.161727\t\tCURRENT LEARNING RATE: 0.03796285183999089\n",
      "previous_iter_valid_loss : 0.16134396195411682\n",
      "\n",
      "    257800\t  0.161470\t  0.161344\t  0.161726\t\tCURRENT LEARNING RATE: 0.03788700201142274\n",
      "previous_iter_valid_loss : 0.1610962301492691\n",
      "\n",
      "\n",
      "Current valid loss: 0.1610962301492691;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "    258000\t  0.161216\t  0.161096\t  0.161720\t\tCURRENT LEARNING RATE: 0.03781130373091317\n",
      "previous_iter_valid_loss : 0.1612468808889389\n",
      "\n",
      "    258200\t  0.161353\t  0.161247\t  0.161719\t\tCURRENT LEARNING RATE: 0.03773575669566892\n",
      "previous_iter_valid_loss : 0.16125833988189697\n",
      "\n",
      "    258400\t  0.161401\t  0.161258\t  0.161716\t\tCURRENT LEARNING RATE: 0.03766036060350179\n",
      "previous_iter_valid_loss : 0.16125255823135376\n",
      "\n",
      "    258600\t  0.161401\t  0.161253\t  0.161714\t\tCURRENT LEARNING RATE: 0.03758511515282727\n",
      "previous_iter_valid_loss : 0.16129784286022186\n",
      "\n",
      "    258800\t  0.161477\t  0.161298\t  0.161712\t\tCURRENT LEARNING RATE: 0.03751002004266349\n",
      "previous_iter_valid_loss : 0.16172093152999878\n",
      "\n",
      "    259000\t  0.161914\t  0.161721\t  0.161710\t\tCURRENT LEARNING RATE: 0.03743507497262987\n",
      "previous_iter_valid_loss : 0.16163921356201172\n",
      "\n",
      "    259200\t  0.161801\t  0.161639\t  0.161711\t\tCURRENT LEARNING RATE: 0.03736027964294608\n",
      "previous_iter_valid_loss : 0.16167698800563812\n",
      "\n",
      "    259400\t  0.161816\t  0.161677\t  0.161705\t\tCURRENT LEARNING RATE: 0.037285633754430655\n",
      "previous_iter_valid_loss : 0.16156087815761566\n",
      "\n",
      "    259600\t  0.161706\t  0.161561\t  0.161703\t\tCURRENT LEARNING RATE: 0.03721113700849998\n",
      "previous_iter_valid_loss : 0.16159126162528992\n",
      "\n",
      "    259800\t  0.161776\t  0.161591\t  0.161703\t\tCURRENT LEARNING RATE: 0.03713678910716694\n",
      "previous_iter_valid_loss : 0.16138465702533722\n",
      "\n",
      "    260000\t  0.161565\t  0.161385\t  0.161703\t\tCURRENT LEARNING RATE: 0.03706258975303985\n",
      "previous_iter_valid_loss : 0.16178490221500397\n",
      "\n",
      "    260200\t  0.161962\t  0.161785\t  0.161697\t\tCURRENT LEARNING RATE: 0.03698853864932118\n",
      "previous_iter_valid_loss : 0.16123928129673004\n",
      "\n",
      "    260400\t  0.161405\t  0.161239\t  0.161693\t\tCURRENT LEARNING RATE: 0.03691463549980645\n",
      "previous_iter_valid_loss : 0.16123546659946442\n",
      "\n",
      "    260600\t  0.161375\t  0.161235\t  0.161686\t\tCURRENT LEARNING RATE: 0.036840880008882915\n",
      "previous_iter_valid_loss : 0.16150234639644623\n",
      "\n",
      "    260800\t  0.161647\t  0.161502\t  0.161684\t\tCURRENT LEARNING RATE: 0.03676727188152855\n",
      "previous_iter_valid_loss : 0.161341592669487\n",
      "\n",
      "    261000\t  0.161519\t  0.161342\t  0.161683\t\tCURRENT LEARNING RATE: 0.03669381082331072\n",
      "previous_iter_valid_loss : 0.16173885762691498\n",
      "\n",
      "    261200\t  0.161910\t  0.161739\t  0.161686\t\tCURRENT LEARNING RATE: 0.03662049654038512\n",
      "previous_iter_valid_loss : 0.16119900345802307\n",
      "\n",
      "    261400\t  0.161384\t  0.161199\t  0.161683\t\tCURRENT LEARNING RATE: 0.036547328739494504\n",
      "previous_iter_valid_loss : 0.1613067388534546\n",
      "\n",
      "    261600\t  0.161480\t  0.161307\t  0.161676\t\tCURRENT LEARNING RATE: 0.036474307127967585\n",
      "previous_iter_valid_loss : 0.16124998033046722\n",
      "\n",
      "    261800\t  0.161369\t  0.161250\t  0.161673\t\tCURRENT LEARNING RATE: 0.036401431413717794\n",
      "previous_iter_valid_loss : 0.16157546639442444\n",
      "\n",
      "    262000\t  0.161709\t  0.161575\t  0.161674\t\tCURRENT LEARNING RATE: 0.03632870130524221\n",
      "previous_iter_valid_loss : 0.16155263781547546\n",
      "\n",
      "    262200\t  0.161687\t  0.161553\t  0.161674\t\tCURRENT LEARNING RATE: 0.036256116511620265\n",
      "previous_iter_valid_loss : 0.16140249371528625\n",
      "\n",
      "    262400\t  0.161477\t  0.161402\t  0.161673\t\tCURRENT LEARNING RATE: 0.03618367674251273\n",
      "previous_iter_valid_loss : 0.16135047376155853\n",
      "\n",
      "    262600\t  0.161439\t  0.161350\t  0.161667\t\tCURRENT LEARNING RATE: 0.03611138170816039\n",
      "previous_iter_valid_loss : 0.16216956079006195\n",
      "\n",
      "    262800\t  0.162307\t  0.162170\t  0.161668\t\tCURRENT LEARNING RATE: 0.03603923111938305\n",
      "previous_iter_valid_loss : 0.1611543744802475\n",
      "\n",
      "    263000\t  0.161296\t  0.161154\t  0.161667\t\tCURRENT LEARNING RATE: 0.03596722468757822\n",
      "previous_iter_valid_loss : 0.161068856716156\n",
      "\n",
      "\n",
      "Current valid loss: 0.161068856716156;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "    263200\t  0.161192\t  0.161069\t  0.161664\t\tCURRENT LEARNING RATE: 0.03589536212472012\n",
      "previous_iter_valid_loss : 0.16166143119335175\n",
      "\n",
      "    263400\t  0.161751\t  0.161661\t  0.161664\t\tCURRENT LEARNING RATE: 0.03582364314335836\n",
      "previous_iter_valid_loss : 0.16201971471309662\n",
      "\n",
      "    263600\t  0.162184\t  0.162020\t  0.161665\t\tCURRENT LEARNING RATE: 0.03575206745661695\n",
      "previous_iter_valid_loss : 0.16120943427085876\n",
      "\n",
      "    263800\t  0.161346\t  0.161209\t  0.161664\t\tCURRENT LEARNING RATE: 0.03568063477819303\n",
      "previous_iter_valid_loss : 0.16148722171783447\n",
      "\n",
      "    264000\t  0.161623\t  0.161487\t  0.161662\t\tCURRENT LEARNING RATE: 0.0356093448223558\n",
      "previous_iter_valid_loss : 0.16132493317127228\n",
      "\n",
      "    264200\t  0.161476\t  0.161325\t  0.161660\t\tCURRENT LEARNING RATE: 0.03553819730394533\n",
      "previous_iter_valid_loss : 0.16242490708827972\n",
      "\n",
      "    264400\t  0.162567\t  0.162425\t  0.161661\t\tCURRENT LEARNING RATE: 0.03546719193837147\n",
      "previous_iter_valid_loss : 0.1615125983953476\n",
      "\n",
      "    264600\t  0.161659\t  0.161513\t  0.161660\t\tCURRENT LEARNING RATE: 0.03539632844161265\n",
      "previous_iter_valid_loss : 0.16237621009349823\n",
      "\n",
      "    264800\t  0.162556\t  0.162376\t  0.161664\t\tCURRENT LEARNING RATE: 0.0353256065302148\n",
      "previous_iter_valid_loss : 0.1611296534538269\n",
      "\n",
      "    265000\t  0.161265\t  0.161130\t  0.161663\t\tCURRENT LEARNING RATE: 0.03525502592129015\n",
      "previous_iter_valid_loss : 0.16190484166145325\n",
      "\n",
      "    265200\t  0.162018\t  0.161905\t  0.161665\t\tCURRENT LEARNING RATE: 0.03518458633251621\n",
      "previous_iter_valid_loss : 0.16190403699874878\n",
      "\n",
      "    265400\t  0.162043\t  0.161904\t  0.161663\t\tCURRENT LEARNING RATE: 0.03511428748213451\n",
      "previous_iter_valid_loss : 0.16195791959762573\n",
      "\n",
      "    265600\t  0.162159\t  0.161958\t  0.161667\t\tCURRENT LEARNING RATE: 0.035044129088949556\n",
      "previous_iter_valid_loss : 0.16128745675086975\n",
      "\n",
      "    265800\t  0.161423\t  0.161287\t  0.161666\t\tCURRENT LEARNING RATE: 0.03497411087232768\n",
      "previous_iter_valid_loss : 0.16129253804683685\n",
      "\n",
      "    266000\t  0.161473\t  0.161293\t  0.161664\t\tCURRENT LEARNING RATE: 0.034904232552195935\n",
      "previous_iter_valid_loss : 0.16129080951213837\n",
      "\n",
      "    266200\t  0.161374\t  0.161291\t  0.161661\t\tCURRENT LEARNING RATE: 0.03483449384904092\n",
      "previous_iter_valid_loss : 0.16117718815803528\n",
      "\n",
      "    266400\t  0.161295\t  0.161177\t  0.161658\t\tCURRENT LEARNING RATE: 0.034764894483907766\n",
      "previous_iter_valid_loss : 0.1615695357322693\n",
      "\n",
      "    266600\t  0.161702\t  0.161570\t  0.161658\t\tCURRENT LEARNING RATE: 0.03469543417839888\n",
      "previous_iter_valid_loss : 0.16131864488124847\n",
      "\n",
      "    266800\t  0.161451\t  0.161319\t  0.161656\t\tCURRENT LEARNING RATE: 0.034626112654673\n",
      "previous_iter_valid_loss : 0.1613350659608841\n",
      "\n",
      "    267000\t  0.161466\t  0.161335\t  0.161647\t\tCURRENT LEARNING RATE: 0.03455692963544387\n",
      "previous_iter_valid_loss : 0.16176311671733856\n",
      "\n",
      "    267200\t  0.161901\t  0.161763\t  0.161650\t\tCURRENT LEARNING RATE: 0.03448788484397939\n",
      "previous_iter_valid_loss : 0.16138432919979095\n",
      "\n",
      "    267400\t  0.161447\t  0.161384\t  0.161650\t\tCURRENT LEARNING RATE: 0.034418978004100244\n",
      "previous_iter_valid_loss : 0.16204416751861572\n",
      "\n",
      "    267600\t  0.162131\t  0.162044\t  0.161654\t\tCURRENT LEARNING RATE: 0.034350208840179024\n",
      "previous_iter_valid_loss : 0.16120846569538116\n",
      "\n",
      "    267800\t  0.161314\t  0.161208\t  0.161648\t\tCURRENT LEARNING RATE: 0.034281577077138956\n",
      "previous_iter_valid_loss : 0.1615084409713745\n",
      "\n",
      "    268000\t  0.161632\t  0.161508\t  0.161647\t\tCURRENT LEARNING RATE: 0.034213082440452916\n",
      "previous_iter_valid_loss : 0.1615847498178482\n",
      "\n",
      "    268200\t  0.161750\t  0.161585\t  0.161649\t\tCURRENT LEARNING RATE: 0.03414472465614224\n",
      "previous_iter_valid_loss : 0.16128908097743988\n",
      "\n",
      "    268400\t  0.161443\t  0.161289\t  0.161643\t\tCURRENT LEARNING RATE: 0.03407650345077573\n",
      "previous_iter_valid_loss : 0.16128703951835632\n",
      "\n",
      "    268600\t  0.161451\t  0.161287\t  0.161635\t\tCURRENT LEARNING RATE: 0.03400841855146844\n",
      "previous_iter_valid_loss : 0.1616075336933136\n",
      "\n",
      "    268800\t  0.161776\t  0.161608\t  0.161634\t\tCURRENT LEARNING RATE: 0.03394046968588072\n",
      "previous_iter_valid_loss : 0.16175299882888794\n",
      "\n",
      "    269000\t  0.161887\t  0.161753\t  0.161631\t\tCURRENT LEARNING RATE: 0.033872656582216984\n",
      "previous_iter_valid_loss : 0.16144941747188568\n",
      "\n",
      "    269200\t  0.161622\t  0.161449\t  0.161631\t\tCURRENT LEARNING RATE: 0.03380497896922475\n",
      "previous_iter_valid_loss : 0.1622687429189682\n",
      "\n",
      "    269400\t  0.162420\t  0.162269\t  0.161634\t\tCURRENT LEARNING RATE: 0.03373743657619345\n",
      "previous_iter_valid_loss : 0.1612733155488968\n",
      "\n",
      "    269600\t  0.161398\t  0.161273\t  0.161632\t\tCURRENT LEARNING RATE: 0.03367002913295346\n",
      "previous_iter_valid_loss : 0.1613515466451645\n",
      "\n",
      "    269800\t  0.161513\t  0.161352\t  0.161632\t\tCURRENT LEARNING RATE: 0.03360275636987488\n",
      "previous_iter_valid_loss : 0.1616504043340683\n",
      "\n",
      "    270000\t  0.161790\t  0.161650\t  0.161629\t\tCURRENT LEARNING RATE: 0.03353561801786659\n",
      "previous_iter_valid_loss : 0.16117799282073975\n",
      "\n",
      "    270200\t  0.161311\t  0.161178\t  0.161625\t\tCURRENT LEARNING RATE: 0.033468613808375076\n",
      "previous_iter_valid_loss : 0.1616230010986328\n",
      "\n",
      "    270400\t  0.161766\t  0.161623\t  0.161624\t\tCURRENT LEARNING RATE: 0.033401743473383434\n",
      "previous_iter_valid_loss : 0.16156300902366638\n",
      "\n",
      "    270600\t  0.161686\t  0.161563\t  0.161624\t\tCURRENT LEARNING RATE: 0.03333500674541021\n",
      "previous_iter_valid_loss : 0.16210982203483582\n",
      "\n",
      "    270800\t  0.162266\t  0.162110\t  0.161628\t\tCURRENT LEARNING RATE: 0.03326840335750843\n",
      "previous_iter_valid_loss : 0.1616099625825882\n",
      "\n",
      "    271000\t  0.161734\t  0.161610\t  0.161629\t\tCURRENT LEARNING RATE: 0.033201933043264416\n",
      "previous_iter_valid_loss : 0.16124016046524048\n",
      "\n",
      "    271200\t  0.161386\t  0.161240\t  0.161623\t\tCURRENT LEARNING RATE: 0.03313559553679686\n",
      "previous_iter_valid_loss : 0.1616896539926529\n",
      "\n",
      "    271400\t  0.161774\t  0.161690\t  0.161624\t\tCURRENT LEARNING RATE: 0.033069390572755625\n",
      "previous_iter_valid_loss : 0.16109821200370789\n",
      "\n",
      "    271600\t  0.161237\t  0.161098\t  0.161617\t\tCURRENT LEARNING RATE: 0.03300331788632078\n",
      "previous_iter_valid_loss : 0.16149938106536865\n",
      "\n",
      "    271800\t  0.161650\t  0.161499\t  0.161615\t\tCURRENT LEARNING RATE: 0.032937377213201474\n",
      "previous_iter_valid_loss : 0.16130252182483673\n",
      "\n",
      "    272000\t  0.161440\t  0.161303\t  0.161614\t\tCURRENT LEARNING RATE: 0.03287156828963495\n",
      "previous_iter_valid_loss : 0.16118836402893066\n",
      "\n",
      "    272200\t  0.161312\t  0.161188\t  0.161610\t\tCURRENT LEARNING RATE: 0.0328058908523854\n",
      "previous_iter_valid_loss : 0.16150051355361938\n",
      "\n",
      "    272400\t  0.161535\t  0.161501\t  0.161612\t\tCURRENT LEARNING RATE: 0.032740344638743014\n",
      "previous_iter_valid_loss : 0.1617002785205841\n",
      "\n",
      "    272600\t  0.161851\t  0.161700\t  0.161611\t\tCURRENT LEARNING RATE: 0.032674929386522826\n",
      "previous_iter_valid_loss : 0.16109412908554077\n",
      "\n",
      "    272800\t  0.161189\t  0.161094\t  0.161605\t\tCURRENT LEARNING RATE: 0.03260964483406376\n",
      "previous_iter_valid_loss : 0.16106246411800385\n",
      "\n",
      "\n",
      "Current valid loss: 0.16106246411800385;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "    273000\t  0.161185\t  0.161062\t  0.161602\t\tCURRENT LEARNING RATE: 0.0325444907202275\n",
      "previous_iter_valid_loss : 0.16120587289333344\n",
      "\n",
      "    273200\t  0.161370\t  0.161206\t  0.161593\t\tCURRENT LEARNING RATE: 0.032479466784397525\n",
      "previous_iter_valid_loss : 0.16150818765163422\n",
      "\n",
      "    273400\t  0.161666\t  0.161508\t  0.161591\t\tCURRENT LEARNING RATE: 0.03241457276647798\n",
      "previous_iter_valid_loss : 0.161752849817276\n",
      "\n",
      "    273600\t  0.161952\t  0.161753\t  0.161593\t\tCURRENT LEARNING RATE: 0.032349808406892736\n",
      "previous_iter_valid_loss : 0.16128221154212952\n",
      "\n",
      "    273800\t  0.161431\t  0.161282\t  0.161590\t\tCURRENT LEARNING RATE: 0.032285173446584235\n",
      "previous_iter_valid_loss : 0.1624506264925003\n",
      "\n",
      "    274000\t  0.162650\t  0.162451\t  0.161595\t\tCURRENT LEARNING RATE: 0.03222066762701259\n",
      "previous_iter_valid_loss : 0.1611640602350235\n",
      "\n",
      "    274200\t  0.161284\t  0.161164\t  0.161590\t\tCURRENT LEARNING RATE: 0.03215629069015439\n",
      "previous_iter_valid_loss : 0.16109585762023926\n",
      "\n",
      "    274400\t  0.161230\t  0.161096\t  0.161590\t\tCURRENT LEARNING RATE: 0.03209204237850184\n",
      "previous_iter_valid_loss : 0.1612841784954071\n",
      "\n",
      "    274600\t  0.161441\t  0.161284\t  0.161589\t\tCURRENT LEARNING RATE: 0.032027922435061584\n",
      "previous_iter_valid_loss : 0.16261409223079681\n",
      "\n",
      "    274800\t  0.162773\t  0.162614\t  0.161592\t\tCURRENT LEARNING RATE: 0.031963930603353785\n",
      "previous_iter_valid_loss : 0.16112831234931946\n",
      "\n",
      "    275000\t  0.161251\t  0.161128\t  0.161588\t\tCURRENT LEARNING RATE: 0.03190006662741102\n",
      "previous_iter_valid_loss : 0.16148021817207336\n",
      "\n",
      "    275200\t  0.161641\t  0.161480\t  0.161588\t\tCURRENT LEARNING RATE: 0.03183633025177728\n",
      "previous_iter_valid_loss : 0.16141162812709808\n",
      "\n",
      "    275400\t  0.161614\t  0.161412\t  0.161586\t\tCURRENT LEARNING RATE: 0.03177272122150701\n",
      "previous_iter_valid_loss : 0.16139547526836395\n",
      "\n",
      "    275600\t  0.161564\t  0.161395\t  0.161583\t\tCURRENT LEARNING RATE: 0.03170923928216398\n",
      "previous_iter_valid_loss : 0.16142912209033966\n",
      "\n",
      "    275800\t  0.161586\t  0.161429\t  0.161579\t\tCURRENT LEARNING RATE: 0.031645884179820366\n",
      "previous_iter_valid_loss : 0.16217972338199615\n",
      "\n",
      "    276000\t  0.162331\t  0.162180\t  0.161582\t\tCURRENT LEARNING RATE: 0.031582655661055656\n",
      "previous_iter_valid_loss : 0.16181616485118866\n",
      "\n",
      "    276200\t  0.161959\t  0.161816\t  0.161583\t\tCURRENT LEARNING RATE: 0.031519553472955715\n",
      "previous_iter_valid_loss : 0.16131417453289032\n",
      "\n",
      "    276400\t  0.161478\t  0.161314\t  0.161583\t\tCURRENT LEARNING RATE: 0.03145657736311167\n",
      "previous_iter_valid_loss : 0.16174843907356262\n",
      "\n",
      "    276600\t  0.161925\t  0.161748\t  0.161584\t\tCURRENT LEARNING RATE: 0.031393727079619044\n",
      "previous_iter_valid_loss : 0.16135989129543304\n",
      "\n",
      "    276800\t  0.161522\t  0.161360\t  0.161581\t\tCURRENT LEARNING RATE: 0.031331002371076576\n",
      "previous_iter_valid_loss : 0.16119728982448578\n",
      "\n",
      "    277000\t  0.161309\t  0.161197\t  0.161579\t\tCURRENT LEARNING RATE: 0.031268402986585384\n",
      "previous_iter_valid_loss : 0.16169779002666473\n",
      "\n",
      "    277200\t  0.161844\t  0.161698\t  0.161578\t\tCURRENT LEARNING RATE: 0.03120592867574781\n",
      "previous_iter_valid_loss : 0.16172173619270325\n",
      "\n",
      "    277400\t  0.161824\t  0.161722\t  0.161581\t\tCURRENT LEARNING RATE: 0.031143579188666563\n",
      "previous_iter_valid_loss : 0.16237132251262665\n",
      "\n",
      "    277600\t  0.162517\t  0.162371\t  0.161586\t\tCURRENT LEARNING RATE: 0.031081354275943582\n",
      "previous_iter_valid_loss : 0.16115425527095795\n",
      "\n",
      "    277800\t  0.161301\t  0.161154\t  0.161584\t\tCURRENT LEARNING RATE: 0.03101925368867916\n",
      "previous_iter_valid_loss : 0.16113421320915222\n",
      "\n",
      "    278000\t  0.161271\t  0.161134\t  0.161582\t\tCURRENT LEARNING RATE: 0.030957277178470837\n",
      "previous_iter_valid_loss : 0.16122977435588837\n",
      "\n",
      "    278200\t  0.161380\t  0.161230\t  0.161580\t\tCURRENT LEARNING RATE: 0.030895424497412522\n",
      "previous_iter_valid_loss : 0.16156885027885437\n",
      "\n",
      "    278400\t  0.161747\t  0.161569\t  0.161580\t\tCURRENT LEARNING RATE: 0.030833695398093372\n",
      "previous_iter_valid_loss : 0.16116370260715485\n",
      "\n",
      "    278600\t  0.161321\t  0.161164\t  0.161577\t\tCURRENT LEARNING RATE: 0.030772089633596945\n",
      "previous_iter_valid_loss : 0.16161571443080902\n",
      "\n",
      "    278800\t  0.161810\t  0.161616\t  0.161578\t\tCURRENT LEARNING RATE: 0.030710606957500063\n",
      "previous_iter_valid_loss : 0.16110561788082123\n",
      "\n",
      "    279000\t  0.161201\t  0.161106\t  0.161576\t\tCURRENT LEARNING RATE: 0.030649247123871976\n",
      "previous_iter_valid_loss : 0.16123542189598083\n",
      "\n",
      "    279200\t  0.161394\t  0.161235\t  0.161576\t\tCURRENT LEARNING RATE: 0.030588009887273233\n",
      "previous_iter_valid_loss : 0.16157221794128418\n",
      "\n",
      "    279400\t  0.161731\t  0.161572\t  0.161576\t\tCURRENT LEARNING RATE: 0.03052689500275484\n",
      "previous_iter_valid_loss : 0.16148968040943146\n",
      "\n",
      "    279600\t  0.161613\t  0.161490\t  0.161577\t\tCURRENT LEARNING RATE: 0.030465902225857145\n",
      "previous_iter_valid_loss : 0.1614275574684143\n",
      "\n",
      "    279800\t  0.161554\t  0.161428\t  0.161578\t\tCURRENT LEARNING RATE: 0.030405031312608986\n",
      "previous_iter_valid_loss : 0.16123497486114502\n",
      "\n",
      "    280000\t  0.161383\t  0.161235\t  0.161577\t\tCURRENT LEARNING RATE: 0.03034428201952661\n",
      "previous_iter_valid_loss : 0.16114240884780884\n",
      "\n",
      "    280200\t  0.161257\t  0.161142\t  0.161575\t\tCURRENT LEARNING RATE: 0.030283654103612778\n",
      "previous_iter_valid_loss : 0.16136644780635834\n",
      "\n",
      "    280400\t  0.161488\t  0.161366\t  0.161574\t\tCURRENT LEARNING RATE: 0.03022314732235573\n",
      "previous_iter_valid_loss : 0.1612827032804489\n",
      "\n",
      "    280600\t  0.161395\t  0.161283\t  0.161570\t\tCURRENT LEARNING RATE: 0.030162761433728282\n",
      "previous_iter_valid_loss : 0.16121026873588562\n",
      "\n",
      "    280800\t  0.161372\t  0.161210\t  0.161570\t\tCURRENT LEARNING RATE: 0.03010249619618677\n",
      "previous_iter_valid_loss : 0.16143786907196045\n",
      "\n",
      "    281000\t  0.161603\t  0.161438\t  0.161571\t\tCURRENT LEARNING RATE: 0.030042351368670193\n",
      "previous_iter_valid_loss : 0.1622328758239746\n",
      "\n",
      "    281200\t  0.162439\t  0.162233\t  0.161575\t\tCURRENT LEARNING RATE: 0.029982326710599135\n",
      "previous_iter_valid_loss : 0.16121362149715424\n",
      "\n",
      "    281400\t  0.161371\t  0.161214\t  0.161574\t\tCURRENT LEARNING RATE: 0.029922421981874912\n",
      "previous_iter_valid_loss : 0.16135206818580627\n",
      "\n",
      "    281600\t  0.161547\t  0.161352\t  0.161571\t\tCURRENT LEARNING RATE: 0.029862636942878495\n",
      "previous_iter_valid_loss : 0.16123345494270325\n",
      "\n",
      "    281800\t  0.161376\t  0.161233\t  0.161571\t\tCURRENT LEARNING RATE: 0.029802971354469684\n",
      "previous_iter_valid_loss : 0.16121578216552734\n",
      "\n",
      "    282000\t  0.161405\t  0.161216\t  0.161571\t\tCURRENT LEARNING RATE: 0.02974342497798601\n",
      "previous_iter_valid_loss : 0.16121019423007965\n",
      "\n",
      "    282200\t  0.161346\t  0.161210\t  0.161569\t\tCURRENT LEARNING RATE: 0.029683997575241924\n",
      "previous_iter_valid_loss : 0.16158752143383026\n",
      "\n",
      "    282400\t  0.161781\t  0.161588\t  0.161568\t\tCURRENT LEARNING RATE: 0.0296246889085277\n",
      "previous_iter_valid_loss : 0.16120022535324097\n",
      "\n",
      "    282600\t  0.161324\t  0.161200\t  0.161566\t\tCURRENT LEARNING RATE: 0.029565498740608626\n",
      "previous_iter_valid_loss : 0.16121575236320496\n",
      "\n",
      "    282800\t  0.161318\t  0.161216\t  0.161557\t\tCURRENT LEARNING RATE: 0.02950642683472392\n",
      "previous_iter_valid_loss : 0.16150875389575958\n",
      "\n",
      "    283000\t  0.161688\t  0.161509\t  0.161557\t\tCURRENT LEARNING RATE: 0.02944747295458591\n",
      "previous_iter_valid_loss : 0.16193047165870667\n",
      "\n",
      "    283200\t  0.162048\t  0.161930\t  0.161558\t\tCURRENT LEARNING RATE: 0.029388636864378967\n",
      "previous_iter_valid_loss : 0.16128647327423096\n",
      "\n",
      "    283400\t  0.161397\t  0.161286\t  0.161550\t\tCURRENT LEARNING RATE: 0.02932991832875868\n",
      "previous_iter_valid_loss : 0.161183163523674\n",
      "\n",
      "    283600\t  0.161307\t  0.161183\t  0.161549\t\tCURRENT LEARNING RATE: 0.0292713171128508\n",
      "previous_iter_valid_loss : 0.16126462817192078\n",
      "\n",
      "    283800\t  0.161430\t  0.161265\t  0.161548\t\tCURRENT LEARNING RATE: 0.029212832982250414\n",
      "previous_iter_valid_loss : 0.161359965801239\n",
      "\n",
      "    284000\t  0.161478\t  0.161360\t  0.161542\t\tCURRENT LEARNING RATE: 0.029154465703020896\n",
      "previous_iter_valid_loss : 0.16157077252864838\n",
      "\n",
      "    284200\t  0.161735\t  0.161571\t  0.161542\t\tCURRENT LEARNING RATE: 0.029096215041693074\n",
      "previous_iter_valid_loss : 0.1612933725118637\n",
      "\n",
      "    284400\t  0.161479\t  0.161293\t  0.161542\t\tCURRENT LEARNING RATE: 0.0290380807652642\n",
      "previous_iter_valid_loss : 0.16229476034641266\n",
      "\n",
      "    284600\t  0.162441\t  0.162295\t  0.161543\t\tCURRENT LEARNING RATE: 0.028980062641197117\n",
      "previous_iter_valid_loss : 0.16110962629318237\n",
      "\n",
      "    284800\t  0.161201\t  0.161110\t  0.161541\t\tCURRENT LEARNING RATE: 0.028922160437419228\n",
      "previous_iter_valid_loss : 0.16159775853157043\n",
      "\n",
      "    285000\t  0.161793\t  0.161598\t  0.161542\t\tCURRENT LEARNING RATE: 0.028864373922321666\n",
      "previous_iter_valid_loss : 0.16145144402980804\n",
      "\n",
      "    285200\t  0.161589\t  0.161451\t  0.161539\t\tCURRENT LEARNING RATE: 0.02880670286475826\n",
      "previous_iter_valid_loss : 0.16112655401229858\n",
      "\n",
      "    285400\t  0.161249\t  0.161127\t  0.161539\t\tCURRENT LEARNING RATE: 0.028749147034044742\n",
      "previous_iter_valid_loss : 0.161558598279953\n",
      "\n",
      "    285600\t  0.161680\t  0.161559\t  0.161538\t\tCURRENT LEARNING RATE: 0.028691706199957676\n",
      "previous_iter_valid_loss : 0.1615571826696396\n",
      "\n",
      "    285800\t  0.161743\t  0.161557\t  0.161538\t\tCURRENT LEARNING RATE: 0.02863438013273368\n",
      "previous_iter_valid_loss : 0.16147953271865845\n",
      "\n",
      "    286000\t  0.161688\t  0.161480\t  0.161538\t\tCURRENT LEARNING RATE: 0.02857716860306838\n",
      "previous_iter_valid_loss : 0.1626458466053009\n",
      "\n",
      "    286200\t  0.162845\t  0.162646\t  0.161545\t\tCURRENT LEARNING RATE: 0.028520071382115608\n",
      "previous_iter_valid_loss : 0.16121011972427368\n",
      "\n",
      "    286400\t  0.161358\t  0.161210\t  0.161543\t\tCURRENT LEARNING RATE: 0.028463088241486377\n",
      "previous_iter_valid_loss : 0.16143035888671875\n",
      "\n",
      "    286600\t  0.161524\t  0.161430\t  0.161540\t\tCURRENT LEARNING RATE: 0.028406218953248078\n",
      "previous_iter_valid_loss : 0.16115951538085938\n",
      "\n",
      "    286800\t  0.161293\t  0.161160\t  0.161539\t\tCURRENT LEARNING RATE: 0.02834946328992345\n",
      "previous_iter_valid_loss : 0.16180932521820068\n",
      "\n",
      "    287000\t  0.161995\t  0.161809\t  0.161541\t\tCURRENT LEARNING RATE: 0.028292821024489802\n",
      "previous_iter_valid_loss : 0.16225509345531464\n",
      "\n",
      "    287200\t  0.162488\t  0.162255\t  0.161541\t\tCURRENT LEARNING RATE: 0.028236291930377955\n",
      "previous_iter_valid_loss : 0.16321034729480743\n",
      "\n",
      "    287400\t  0.163303\t  0.163210\t  0.161550\t\tCURRENT LEARNING RATE: 0.028179875781471495\n",
      "previous_iter_valid_loss : 0.16135273873806\n",
      "\n",
      "    287600\t  0.161527\t  0.161353\t  0.161551\t\tCURRENT LEARNING RATE: 0.02812357235210572\n",
      "previous_iter_valid_loss : 0.16114531457424164\n",
      "\n",
      "    287800\t  0.161293\t  0.161145\t  0.161549\t\tCURRENT LEARNING RATE: 0.028067381417066863\n",
      "previous_iter_valid_loss : 0.16127502918243408\n",
      "\n",
      "    288000\t  0.161443\t  0.161275\t  0.161541\t\tCURRENT LEARNING RATE: 0.028011302751591086\n",
      "previous_iter_valid_loss : 0.16210368275642395\n",
      "\n",
      "    288200\t  0.162329\t  0.162104\t  0.161536\t\tCURRENT LEARNING RATE: 0.027955336131363678\n",
      "previous_iter_valid_loss : 0.16123613715171814\n",
      "\n",
      "    288400\t  0.161394\t  0.161236\t  0.161536\t\tCURRENT LEARNING RATE: 0.027899481332518055\n",
      "previous_iter_valid_loss : 0.16107416152954102\n",
      "\n",
      "    288600\t  0.161230\t  0.161074\t  0.161529\t\tCURRENT LEARNING RATE: 0.027843738131634974\n",
      "previous_iter_valid_loss : 0.1611669957637787\n",
      "\n",
      "    288800\t  0.161257\t  0.161167\t  0.161525\t\tCURRENT LEARNING RATE: 0.02778810630574153\n",
      "previous_iter_valid_loss : 0.16109299659729004\n",
      "\n",
      "    289000\t  0.161214\t  0.161093\t  0.161524\t\tCURRENT LEARNING RATE: 0.027732585632310375\n",
      "previous_iter_valid_loss : 0.1617748737335205\n",
      "\n",
      "    289200\t  0.161899\t  0.161775\t  0.161527\t\tCURRENT LEARNING RATE: 0.027677175889258714\n",
      "previous_iter_valid_loss : 0.16147318482398987\n",
      "\n",
      "    289400\t  0.161569\t  0.161473\t  0.161527\t\tCURRENT LEARNING RATE: 0.027621876854947523\n",
      "previous_iter_valid_loss : 0.16177888214588165\n",
      "\n",
      "    289600\t  0.161918\t  0.161779\t  0.161528\t\tCURRENT LEARNING RATE: 0.02756668830818057\n",
      "previous_iter_valid_loss : 0.16205058991909027\n",
      "\n",
      "    289800\t  0.162211\t  0.162051\t  0.161532\t\tCURRENT LEARNING RATE: 0.027511610028203615\n",
      "previous_iter_valid_loss : 0.16117003560066223\n",
      "\n",
      "    290000\t  0.161263\t  0.161170\t  0.161525\t\tCURRENT LEARNING RATE: 0.027456641794703446\n",
      "previous_iter_valid_loss : 0.1613144427537918\n",
      "\n",
      "    290200\t  0.161402\t  0.161314\t  0.161520\t\tCURRENT LEARNING RATE: 0.027401783387807077\n",
      "previous_iter_valid_loss : 0.16189227998256683\n",
      "\n",
      "    290400\t  0.162060\t  0.161892\t  0.161513\t\tCURRENT LEARNING RATE: 0.02734703458808078\n",
      "previous_iter_valid_loss : 0.16153880953788757\n",
      "\n",
      "    290600\t  0.161698\t  0.161539\t  0.161510\t\tCURRENT LEARNING RATE: 0.027292395176529313\n",
      "previous_iter_valid_loss : 0.1612633466720581\n",
      "\n",
      "    290800\t  0.161366\t  0.161263\t  0.161508\t\tCURRENT LEARNING RATE: 0.02723786493459493\n",
      "previous_iter_valid_loss : 0.16124367713928223\n",
      "\n",
      "    291000\t  0.161405\t  0.161244\t  0.161507\t\tCURRENT LEARNING RATE: 0.02718344364415661\n",
      "previous_iter_valid_loss : 0.16140200197696686\n",
      "\n",
      "    291200\t  0.161533\t  0.161402\t  0.161503\t\tCURRENT LEARNING RATE: 0.027129131087529106\n",
      "previous_iter_valid_loss : 0.16130861639976501\n",
      "\n",
      "    291400\t  0.161444\t  0.161309\t  0.161503\t\tCURRENT LEARNING RATE: 0.027074927047462134\n",
      "previous_iter_valid_loss : 0.16152255237102509\n",
      "\n",
      "    291600\t  0.161591\t  0.161523\t  0.161502\t\tCURRENT LEARNING RATE: 0.027020831307139438\n",
      "previous_iter_valid_loss : 0.16140852868556976\n",
      "\n",
      "    291800\t  0.161542\t  0.161409\t  0.161502\t\tCURRENT LEARNING RATE: 0.02696684365017801\n",
      "previous_iter_valid_loss : 0.1613905280828476\n",
      "\n",
      "    292000\t  0.161471\t  0.161391\t  0.161502\t\tCURRENT LEARNING RATE: 0.026912963860627127\n",
      "previous_iter_valid_loss : 0.1610981822013855\n",
      "\n",
      "    292200\t  0.161230\t  0.161098\t  0.161497\t\tCURRENT LEARNING RATE: 0.026859191722967583\n",
      "previous_iter_valid_loss : 0.16257449984550476\n",
      "\n",
      "    292400\t  0.162761\t  0.162574\t  0.161503\t\tCURRENT LEARNING RATE: 0.026805527022110733\n",
      "previous_iter_valid_loss : 0.16132700443267822\n",
      "\n",
      "    292600\t  0.161420\t  0.161327\t  0.161504\t\tCURRENT LEARNING RATE: 0.02675196954339772\n",
      "previous_iter_valid_loss : 0.16119809448719025\n",
      "\n",
      "    292800\t  0.161301\t  0.161198\t  0.161503\t\tCURRENT LEARNING RATE: 0.026698519072598542\n",
      "previous_iter_valid_loss : 0.16109299659729004\n",
      "\n",
      "    293000\t  0.161221\t  0.161093\t  0.161495\t\tCURRENT LEARNING RATE: 0.026645175395911262\n",
      "previous_iter_valid_loss : 0.16126181185245514\n",
      "\n",
      "    293200\t  0.161406\t  0.161262\t  0.161494\t\tCURRENT LEARNING RATE: 0.02659193829996108\n",
      "previous_iter_valid_loss : 0.16219231486320496\n",
      "\n",
      "    293400\t  0.162393\t  0.162192\t  0.161496\t\tCURRENT LEARNING RATE: 0.026538807571799567\n",
      "previous_iter_valid_loss : 0.16181012988090515\n",
      "\n",
      "    293600\t  0.162022\t  0.161810\t  0.161498\t\tCURRENT LEARNING RATE: 0.026485782998903713\n",
      "previous_iter_valid_loss : 0.16157330572605133\n",
      "\n",
      "    293800\t  0.161807\t  0.161573\t  0.161498\t\tCURRENT LEARNING RATE: 0.026432864369175184\n",
      "previous_iter_valid_loss : 0.16173312067985535\n",
      "\n",
      "    294000\t  0.161962\t  0.161733\t  0.161498\t\tCURRENT LEARNING RATE: 0.026380051470939362\n",
      "previous_iter_valid_loss : 0.16179253160953522\n",
      "\n",
      "    294200\t  0.162033\t  0.161793\t  0.161498\t\tCURRENT LEARNING RATE: 0.026327344092944606\n",
      "previous_iter_valid_loss : 0.1614217758178711\n",
      "\n",
      "    294400\t  0.161595\t  0.161422\t  0.161497\t\tCURRENT LEARNING RATE: 0.02627474202436132\n",
      "previous_iter_valid_loss : 0.16116362810134888\n",
      "\n",
      "    294600\t  0.161346\t  0.161164\t  0.161497\t\tCURRENT LEARNING RATE: 0.02622224505478117\n",
      "previous_iter_valid_loss : 0.16115455329418182\n",
      "\n",
      "    294800\t  0.161346\t  0.161155\t  0.161496\t\tCURRENT LEARNING RATE: 0.02616985297421619\n",
      "previous_iter_valid_loss : 0.16178813576698303\n",
      "\n",
      "    295000\t  0.162076\t  0.161788\t  0.161498\t\tCURRENT LEARNING RATE: 0.026117565573098016\n",
      "previous_iter_valid_loss : 0.1611526906490326\n",
      "\n",
      "    295200\t  0.161339\t  0.161153\t  0.161496\t\tCURRENT LEARNING RATE: 0.026065382642276945\n",
      "previous_iter_valid_loss : 0.16173776984214783\n",
      "\n",
      "    295400\t  0.161958\t  0.161738\t  0.161498\t\tCURRENT LEARNING RATE: 0.026013303973021207\n",
      "previous_iter_valid_loss : 0.16117998957633972\n",
      "\n",
      "    295600\t  0.161389\t  0.161180\t  0.161497\t\tCURRENT LEARNING RATE: 0.025961329357016037\n",
      "previous_iter_valid_loss : 0.1616671234369278\n",
      "\n",
      "    295800\t  0.161885\t  0.161667\t  0.161497\t\tCURRENT LEARNING RATE: 0.025909458586362916\n",
      "previous_iter_valid_loss : 0.16131791472434998\n",
      "\n",
      "    296000\t  0.161538\t  0.161318\t  0.161496\t\tCURRENT LEARNING RATE: 0.02585769145357868\n",
      "previous_iter_valid_loss : 0.1613420695066452\n",
      "\n",
      "    296200\t  0.161593\t  0.161342\t  0.161495\t\tCURRENT LEARNING RATE: 0.025806027751594744\n",
      "previous_iter_valid_loss : 0.1617991030216217\n",
      "\n",
      "    296400\t  0.162021\t  0.161799\t  0.161495\t\tCURRENT LEARNING RATE: 0.025754467273756212\n",
      "previous_iter_valid_loss : 0.16160637140274048\n",
      "\n",
      "    296600\t  0.161783\t  0.161606\t  0.161495\t\tCURRENT LEARNING RATE: 0.025703009813821127\n",
      "previous_iter_valid_loss : 0.16118307411670685\n",
      "\n",
      "    296800\t  0.161347\t  0.161183\t  0.161494\t\tCURRENT LEARNING RATE: 0.025651655165959554\n",
      "previous_iter_valid_loss : 0.16124337911605835\n",
      "\n",
      "    297000\t  0.161433\t  0.161243\t  0.161490\t\tCURRENT LEARNING RATE: 0.02560040312475286\n",
      "previous_iter_valid_loss : 0.1613059788942337\n",
      "\n",
      "    297200\t  0.161525\t  0.161306\t  0.161490\t\tCURRENT LEARNING RATE: 0.02554925348519279\n",
      "previous_iter_valid_loss : 0.16137194633483887\n",
      "\n",
      "    297400\t  0.161603\t  0.161372\t  0.161490\t\tCURRENT LEARNING RATE: 0.025498206042680733\n",
      "previous_iter_valid_loss : 0.16121332347393036\n",
      "\n",
      "    297600\t  0.161392\t  0.161213\t  0.161490\t\tCURRENT LEARNING RATE: 0.025447260593026835\n",
      "previous_iter_valid_loss : 0.16133281588554382\n",
      "\n",
      "    297800\t  0.161491\t  0.161333\t  0.161490\t\tCURRENT LEARNING RATE: 0.02539641693244925\n",
      "previous_iter_valid_loss : 0.16118159890174866\n",
      "\n",
      "    298000\t  0.161367\t  0.161182\t  0.161491\t\tCURRENT LEARNING RATE: 0.025345674857573247\n",
      "previous_iter_valid_loss : 0.16121536493301392\n",
      "\n",
      "    298200\t  0.161347\t  0.161215\t  0.161490\t\tCURRENT LEARNING RATE: 0.02529503416543048\n",
      "previous_iter_valid_loss : 0.16119778156280518\n",
      "\n",
      "    298400\t  0.161368\t  0.161198\t  0.161490\t\tCURRENT LEARNING RATE: 0.025244494653458086\n",
      "previous_iter_valid_loss : 0.16107003390789032\n",
      "\n",
      "    298600\t  0.161208\t  0.161070\t  0.161489\t\tCURRENT LEARNING RATE: 0.02519405611949798\n",
      "previous_iter_valid_loss : 0.16103613376617432\n",
      "\n",
      "\n",
      "Current valid loss: 0.16103613376617432;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "    298800\t  0.161192\t  0.161036\t  0.161488\t\tCURRENT LEARNING RATE: 0.025143718361795932\n",
      "previous_iter_valid_loss : 0.16131320595741272\n",
      "\n",
      "    299000\t  0.161539\t  0.161313\t  0.161486\t\tCURRENT LEARNING RATE: 0.025093481179000867\n",
      "previous_iter_valid_loss : 0.16127213835716248\n",
      "\n",
      "    299200\t  0.161480\t  0.161272\t  0.161484\t\tCURRENT LEARNING RATE: 0.025043344370163964\n",
      "previous_iter_valid_loss : 0.16211441159248352\n",
      "\n",
      "    299400\t  0.162260\t  0.162114\t  0.161486\t\tCURRENT LEARNING RATE: 0.024993307734737947\n",
      "previous_iter_valid_loss : 0.16140300035476685\n",
      "\n",
      "    299600\t  0.161637\t  0.161403\t  0.161485\t\tCURRENT LEARNING RATE: 0.02494337107257618\n",
      "previous_iter_valid_loss : 0.16113507747650146\n",
      "\n",
      "    299800\t  0.161341\t  0.161135\t  0.161483\t\tCURRENT LEARNING RATE: 0.024893534183931972\n",
      "previous_iter_valid_loss : 0.16137391328811646\n",
      "\n",
      "    300000\t  0.161518\t  0.161374\t  0.161483\t\tCURRENT LEARNING RATE: 0.02484379686945769\n",
      "previous_iter_valid_loss : 0.1613638550043106\n",
      "\n",
      "    300200\t  0.161598\t  0.161364\t  0.161481\t\tCURRENT LEARNING RATE: 0.024794158930204\n",
      "previous_iter_valid_loss : 0.1620163768529892\n",
      "\n",
      "    300400\t  0.162175\t  0.162016\t  0.161485\t\tCURRENT LEARNING RATE: 0.024744620167619105\n",
      "previous_iter_valid_loss : 0.16140206158161163\n",
      "\n",
      "    300600\t  0.161620\t  0.161402\t  0.161486\t\tCURRENT LEARNING RATE: 0.024695180383547857\n",
      "previous_iter_valid_loss : 0.1611834466457367\n",
      "\n",
      "    300800\t  0.161340\t  0.161183\t  0.161484\t\tCURRENT LEARNING RATE: 0.024645839380231085\n",
      "previous_iter_valid_loss : 0.16173753142356873\n",
      "\n",
      "    301000\t  0.162005\t  0.161738\t  0.161486\t\tCURRENT LEARNING RATE: 0.02459659696030468\n",
      "previous_iter_valid_loss : 0.1611720621585846\n",
      "\n",
      "    301200\t  0.161394\t  0.161172\t  0.161483\t\tCURRENT LEARNING RATE: 0.024547452926798927\n",
      "previous_iter_valid_loss : 0.16117911040782928\n",
      "\n",
      "    301400\t  0.161370\t  0.161179\t  0.161483\t\tCURRENT LEARNING RATE: 0.0244984070831376\n",
      "previous_iter_valid_loss : 0.16121022403240204\n",
      "\n",
      "    301600\t  0.161434\t  0.161210\t  0.161483\t\tCURRENT LEARNING RATE: 0.02444945923313728\n",
      "previous_iter_valid_loss : 0.16116468608379364\n",
      "\n",
      "    301800\t  0.161364\t  0.161165\t  0.161482\t\tCURRENT LEARNING RATE: 0.02440060918100648\n",
      "previous_iter_valid_loss : 0.1611594706773758\n",
      "\n",
      "    302000\t  0.161333\t  0.161159\t  0.161480\t\tCURRENT LEARNING RATE: 0.024351856731344948\n",
      "previous_iter_valid_loss : 0.1611482948064804\n",
      "\n",
      "    302200\t  0.161333\t  0.161148\t  0.161478\t\tCURRENT LEARNING RATE: 0.024303201689142802\n",
      "previous_iter_valid_loss : 0.16138246655464172\n",
      "\n",
      "    302400\t  0.161579\t  0.161382\t  0.161478\t\tCURRENT LEARNING RATE: 0.024254643859779827\n",
      "previous_iter_valid_loss : 0.16129250824451447\n",
      "\n",
      "    302600\t  0.161451\t  0.161293\t  0.161478\t\tCURRENT LEARNING RATE: 0.02420618304902462\n",
      "previous_iter_valid_loss : 0.16119913756847382\n",
      "\n",
      "    302800\t  0.161346\t  0.161199\t  0.161473\t\tCURRENT LEARNING RATE: 0.024157819063033895\n",
      "previous_iter_valid_loss : 0.1612810641527176\n",
      "\n",
      "    303000\t  0.161474\t  0.161281\t  0.161474\t\tCURRENT LEARNING RATE: 0.02410955170835162\n",
      "previous_iter_valid_loss : 0.1611621081829071\n",
      "\n",
      "    303200\t  0.161308\t  0.161162\t  0.161474\t\tCURRENT LEARNING RATE: 0.024061380791908338\n",
      "previous_iter_valid_loss : 0.1614246815443039\n",
      "\n",
      "    303400\t  0.161658\t  0.161425\t  0.161473\t\tCURRENT LEARNING RATE: 0.024013306121020293\n",
      "previous_iter_valid_loss : 0.16152288019657135\n",
      "\n",
      "    303600\t  0.161690\t  0.161523\t  0.161470\t\tCURRENT LEARNING RATE: 0.02396532750338876\n",
      "previous_iter_valid_loss : 0.16134200990200043\n",
      "\n",
      "    303800\t  0.161545\t  0.161342\t  0.161471\t\tCURRENT LEARNING RATE: 0.023917444747099184\n",
      "previous_iter_valid_loss : 0.1613566279411316\n",
      "\n",
      "    304000\t  0.161551\t  0.161357\t  0.161470\t\tCURRENT LEARNING RATE: 0.023869657660620498\n",
      "previous_iter_valid_loss : 0.16136431694030762\n",
      "\n",
      "    304200\t  0.161559\t  0.161364\t  0.161471\t\tCURRENT LEARNING RATE: 0.023821966052804268\n",
      "previous_iter_valid_loss : 0.16180337965488434\n",
      "\n",
      "    304400\t  0.161960\t  0.161803\t  0.161468\t\tCURRENT LEARNING RATE: 0.023774369732884024\n",
      "previous_iter_valid_loss : 0.1612103283405304\n",
      "\n",
      "    304600\t  0.161432\t  0.161210\t  0.161466\t\tCURRENT LEARNING RATE: 0.0237268685104744\n",
      "previous_iter_valid_loss : 0.16170218586921692\n",
      "\n",
      "    304800\t  0.161897\t  0.161702\t  0.161463\t\tCURRENT LEARNING RATE: 0.023679462195570464\n",
      "previous_iter_valid_loss : 0.16149862110614777\n",
      "\n",
      "    305000\t  0.161690\t  0.161499\t  0.161464\t\tCURRENT LEARNING RATE: 0.023632150598546873\n",
      "previous_iter_valid_loss : 0.1611778289079666\n",
      "\n",
      "    305200\t  0.161343\t  0.161178\t  0.161461\t\tCURRENT LEARNING RATE: 0.023584933530157195\n",
      "previous_iter_valid_loss : 0.16104620695114136\n",
      "\n",
      "    305400\t  0.161200\t  0.161046\t  0.161457\t\tCURRENT LEARNING RATE: 0.023537810801533075\n",
      "previous_iter_valid_loss : 0.16110174357891083\n",
      "\n",
      "    305600\t  0.161299\t  0.161102\t  0.161452\t\tCURRENT LEARNING RATE: 0.023490782224183555\n",
      "previous_iter_valid_loss : 0.1613163948059082\n",
      "\n",
      "    305800\t  0.161423\t  0.161316\t  0.161452\t\tCURRENT LEARNING RATE: 0.023443847609994243\n",
      "previous_iter_valid_loss : 0.16126254200935364\n",
      "\n",
      "    306000\t  0.161432\t  0.161263\t  0.161452\t\tCURRENT LEARNING RATE: 0.02339700677122664\n",
      "previous_iter_valid_loss : 0.1612931787967682\n",
      "\n",
      "    306200\t  0.161443\t  0.161293\t  0.161452\t\tCURRENT LEARNING RATE: 0.023350259520517305\n",
      "previous_iter_valid_loss : 0.16160713136196136\n",
      "\n",
      "    306400\t  0.161736\t  0.161607\t  0.161454\t\tCURRENT LEARNING RATE: 0.0233036056708772\n",
      "previous_iter_valid_loss : 0.1614672988653183\n",
      "\n",
      "    306600\t  0.161651\t  0.161467\t  0.161454\t\tCURRENT LEARNING RATE: 0.023257045035690836\n",
      "previous_iter_valid_loss : 0.1613752543926239\n",
      "\n",
      "    306800\t  0.161553\t  0.161375\t  0.161454\t\tCURRENT LEARNING RATE: 0.023210577428715636\n",
      "previous_iter_valid_loss : 0.1614728569984436\n",
      "\n",
      "    307000\t  0.161661\t  0.161473\t  0.161455\t\tCURRENT LEARNING RATE: 0.023164202664081087\n",
      "previous_iter_valid_loss : 0.1613464057445526\n",
      "\n",
      "    307200\t  0.161533\t  0.161346\t  0.161453\t\tCURRENT LEARNING RATE: 0.023117920556288092\n",
      "previous_iter_valid_loss : 0.1612502634525299\n",
      "\n",
      "    307400\t  0.161468\t  0.161250\t  0.161452\t\tCURRENT LEARNING RATE: 0.023071730920208134\n",
      "previous_iter_valid_loss : 0.1613653153181076\n",
      "\n",
      "    307600\t  0.161549\t  0.161365\t  0.161449\t\tCURRENT LEARNING RATE: 0.023025633571082633\n",
      "previous_iter_valid_loss : 0.1611240655183792\n",
      "\n",
      "    307800\t  0.161300\t  0.161124\t  0.161448\t\tCURRENT LEARNING RATE: 0.022979628324522102\n",
      "previous_iter_valid_loss : 0.1611018031835556\n",
      "\n",
      "    308000\t  0.161272\t  0.161102\t  0.161446\t\tCURRENT LEARNING RATE: 0.02293371499650552\n",
      "previous_iter_valid_loss : 0.16147324442863464\n",
      "\n",
      "    308200\t  0.161640\t  0.161473\t  0.161446\t\tCURRENT LEARNING RATE: 0.022887893403379496\n",
      "previous_iter_valid_loss : 0.16112375259399414\n",
      "\n",
      "    308400\t  0.161270\t  0.161124\t  0.161445\t\tCURRENT LEARNING RATE: 0.02284216336185761\n",
      "previous_iter_valid_loss : 0.16112279891967773\n",
      "\n",
      "    308600\t  0.161281\t  0.161123\t  0.161444\t\tCURRENT LEARNING RATE: 0.022796524689019618\n",
      "previous_iter_valid_loss : 0.161322221159935\n",
      "\n",
      "    308800\t  0.161488\t  0.161322\t  0.161443\t\tCURRENT LEARNING RATE: 0.022750977202310785\n",
      "previous_iter_valid_loss : 0.16123096644878387\n",
      "\n",
      "    309000\t  0.161396\t  0.161231\t  0.161440\t\tCURRENT LEARNING RATE: 0.02270552071954109\n",
      "previous_iter_valid_loss : 0.16134265065193176\n",
      "\n",
      "    309200\t  0.161519\t  0.161343\t  0.161440\t\tCURRENT LEARNING RATE: 0.022660155058884555\n",
      "previous_iter_valid_loss : 0.16115406155586243\n",
      "\n",
      "    309400\t  0.161322\t  0.161154\t  0.161434\t\tCURRENT LEARNING RATE: 0.02261488003887846\n",
      "previous_iter_valid_loss : 0.1611129492521286\n",
      "\n",
      "    309600\t  0.161266\t  0.161113\t  0.161433\t\tCURRENT LEARNING RATE: 0.02256969547842268\n",
      "previous_iter_valid_loss : 0.16140876710414886\n",
      "\n",
      "    309800\t  0.161610\t  0.161409\t  0.161433\t\tCURRENT LEARNING RATE: 0.0225246011967789\n",
      "previous_iter_valid_loss : 0.1611688882112503\n",
      "\n",
      "    310000\t  0.161362\t  0.161169\t  0.161431\t\tCURRENT LEARNING RATE: 0.02247959701356995\n",
      "previous_iter_valid_loss : 0.16112545132637024\n",
      "\n",
      "    310200\t  0.161291\t  0.161125\t  0.161431\t\tCURRENT LEARNING RATE: 0.022434682748779015\n",
      "previous_iter_valid_loss : 0.16124188899993896\n",
      "\n",
      "    310400\t  0.161426\t  0.161242\t  0.161429\t\tCURRENT LEARNING RATE: 0.022389858222749002\n",
      "previous_iter_valid_loss : 0.16126352548599243\n",
      "\n",
      "    310600\t  0.161507\t  0.161264\t  0.161427\t\tCURRENT LEARNING RATE: 0.02234512325618172\n",
      "previous_iter_valid_loss : 0.161209836602211\n",
      "\n",
      "    310800\t  0.161390\t  0.161210\t  0.161423\t\tCURRENT LEARNING RATE: 0.022300477670137268\n",
      "previous_iter_valid_loss : 0.16114377975463867\n",
      "\n",
      "    311000\t  0.161313\t  0.161144\t  0.161421\t\tCURRENT LEARNING RATE: 0.02225592128603322\n",
      "previous_iter_valid_loss : 0.16133834421634674\n",
      "\n",
      "    311200\t  0.161542\t  0.161338\t  0.161421\t\tCURRENT LEARNING RATE: 0.022211453925643998\n",
      "previous_iter_valid_loss : 0.16108693182468414\n",
      "\n",
      "    311400\t  0.161249\t  0.161087\t  0.161418\t\tCURRENT LEARNING RATE: 0.022167075411100086\n",
      "previous_iter_valid_loss : 0.16122791171073914\n",
      "\n",
      "    311600\t  0.161412\t  0.161228\t  0.161419\t\tCURRENT LEARNING RATE: 0.022122785564887386\n",
      "previous_iter_valid_loss : 0.1611117571592331\n",
      "\n",
      "    311800\t  0.161287\t  0.161112\t  0.161417\t\tCURRENT LEARNING RATE: 0.02207858420984643\n",
      "previous_iter_valid_loss : 0.16132308542728424\n",
      "\n",
      "    312000\t  0.161512\t  0.161323\t  0.161417\t\tCURRENT LEARNING RATE: 0.022034471169171763\n",
      "previous_iter_valid_loss : 0.1614290326833725\n",
      "\n",
      "    312200\t  0.161616\t  0.161429\t  0.161418\t\tCURRENT LEARNING RATE: 0.021990446266411143\n",
      "previous_iter_valid_loss : 0.16129758954048157\n",
      "\n",
      "    312400\t  0.161456\t  0.161298\t  0.161417\t\tCURRENT LEARNING RATE: 0.02194650932546492\n",
      "previous_iter_valid_loss : 0.16141590476036072\n",
      "\n",
      "    312600\t  0.161615\t  0.161416\t  0.161416\t\tCURRENT LEARNING RATE: 0.021902660170585245\n",
      "previous_iter_valid_loss : 0.1612202525138855\n",
      "\n",
      "    312800\t  0.161324\t  0.161220\t  0.161416\t\tCURRENT LEARNING RATE: 0.02185889862637547\n",
      "previous_iter_valid_loss : 0.1611684411764145\n",
      "\n",
      "    313000\t  0.161346\t  0.161168\t  0.161417\t\tCURRENT LEARNING RATE: 0.021815224517789337\n",
      "previous_iter_valid_loss : 0.16162699460983276\n",
      "\n",
      "    313200\t  0.161830\t  0.161627\t  0.161419\t\tCURRENT LEARNING RATE: 0.02177163767013037\n",
      "previous_iter_valid_loss : 0.16140314936637878\n",
      "\n",
      "    313400\t  0.161588\t  0.161403\t  0.161418\t\tCURRENT LEARNING RATE: 0.021728137909051103\n",
      "previous_iter_valid_loss : 0.16109496355056763\n",
      "\n",
      "    313600\t  0.161289\t  0.161095\t  0.161415\t\tCURRENT LEARNING RATE: 0.021684725060552454\n",
      "previous_iter_valid_loss : 0.16125169396400452\n",
      "\n",
      "    313800\t  0.161500\t  0.161252\t  0.161415\t\tCURRENT LEARNING RATE: 0.021641398950982948\n",
      "previous_iter_valid_loss : 0.16116105020046234\n",
      "\n",
      "    314000\t  0.161415\t  0.161161\t  0.161408\t\tCURRENT LEARNING RATE: 0.02159815940703811\n",
      "previous_iter_valid_loss : 0.16145244240760803\n",
      "\n",
      "    314200\t  0.161706\t  0.161452\t  0.161410\t\tCURRENT LEARNING RATE: 0.021555006255759693\n",
      "previous_iter_valid_loss : 0.1610662341117859\n",
      "\n",
      "    314400\t  0.161227\t  0.161066\t  0.161410\t\tCURRENT LEARNING RATE: 0.021511939324535045\n",
      "previous_iter_valid_loss : 0.1613561362028122\n",
      "\n",
      "    314600\t  0.161578\t  0.161356\t  0.161410\t\tCURRENT LEARNING RATE: 0.021468958441096368\n",
      "previous_iter_valid_loss : 0.16114972531795502\n",
      "\n",
      "    314800\t  0.161355\t  0.161150\t  0.161403\t\tCURRENT LEARNING RATE: 0.021426063433520093\n",
      "previous_iter_valid_loss : 0.1614101529121399\n",
      "\n",
      "    315000\t  0.161637\t  0.161410\t  0.161404\t\tCURRENT LEARNING RATE: 0.02138325413022611\n",
      "previous_iter_valid_loss : 0.16112683713436127\n",
      "\n",
      "    315200\t  0.161302\t  0.161127\t  0.161402\t\tCURRENT LEARNING RATE: 0.021340530359977166\n",
      "previous_iter_valid_loss : 0.16125066578388214\n",
      "\n",
      "    315400\t  0.161479\t  0.161251\t  0.161402\t\tCURRENT LEARNING RATE: 0.021297891951878107\n",
      "previous_iter_valid_loss : 0.1612994372844696\n",
      "\n",
      "    315600\t  0.161514\t  0.161299\t  0.161401\t\tCURRENT LEARNING RATE: 0.021255338735375263\n",
      "previous_iter_valid_loss : 0.16133719682693481\n",
      "\n",
      "    315800\t  0.161517\t  0.161337\t  0.161401\t\tCURRENT LEARNING RATE: 0.021212870540255693\n",
      "previous_iter_valid_loss : 0.1612466722726822\n",
      "\n",
      "    316000\t  0.161415\t  0.161247\t  0.161396\t\tCURRENT LEARNING RATE: 0.021170487196646572\n",
      "previous_iter_valid_loss : 0.16132326424121857\n",
      "\n",
      "    316200\t  0.161488\t  0.161323\t  0.161394\t\tCURRENT LEARNING RATE: 0.021128188535014462\n",
      "previous_iter_valid_loss : 0.16115731000900269\n",
      "\n",
      "    316400\t  0.161324\t  0.161157\t  0.161393\t\tCURRENT LEARNING RATE: 0.021085974386164667\n",
      "previous_iter_valid_loss : 0.16107547283172607\n",
      "\n",
      "    316600\t  0.161260\t  0.161075\t  0.161389\t\tCURRENT LEARNING RATE: 0.021043844581240527\n",
      "previous_iter_valid_loss : 0.16119132936000824\n",
      "\n",
      "    316800\t  0.161380\t  0.161191\t  0.161389\t\tCURRENT LEARNING RATE: 0.021001798951722776\n",
      "previous_iter_valid_loss : 0.1616949439048767\n",
      "\n",
      "    317000\t  0.161857\t  0.161695\t  0.161391\t\tCURRENT LEARNING RATE: 0.020959837329428826\n",
      "previous_iter_valid_loss : 0.1611594706773758\n",
      "\n",
      "    317200\t  0.161336\t  0.161159\t  0.161388\t\tCURRENT LEARNING RATE: 0.02091795954651215\n",
      "previous_iter_valid_loss : 0.1615113466978073\n",
      "\n",
      "    317400\t  0.161707\t  0.161511\t  0.161387\t\tCURRENT LEARNING RATE: 0.02087616543546154\n",
      "previous_iter_valid_loss : 0.16122500598430634\n",
      "\n",
      "    317600\t  0.161429\t  0.161225\t  0.161382\t\tCURRENT LEARNING RATE: 0.02083445482910052\n",
      "previous_iter_valid_loss : 0.16147549450397491\n",
      "\n",
      "    317800\t  0.161708\t  0.161475\t  0.161383\t\tCURRENT LEARNING RATE: 0.02079282756058658\n",
      "previous_iter_valid_loss : 0.1614450216293335\n",
      "\n",
      "    318000\t  0.161643\t  0.161445\t  0.161385\t\tCURRENT LEARNING RATE: 0.02075128346341062\n",
      "previous_iter_valid_loss : 0.16131983697414398\n",
      "\n",
      "    318200\t  0.161529\t  0.161320\t  0.161385\t\tCURRENT LEARNING RATE: 0.020709822371396173\n",
      "previous_iter_valid_loss : 0.16136668622493744\n",
      "\n",
      "    318400\t  0.161617\t  0.161367\t  0.161384\t\tCURRENT LEARNING RATE: 0.020668444118698833\n",
      "previous_iter_valid_loss : 0.16147752106189728\n",
      "\n",
      "    318600\t  0.161673\t  0.161478\t  0.161386\t\tCURRENT LEARNING RATE: 0.020627148539805514\n",
      "previous_iter_valid_loss : 0.16122128069400787\n",
      "\n",
      "    318800\t  0.161378\t  0.161221\t  0.161384\t\tCURRENT LEARNING RATE: 0.02058593546953387\n",
      "previous_iter_valid_loss : 0.16130509972572327\n",
      "\n",
      "    319000\t  0.161515\t  0.161305\t  0.161385\t\tCURRENT LEARNING RATE: 0.02054480474303154\n",
      "previous_iter_valid_loss : 0.16111621260643005\n",
      "\n",
      "    319200\t  0.161324\t  0.161116\t  0.161384\t\tCURRENT LEARNING RATE: 0.020503756195775585\n",
      "previous_iter_valid_loss : 0.16123062372207642\n",
      "\n",
      "    319400\t  0.161410\t  0.161231\t  0.161382\t\tCURRENT LEARNING RATE: 0.020462789663571745\n",
      "previous_iter_valid_loss : 0.1611858755350113\n",
      "\n",
      "    319600\t  0.161392\t  0.161186\t  0.161381\t\tCURRENT LEARNING RATE: 0.02042190498255385\n",
      "previous_iter_valid_loss : 0.16105477511882782\n",
      "\n",
      "    319800\t  0.161241\t  0.161055\t  0.161379\t\tCURRENT LEARNING RATE: 0.020381101989183106\n",
      "previous_iter_valid_loss : 0.16135728359222412\n",
      "\n",
      "    320000\t  0.161567\t  0.161357\t  0.161380\t\tCURRENT LEARNING RATE: 0.0203403805202475\n",
      "previous_iter_valid_loss : 0.16150568425655365\n",
      "\n",
      "    320200\t  0.161691\t  0.161506\t  0.161381\t\tCURRENT LEARNING RATE: 0.02029974041286109\n",
      "previous_iter_valid_loss : 0.1612389087677002\n",
      "\n",
      "    320400\t  0.161378\t  0.161239\t  0.161381\t\tCURRENT LEARNING RATE: 0.020259181504463403\n",
      "previous_iter_valid_loss : 0.16150446236133575\n",
      "\n",
      "    320600\t  0.161695\t  0.161504\t  0.161382\t\tCURRENT LEARNING RATE: 0.02021870363281874\n",
      "previous_iter_valid_loss : 0.16125953197479248\n",
      "\n",
      "    320800\t  0.161466\t  0.161260\t  0.161382\t\tCURRENT LEARNING RATE: 0.020178306636015574\n",
      "previous_iter_valid_loss : 0.1610250324010849\n",
      "\n",
      "\n",
      "Current valid loss: 0.1610250324010849;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "    321000\t  0.161182\t  0.161025\t  0.161380\t\tCURRENT LEARNING RATE: 0.02013799035246585\n",
      "previous_iter_valid_loss : 0.16114433109760284\n",
      "\n",
      "    321200\t  0.161325\t  0.161144\t  0.161375\t\tCURRENT LEARNING RATE: 0.020097754620904393\n",
      "previous_iter_valid_loss : 0.16124273836612701\n",
      "\n",
      "    321400\t  0.161431\t  0.161243\t  0.161375\t\tCURRENT LEARNING RATE: 0.020057599280388208\n",
      "previous_iter_valid_loss : 0.1611582636833191\n",
      "\n",
      "    321600\t  0.161346\t  0.161158\t  0.161374\t\tCURRENT LEARNING RATE: 0.020017524170295897\n",
      "previous_iter_valid_loss : 0.16113805770874023\n",
      "\n",
      "    321800\t  0.161345\t  0.161138\t  0.161373\t\tCURRENT LEARNING RATE: 0.019977529130326948\n",
      "previous_iter_valid_loss : 0.16102856397628784\n",
      "\n",
      "    322000\t  0.161205\t  0.161029\t  0.161372\t\tCURRENT LEARNING RATE: 0.019937614000501168\n",
      "previous_iter_valid_loss : 0.1612619310617447\n",
      "\n",
      "    322200\t  0.161494\t  0.161262\t  0.161373\t\tCURRENT LEARNING RATE: 0.019897778621157963\n",
      "previous_iter_valid_loss : 0.16149069368839264\n",
      "\n",
      "    322400\t  0.161698\t  0.161491\t  0.161372\t\tCURRENT LEARNING RATE: 0.019858022832955784\n",
      "previous_iter_valid_loss : 0.16133984923362732\n",
      "\n",
      "    322600\t  0.161522\t  0.161340\t  0.161373\t\tCURRENT LEARNING RATE: 0.0198183464768714\n",
      "previous_iter_valid_loss : 0.16114577651023865\n",
      "\n",
      "    322800\t  0.161321\t  0.161146\t  0.161373\t\tCURRENT LEARNING RATE: 0.019778749394199362\n",
      "previous_iter_valid_loss : 0.16110600531101227\n",
      "\n",
      "    323000\t  0.161247\t  0.161106\t  0.161371\t\tCURRENT LEARNING RATE: 0.019739231426551263\n",
      "previous_iter_valid_loss : 0.16111664474010468\n",
      "\n",
      "    323200\t  0.161292\t  0.161117\t  0.161367\t\tCURRENT LEARNING RATE: 0.019699792415855195\n",
      "previous_iter_valid_loss : 0.16135966777801514\n",
      "\n",
      "    323400\t  0.161534\t  0.161360\t  0.161367\t\tCURRENT LEARNING RATE: 0.019660432204355052\n",
      "previous_iter_valid_loss : 0.16111695766448975\n",
      "\n",
      "    323600\t  0.161322\t  0.161117\t  0.161367\t\tCURRENT LEARNING RATE: 0.019621150634609945\n",
      "previous_iter_valid_loss : 0.16111263632774353\n",
      "\n",
      "    323800\t  0.161298\t  0.161113\t  0.161366\t\tCURRENT LEARNING RATE: 0.019581947549493533\n",
      "previous_iter_valid_loss : 0.1611870378255844\n",
      "\n",
      "    324000\t  0.161375\t  0.161187\t  0.161365\t\tCURRENT LEARNING RATE: 0.019542822792193434\n",
      "previous_iter_valid_loss : 0.1611374020576477\n",
      "\n",
      "    324200\t  0.161336\t  0.161137\t  0.161363\t\tCURRENT LEARNING RATE: 0.019503776206210556\n",
      "previous_iter_valid_loss : 0.1613215059041977\n",
      "\n",
      "    324400\t  0.161574\t  0.161322\t  0.161363\t\tCURRENT LEARNING RATE: 0.019464807635358513\n",
      "previous_iter_valid_loss : 0.16125278174877167\n",
      "\n",
      "    324600\t  0.161453\t  0.161253\t  0.161358\t\tCURRENT LEARNING RATE: 0.019425916923762956\n",
      "previous_iter_valid_loss : 0.1616629958152771\n",
      "\n",
      "    324800\t  0.161920\t  0.161663\t  0.161360\t\tCURRENT LEARNING RATE: 0.019387103915861004\n",
      "previous_iter_valid_loss : 0.16117294132709503\n",
      "\n",
      "    325000\t  0.161322\t  0.161173\t  0.161358\t\tCURRENT LEARNING RATE: 0.019348368456400568\n",
      "previous_iter_valid_loss : 0.16124431788921356\n",
      "\n",
      "    325200\t  0.161425\t  0.161244\t  0.161357\t\tCURRENT LEARNING RATE: 0.019309710390439744\n",
      "previous_iter_valid_loss : 0.1614428609609604\n",
      "\n",
      "    325400\t  0.161662\t  0.161443\t  0.161359\t\tCURRENT LEARNING RATE: 0.019271129563346236\n",
      "previous_iter_valid_loss : 0.1613246202468872\n",
      "\n",
      "    325600\t  0.161509\t  0.161325\t  0.161358\t\tCURRENT LEARNING RATE: 0.01923262582079667\n",
      "previous_iter_valid_loss : 0.16110244393348694\n",
      "\n",
      "    325800\t  0.161296\t  0.161102\t  0.161355\t\tCURRENT LEARNING RATE: 0.019194199008776038\n",
      "previous_iter_valid_loss : 0.16102130711078644\n",
      "\n",
      "\n",
      "Current valid loss: 0.16102130711078644;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "    326000\t  0.161178\t  0.161021\t  0.161353\t\tCURRENT LEARNING RATE: 0.019155848973577024\n",
      "previous_iter_valid_loss : 0.1611257791519165\n",
      "\n",
      "    326200\t  0.161238\t  0.161126\t  0.161346\t\tCURRENT LEARNING RATE: 0.019117575561799455\n",
      "previous_iter_valid_loss : 0.16106778383255005\n",
      "\n",
      "    326400\t  0.161259\t  0.161068\t  0.161345\t\tCURRENT LEARNING RATE: 0.019079378620349613\n",
      "previous_iter_valid_loss : 0.16109909117221832\n",
      "\n",
      "    326600\t  0.161244\t  0.161099\t  0.161343\t\tCURRENT LEARNING RATE: 0.019041257996439704\n",
      "previous_iter_valid_loss : 0.16117137670516968\n",
      "\n",
      "    326800\t  0.161339\t  0.161171\t  0.161343\t\tCURRENT LEARNING RATE: 0.019003213537587157\n",
      "previous_iter_valid_loss : 0.161049947142601\n",
      "\n",
      "    327000\t  0.161227\t  0.161050\t  0.161339\t\tCURRENT LEARNING RATE: 0.018965245091614107\n",
      "previous_iter_valid_loss : 0.16108308732509613\n",
      "\n",
      "    327200\t  0.161214\t  0.161083\t  0.161334\t\tCURRENT LEARNING RATE: 0.018927352506646705\n",
      "previous_iter_valid_loss : 0.1614011973142624\n",
      "\n",
      "    327400\t  0.161583\t  0.161401\t  0.161325\t\tCURRENT LEARNING RATE: 0.01888953563111457\n",
      "previous_iter_valid_loss : 0.1611032634973526\n",
      "\n",
      "    327600\t  0.161270\t  0.161103\t  0.161323\t\tCURRENT LEARNING RATE: 0.018851794313750142\n",
      "previous_iter_valid_loss : 0.16115416586399078\n",
      "\n",
      "    327800\t  0.161298\t  0.161154\t  0.161323\t\tCURRENT LEARNING RATE: 0.01881412840358811\n",
      "previous_iter_valid_loss : 0.16110219061374664\n",
      "\n",
      "    328000\t  0.161264\t  0.161102\t  0.161323\t\tCURRENT LEARNING RATE: 0.01877653774996477\n",
      "previous_iter_valid_loss : 0.16175945103168488\n",
      "\n",
      "    328200\t  0.161917\t  0.161759\t  0.161321\t\tCURRENT LEARNING RATE: 0.018739022202517473\n",
      "previous_iter_valid_loss : 0.16141311824321747\n",
      "\n",
      "    328400\t  0.161555\t  0.161413\t  0.161322\t\tCURRENT LEARNING RATE: 0.018701581611183963\n",
      "previous_iter_valid_loss : 0.16107502579689026\n",
      "\n",
      "    328600\t  0.161253\t  0.161075\t  0.161322\t\tCURRENT LEARNING RATE: 0.01866421582620184\n",
      "previous_iter_valid_loss : 0.16120880842208862\n",
      "\n",
      "    328800\t  0.161387\t  0.161209\t  0.161322\t\tCURRENT LEARNING RATE: 0.018626924698107904\n",
      "previous_iter_valid_loss : 0.16105599701404572\n",
      "\n",
      "    329000\t  0.161217\t  0.161056\t  0.161322\t\tCURRENT LEARNING RATE: 0.0185897080777376\n",
      "previous_iter_valid_loss : 0.16104133427143097\n",
      "\n",
      "    329200\t  0.161182\t  0.161041\t  0.161318\t\tCURRENT LEARNING RATE: 0.018552565816224387\n",
      "previous_iter_valid_loss : 0.16102898120880127\n",
      "\n",
      "    329400\t  0.161197\t  0.161029\t  0.161316\t\tCURRENT LEARNING RATE: 0.018515497764999184\n",
      "previous_iter_valid_loss : 0.16106566786766052\n",
      "\n",
      "    329600\t  0.161245\t  0.161066\t  0.161312\t\tCURRENT LEARNING RATE: 0.01847850377578972\n",
      "previous_iter_valid_loss : 0.16136763989925385\n",
      "\n",
      "    329800\t  0.161570\t  0.161368\t  0.161309\t\tCURRENT LEARNING RATE: 0.018441583700620007\n",
      "previous_iter_valid_loss : 0.16129086911678314\n",
      "\n",
      "    330000\t  0.161448\t  0.161291\t  0.161309\t\tCURRENT LEARNING RATE: 0.018404737391809676\n",
      "previous_iter_valid_loss : 0.16169025003910065\n",
      "\n",
      "    330200\t  0.161879\t  0.161690\t  0.161311\t\tCURRENT LEARNING RATE: 0.01836796470197346\n",
      "previous_iter_valid_loss : 0.16114740073680878\n",
      "\n",
      "    330400\t  0.161343\t  0.161147\t  0.161308\t\tCURRENT LEARNING RATE: 0.01833126548402053\n",
      "previous_iter_valid_loss : 0.1611834317445755\n",
      "\n",
      "    330600\t  0.161377\t  0.161183\t  0.161306\t\tCURRENT LEARNING RATE: 0.018294639591153992\n",
      "previous_iter_valid_loss : 0.16115142405033112\n",
      "\n",
      "    330800\t  0.161342\t  0.161151\t  0.161305\t\tCURRENT LEARNING RATE: 0.0182580868768702\n",
      "previous_iter_valid_loss : 0.16103628277778625\n",
      "\n",
      "    331000\t  0.161232\t  0.161036\t  0.161304\t\tCURRENT LEARNING RATE: 0.01822160719495827\n",
      "previous_iter_valid_loss : 0.16113369166851044\n",
      "\n",
      "    331200\t  0.161362\t  0.161134\t  0.161303\t\tCURRENT LEARNING RATE: 0.018185200399499404\n",
      "previous_iter_valid_loss : 0.16108886897563934\n",
      "\n",
      "    331400\t  0.161292\t  0.161089\t  0.161302\t\tCURRENT LEARNING RATE: 0.018148866344866392\n",
      "previous_iter_valid_loss : 0.16109223663806915\n",
      "\n",
      "    331600\t  0.161311\t  0.161092\t  0.161300\t\tCURRENT LEARNING RATE: 0.018112604885722954\n",
      "previous_iter_valid_loss : 0.16110152006149292\n",
      "\n",
      "    331800\t  0.161280\t  0.161102\t  0.161298\t\tCURRENT LEARNING RATE: 0.018076415877023213\n",
      "previous_iter_valid_loss : 0.16105008125305176\n",
      "\n",
      "    332000\t  0.161256\t  0.161050\t  0.161296\t\tCURRENT LEARNING RATE: 0.018040299174011076\n",
      "previous_iter_valid_loss : 0.16114185750484467\n",
      "\n",
      "    332200\t  0.161329\t  0.161142\t  0.161297\t\tCURRENT LEARNING RATE: 0.018004254632219694\n",
      "previous_iter_valid_loss : 0.1613348424434662\n",
      "\n",
      "    332400\t  0.161516\t  0.161335\t  0.161290\t\tCURRENT LEARNING RATE: 0.01796828210747084\n",
      "previous_iter_valid_loss : 0.1611839085817337\n",
      "\n",
      "    332600\t  0.161391\t  0.161184\t  0.161290\t\tCURRENT LEARNING RATE: 0.01793238145587438\n",
      "previous_iter_valid_loss : 0.1610553115606308\n",
      "\n",
      "    332800\t  0.161252\t  0.161055\t  0.161289\t\tCURRENT LEARNING RATE: 0.01789655253382765\n",
      "previous_iter_valid_loss : 0.16109216213226318\n",
      "\n",
      "    333000\t  0.161265\t  0.161092\t  0.161289\t\tCURRENT LEARNING RATE: 0.017860795198014923\n",
      "previous_iter_valid_loss : 0.16123519837856293\n",
      "\n",
      "    333200\t  0.161474\t  0.161235\t  0.161289\t\tCURRENT LEARNING RATE: 0.017825109305406792\n",
      "previous_iter_valid_loss : 0.1613471508026123\n",
      "\n",
      "    333400\t  0.161573\t  0.161347\t  0.161285\t\tCURRENT LEARNING RATE: 0.01778949471325966\n",
      "previous_iter_valid_loss : 0.16124528646469116\n",
      "\n",
      "    333600\t  0.161428\t  0.161245\t  0.161282\t\tCURRENT LEARNING RATE: 0.017753951279115093\n",
      "previous_iter_valid_loss : 0.16128431260585785\n",
      "\n",
      "    333800\t  0.161499\t  0.161284\t  0.161280\t\tCURRENT LEARNING RATE: 0.01771847886079932\n",
      "previous_iter_valid_loss : 0.16108334064483643\n",
      "\n",
      "    334000\t  0.161274\t  0.161083\t  0.161277\t\tCURRENT LEARNING RATE: 0.01768307731642261\n",
      "previous_iter_valid_loss : 0.16112062335014343\n",
      "\n",
      "    334200\t  0.161287\t  0.161121\t  0.161274\t\tCURRENT LEARNING RATE: 0.017647746504378746\n",
      "previous_iter_valid_loss : 0.16103912889957428\n",
      "\n",
      "    334400\t  0.161232\t  0.161039\t  0.161272\t\tCURRENT LEARNING RATE: 0.017612486283344428\n",
      "previous_iter_valid_loss : 0.16113172471523285\n",
      "\n",
      "    334600\t  0.161324\t  0.161132\t  0.161272\t\tCURRENT LEARNING RATE: 0.01757729651227873\n",
      "previous_iter_valid_loss : 0.16127924621105194\n",
      "\n",
      "    334800\t  0.161451\t  0.161279\t  0.161272\t\tCURRENT LEARNING RATE: 0.017542177050422512\n",
      "previous_iter_valid_loss : 0.16145795583724976\n",
      "\n",
      "    335000\t  0.161609\t  0.161458\t  0.161271\t\tCURRENT LEARNING RATE: 0.017507127757297892\n",
      "previous_iter_valid_loss : 0.161090686917305\n",
      "\n",
      "    335200\t  0.161283\t  0.161091\t  0.161270\t\tCURRENT LEARNING RATE: 0.017472148492707635\n",
      "previous_iter_valid_loss : 0.16114915907382965\n",
      "\n",
      "    335400\t  0.161317\t  0.161149\t  0.161267\t\tCURRENT LEARNING RATE: 0.017437239116734657\n",
      "previous_iter_valid_loss : 0.16113850474357605\n",
      "\n",
      "    335600\t  0.161349\t  0.161139\t  0.161267\t\tCURRENT LEARNING RATE: 0.017402399489741385\n",
      "previous_iter_valid_loss : 0.1610718071460724\n",
      "\n",
      "    335800\t  0.161233\t  0.161072\t  0.161264\t\tCURRENT LEARNING RATE: 0.01736762947236928\n",
      "previous_iter_valid_loss : 0.16124702990055084\n",
      "\n",
      "    336000\t  0.161448\t  0.161247\t  0.161264\t\tCURRENT LEARNING RATE: 0.01733292892553822\n",
      "previous_iter_valid_loss : 0.16107068955898285\n",
      "\n",
      "    336200\t  0.161278\t  0.161071\t  0.161263\t\tCURRENT LEARNING RATE: 0.017298297710445977\n",
      "previous_iter_valid_loss : 0.16126161813735962\n",
      "\n",
      "    336400\t  0.161450\t  0.161262\t  0.161260\t\tCURRENT LEARNING RATE: 0.017263735688567632\n",
      "previous_iter_valid_loss : 0.161515474319458\n",
      "\n",
      "    336600\t  0.161699\t  0.161515\t  0.161259\t\tCURRENT LEARNING RATE: 0.017229242721655068\n",
      "previous_iter_valid_loss : 0.16133643686771393\n",
      "\n",
      "    336800\t  0.161491\t  0.161336\t  0.161260\t\tCURRENT LEARNING RATE: 0.017194818671736355\n",
      "previous_iter_valid_loss : 0.1611153483390808\n",
      "\n",
      "    337000\t  0.161293\t  0.161115\t  0.161260\t\tCURRENT LEARNING RATE: 0.017160463401115263\n",
      "previous_iter_valid_loss : 0.16126784682273865\n",
      "\n",
      "    337200\t  0.161489\t  0.161268\t  0.161259\t\tCURRENT LEARNING RATE: 0.01712617677237065\n",
      "previous_iter_valid_loss : 0.1611684411764145\n",
      "\n",
      "    337400\t  0.161336\t  0.161168\t  0.161258\t\tCURRENT LEARNING RATE: 0.017091958648355967\n",
      "previous_iter_valid_loss : 0.16103577613830566\n",
      "\n",
      "    337600\t  0.161198\t  0.161036\t  0.161257\t\tCURRENT LEARNING RATE: 0.01705780889219866\n",
      "previous_iter_valid_loss : 0.1610213816165924\n",
      "\n",
      "    337800\t  0.161199\t  0.161021\t  0.161256\t\tCURRENT LEARNING RATE: 0.017023727367299672\n",
      "previous_iter_valid_loss : 0.16104964911937714\n",
      "\n",
      "    338000\t  0.161226\t  0.161050\t  0.161255\t\tCURRENT LEARNING RATE: 0.016989713937332847\n",
      "previous_iter_valid_loss : 0.16123630106449127\n",
      "\n",
      "    338200\t  0.161458\t  0.161236\t  0.161255\t\tCURRENT LEARNING RATE: 0.016955768466244428\n",
      "previous_iter_valid_loss : 0.16139082610607147\n",
      "\n",
      "    338400\t  0.161598\t  0.161391\t  0.161256\t\tCURRENT LEARNING RATE: 0.016921890818252475\n",
      "previous_iter_valid_loss : 0.16112853586673737\n",
      "\n",
      "    338600\t  0.161313\t  0.161129\t  0.161257\t\tCURRENT LEARNING RATE: 0.016888080857846367\n",
      "previous_iter_valid_loss : 0.161146342754364\n",
      "\n",
      "    338800\t  0.161345\t  0.161146\t  0.161257\t\tCURRENT LEARNING RATE: 0.016854338449786198\n",
      "previous_iter_valid_loss : 0.16107718646526337\n",
      "\n",
      "    339000\t  0.161265\t  0.161077\t  0.161256\t\tCURRENT LEARNING RATE: 0.01682066345910231\n",
      "previous_iter_valid_loss : 0.16108471155166626\n",
      "\n",
      "    339200\t  0.161237\t  0.161085\t  0.161255\t\tCURRENT LEARNING RATE: 0.016787055751094678\n",
      "previous_iter_valid_loss : 0.16102971136569977\n",
      "\n",
      "    339400\t  0.161225\t  0.161030\t  0.161250\t\tCURRENT LEARNING RATE: 0.01675351519133244\n",
      "previous_iter_valid_loss : 0.1613677740097046\n",
      "\n",
      "    339600\t  0.161550\t  0.161368\t  0.161249\t\tCURRENT LEARNING RATE: 0.0167200416456533\n",
      "previous_iter_valid_loss : 0.161117285490036\n",
      "\n",
      "    339800\t  0.161302\t  0.161117\t  0.161249\t\tCURRENT LEARNING RATE: 0.01668663498016304\n",
      "previous_iter_valid_loss : 0.16110166907310486\n",
      "\n",
      "    340000\t  0.161307\t  0.161102\t  0.161248\t\tCURRENT LEARNING RATE: 0.016653295061234946\n",
      "previous_iter_valid_loss : 0.16103112697601318\n",
      "\n",
      "    340200\t  0.161202\t  0.161031\t  0.161246\t\tCURRENT LEARNING RATE: 0.016620021755509307\n",
      "previous_iter_valid_loss : 0.16121584177017212\n",
      "\n",
      "    340400\t  0.161425\t  0.161216\t  0.161242\t\tCURRENT LEARNING RATE: 0.01658681492989284\n",
      "previous_iter_valid_loss : 0.161136656999588\n",
      "\n",
      "    340600\t  0.161337\t  0.161137\t  0.161241\t\tCURRENT LEARNING RATE: 0.01655367445155822\n",
      "previous_iter_valid_loss : 0.16107945144176483\n",
      "\n",
      "    340800\t  0.161288\t  0.161079\t  0.161240\t\tCURRENT LEARNING RATE: 0.016520600187943466\n",
      "previous_iter_valid_loss : 0.16124184429645538\n",
      "\n",
      "    341000\t  0.161433\t  0.161242\t  0.161238\t\tCURRENT LEARNING RATE: 0.0164875920067515\n",
      "previous_iter_valid_loss : 0.1611221432685852\n",
      "\n",
      "    341200\t  0.161324\t  0.161122\t  0.161238\t\tCURRENT LEARNING RATE: 0.01645464977594954\n",
      "previous_iter_valid_loss : 0.16111208498477936\n",
      "\n",
      "    341400\t  0.161296\t  0.161112\t  0.161237\t\tCURRENT LEARNING RATE: 0.01642177336376863\n",
      "previous_iter_valid_loss : 0.1611672043800354\n",
      "\n",
      "    341600\t  0.161382\t  0.161167\t  0.161237\t\tCURRENT LEARNING RATE: 0.016388962638703063\n",
      "previous_iter_valid_loss : 0.1613251268863678\n",
      "\n",
      "    341800\t  0.161506\t  0.161325\t  0.161238\t\tCURRENT LEARNING RATE: 0.01635621746950991\n",
      "previous_iter_valid_loss : 0.16103781759738922\n",
      "\n",
      "    342000\t  0.161231\t  0.161038\t  0.161237\t\tCURRENT LEARNING RATE: 0.016323537725208434\n",
      "previous_iter_valid_loss : 0.16109058260917664\n",
      "\n",
      "    342200\t  0.161286\t  0.161091\t  0.161237\t\tCURRENT LEARNING RATE: 0.01629092327507963\n",
      "previous_iter_valid_loss : 0.161109060049057\n",
      "\n",
      "    342400\t  0.161308\t  0.161109\t  0.161236\t\tCURRENT LEARNING RATE: 0.016258373988665645\n",
      "previous_iter_valid_loss : 0.16128601133823395\n",
      "\n",
      "    342600\t  0.161518\t  0.161286\t  0.161236\t\tCURRENT LEARNING RATE: 0.016225889735769296\n",
      "previous_iter_valid_loss : 0.16124816238880157\n",
      "\n",
      "    342800\t  0.161466\t  0.161248\t  0.161236\t\tCURRENT LEARNING RATE: 0.01619347038645352\n",
      "previous_iter_valid_loss : 0.16128388047218323\n",
      "\n",
      "    343000\t  0.161514\t  0.161284\t  0.161236\t\tCURRENT LEARNING RATE: 0.016161115811040884\n",
      "previous_iter_valid_loss : 0.16107210516929626\n",
      "\n",
      "    343200\t  0.161282\t  0.161072\t  0.161235\t\tCURRENT LEARNING RATE: 0.016128825880113037\n",
      "previous_iter_valid_loss : 0.16131040453910828\n",
      "\n",
      "    343400\t  0.161544\t  0.161310\t  0.161235\t\tCURRENT LEARNING RATE: 0.01609660046451022\n",
      "previous_iter_valid_loss : 0.1611858457326889\n",
      "\n",
      "    343600\t  0.161412\t  0.161186\t  0.161233\t\tCURRENT LEARNING RATE: 0.01606443943533072\n",
      "previous_iter_valid_loss : 0.16115254163742065\n",
      "\n",
      "    343800\t  0.161385\t  0.161153\t  0.161232\t\tCURRENT LEARNING RATE: 0.016032342663930384\n",
      "previous_iter_valid_loss : 0.1611914038658142\n",
      "\n",
      "    344000\t  0.161385\t  0.161191\t  0.161231\t\tCURRENT LEARNING RATE: 0.016000310021922075\n",
      "previous_iter_valid_loss : 0.16115950047969818\n",
      "\n",
      "    344200\t  0.161366\t  0.161160\t  0.161230\t\tCURRENT LEARNING RATE: 0.015968341381175196\n",
      "previous_iter_valid_loss : 0.16123083233833313\n",
      "\n",
      "    344400\t  0.161462\t  0.161231\t  0.161228\t\tCURRENT LEARNING RATE: 0.015936436613815122\n",
      "previous_iter_valid_loss : 0.16115476191043854\n",
      "\n",
      "    344600\t  0.161338\t  0.161155\t  0.161227\t\tCURRENT LEARNING RATE: 0.01590459559222276\n",
      "previous_iter_valid_loss : 0.161099374294281\n",
      "\n",
      "    344800\t  0.161309\t  0.161099\t  0.161224\t\tCURRENT LEARNING RATE: 0.01587281818903397\n",
      "previous_iter_valid_loss : 0.1613498479127884\n",
      "\n",
      "    345000\t  0.161564\t  0.161350\t  0.161224\t\tCURRENT LEARNING RATE: 0.0158411042771391\n",
      "previous_iter_valid_loss : 0.16103330254554749\n",
      "\n",
      "    345200\t  0.161238\t  0.161033\t  0.161223\t\tCURRENT LEARNING RATE: 0.015809453729682458\n",
      "previous_iter_valid_loss : 0.16127422451972961\n",
      "\n",
      "    345400\t  0.161459\t  0.161274\t  0.161224\t\tCURRENT LEARNING RATE: 0.01577786642006182\n",
      "previous_iter_valid_loss : 0.16109874844551086\n",
      "\n",
      "    345600\t  0.161311\t  0.161099\t  0.161224\t\tCURRENT LEARNING RATE: 0.015746342221927893\n",
      "previous_iter_valid_loss : 0.16117770969867706\n",
      "\n",
      "    345800\t  0.161378\t  0.161178\t  0.161223\t\tCURRENT LEARNING RATE: 0.015714881009183855\n",
      "previous_iter_valid_loss : 0.16129952669143677\n",
      "\n",
      "    346000\t  0.161480\t  0.161300\t  0.161223\t\tCURRENT LEARNING RATE: 0.0156834826559848\n",
      "previous_iter_valid_loss : 0.1612071543931961\n",
      "\n",
      "    346200\t  0.161408\t  0.161207\t  0.161223\t\tCURRENT LEARNING RATE: 0.01565214703673729\n",
      "previous_iter_valid_loss : 0.16125419735908508\n",
      "\n",
      "    346400\t  0.161463\t  0.161254\t  0.161221\t\tCURRENT LEARNING RATE: 0.015620874026098783\n",
      "previous_iter_valid_loss : 0.16112816333770752\n",
      "\n",
      "    346600\t  0.161340\t  0.161128\t  0.161220\t\tCURRENT LEARNING RATE: 0.015589663498977219\n",
      "previous_iter_valid_loss : 0.16123157739639282\n",
      "\n",
      "    346800\t  0.161416\t  0.161232\t  0.161219\t\tCURRENT LEARNING RATE: 0.01555851533053043\n",
      "previous_iter_valid_loss : 0.16116949915885925\n",
      "\n",
      "    347000\t  0.161361\t  0.161169\t  0.161217\t\tCURRENT LEARNING RATE: 0.015527429396165715\n",
      "previous_iter_valid_loss : 0.161091148853302\n",
      "\n",
      "    347200\t  0.161264\t  0.161091\t  0.161216\t\tCURRENT LEARNING RATE: 0.01549640557153928\n",
      "previous_iter_valid_loss : 0.16103406250476837\n",
      "\n",
      "    347400\t  0.161229\t  0.161034\t  0.161215\t\tCURRENT LEARNING RATE: 0.015465443732555801\n",
      "previous_iter_valid_loss : 0.16104044020175934\n",
      "\n",
      "    347600\t  0.161217\t  0.161040\t  0.161213\t\tCURRENT LEARNING RATE: 0.015434543755367866\n",
      "previous_iter_valid_loss : 0.16101181507110596\n",
      "\n",
      "\n",
      "Current valid loss: 0.16101181507110596;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "    347800\t  0.161189\t  0.161012\t  0.161213\t\tCURRENT LEARNING RATE: 0.015403705516375538\n",
      "previous_iter_valid_loss : 0.16106602549552917\n",
      "\n",
      "    348000\t  0.161258\t  0.161066\t  0.161213\t\tCURRENT LEARNING RATE: 0.015372928892225808\n",
      "previous_iter_valid_loss : 0.16098394989967346\n",
      "\n",
      "\n",
      "Current valid loss: 0.16098394989967346;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "    348200\t  0.161166\t  0.160984\t  0.161210\t\tCURRENT LEARNING RATE: 0.01534221375981215\n",
      "previous_iter_valid_loss : 0.16133436560630798\n",
      "\n",
      "    348400\t  0.161542\t  0.161334\t  0.161211\t\tCURRENT LEARNING RATE: 0.01531155999627398\n",
      "previous_iter_valid_loss : 0.16110368072986603\n",
      "\n",
      "    348600\t  0.161285\t  0.161104\t  0.161211\t\tCURRENT LEARNING RATE: 0.015280967478996219\n",
      "previous_iter_valid_loss : 0.1612449288368225\n",
      "\n",
      "    348800\t  0.161442\t  0.161245\t  0.161211\t\tCURRENT LEARNING RATE: 0.015250436085608741\n",
      "previous_iter_valid_loss : 0.1612461507320404\n",
      "\n",
      "    349000\t  0.161445\t  0.161246\t  0.161211\t\tCURRENT LEARNING RATE: 0.015219965693985945\n",
      "previous_iter_valid_loss : 0.16109077632427216\n",
      "\n",
      "    349200\t  0.161276\t  0.161091\t  0.161209\t\tCURRENT LEARNING RATE: 0.015189556182246215\n",
      "previous_iter_valid_loss : 0.16097627580165863\n",
      "\n",
      "\n",
      "Current valid loss: 0.16097627580165863;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "    349400\t  0.161154\t  0.160976\t  0.161209\t\tCURRENT LEARNING RATE: 0.01515920742875147\n",
      "previous_iter_valid_loss : 0.1611126810312271\n",
      "\n",
      "    349600\t  0.161287\t  0.161113\t  0.161209\t\tCURRENT LEARNING RATE: 0.015128919312106647\n",
      "previous_iter_valid_loss : 0.16126114130020142\n",
      "\n",
      "    349800\t  0.161440\t  0.161261\t  0.161208\t\tCURRENT LEARNING RATE: 0.01509869171115925\n",
      "previous_iter_valid_loss : 0.16114598512649536\n",
      "\n",
      "    350000\t  0.161367\t  0.161146\t  0.161208\t\tCURRENT LEARNING RATE: 0.01506852450499883\n",
      "previous_iter_valid_loss : 0.1611112505197525\n",
      "\n",
      "    350200\t  0.161275\t  0.161111\t  0.161208\t\tCURRENT LEARNING RATE: 0.015038417572956516\n",
      "previous_iter_valid_loss : 0.16130328178405762\n",
      "\n",
      "    350400\t  0.161510\t  0.161303\t  0.161208\t\tCURRENT LEARNING RATE: 0.015008370794604549\n",
      "previous_iter_valid_loss : 0.16109056770801544\n",
      "\n",
      "    350600\t  0.161288\t  0.161091\t  0.161207\t\tCURRENT LEARNING RATE: 0.014978384049755766\n",
      "previous_iter_valid_loss : 0.16168805956840515\n",
      "\n",
      "    350800\t  0.161887\t  0.161688\t  0.161209\t\tCURRENT LEARNING RATE: 0.01494845721846316\n",
      "previous_iter_valid_loss : 0.16103950142860413\n",
      "\n",
      "    351000\t  0.161207\t  0.161040\t  0.161209\t\tCURRENT LEARNING RATE: 0.014918590181019353\n",
      "previous_iter_valid_loss : 0.16102080047130585\n",
      "\n",
      "    351200\t  0.161190\t  0.161021\t  0.161207\t\tCURRENT LEARNING RATE: 0.014888782817956168\n",
      "previous_iter_valid_loss : 0.16142623126506805\n",
      "\n",
      "    351400\t  0.161625\t  0.161426\t  0.161209\t\tCURRENT LEARNING RATE: 0.0148590350100441\n",
      "previous_iter_valid_loss : 0.1611778885126114\n",
      "\n",
      "    351600\t  0.161311\t  0.161178\t  0.161209\t\tCURRENT LEARNING RATE: 0.01482934663829189\n",
      "previous_iter_valid_loss : 0.16102531552314758\n",
      "\n",
      "    351800\t  0.161184\t  0.161025\t  0.161208\t\tCURRENT LEARNING RATE: 0.014799717583946\n",
      "previous_iter_valid_loss : 0.16111639142036438\n",
      "\n",
      "    352000\t  0.161268\t  0.161116\t  0.161207\t\tCURRENT LEARNING RATE: 0.014770147728490186\n",
      "previous_iter_valid_loss : 0.16108079254627228\n",
      "\n",
      "    352200\t  0.161242\t  0.161081\t  0.161206\t\tCURRENT LEARNING RATE: 0.01474063695364497\n",
      "previous_iter_valid_loss : 0.16123367846012115\n",
      "\n",
      "    352400\t  0.161411\t  0.161234\t  0.161205\t\tCURRENT LEARNING RATE: 0.014711185141367232\n",
      "previous_iter_valid_loss : 0.1611725240945816\n",
      "\n",
      "    352600\t  0.161340\t  0.161173\t  0.161204\t\tCURRENT LEARNING RATE: 0.014681792173849666\n",
      "previous_iter_valid_loss : 0.16122756898403168\n",
      "\n",
      "    352800\t  0.161431\t  0.161228\t  0.161204\t\tCURRENT LEARNING RATE: 0.01465245793352038\n",
      "previous_iter_valid_loss : 0.16142240166664124\n",
      "\n",
      "    353000\t  0.161574\t  0.161422\t  0.161205\t\tCURRENT LEARNING RATE: 0.014623182303042357\n",
      "previous_iter_valid_loss : 0.1610645204782486\n",
      "\n",
      "    353200\t  0.161215\t  0.161065\t  0.161203\t\tCURRENT LEARNING RATE: 0.01459396516531305\n",
      "previous_iter_valid_loss : 0.1610671430826187\n",
      "\n",
      "    353400\t  0.161253\t  0.161067\t  0.161201\t\tCURRENT LEARNING RATE: 0.014564806403463856\n",
      "previous_iter_valid_loss : 0.1610586941242218\n",
      "\n",
      "    353600\t  0.161208\t  0.161059\t  0.161201\t\tCURRENT LEARNING RATE: 0.014535705900859702\n",
      "previous_iter_valid_loss : 0.1611127257347107\n",
      "\n",
      "    353800\t  0.161276\t  0.161113\t  0.161200\t\tCURRENT LEARNING RATE: 0.014506663541098527\n",
      "previous_iter_valid_loss : 0.1612762063741684\n",
      "\n",
      "    354000\t  0.161462\t  0.161276\t  0.161201\t\tCURRENT LEARNING RATE: 0.014477679208010864\n",
      "previous_iter_valid_loss : 0.1611233949661255\n",
      "\n",
      "    354200\t  0.161314\t  0.161123\t  0.161199\t\tCURRENT LEARNING RATE: 0.014448752785659331\n",
      "previous_iter_valid_loss : 0.16114868223667145\n",
      "\n",
      "    354400\t  0.161320\t  0.161149\t  0.161199\t\tCURRENT LEARNING RATE: 0.014419884158338211\n",
      "previous_iter_valid_loss : 0.16120728850364685\n",
      "\n",
      "    354600\t  0.161396\t  0.161207\t  0.161199\t\tCURRENT LEARNING RATE: 0.014391073210572945\n",
      "previous_iter_valid_loss : 0.16112184524536133\n",
      "\n",
      "    354800\t  0.161321\t  0.161122\t  0.161199\t\tCURRENT LEARNING RATE: 0.014362319827119717\n",
      "previous_iter_valid_loss : 0.16101466119289398\n",
      "\n",
      "    355000\t  0.161183\t  0.161015\t  0.161197\t\tCURRENT LEARNING RATE: 0.01433362389296494\n",
      "previous_iter_valid_loss : 0.16112665832042694\n",
      "\n",
      "    355200\t  0.161295\t  0.161127\t  0.161197\t\tCURRENT LEARNING RATE: 0.014304985293324853\n",
      "previous_iter_valid_loss : 0.161356121301651\n",
      "\n",
      "    355400\t  0.161543\t  0.161356\t  0.161197\t\tCURRENT LEARNING RATE: 0.014276403913645005\n",
      "previous_iter_valid_loss : 0.1611965000629425\n",
      "\n",
      "    355600\t  0.161405\t  0.161197\t  0.161197\t\tCURRENT LEARNING RATE: 0.014247879639599854\n",
      "previous_iter_valid_loss : 0.16107624769210815\n",
      "\n",
      "    355800\t  0.161283\t  0.161076\t  0.161195\t\tCURRENT LEARNING RATE: 0.014219412357092252\n",
      "previous_iter_valid_loss : 0.16112512350082397\n",
      "\n",
      "    356000\t  0.161327\t  0.161125\t  0.161195\t\tCURRENT LEARNING RATE: 0.014191001952253045\n",
      "previous_iter_valid_loss : 0.16138523817062378\n",
      "\n",
      "    356200\t  0.161588\t  0.161385\t  0.161195\t\tCURRENT LEARNING RATE: 0.01416264831144056\n",
      "previous_iter_valid_loss : 0.1612192541360855\n",
      "\n",
      "    356400\t  0.161423\t  0.161219\t  0.161195\t\tCURRENT LEARNING RATE: 0.014134351321240213\n",
      "previous_iter_valid_loss : 0.1611039638519287\n",
      "\n",
      "    356600\t  0.161319\t  0.161104\t  0.161195\t\tCURRENT LEARNING RATE: 0.01410611086846399\n",
      "previous_iter_valid_loss : 0.1613640934228897\n",
      "\n",
      "    356800\t  0.161551\t  0.161364\t  0.161196\t\tCURRENT LEARNING RATE: 0.014077926840150053\n",
      "previous_iter_valid_loss : 0.161199152469635\n",
      "\n",
      "    357000\t  0.161383\t  0.161199\t  0.161194\t\tCURRENT LEARNING RATE: 0.014049799123562244\n",
      "previous_iter_valid_loss : 0.16100867092609406\n",
      "\n",
      "    357200\t  0.161182\t  0.161009\t  0.161193\t\tCURRENT LEARNING RATE: 0.014021727606189666\n",
      "previous_iter_valid_loss : 0.16119523346424103\n",
      "\n",
      "    357400\t  0.161372\t  0.161195\t  0.161191\t\tCURRENT LEARNING RATE: 0.013993712175746202\n",
      "previous_iter_valid_loss : 0.1611109972000122\n",
      "\n",
      "    357600\t  0.161289\t  0.161111\t  0.161191\t\tCURRENT LEARNING RATE: 0.013965752720170107\n",
      "previous_iter_valid_loss : 0.16111895442008972\n",
      "\n",
      "    357800\t  0.161274\t  0.161119\t  0.161189\t\tCURRENT LEARNING RATE: 0.013937849127623508\n",
      "previous_iter_valid_loss : 0.1613442301750183\n",
      "\n",
      "    358000\t  0.161591\t  0.161344\t  0.161189\t\tCURRENT LEARNING RATE: 0.013910001286492009\n",
      "previous_iter_valid_loss : 0.16111095249652863\n",
      "\n",
      "    358200\t  0.161303\t  0.161111\t  0.161188\t\tCURRENT LEARNING RATE: 0.013882209085384196\n",
      "previous_iter_valid_loss : 0.16103143990039825\n",
      "\n",
      "    358400\t  0.161214\t  0.161031\t  0.161186\t\tCURRENT LEARNING RATE: 0.01385447241313124\n",
      "previous_iter_valid_loss : 0.161068856716156\n",
      "\n",
      "    358600\t  0.161224\t  0.161069\t  0.161184\t\tCURRENT LEARNING RATE: 0.013826791158786404\n",
      "previous_iter_valid_loss : 0.16104426980018616\n",
      "\n",
      "    358800\t  0.161213\t  0.161044\t  0.161183\t\tCURRENT LEARNING RATE: 0.013799165211624644\n",
      "previous_iter_valid_loss : 0.1612824648618698\n",
      "\n",
      "    359000\t  0.161466\t  0.161282\t  0.161183\t\tCURRENT LEARNING RATE: 0.013771594461142124\n",
      "previous_iter_valid_loss : 0.16118282079696655\n",
      "\n",
      "    359200\t  0.161387\t  0.161183\t  0.161183\t\tCURRENT LEARNING RATE: 0.013744078797055817\n",
      "previous_iter_valid_loss : 0.1610507071018219\n",
      "\n",
      "    359400\t  0.161237\t  0.161051\t  0.161182\t\tCURRENT LEARNING RATE: 0.013716618109303016\n",
      "previous_iter_valid_loss : 0.16101934015750885\n",
      "\n",
      "    359600\t  0.161193\t  0.161019\t  0.161181\t\tCURRENT LEARNING RATE: 0.013689212288040948\n",
      "previous_iter_valid_loss : 0.16153202950954437\n",
      "\n",
      "    359800\t  0.161724\t  0.161532\t  0.161184\t\tCURRENT LEARNING RATE: 0.01366186122364628\n",
      "previous_iter_valid_loss : 0.16108502447605133\n",
      "\n",
      "    360000\t  0.161263\t  0.161085\t  0.161182\t\tCURRENT LEARNING RATE: 0.013634564806714726\n",
      "previous_iter_valid_loss : 0.16104839742183685\n",
      "\n",
      "    360200\t  0.161224\t  0.161048\t  0.161180\t\tCURRENT LEARNING RATE: 0.013607322928060573\n",
      "previous_iter_valid_loss : 0.161054790019989\n",
      "\n",
      "    360400\t  0.161249\t  0.161055\t  0.161179\t\tCURRENT LEARNING RATE: 0.013580135478716282\n",
      "previous_iter_valid_loss : 0.161026269197464\n",
      "\n",
      "    360600\t  0.161207\t  0.161026\t  0.161177\t\tCURRENT LEARNING RATE: 0.013553002349932007\n",
      "previous_iter_valid_loss : 0.16115938127040863\n",
      "\n",
      "    360800\t  0.161331\t  0.161159\t  0.161176\t\tCURRENT LEARNING RATE: 0.013525923433175208\n",
      "previous_iter_valid_loss : 0.1611415296792984\n",
      "\n",
      "    361000\t  0.161300\t  0.161142\t  0.161177\t\tCURRENT LEARNING RATE: 0.01349889862013017\n",
      "previous_iter_valid_loss : 0.16116197407245636\n",
      "\n",
      "    361200\t  0.161353\t  0.161162\t  0.161177\t\tCURRENT LEARNING RATE: 0.013471927802697617\n",
      "previous_iter_valid_loss : 0.16115356981754303\n",
      "\n",
      "    361400\t  0.161330\t  0.161154\t  0.161177\t\tCURRENT LEARNING RATE: 0.013445010872994231\n",
      "previous_iter_valid_loss : 0.16111227869987488\n",
      "\n",
      "    361600\t  0.161281\t  0.161112\t  0.161176\t\tCURRENT LEARNING RATE: 0.01341814772335227\n",
      "previous_iter_valid_loss : 0.16123588383197784\n",
      "\n",
      "    361800\t  0.161440\t  0.161236\t  0.161177\t\tCURRENT LEARNING RATE: 0.013391338246319088\n",
      "previous_iter_valid_loss : 0.16124777495861053\n",
      "\n",
      "    362000\t  0.161439\t  0.161248\t  0.161178\t\tCURRENT LEARNING RATE: 0.01336458233465675\n",
      "previous_iter_valid_loss : 0.16116535663604736\n",
      "\n",
      "    362200\t  0.161343\t  0.161165\t  0.161177\t\tCURRENT LEARNING RATE: 0.013337879881341566\n",
      "previous_iter_valid_loss : 0.16104651987552643\n",
      "\n",
      "    362400\t  0.161232\t  0.161047\t  0.161175\t\tCURRENT LEARNING RATE: 0.013311230779563699\n",
      "previous_iter_valid_loss : 0.16123753786087036\n",
      "\n",
      "    362600\t  0.161428\t  0.161238\t  0.161175\t\tCURRENT LEARNING RATE: 0.01328463492272669\n",
      "previous_iter_valid_loss : 0.16101722419261932\n",
      "\n",
      "    362800\t  0.161168\t  0.161017\t  0.161174\t\tCURRENT LEARNING RATE: 0.01325809220444709\n",
      "previous_iter_valid_loss : 0.16104987263679504\n",
      "\n",
      "    363000\t  0.161209\t  0.161050\t  0.161174\t\tCURRENT LEARNING RATE: 0.013231602518553981\n",
      "previous_iter_valid_loss : 0.1610756814479828\n",
      "\n",
      "    363200\t  0.161229\t  0.161076\t  0.161174\t\tCURRENT LEARNING RATE: 0.013205165759088594\n",
      "previous_iter_valid_loss : 0.16130200028419495\n",
      "\n",
      "    363400\t  0.161532\t  0.161302\t  0.161173\t\tCURRENT LEARNING RATE: 0.013178781820303844\n",
      "previous_iter_valid_loss : 0.1613333523273468\n",
      "\n",
      "    363600\t  0.161467\t  0.161333\t  0.161174\t\tCURRENT LEARNING RATE: 0.013152450596663954\n",
      "previous_iter_valid_loss : 0.16112233698368073\n",
      "\n",
      "    363800\t  0.161302\t  0.161122\t  0.161174\t\tCURRENT LEARNING RATE: 0.01312617198284398\n",
      "previous_iter_valid_loss : 0.1611090451478958\n",
      "\n",
      "    364000\t  0.161289\t  0.161109\t  0.161174\t\tCURRENT LEARNING RATE: 0.013099945873729445\n",
      "previous_iter_valid_loss : 0.16108322143554688\n",
      "\n",
      "    364200\t  0.161266\t  0.161083\t  0.161174\t\tCURRENT LEARNING RATE: 0.013073772164415867\n",
      "previous_iter_valid_loss : 0.16102364659309387\n",
      "\n",
      "    364400\t  0.161187\t  0.161024\t  0.161172\t\tCURRENT LEARNING RATE: 0.013047650750208382\n",
      "previous_iter_valid_loss : 0.16101039946079254\n",
      "\n",
      "    364600\t  0.161168\t  0.161010\t  0.161171\t\tCURRENT LEARNING RATE: 0.01302158152662129\n",
      "previous_iter_valid_loss : 0.16112810373306274\n",
      "\n",
      "    364800\t  0.161309\t  0.161128\t  0.161168\t\tCURRENT LEARNING RATE: 0.012995564389377674\n",
      "previous_iter_valid_loss : 0.16118274629116058\n",
      "\n",
      "    365000\t  0.161365\t  0.161183\t  0.161169\t\tCURRENT LEARNING RATE: 0.012969599234408935\n",
      "previous_iter_valid_loss : 0.16100703179836273\n",
      "\n",
      "    365200\t  0.161191\t  0.161007\t  0.161167\t\tCURRENT LEARNING RATE: 0.012943685957854433\n",
      "previous_iter_valid_loss : 0.1612444370985031\n",
      "\n",
      "    365400\t  0.161436\t  0.161244\t  0.161166\t\tCURRENT LEARNING RATE: 0.012917824456061013\n",
      "previous_iter_valid_loss : 0.16104598343372345\n",
      "\n",
      "    365600\t  0.161228\t  0.161046\t  0.161165\t\tCURRENT LEARNING RATE: 0.01289201462558265\n",
      "previous_iter_valid_loss : 0.1610191911458969\n",
      "\n",
      "    365800\t  0.161188\t  0.161019\t  0.161165\t\tCURRENT LEARNING RATE: 0.01286625636317997\n",
      "previous_iter_valid_loss : 0.1610817164182663\n",
      "\n",
      "    366000\t  0.161216\t  0.161082\t  0.161165\t\tCURRENT LEARNING RATE: 0.012840549565819906\n",
      "previous_iter_valid_loss : 0.16127590835094452\n",
      "\n",
      "    366200\t  0.161452\t  0.161276\t  0.161166\t\tCURRENT LEARNING RATE: 0.01281489413067522\n",
      "previous_iter_valid_loss : 0.16100631654262543\n",
      "\n",
      "    366400\t  0.161161\t  0.161006\t  0.161165\t\tCURRENT LEARNING RATE: 0.012789289955124147\n",
      "previous_iter_valid_loss : 0.16104717552661896\n",
      "\n",
      "    366600\t  0.161242\t  0.161047\t  0.161165\t\tCURRENT LEARNING RATE: 0.012763736936749943\n",
      "previous_iter_valid_loss : 0.16113127768039703\n",
      "\n",
      "    366800\t  0.161275\t  0.161131\t  0.161165\t\tCURRENT LEARNING RATE: 0.012738234973340508\n",
      "previous_iter_valid_loss : 0.16160717606544495\n",
      "\n",
      "    367000\t  0.161777\t  0.161607\t  0.161168\t\tCURRENT LEARNING RATE: 0.012712783962887947\n",
      "previous_iter_valid_loss : 0.16105225682258606\n",
      "\n",
      "    367200\t  0.161240\t  0.161052\t  0.161167\t\tCURRENT LEARNING RATE: 0.012687383803588193\n",
      "previous_iter_valid_loss : 0.16098333895206451\n",
      "\n",
      "    367400\t  0.161128\t  0.160983\t  0.161165\t\tCURRENT LEARNING RATE: 0.012662034393840563\n",
      "previous_iter_valid_loss : 0.16125325858592987\n",
      "\n",
      "    367600\t  0.161455\t  0.161253\t  0.161166\t\tCURRENT LEARNING RATE: 0.012636735632247398\n",
      "previous_iter_valid_loss : 0.1610390990972519\n",
      "\n",
      "    367800\t  0.161210\t  0.161039\t  0.161165\t\tCURRENT LEARNING RATE: 0.012611487417613606\n",
      "previous_iter_valid_loss : 0.16105087101459503\n",
      "\n",
      "    368000\t  0.161191\t  0.161051\t  0.161165\t\tCURRENT LEARNING RATE: 0.012586289648946303\n",
      "previous_iter_valid_loss : 0.1610313057899475\n",
      "\n",
      "    368200\t  0.161186\t  0.161031\t  0.161162\t\tCURRENT LEARNING RATE: 0.012561142225454375\n",
      "previous_iter_valid_loss : 0.16117431223392487\n",
      "\n",
      "    368400\t  0.161317\t  0.161174\t  0.161160\t\tCURRENT LEARNING RATE: 0.012536045046548101\n",
      "previous_iter_valid_loss : 0.16121502220630646\n",
      "\n",
      "    368600\t  0.161357\t  0.161215\t  0.161161\t\tCURRENT LEARNING RATE: 0.012510998011838722\n",
      "previous_iter_valid_loss : 0.16120804846286774\n",
      "\n",
      "    368800\t  0.161337\t  0.161208\t  0.161161\t\tCURRENT LEARNING RATE: 0.012486001021138077\n",
      "previous_iter_valid_loss : 0.16124583780765533\n",
      "\n",
      "    369000\t  0.161402\t  0.161246\t  0.161162\t\tCURRENT LEARNING RATE: 0.01246105397445816\n",
      "previous_iter_valid_loss : 0.16100665926933289\n",
      "\n",
      "    369200\t  0.161146\t  0.161007\t  0.161162\t\tCURRENT LEARNING RATE: 0.012436156772010761\n",
      "previous_iter_valid_loss : 0.16105404496192932\n",
      "\n",
      "    369400\t  0.161185\t  0.161054\t  0.161162\t\tCURRENT LEARNING RATE: 0.012411309314207026\n",
      "previous_iter_valid_loss : 0.16109733283519745\n",
      "\n",
      "    369600\t  0.161242\t  0.161097\t  0.161162\t\tCURRENT LEARNING RATE: 0.0123865115016571\n",
      "previous_iter_valid_loss : 0.16103562712669373\n",
      "\n",
      "    369800\t  0.161162\t  0.161036\t  0.161161\t\tCURRENT LEARNING RATE: 0.012361763235169694\n",
      "previous_iter_valid_loss : 0.16112419962882996\n",
      "\n",
      "    370000\t  0.161299\t  0.161124\t  0.161160\t\tCURRENT LEARNING RATE: 0.012337064415751714\n",
      "previous_iter_valid_loss : 0.16104334592819214\n",
      "\n",
      "    370200\t  0.161207\t  0.161043\t  0.161156\t\tCURRENT LEARNING RATE: 0.012312414944607842\n",
      "previous_iter_valid_loss : 0.161166250705719\n",
      "\n",
      "    370400\t  0.161351\t  0.161166\t  0.161157\t\tCURRENT LEARNING RATE: 0.012287814723140169\n",
      "previous_iter_valid_loss : 0.1611623764038086\n",
      "\n",
      "    370600\t  0.161309\t  0.161162\t  0.161156\t\tCURRENT LEARNING RATE: 0.012263263652947769\n",
      "previous_iter_valid_loss : 0.16103675961494446\n",
      "\n",
      "    370800\t  0.161151\t  0.161037\t  0.161156\t\tCURRENT LEARNING RATE: 0.012238761635826335\n",
      "previous_iter_valid_loss : 0.16111944615840912\n",
      "\n",
      "    371000\t  0.161277\t  0.161119\t  0.161156\t\tCURRENT LEARNING RATE: 0.012214308573767759\n",
      "previous_iter_valid_loss : 0.16107438504695892\n",
      "\n",
      "    371200\t  0.161216\t  0.161074\t  0.161156\t\tCURRENT LEARNING RATE: 0.012189904368959769\n",
      "previous_iter_valid_loss : 0.16113506257534027\n",
      "\n",
      "    371400\t  0.161284\t  0.161135\t  0.161156\t\tCURRENT LEARNING RATE: 0.012165548923785501\n",
      "previous_iter_valid_loss : 0.16132666170597076\n",
      "\n",
      "    371600\t  0.161501\t  0.161327\t  0.161157\t\tCURRENT LEARNING RATE: 0.012141242140823155\n",
      "previous_iter_valid_loss : 0.1610351800918579\n",
      "\n",
      "    371800\t  0.161159\t  0.161035\t  0.161157\t\tCURRENT LEARNING RATE: 0.012116983922845556\n",
      "previous_iter_valid_loss : 0.16101495921611786\n",
      "\n",
      "    372000\t  0.161144\t  0.161015\t  0.161157\t\tCURRENT LEARNING RATE: 0.01209277417281981\n",
      "previous_iter_valid_loss : 0.16108912229537964\n",
      "\n",
      "    372200\t  0.161228\t  0.161089\t  0.161157\t\tCURRENT LEARNING RATE: 0.012068612793906874\n",
      "previous_iter_valid_loss : 0.16101722419261932\n",
      "\n",
      "    372400\t  0.161167\t  0.161017\t  0.161155\t\tCURRENT LEARNING RATE: 0.012044499689461209\n",
      "previous_iter_valid_loss : 0.16108521819114685\n",
      "\n",
      "    372600\t  0.161211\t  0.161085\t  0.161154\t\tCURRENT LEARNING RATE: 0.012020434763030356\n",
      "previous_iter_valid_loss : 0.16107161343097687\n",
      "\n",
      "    372800\t  0.161226\t  0.161072\t  0.161155\t\tCURRENT LEARNING RATE: 0.011996417918354587\n",
      "previous_iter_valid_loss : 0.16107220947742462\n",
      "\n",
      "    373000\t  0.161215\t  0.161072\t  0.161154\t\tCURRENT LEARNING RATE: 0.011972449059366484\n",
      "previous_iter_valid_loss : 0.16108015179634094\n",
      "\n",
      "    373200\t  0.161251\t  0.161080\t  0.161154\t\tCURRENT LEARNING RATE: 0.011948528090190584\n",
      "previous_iter_valid_loss : 0.16118228435516357\n",
      "\n",
      "    373400\t  0.161320\t  0.161182\t  0.161153\t\tCURRENT LEARNING RATE: 0.011924654915142973\n",
      "previous_iter_valid_loss : 0.16150116920471191\n",
      "\n",
      "    373600\t  0.161646\t  0.161501\t  0.161154\t\tCURRENT LEARNING RATE: 0.011900829438730927\n",
      "previous_iter_valid_loss : 0.16116856038570404\n",
      "\n",
      "    373800\t  0.161333\t  0.161169\t  0.161154\t\tCURRENT LEARNING RATE: 0.011877051565652498\n",
      "previous_iter_valid_loss : 0.16113148629665375\n",
      "\n",
      "    374000\t  0.161267\t  0.161131\t  0.161154\t\tCURRENT LEARNING RATE: 0.011853321200796173\n",
      "previous_iter_valid_loss : 0.16110025346279144\n",
      "\n",
      "    374200\t  0.161227\t  0.161100\t  0.161154\t\tCURRENT LEARNING RATE: 0.01182963824924045\n",
      "previous_iter_valid_loss : 0.161107137799263\n",
      "\n",
      "    374400\t  0.161250\t  0.161107\t  0.161154\t\tCURRENT LEARNING RATE: 0.011806002616253503\n",
      "previous_iter_valid_loss : 0.16113340854644775\n",
      "\n",
      "    374600\t  0.161277\t  0.161133\t  0.161154\t\tCURRENT LEARNING RATE: 0.011782414207292756\n",
      "previous_iter_valid_loss : 0.16103190183639526\n",
      "\n",
      "    374800\t  0.161177\t  0.161032\t  0.161153\t\tCURRENT LEARNING RATE: 0.011758872928004553\n",
      "previous_iter_valid_loss : 0.16100236773490906\n",
      "\n",
      "    375000\t  0.161152\t  0.161002\t  0.161151\t\tCURRENT LEARNING RATE: 0.011735378684223743\n",
      "previous_iter_valid_loss : 0.1611160933971405\n",
      "\n",
      "    375200\t  0.161233\t  0.161116\t  0.161151\t\tCURRENT LEARNING RATE: 0.011711931381973309\n",
      "previous_iter_valid_loss : 0.16103656589984894\n",
      "\n",
      "    375400\t  0.161180\t  0.161037\t  0.161150\t\tCURRENT LEARNING RATE: 0.011688530927464027\n",
      "previous_iter_valid_loss : 0.16105474531650543\n",
      "\n",
      "    375600\t  0.161203\t  0.161055\t  0.161150\t\tCURRENT LEARNING RATE: 0.011665177227094032\n",
      "previous_iter_valid_loss : 0.16107086837291718\n",
      "\n",
      "    375800\t  0.161215\t  0.161071\t  0.161150\t\tCURRENT LEARNING RATE: 0.011641870187448505\n",
      "previous_iter_valid_loss : 0.16099749505519867\n",
      "\n",
      "    376000\t  0.161133\t  0.160997\t  0.161148\t\tCURRENT LEARNING RATE: 0.011618609715299244\n",
      "previous_iter_valid_loss : 0.1610511690378189\n",
      "\n",
      "    376200\t  0.161169\t  0.161051\t  0.161148\t\tCURRENT LEARNING RATE: 0.011595395717604342\n",
      "previous_iter_valid_loss : 0.1612350195646286\n",
      "\n",
      "    376400\t  0.161393\t  0.161235\t  0.161148\t\tCURRENT LEARNING RATE: 0.011572228101507766\n",
      "previous_iter_valid_loss : 0.16121640801429749\n",
      "\n",
      "    376600\t  0.161379\t  0.161216\t  0.161147\t\tCURRENT LEARNING RATE: 0.01154910677433903\n",
      "previous_iter_valid_loss : 0.16105332970619202\n",
      "\n",
      "    376800\t  0.161222\t  0.161053\t  0.161145\t\tCURRENT LEARNING RATE: 0.011526031643612785\n",
      "previous_iter_valid_loss : 0.16135583817958832\n",
      "\n",
      "    377000\t  0.161549\t  0.161356\t  0.161147\t\tCURRENT LEARNING RATE: 0.011503002617028487\n",
      "previous_iter_valid_loss : 0.16107523441314697\n",
      "\n",
      "    377200\t  0.161254\t  0.161075\t  0.161146\t\tCURRENT LEARNING RATE: 0.011480019602469992\n",
      "previous_iter_valid_loss : 0.16114531457424164\n",
      "\n",
      "    377400\t  0.161314\t  0.161145\t  0.161145\t\tCURRENT LEARNING RATE: 0.011457082508005216\n",
      "previous_iter_valid_loss : 0.16100290417671204\n",
      "\n",
      "    377600\t  0.161144\t  0.161003\t  0.161145\t\tCURRENT LEARNING RATE: 0.011434191241885744\n",
      "previous_iter_valid_loss : 0.16124868392944336\n",
      "\n",
      "    377800\t  0.161392\t  0.161249\t  0.161146\t\tCURRENT LEARNING RATE: 0.01141134571254649\n",
      "previous_iter_valid_loss : 0.16140377521514893\n",
      "\n",
      "    378000\t  0.161557\t  0.161404\t  0.161148\t\tCURRENT LEARNING RATE: 0.011388545828605297\n",
      "previous_iter_valid_loss : 0.16102482378482819\n",
      "\n",
      "    378200\t  0.161195\t  0.161025\t  0.161147\t\tCURRENT LEARNING RATE: 0.011365791498862608\n",
      "previous_iter_valid_loss : 0.16112284362316132\n",
      "\n",
      "    378400\t  0.161272\t  0.161123\t  0.161146\t\tCURRENT LEARNING RATE: 0.011343082632301063\n",
      "previous_iter_valid_loss : 0.1610633134841919\n",
      "\n",
      "    378600\t  0.161215\t  0.161063\t  0.161146\t\tCURRENT LEARNING RATE: 0.011320419138085177\n",
      "previous_iter_valid_loss : 0.16120868921279907\n",
      "\n",
      "    378800\t  0.161385\t  0.161209\t  0.161146\t\tCURRENT LEARNING RATE: 0.011297800925560932\n",
      "previous_iter_valid_loss : 0.16122837364673615\n",
      "\n",
      "    379000\t  0.161402\t  0.161228\t  0.161147\t\tCURRENT LEARNING RATE: 0.011275227904255457\n",
      "previous_iter_valid_loss : 0.1610514372587204\n",
      "\n",
      "    379200\t  0.161224\t  0.161051\t  0.161146\t\tCURRENT LEARNING RATE: 0.01125269998387663\n",
      "previous_iter_valid_loss : 0.16100464761257172\n",
      "\n",
      "    379400\t  0.161140\t  0.161005\t  0.161146\t\tCURRENT LEARNING RATE: 0.011230217074312746\n",
      "previous_iter_valid_loss : 0.16132739186286926\n",
      "\n",
      "    379600\t  0.161482\t  0.161327\t  0.161146\t\tCURRENT LEARNING RATE: 0.011207779085632127\n",
      "previous_iter_valid_loss : 0.1610342115163803\n",
      "\n",
      "    379800\t  0.161178\t  0.161034\t  0.161146\t\tCURRENT LEARNING RATE: 0.0111853859280828\n",
      "previous_iter_valid_loss : 0.16135577857494354\n",
      "\n",
      "    380000\t  0.161499\t  0.161356\t  0.161147\t\tCURRENT LEARNING RATE: 0.011163037512092093\n",
      "previous_iter_valid_loss : 0.16115865111351013\n",
      "\n",
      "    380200\t  0.161317\t  0.161159\t  0.161148\t\tCURRENT LEARNING RATE: 0.011140733748266326\n",
      "previous_iter_valid_loss : 0.16102664172649384\n",
      "\n",
      "    380400\t  0.161175\t  0.161027\t  0.161147\t\tCURRENT LEARNING RATE: 0.0111184745473904\n",
      "previous_iter_valid_loss : 0.16104361414909363\n",
      "\n",
      "    380600\t  0.161190\t  0.161044\t  0.161146\t\tCURRENT LEARNING RATE: 0.011096259820427492\n",
      "previous_iter_valid_loss : 0.16106460988521576\n",
      "\n",
      "    380800\t  0.161221\t  0.161065\t  0.161146\t\tCURRENT LEARNING RATE: 0.011074089478518657\n",
      "previous_iter_valid_loss : 0.1610201746225357\n",
      "\n",
      "    381000\t  0.161187\t  0.161020\t  0.161145\t\tCURRENT LEARNING RATE: 0.011051963432982507\n",
      "previous_iter_valid_loss : 0.16125237941741943\n",
      "\n",
      "    381200\t  0.161410\t  0.161252\t  0.161146\t\tCURRENT LEARNING RATE: 0.011029881595314818\n",
      "previous_iter_valid_loss : 0.16107311844825745\n",
      "\n",
      "    381400\t  0.161231\t  0.161073\t  0.161145\t\tCURRENT LEARNING RATE: 0.011007843877188225\n",
      "previous_iter_valid_loss : 0.1610901653766632\n",
      "\n",
      "    381600\t  0.161233\t  0.161090\t  0.161145\t\tCURRENT LEARNING RATE: 0.010985850190451809\n",
      "previous_iter_valid_loss : 0.16115835309028625\n",
      "\n",
      "    381800\t  0.161301\t  0.161158\t  0.161144\t\tCURRENT LEARNING RATE: 0.01096390044713081\n",
      "previous_iter_valid_loss : 0.1611129492521286\n",
      "\n",
      "    382000\t  0.161283\t  0.161113\t  0.161145\t\tCURRENT LEARNING RATE: 0.010941994559426212\n",
      "previous_iter_valid_loss : 0.16099834442138672\n",
      "\n",
      "    382200\t  0.161155\t  0.160998\t  0.161144\t\tCURRENT LEARNING RATE: 0.010920132439714448\n",
      "previous_iter_valid_loss : 0.1610855609178543\n",
      "\n",
      "    382400\t  0.161246\t  0.161086\t  0.161144\t\tCURRENT LEARNING RATE: 0.010898314000546996\n",
      "previous_iter_valid_loss : 0.1610656976699829\n",
      "\n",
      "    382600\t  0.161208\t  0.161066\t  0.161143\t\tCURRENT LEARNING RATE: 0.010876539154650082\n",
      "previous_iter_valid_loss : 0.1610144078731537\n",
      "\n",
      "    382800\t  0.161183\t  0.161014\t  0.161142\t\tCURRENT LEARNING RATE: 0.010854807814924285\n",
      "previous_iter_valid_loss : 0.16113711893558502\n",
      "\n",
      "    383000\t  0.161307\t  0.161137\t  0.161141\t\tCURRENT LEARNING RATE: 0.010833119894444226\n",
      "previous_iter_valid_loss : 0.16100424528121948\n",
      "\n",
      "    383200\t  0.161159\t  0.161004\t  0.161141\t\tCURRENT LEARNING RATE: 0.010811475306458183\n",
      "previous_iter_valid_loss : 0.16105428338050842\n",
      "\n",
      "    383400\t  0.161199\t  0.161054\t  0.161139\t\tCURRENT LEARNING RATE: 0.010789873964387787\n",
      "previous_iter_valid_loss : 0.16103439033031464\n",
      "\n",
      "    383600\t  0.161192\t  0.161034\t  0.161139\t\tCURRENT LEARNING RATE: 0.01076831578182763\n",
      "previous_iter_valid_loss : 0.16110889613628387\n",
      "\n",
      "    383800\t  0.161267\t  0.161109\t  0.161138\t\tCURRENT LEARNING RATE: 0.010746800672544961\n",
      "previous_iter_valid_loss : 0.16126415133476257\n",
      "\n",
      "    384000\t  0.161434\t  0.161264\t  0.161139\t\tCURRENT LEARNING RATE: 0.010725328550479307\n",
      "previous_iter_valid_loss : 0.16111895442008972\n",
      "\n",
      "    384200\t  0.161304\t  0.161119\t  0.161139\t\tCURRENT LEARNING RATE: 0.010703899329742162\n",
      "previous_iter_valid_loss : 0.161121666431427\n",
      "\n",
      "    384400\t  0.161292\t  0.161122\t  0.161138\t\tCURRENT LEARNING RATE: 0.010682512924616602\n",
      "previous_iter_valid_loss : 0.16104227304458618\n",
      "\n",
      "    384600\t  0.161220\t  0.161042\t  0.161137\t\tCURRENT LEARNING RATE: 0.01066116924955699\n",
      "previous_iter_valid_loss : 0.16129466891288757\n",
      "\n",
      "    384800\t  0.161460\t  0.161295\t  0.161138\t\tCURRENT LEARNING RATE: 0.010639868219188584\n",
      "previous_iter_valid_loss : 0.16126278042793274\n",
      "\n",
      "    385000\t  0.161420\t  0.161263\t  0.161138\t\tCURRENT LEARNING RATE: 0.010618609748307247\n",
      "previous_iter_valid_loss : 0.16108930110931396\n",
      "\n",
      "    385200\t  0.161249\t  0.161089\t  0.161138\t\tCURRENT LEARNING RATE: 0.010597393751879056\n",
      "previous_iter_valid_loss : 0.16153444349765778\n",
      "\n",
      "    385400\t  0.161764\t  0.161534\t  0.161140\t\tCURRENT LEARNING RATE: 0.010576220145040009\n",
      "previous_iter_valid_loss : 0.1610046625137329\n",
      "\n",
      "    385600\t  0.161153\t  0.161005\t  0.161139\t\tCURRENT LEARNING RATE: 0.010555088843095637\n",
      "previous_iter_valid_loss : 0.16111063957214355\n",
      "\n",
      "    385800\t  0.161278\t  0.161111\t  0.161139\t\tCURRENT LEARNING RATE: 0.010533999761520717\n",
      "previous_iter_valid_loss : 0.16106249392032623\n",
      "\n",
      "    386000\t  0.161240\t  0.161062\t  0.161138\t\tCURRENT LEARNING RATE: 0.010512952815958883\n",
      "previous_iter_valid_loss : 0.1610495150089264\n",
      "\n",
      "    386200\t  0.161207\t  0.161050\t  0.161137\t\tCURRENT LEARNING RATE: 0.010491947922222335\n",
      "previous_iter_valid_loss : 0.16116416454315186\n",
      "\n",
      "    386400\t  0.161299\t  0.161164\t  0.161136\t\tCURRENT LEARNING RATE: 0.01047098499629146\n",
      "previous_iter_valid_loss : 0.16110791265964508\n",
      "\n",
      "    386600\t  0.161247\t  0.161108\t  0.161136\t\tCURRENT LEARNING RATE: 0.010450063954314536\n",
      "previous_iter_valid_loss : 0.16103148460388184\n",
      "\n",
      "    386800\t  0.161180\t  0.161031\t  0.161135\t\tCURRENT LEARNING RATE: 0.010429184712607358\n",
      "previous_iter_valid_loss : 0.16105566918849945\n",
      "\n",
      "    387000\t  0.161186\t  0.161056\t  0.161135\t\tCURRENT LEARNING RATE: 0.010408347187652942\n",
      "previous_iter_valid_loss : 0.16102759540081024\n",
      "\n",
      "    387200\t  0.161167\t  0.161028\t  0.161134\t\tCURRENT LEARNING RATE: 0.010387551296101149\n",
      "previous_iter_valid_loss : 0.1610485017299652\n",
      "\n",
      "    387400\t  0.161214\t  0.161049\t  0.161134\t\tCURRENT LEARNING RATE: 0.010366796954768396\n",
      "previous_iter_valid_loss : 0.16101643443107605\n",
      "\n",
      "    387600\t  0.161178\t  0.161016\t  0.161134\t\tCURRENT LEARNING RATE: 0.010346084080637278\n",
      "previous_iter_valid_loss : 0.16102689504623413\n",
      "\n",
      "    387800\t  0.161178\t  0.161027\t  0.161134\t\tCURRENT LEARNING RATE: 0.010325412590856283\n",
      "previous_iter_valid_loss : 0.1610787957906723\n",
      "\n",
      "    388000\t  0.161227\t  0.161079\t  0.161134\t\tCURRENT LEARNING RATE: 0.010304782402739413\n",
      "previous_iter_valid_loss : 0.16109055280685425\n",
      "\n",
      "    388200\t  0.161269\t  0.161091\t  0.161135\t\tCURRENT LEARNING RATE: 0.0102841934337659\n",
      "previous_iter_valid_loss : 0.16106463968753815\n",
      "\n",
      "    388400\t  0.161215\t  0.161065\t  0.161134\t\tCURRENT LEARNING RATE: 0.01026364560157983\n",
      "previous_iter_valid_loss : 0.1612231284379959\n",
      "\n",
      "    388600\t  0.161380\t  0.161223\t  0.161134\t\tCURRENT LEARNING RATE: 0.010243138823989853\n",
      "previous_iter_valid_loss : 0.16103246808052063\n",
      "\n",
      "    388800\t  0.161201\t  0.161032\t  0.161133\t\tCURRENT LEARNING RATE: 0.010222673018968826\n",
      "previous_iter_valid_loss : 0.16111555695533752\n",
      "\n",
      "    389000\t  0.161288\t  0.161116\t  0.161133\t\tCURRENT LEARNING RATE: 0.01020224810465351\n",
      "previous_iter_valid_loss : 0.16110293567180634\n",
      "\n",
      "    389200\t  0.161254\t  0.161103\t  0.161133\t\tCURRENT LEARNING RATE: 0.010181863999344213\n",
      "previous_iter_valid_loss : 0.1610487699508667\n",
      "\n",
      "    389400\t  0.161203\t  0.161049\t  0.161133\t\tCURRENT LEARNING RATE: 0.010161520621504492\n",
      "previous_iter_valid_loss : 0.1611546128988266\n",
      "\n",
      "    389600\t  0.161330\t  0.161155\t  0.161133\t\tCURRENT LEARNING RATE: 0.0101412178897608\n",
      "previous_iter_valid_loss : 0.16119815409183502\n",
      "\n",
      "    389800\t  0.161345\t  0.161198\t  0.161133\t\tCURRENT LEARNING RATE: 0.010120955722902196\n",
      "previous_iter_valid_loss : 0.1610070914030075\n",
      "\n",
      "    390000\t  0.161146\t  0.161007\t  0.161132\t\tCURRENT LEARNING RATE: 0.010100734039879971\n",
      "previous_iter_valid_loss : 0.16113924980163574\n",
      "\n",
      "    390200\t  0.161307\t  0.161139\t  0.161132\t\tCURRENT LEARNING RATE: 0.01008055275980738\n",
      "previous_iter_valid_loss : 0.16109241545200348\n",
      "\n",
      "    390400\t  0.161249\t  0.161092\t  0.161131\t\tCURRENT LEARNING RATE: 0.010060411801959263\n",
      "previous_iter_valid_loss : 0.16098864376544952\n",
      "\n",
      "    390600\t  0.161138\t  0.160989\t  0.161131\t\tCURRENT LEARNING RATE: 0.010040311085771771\n",
      "previous_iter_valid_loss : 0.16127826273441315\n",
      "\n",
      "    390800\t  0.161446\t  0.161278\t  0.161129\t\tCURRENT LEARNING RATE: 0.010020250530842007\n",
      "previous_iter_valid_loss : 0.16107624769210815\n",
      "\n",
      "    391000\t  0.161231\t  0.161076\t  0.161129\t\tCURRENT LEARNING RATE: 0.01000023005692773\n",
      "previous_iter_valid_loss : 0.16119660437107086\n",
      "\n",
      "    391200\t  0.161347\t  0.161197\t  0.161130\t\tCURRENT LEARNING RATE: 0.00998024958394701\n",
      "previous_iter_valid_loss : 0.1610470414161682\n",
      "\n",
      "    391400\t  0.161188\t  0.161047\t  0.161128\t\tCURRENT LEARNING RATE: 0.009960309031977938\n",
      "previous_iter_valid_loss : 0.16100746393203735\n",
      "\n",
      "    391600\t  0.161138\t  0.161007\t  0.161127\t\tCURRENT LEARNING RATE: 0.00994040832125827\n",
      "previous_iter_valid_loss : 0.16102813184261322\n",
      "\n",
      "    391800\t  0.161165\t  0.161028\t  0.161127\t\tCURRENT LEARNING RATE: 0.009920547372185144\n",
      "previous_iter_valid_loss : 0.16102637350559235\n",
      "\n",
      "    392000\t  0.161180\t  0.161026\t  0.161127\t\tCURRENT LEARNING RATE: 0.009900726105314731\n",
      "previous_iter_valid_loss : 0.16105249524116516\n",
      "\n",
      "    392200\t  0.161213\t  0.161052\t  0.161126\t\tCURRENT LEARNING RATE: 0.009880944441361943\n",
      "previous_iter_valid_loss : 0.16108110547065735\n",
      "\n",
      "    392400\t  0.161222\t  0.161081\t  0.161126\t\tCURRENT LEARNING RATE: 0.009861202301200092\n",
      "previous_iter_valid_loss : 0.16121996939182281\n",
      "\n",
      "    392600\t  0.161363\t  0.161220\t  0.161126\t\tCURRENT LEARNING RATE: 0.009841499605860598\n",
      "previous_iter_valid_loss : 0.1610371619462967\n",
      "\n",
      "    392800\t  0.161199\t  0.161037\t  0.161125\t\tCURRENT LEARNING RATE: 0.009821836276532646\n",
      "previous_iter_valid_loss : 0.1610715240240097\n",
      "\n",
      "    393000\t  0.161219\t  0.161072\t  0.161123\t\tCURRENT LEARNING RATE: 0.0098022122345629\n",
      "previous_iter_valid_loss : 0.1610749214887619\n",
      "\n",
      "    393200\t  0.161240\t  0.161075\t  0.161123\t\tCURRENT LEARNING RATE: 0.009782627401455156\n",
      "previous_iter_valid_loss : 0.16110412776470184\n",
      "\n",
      "    393400\t  0.161256\t  0.161104\t  0.161123\t\tCURRENT LEARNING RATE: 0.009763081698870068\n",
      "previous_iter_valid_loss : 0.16098369657993317\n",
      "\n",
      "    393600\t  0.161138\t  0.160984\t  0.161123\t\tCURRENT LEARNING RATE: 0.009743575048624786\n",
      "previous_iter_valid_loss : 0.16105425357818604\n",
      "\n",
      "    393800\t  0.161208\t  0.161054\t  0.161123\t\tCURRENT LEARNING RATE: 0.009724107372692695\n",
      "previous_iter_valid_loss : 0.16111283004283905\n",
      "\n",
      "    394000\t  0.161299\t  0.161113\t  0.161122\t\tCURRENT LEARNING RATE: 0.009704678593203057\n",
      "previous_iter_valid_loss : 0.1611027717590332\n",
      "\n",
      "    394200\t  0.161252\t  0.161103\t  0.161122\t\tCURRENT LEARNING RATE: 0.009685288632440735\n",
      "previous_iter_valid_loss : 0.16128164529800415\n",
      "\n",
      "    394400\t  0.161462\t  0.161282\t  0.161123\t\tCURRENT LEARNING RATE: 0.009665937412845852\n",
      "previous_iter_valid_loss : 0.16098825633525848\n",
      "\n",
      "    394600\t  0.161145\t  0.160988\t  0.161121\t\tCURRENT LEARNING RATE: 0.009646624857013513\n",
      "previous_iter_valid_loss : 0.16107025742530823\n",
      "\n",
      "    394800\t  0.161231\t  0.161070\t  0.161121\t\tCURRENT LEARNING RATE: 0.00962735088769346\n",
      "previous_iter_valid_loss : 0.16102759540081024\n",
      "\n",
      "    395000\t  0.161194\t  0.161028\t  0.161121\t\tCURRENT LEARNING RATE: 0.009608115427789799\n",
      "previous_iter_valid_loss : 0.16114766895771027\n",
      "\n",
      "    395200\t  0.161305\t  0.161148\t  0.161121\t\tCURRENT LEARNING RATE: 0.009588918400360654\n",
      "previous_iter_valid_loss : 0.16110728681087494\n",
      "\n",
      "    395400\t  0.161261\t  0.161107\t  0.161120\t\tCURRENT LEARNING RATE: 0.009569759728617903\n",
      "previous_iter_valid_loss : 0.16111673414707184\n",
      "\n",
      "    395600\t  0.161272\t  0.161117\t  0.161120\t\tCURRENT LEARNING RATE: 0.009550639335926819\n",
      "previous_iter_valid_loss : 0.16112996637821198\n",
      "\n",
      "    395800\t  0.161307\t  0.161130\t  0.161120\t\tCURRENT LEARNING RATE: 0.009531557145805818\n",
      "previous_iter_valid_loss : 0.1611379235982895\n",
      "\n",
      "    396000\t  0.161304\t  0.161138\t  0.161120\t\tCURRENT LEARNING RATE: 0.009512513081926105\n",
      "previous_iter_valid_loss : 0.1609915792942047\n",
      "\n",
      "    396200\t  0.161145\t  0.160992\t  0.161118\t\tCURRENT LEARNING RATE: 0.009493507068111407\n",
      "previous_iter_valid_loss : 0.16101066768169403\n",
      "\n",
      "    396400\t  0.161177\t  0.161011\t  0.161117\t\tCURRENT LEARNING RATE: 0.009474539028337635\n",
      "previous_iter_valid_loss : 0.16100971400737762\n",
      "\n",
      "    396600\t  0.161171\t  0.161010\t  0.161117\t\tCURRENT LEARNING RATE: 0.009455608886732613\n",
      "previous_iter_valid_loss : 0.161012664437294\n",
      "\n",
      "    396800\t  0.161171\t  0.161013\t  0.161115\t\tCURRENT LEARNING RATE: 0.009436716567575743\n",
      "previous_iter_valid_loss : 0.16108649969100952\n",
      "\n",
      "    397000\t  0.161244\t  0.161086\t  0.161114\t\tCURRENT LEARNING RATE: 0.009417861995297728\n",
      "previous_iter_valid_loss : 0.16103191673755646\n",
      "\n",
      "    397200\t  0.161187\t  0.161032\t  0.161114\t\tCURRENT LEARNING RATE: 0.009399045094480248\n",
      "previous_iter_valid_loss : 0.1611354798078537\n",
      "\n",
      "    397400\t  0.161287\t  0.161135\t  0.161114\t\tCURRENT LEARNING RATE: 0.009380265789855681\n",
      "previous_iter_valid_loss : 0.16105006635189056\n",
      "\n",
      "    397600\t  0.161227\t  0.161050\t  0.161114\t\tCURRENT LEARNING RATE: 0.009361524006306778\n",
      "previous_iter_valid_loss : 0.1611732542514801\n",
      "\n",
      "    397800\t  0.161362\t  0.161173\t  0.161114\t\tCURRENT LEARNING RATE: 0.009342819668866386\n",
      "previous_iter_valid_loss : 0.16122668981552124\n",
      "\n",
      "    398000\t  0.161396\t  0.161227\t  0.161113\t\tCURRENT LEARNING RATE: 0.009324152702717121\n",
      "previous_iter_valid_loss : 0.16104163229465485\n",
      "\n",
      "    398200\t  0.161222\t  0.161042\t  0.161113\t\tCURRENT LEARNING RATE: 0.009305523033191106\n",
      "previous_iter_valid_loss : 0.16128958761692047\n",
      "\n",
      "    398400\t  0.161441\t  0.161290\t  0.161114\t\tCURRENT LEARNING RATE: 0.009286930585769624\n",
      "previous_iter_valid_loss : 0.16118323802947998\n",
      "\n",
      "    398600\t  0.161358\t  0.161183\t  0.161115\t\tCURRENT LEARNING RATE: 0.009268375286082873\n",
      "previous_iter_valid_loss : 0.1610376089811325\n",
      "\n",
      "    398800\t  0.161218\t  0.161038\t  0.161115\t\tCURRENT LEARNING RATE: 0.009249857059909621\n",
      "previous_iter_valid_loss : 0.16113290190696716\n",
      "\n",
      "    399000\t  0.161296\t  0.161133\t  0.161114\t\tCURRENT LEARNING RATE: 0.009231375833176944\n",
      "previous_iter_valid_loss : 0.16124166548252106\n",
      "\n",
      "    399200\t  0.161424\t  0.161242\t  0.161114\t\tCURRENT LEARNING RATE: 0.009212931531959906\n",
      "previous_iter_valid_loss : 0.16108064353466034\n",
      "\n",
      "    399400\t  0.161242\t  0.161081\t  0.161115\t\tCURRENT LEARNING RATE: 0.009194524082481283\n",
      "previous_iter_valid_loss : 0.16111375391483307\n",
      "\n",
      "    399600\t  0.161281\t  0.161114\t  0.161115\t\tCURRENT LEARNING RATE: 0.009176153411111245\n",
      "previous_iter_valid_loss : 0.1611725240945816\n",
      "\n",
      "    399800\t  0.161333\t  0.161173\t  0.161113\t\tCURRENT LEARNING RATE: 0.00915781944436709\n",
      "previous_iter_valid_loss : 0.16106076538562775\n",
      "\n",
      "    400000\t  0.161228\t  0.161061\t  0.161113\t\tCURRENT LEARNING RATE: 0.009139522108912923\n",
      "previous_iter_valid_loss : 0.1610763520002365\n",
      "\n",
      "    400200\t  0.161243\t  0.161076\t  0.161113\t\tCURRENT LEARNING RATE: 0.00912126133155938\n",
      "previous_iter_valid_loss : 0.16105270385742188\n",
      "\n",
      "    400400\t  0.161226\t  0.161053\t  0.161113\t\tCURRENT LEARNING RATE: 0.009103037039263314\n",
      "previous_iter_valid_loss : 0.16109274327754974\n",
      "\n",
      "    400600\t  0.161255\t  0.161093\t  0.161114\t\tCURRENT LEARNING RATE: 0.00908484915912755\n",
      "previous_iter_valid_loss : 0.16102415323257446\n",
      "\n",
      "    400800\t  0.161185\t  0.161024\t  0.161113\t\tCURRENT LEARNING RATE: 0.009066697618400538\n",
      "previous_iter_valid_loss : 0.16108739376068115\n",
      "\n",
      "    401000\t  0.161252\t  0.161087\t  0.161113\t\tCURRENT LEARNING RATE: 0.009048582344476088\n",
      "previous_iter_valid_loss : 0.16109681129455566\n",
      "\n",
      "    401200\t  0.161279\t  0.161097\t  0.161112\t\tCURRENT LEARNING RATE: 0.009030503264893072\n",
      "previous_iter_valid_loss : 0.16120772063732147\n",
      "\n",
      "    401400\t  0.161388\t  0.161208\t  0.161113\t\tCURRENT LEARNING RATE: 0.009012460307335164\n",
      "previous_iter_valid_loss : 0.16108901798725128\n",
      "\n",
      "    401600\t  0.161273\t  0.161089\t  0.161112\t\tCURRENT LEARNING RATE: 0.008994453399630504\n",
      "previous_iter_valid_loss : 0.1612718254327774\n",
      "\n",
      "    401800\t  0.161439\t  0.161272\t  0.161113\t\tCURRENT LEARNING RATE: 0.008976482469751433\n",
      "previous_iter_valid_loss : 0.16104303300380707\n",
      "\n",
      "    402000\t  0.161207\t  0.161043\t  0.161112\t\tCURRENT LEARNING RATE: 0.008958547445814202\n",
      "previous_iter_valid_loss : 0.16104944050312042\n",
      "\n",
      "    402200\t  0.161181\t  0.161049\t  0.161111\t\tCURRENT LEARNING RATE: 0.008940648256078708\n",
      "previous_iter_valid_loss : 0.16111433506011963\n",
      "\n",
      "    402400\t  0.161238\t  0.161114\t  0.161111\t\tCURRENT LEARNING RATE: 0.008922784828948158\n",
      "previous_iter_valid_loss : 0.16105681657791138\n",
      "\n",
      "    402600\t  0.161215\t  0.161057\t  0.161110\t\tCURRENT LEARNING RATE: 0.00890495709296882\n",
      "previous_iter_valid_loss : 0.1610126942396164\n",
      "\n",
      "    402800\t  0.161169\t  0.161013\t  0.161110\t\tCURRENT LEARNING RATE: 0.00888716497682972\n",
      "previous_iter_valid_loss : 0.16114503145217896\n",
      "\n",
      "    403000\t  0.161284\t  0.161145\t  0.161111\t\tCURRENT LEARNING RATE: 0.008869408409362387\n",
      "previous_iter_valid_loss : 0.16109666228294373\n",
      "\n",
      "    403200\t  0.161226\t  0.161097\t  0.161111\t\tCURRENT LEARNING RATE: 0.008851687319540516\n",
      "previous_iter_valid_loss : 0.16108888387680054\n",
      "\n",
      "    403400\t  0.161258\t  0.161089\t  0.161110\t\tCURRENT LEARNING RATE: 0.008834001636479724\n",
      "previous_iter_valid_loss : 0.1610398143529892\n",
      "\n",
      "    403600\t  0.161199\t  0.161040\t  0.161108\t\tCURRENT LEARNING RATE: 0.00881635128943725\n",
      "previous_iter_valid_loss : 0.16119658946990967\n",
      "\n",
      "    403800\t  0.161376\t  0.161197\t  0.161109\t\tCURRENT LEARNING RATE: 0.008798736207811696\n",
      "previous_iter_valid_loss : 0.16102954745292664\n",
      "\n",
      "    404000\t  0.161173\t  0.161030\t  0.161108\t\tCURRENT LEARNING RATE: 0.008781156321142706\n",
      "previous_iter_valid_loss : 0.16112108528614044\n",
      "\n",
      "    404200\t  0.161268\t  0.161121\t  0.161109\t\tCURRENT LEARNING RATE: 0.008763611559110708\n",
      "previous_iter_valid_loss : 0.1609913557767868\n",
      "\n",
      "    404400\t  0.161153\t  0.160991\t  0.161108\t\tCURRENT LEARNING RATE: 0.008746101851536623\n",
      "previous_iter_valid_loss : 0.16102460026741028\n",
      "\n",
      "    404600\t  0.161193\t  0.161025\t  0.161109\t\tCURRENT LEARNING RATE: 0.008728627128381615\n",
      "previous_iter_valid_loss : 0.16107074916362762\n",
      "\n",
      "    404800\t  0.161211\t  0.161071\t  0.161108\t\tCURRENT LEARNING RATE: 0.008711187319746757\n",
      "previous_iter_valid_loss : 0.1610298454761505\n",
      "\n",
      "    405000\t  0.161189\t  0.161030\t  0.161108\t\tCURRENT LEARNING RATE: 0.008693782355872794\n",
      "previous_iter_valid_loss : 0.16110791265964508\n",
      "\n",
      "    405200\t  0.161250\t  0.161108\t  0.161108\t\tCURRENT LEARNING RATE: 0.008676412167139838\n",
      "previous_iter_valid_loss : 0.16100303828716278\n",
      "\n",
      "    405400\t  0.161152\t  0.161003\t  0.161107\t\tCURRENT LEARNING RATE: 0.008659076684067128\n",
      "previous_iter_valid_loss : 0.1610267162322998\n",
      "\n",
      "    405600\t  0.161170\t  0.161027\t  0.161107\t\tCURRENT LEARNING RATE: 0.008641775837312697\n",
      "previous_iter_valid_loss : 0.16100801527500153\n",
      "\n",
      "    405800\t  0.161119\t  0.161008\t  0.161107\t\tCURRENT LEARNING RATE: 0.00862450955767314\n",
      "previous_iter_valid_loss : 0.16099247336387634\n",
      "\n",
      "    406000\t  0.161116\t  0.160992\t  0.161106\t\tCURRENT LEARNING RATE: 0.008607277776083304\n",
      "previous_iter_valid_loss : 0.16105853021144867\n",
      "\n",
      "    406200\t  0.161182\t  0.161059\t  0.161105\t\tCURRENT LEARNING RATE: 0.008590080423616057\n",
      "previous_iter_valid_loss : 0.16108638048171997\n",
      "\n",
      "    406400\t  0.161201\t  0.161086\t  0.161106\t\tCURRENT LEARNING RATE: 0.008572917431481959\n",
      "previous_iter_valid_loss : 0.16109009087085724\n",
      "\n",
      "    406600\t  0.161229\t  0.161090\t  0.161106\t\tCURRENT LEARNING RATE: 0.008555788731029015\n",
      "previous_iter_valid_loss : 0.16100652515888214\n",
      "\n",
      "    406800\t  0.161120\t  0.161007\t  0.161105\t\tCURRENT LEARNING RATE: 0.008538694253742396\n",
      "previous_iter_valid_loss : 0.16106994450092316\n",
      "\n",
      "    407000\t  0.161204\t  0.161070\t  0.161102\t\tCURRENT LEARNING RATE: 0.008521633931244187\n",
      "previous_iter_valid_loss : 0.16109080612659454\n",
      "\n",
      "    407200\t  0.161237\t  0.161091\t  0.161103\t\tCURRENT LEARNING RATE: 0.008504607695293062\n",
      "previous_iter_valid_loss : 0.16105180978775024\n",
      "\n",
      "    407400\t  0.161179\t  0.161052\t  0.161103\t\tCURRENT LEARNING RATE: 0.00848761547778406\n",
      "previous_iter_valid_loss : 0.1610562950372696\n",
      "\n",
      "    407600\t  0.161208\t  0.161056\t  0.161102\t\tCURRENT LEARNING RATE: 0.008470657210748276\n",
      "previous_iter_valid_loss : 0.16108354926109314\n",
      "\n",
      "    407800\t  0.161221\t  0.161084\t  0.161102\t\tCURRENT LEARNING RATE: 0.00845373282635264\n",
      "previous_iter_valid_loss : 0.16100580990314484\n",
      "\n",
      "    408000\t  0.161159\t  0.161006\t  0.161102\t\tCURRENT LEARNING RATE: 0.008436842256899578\n",
      "previous_iter_valid_loss : 0.16118620336055756\n",
      "\n",
      "    408200\t  0.161345\t  0.161186\t  0.161103\t\tCURRENT LEARNING RATE: 0.008419985434826794\n",
      "previous_iter_valid_loss : 0.16109290719032288\n",
      "\n",
      "    408400\t  0.161245\t  0.161093\t  0.161102\t\tCURRENT LEARNING RATE: 0.008403162292706969\n",
      "previous_iter_valid_loss : 0.16116727888584137\n",
      "\n",
      "    408600\t  0.161326\t  0.161167\t  0.161102\t\tCURRENT LEARNING RATE: 0.008386372763247524\n",
      "previous_iter_valid_loss : 0.16105014085769653\n",
      "\n",
      "    408800\t  0.161216\t  0.161050\t  0.161101\t\tCURRENT LEARNING RATE: 0.008369616779290316\n",
      "previous_iter_valid_loss : 0.16102661192417145\n",
      "\n",
      "    409000\t  0.161194\t  0.161027\t  0.161100\t\tCURRENT LEARNING RATE: 0.008352894273811385\n",
      "previous_iter_valid_loss : 0.16102884709835052\n",
      "\n",
      "    409200\t  0.161190\t  0.161029\t  0.161100\t\tCURRENT LEARNING RATE: 0.008336205179920678\n",
      "previous_iter_valid_loss : 0.16101133823394775\n",
      "\n",
      "    409400\t  0.161169\t  0.161011\t  0.161100\t\tCURRENT LEARNING RATE: 0.008319549430861812\n",
      "previous_iter_valid_loss : 0.16101603209972382\n",
      "\n",
      "    409600\t  0.161163\t  0.161016\t  0.161100\t\tCURRENT LEARNING RATE: 0.008302926960011765\n",
      "previous_iter_valid_loss : 0.1610511839389801\n",
      "\n",
      "    409800\t  0.161191\t  0.161051\t  0.161100\t\tCURRENT LEARNING RATE: 0.008286337700880627\n",
      "previous_iter_valid_loss : 0.1610523760318756\n",
      "\n",
      "    410000\t  0.161204\t  0.161052\t  0.161099\t\tCURRENT LEARNING RATE: 0.008269781587111334\n",
      "previous_iter_valid_loss : 0.16124223172664642\n",
      "\n",
      "    410200\t  0.161393\t  0.161242\t  0.161100\t\tCURRENT LEARNING RATE: 0.008253258552479423\n",
      "previous_iter_valid_loss : 0.16102643311023712\n",
      "\n",
      "    410400\t  0.161165\t  0.161026\t  0.161100\t\tCURRENT LEARNING RATE: 0.008236768530892726\n",
      "previous_iter_valid_loss : 0.16107280552387238\n",
      "\n",
      "    410600\t  0.161223\t  0.161073\t  0.161099\t\tCURRENT LEARNING RATE: 0.008220311456391134\n",
      "previous_iter_valid_loss : 0.161103755235672\n",
      "\n",
      "    410800\t  0.161266\t  0.161104\t  0.161100\t\tCURRENT LEARNING RATE: 0.008203887263146322\n",
      "previous_iter_valid_loss : 0.16115714609622955\n",
      "\n",
      "    411000\t  0.161311\t  0.161157\t  0.161100\t\tCURRENT LEARNING RATE: 0.00818749588546151\n",
      "previous_iter_valid_loss : 0.16114819049835205\n",
      "\n",
      "    411200\t  0.161314\t  0.161148\t  0.161100\t\tCURRENT LEARNING RATE: 0.008171137257771154\n",
      "previous_iter_valid_loss : 0.1614372879266739\n",
      "\n",
      "    411400\t  0.161603\t  0.161437\t  0.161102\t\tCURRENT LEARNING RATE: 0.008154811314640725\n",
      "previous_iter_valid_loss : 0.16135728359222412\n",
      "\n",
      "    411600\t  0.161516\t  0.161357\t  0.161102\t\tCURRENT LEARNING RATE: 0.008138517990766418\n",
      "previous_iter_valid_loss : 0.16107448935508728\n",
      "\n",
      "    411800\t  0.161211\t  0.161074\t  0.161102\t\tCURRENT LEARNING RATE: 0.008122257220974935\n",
      "previous_iter_valid_loss : 0.1610046625137329\n",
      "\n",
      "    412000\t  0.161159\t  0.161005\t  0.161102\t\tCURRENT LEARNING RATE: 0.008106028940223166\n",
      "previous_iter_valid_loss : 0.16133995354175568\n",
      "\n",
      "    412200\t  0.161507\t  0.161340\t  0.161103\t\tCURRENT LEARNING RATE: 0.008089833083597965\n",
      "previous_iter_valid_loss : 0.16119517385959625\n",
      "\n",
      "    412400\t  0.161323\t  0.161195\t  0.161104\t\tCURRENT LEARNING RATE: 0.008073669586315878\n",
      "previous_iter_valid_loss : 0.16103355586528778\n",
      "\n",
      "    412600\t  0.161172\t  0.161034\t  0.161104\t\tCURRENT LEARNING RATE: 0.008057538383722907\n",
      "previous_iter_valid_loss : 0.16110225021839142\n",
      "\n",
      "    412800\t  0.161248\t  0.161102\t  0.161104\t\tCURRENT LEARNING RATE: 0.008041439411294217\n",
      "previous_iter_valid_loss : 0.16106750071048737\n",
      "\n",
      "    413000\t  0.161226\t  0.161068\t  0.161104\t\tCURRENT LEARNING RATE: 0.008025372604633893\n",
      "previous_iter_valid_loss : 0.1610260009765625\n",
      "\n",
      "    413200\t  0.161171\t  0.161026\t  0.161104\t\tCURRENT LEARNING RATE: 0.008009337899474679\n",
      "previous_iter_valid_loss : 0.16112515330314636\n",
      "\n",
      "    413400\t  0.161304\t  0.161125\t  0.161103\t\tCURRENT LEARNING RATE: 0.00799333523167775\n",
      "previous_iter_valid_loss : 0.16119609773159027\n",
      "\n",
      "    413600\t  0.161339\t  0.161196\t  0.161102\t\tCURRENT LEARNING RATE: 0.007977364537232407\n",
      "previous_iter_valid_loss : 0.16105856001377106\n",
      "\n",
      "    413800\t  0.161207\t  0.161059\t  0.161101\t\tCURRENT LEARNING RATE: 0.007961425752255849\n",
      "previous_iter_valid_loss : 0.1612020879983902\n",
      "\n",
      "    414000\t  0.161354\t  0.161202\t  0.161102\t\tCURRENT LEARNING RATE: 0.007945518812992908\n",
      "previous_iter_valid_loss : 0.16107790172100067\n",
      "\n",
      "    414200\t  0.161201\t  0.161078\t  0.161102\t\tCURRENT LEARNING RATE: 0.007929643655815818\n",
      "previous_iter_valid_loss : 0.16105028986930847\n",
      "\n",
      "    414400\t  0.161203\t  0.161050\t  0.161101\t\tCURRENT LEARNING RATE: 0.007913800217223927\n",
      "previous_iter_valid_loss : 0.1610628366470337\n",
      "\n",
      "    414600\t  0.161198\t  0.161063\t  0.161101\t\tCURRENT LEARNING RATE: 0.007897988433843456\n",
      "previous_iter_valid_loss : 0.16098418831825256\n",
      "\n",
      "    414800\t  0.161124\t  0.160984\t  0.161101\t\tCURRENT LEARNING RATE: 0.007882208242427243\n",
      "previous_iter_valid_loss : 0.1610584706068039\n",
      "\n",
      "    415000\t  0.161188\t  0.161058\t  0.161101\t\tCURRENT LEARNING RATE: 0.007866459579854516\n",
      "previous_iter_valid_loss : 0.16122068464756012\n",
      "\n",
      "    415200\t  0.161383\t  0.161221\t  0.161102\t\tCURRENT LEARNING RATE: 0.007850742383130598\n",
      "previous_iter_valid_loss : 0.16108287870883942\n",
      "\n",
      "    415400\t  0.161238\t  0.161083\t  0.161102\t\tCURRENT LEARNING RATE: 0.00783505658938668\n",
      "previous_iter_valid_loss : 0.16120219230651855\n",
      "\n",
      "    415600\t  0.161367\t  0.161202\t  0.161103\t\tCURRENT LEARNING RATE: 0.007819402135879559\n",
      "previous_iter_valid_loss : 0.16116857528686523\n",
      "\n",
      "    415800\t  0.161334\t  0.161169\t  0.161103\t\tCURRENT LEARNING RATE: 0.007803778959991415\n",
      "previous_iter_valid_loss : 0.16104018688201904\n",
      "\n",
      "    416000\t  0.161191\t  0.161040\t  0.161103\t\tCURRENT LEARNING RATE: 0.007788186999229516\n",
      "previous_iter_valid_loss : 0.16102418303489685\n",
      "\n",
      "    416200\t  0.161167\t  0.161024\t  0.161103\t\tCURRENT LEARNING RATE: 0.007772626191225998\n",
      "previous_iter_valid_loss : 0.16100037097930908\n",
      "\n",
      "    416400\t  0.161152\t  0.161000\t  0.161102\t\tCURRENT LEARNING RATE: 0.007757096473737601\n",
      "previous_iter_valid_loss : 0.16101545095443726\n",
      "\n",
      "    416600\t  0.161171\t  0.161015\t  0.161101\t\tCURRENT LEARNING RATE: 0.0077415977846454495\n",
      "previous_iter_valid_loss : 0.16104353964328766\n",
      "\n",
      "    416800\t  0.161207\t  0.161044\t  0.161101\t\tCURRENT LEARNING RATE: 0.007726130061954758\n",
      "previous_iter_valid_loss : 0.16106602549552917\n",
      "\n",
      "    417000\t  0.161235\t  0.161066\t  0.161099\t\tCURRENT LEARNING RATE: 0.007710693243794616\n",
      "previous_iter_valid_loss : 0.16121144592761993\n",
      "\n",
      "    417200\t  0.161385\t  0.161211\t  0.161100\t\tCURRENT LEARNING RATE: 0.007695287268417723\n",
      "previous_iter_valid_loss : 0.16105015575885773\n",
      "\n",
      "    417400\t  0.161184\t  0.161050\t  0.161100\t\tCURRENT LEARNING RATE: 0.007679912074200172\n",
      "previous_iter_valid_loss : 0.16106657683849335\n",
      "\n",
      "    417600\t  0.161227\t  0.161067\t  0.161100\t\tCURRENT LEARNING RATE: 0.007664567599641157\n",
      "previous_iter_valid_loss : 0.1610473245382309\n",
      "\n",
      "    417800\t  0.161196\t  0.161047\t  0.161099\t\tCURRENT LEARNING RATE: 0.007649253783362759\n",
      "previous_iter_valid_loss : 0.16101565957069397\n",
      "\n",
      "    418000\t  0.161148\t  0.161016\t  0.161097\t\tCURRENT LEARNING RATE: 0.007633970564109688\n",
      "previous_iter_valid_loss : 0.16100534796714783\n",
      "\n",
      "    418200\t  0.161135\t  0.161005\t  0.161097\t\tCURRENT LEARNING RATE: 0.007618717880749058\n",
      "previous_iter_valid_loss : 0.16109897196292877\n",
      "\n",
      "    418400\t  0.161232\t  0.161099\t  0.161097\t\tCURRENT LEARNING RATE: 0.007603495672270109\n",
      "previous_iter_valid_loss : 0.1610075682401657\n",
      "\n",
      "    418600\t  0.161143\t  0.161008\t  0.161096\t\tCURRENT LEARNING RATE: 0.007588303877783989\n",
      "previous_iter_valid_loss : 0.16099302470684052\n",
      "\n",
      "    418800\t  0.161131\t  0.160993\t  0.161095\t\tCURRENT LEARNING RATE: 0.00757314243652349\n",
      "previous_iter_valid_loss : 0.1610698699951172\n",
      "\n",
      "    419000\t  0.161224\t  0.161070\t  0.161095\t\tCURRENT LEARNING RATE: 0.007558011287842841\n",
      "previous_iter_valid_loss : 0.16113319993019104\n",
      "\n",
      "    419200\t  0.161290\t  0.161133\t  0.161095\t\tCURRENT LEARNING RATE: 0.00754291037121742\n",
      "previous_iter_valid_loss : 0.16103237867355347\n",
      "\n",
      "    419400\t  0.161168\t  0.161032\t  0.161095\t\tCURRENT LEARNING RATE: 0.007527839626243543\n",
      "previous_iter_valid_loss : 0.16109104454517365\n",
      "\n",
      "    419600\t  0.161238\t  0.161091\t  0.161094\t\tCURRENT LEARNING RATE: 0.0075127989926382\n",
      "previous_iter_valid_loss : 0.16113579273223877\n",
      "\n",
      "    419800\t  0.161279\t  0.161136\t  0.161094\t\tCURRENT LEARNING RATE: 0.007497788410238852\n",
      "previous_iter_valid_loss : 0.16108185052871704\n",
      "\n",
      "    420000\t  0.161220\t  0.161082\t  0.161093\t\tCURRENT LEARNING RATE: 0.0074828078190031415\n",
      "previous_iter_valid_loss : 0.16111980378627777\n",
      "\n",
      "    420200\t  0.161244\t  0.161120\t  0.161093\t\tCURRENT LEARNING RATE: 0.007467857159008684\n",
      "previous_iter_valid_loss : 0.1610986888408661\n",
      "\n",
      "    420400\t  0.161233\t  0.161099\t  0.161093\t\tCURRENT LEARNING RATE: 0.007452936370452814\n",
      "previous_iter_valid_loss : 0.16099391877651215\n",
      "\n",
      "    420600\t  0.161112\t  0.160994\t  0.161093\t\tCURRENT LEARNING RATE: 0.007438045393652368\n",
      "previous_iter_valid_loss : 0.1611427515745163\n",
      "\n",
      "    420800\t  0.161303\t  0.161143\t  0.161093\t\tCURRENT LEARNING RATE: 0.007423184169043416\n",
      "previous_iter_valid_loss : 0.1611204892396927\n",
      "\n",
      "    421000\t  0.161234\t  0.161120\t  0.161094\t\tCURRENT LEARNING RATE: 0.007408352637181036\n",
      "previous_iter_valid_loss : 0.16098611056804657\n",
      "\n",
      "    421200\t  0.161108\t  0.160986\t  0.161093\t\tCURRENT LEARNING RATE: 0.007393550738739077\n",
      "previous_iter_valid_loss : 0.1609933078289032\n",
      "\n",
      "    421400\t  0.161127\t  0.160993\t  0.161092\t\tCURRENT LEARNING RATE: 0.0073787784145099376\n",
      "previous_iter_valid_loss : 0.16098472476005554\n",
      "\n",
      "    421600\t  0.161112\t  0.160985\t  0.161092\t\tCURRENT LEARNING RATE: 0.007364035605404294\n",
      "previous_iter_valid_loss : 0.1610173135995865\n",
      "\n",
      "    421800\t  0.161169\t  0.161017\t  0.161091\t\tCURRENT LEARNING RATE: 0.007349322252450892\n",
      "previous_iter_valid_loss : 0.16119511425495148\n",
      "\n",
      "    422000\t  0.161363\t  0.161195\t  0.161091\t\tCURRENT LEARNING RATE: 0.007334638296796291\n",
      "previous_iter_valid_loss : 0.16109216213226318\n",
      "\n",
      "    422200\t  0.161243\t  0.161092\t  0.161092\t\tCURRENT LEARNING RATE: 0.007319983679704664\n",
      "previous_iter_valid_loss : 0.16097813844680786\n",
      "\n",
      "    422400\t  0.161128\t  0.160978\t  0.161091\t\tCURRENT LEARNING RATE: 0.007305358342557515\n",
      "previous_iter_valid_loss : 0.1609916388988495\n",
      "\n",
      "    422600\t  0.161128\t  0.160992\t  0.161091\t\tCURRENT LEARNING RATE: 0.007290762226853477\n",
      "previous_iter_valid_loss : 0.1610642373561859\n",
      "\n",
      "    422800\t  0.161202\t  0.161064\t  0.161091\t\tCURRENT LEARNING RATE: 0.007276195274208062\n",
      "previous_iter_valid_loss : 0.1610621213912964\n",
      "\n",
      "    423000\t  0.161197\t  0.161062\t  0.161091\t\tCURRENT LEARNING RATE: 0.00726165742635345\n",
      "previous_iter_valid_loss : 0.16110165417194366\n",
      "\n",
      "    423200\t  0.161237\t  0.161102\t  0.161091\t\tCURRENT LEARNING RATE: 0.007247148625138227\n",
      "previous_iter_valid_loss : 0.1610102504491806\n",
      "\n",
      "    423400\t  0.161144\t  0.161010\t  0.161091\t\tCURRENT LEARNING RATE: 0.007232668812527167\n",
      "previous_iter_valid_loss : 0.16102559864521027\n",
      "\n",
      "    423600\t  0.161138\t  0.161026\t  0.161091\t\tCURRENT LEARNING RATE: 0.0072182179306009946\n",
      "previous_iter_valid_loss : 0.1610117256641388\n",
      "\n",
      "    423800\t  0.161163\t  0.161012\t  0.161091\t\tCURRENT LEARNING RATE: 0.007203795921556175\n",
      "previous_iter_valid_loss : 0.16105206310749054\n",
      "\n",
      "    424000\t  0.161189\t  0.161052\t  0.161089\t\tCURRENT LEARNING RATE: 0.007189402727704647\n",
      "previous_iter_valid_loss : 0.1610409915447235\n",
      "\n",
      "    424200\t  0.161168\t  0.161041\t  0.161089\t\tCURRENT LEARNING RATE: 0.007175038291473615\n",
      "previous_iter_valid_loss : 0.16109544038772583\n",
      "\n",
      "    424400\t  0.161228\t  0.161095\t  0.161089\t\tCURRENT LEARNING RATE: 0.00716070255540531\n",
      "previous_iter_valid_loss : 0.16108325123786926\n",
      "\n",
      "    424600\t  0.161223\t  0.161083\t  0.161089\t\tCURRENT LEARNING RATE: 0.0071463954621567806\n",
      "previous_iter_valid_loss : 0.16106784343719482\n",
      "\n",
      "    424800\t  0.161226\t  0.161068\t  0.161088\t\tCURRENT LEARNING RATE: 0.007132116954499628\n",
      "previous_iter_valid_loss : 0.16104969382286072\n",
      "\n",
      "    425000\t  0.161202\t  0.161050\t  0.161087\t\tCURRENT LEARNING RATE: 0.007117866975319803\n",
      "previous_iter_valid_loss : 0.16112542152404785\n",
      "\n",
      "    425200\t  0.161280\t  0.161125\t  0.161087\t\tCURRENT LEARNING RATE: 0.007103645467617369\n",
      "previous_iter_valid_loss : 0.161014586687088\n",
      "\n",
      "    425400\t  0.161167\t  0.161015\t  0.161085\t\tCURRENT LEARNING RATE: 0.007089452374506272\n",
      "previous_iter_valid_loss : 0.16107572615146637\n",
      "\n",
      "    425600\t  0.161234\t  0.161076\t  0.161085\t\tCURRENT LEARNING RATE: 0.007075287639214131\n",
      "previous_iter_valid_loss : 0.16106216609477997\n",
      "\n",
      "    425800\t  0.161201\t  0.161062\t  0.161085\t\tCURRENT LEARNING RATE: 0.007061151205081981\n",
      "previous_iter_valid_loss : 0.16106672585010529\n",
      "\n",
      "    426000\t  0.161213\t  0.161067\t  0.161085\t\tCURRENT LEARNING RATE: 0.007047043015564066\n",
      "previous_iter_valid_loss : 0.16107094287872314\n",
      "\n",
      "    426200\t  0.161201\t  0.161071\t  0.161085\t\tCURRENT LEARNING RATE: 0.007032963014227603\n",
      "previous_iter_valid_loss : 0.16109386086463928\n",
      "\n",
      "    426400\t  0.161220\t  0.161094\t  0.161084\t\tCURRENT LEARNING RATE: 0.007018911144752581\n",
      "previous_iter_valid_loss : 0.16105400025844574\n",
      "\n",
      "    426600\t  0.161200\t  0.161054\t  0.161084\t\tCURRENT LEARNING RATE: 0.007004887350931495\n",
      "previous_iter_valid_loss : 0.1610582321882248\n",
      "\n",
      "    426800\t  0.161212\t  0.161058\t  0.161084\t\tCURRENT LEARNING RATE: 0.006990891576669154\n",
      "previous_iter_valid_loss : 0.16121543943881989\n",
      "\n",
      "    427000\t  0.161350\t  0.161215\t  0.161085\t\tCURRENT LEARNING RATE: 0.006976923765982434\n",
      "previous_iter_valid_loss : 0.1610661894083023\n",
      "\n",
      "    427200\t  0.161198\t  0.161066\t  0.161085\t\tCURRENT LEARNING RATE: 0.006962983863000087\n",
      "previous_iter_valid_loss : 0.1609925627708435\n",
      "\n",
      "    427400\t  0.161125\t  0.160993\t  0.161085\t\tCURRENT LEARNING RATE: 0.006949071811962477\n",
      "previous_iter_valid_loss : 0.16102002561092377\n",
      "\n",
      "    427600\t  0.161163\t  0.161020\t  0.161085\t\tCURRENT LEARNING RATE: 0.006935187557221379\n",
      "previous_iter_valid_loss : 0.1610693484544754\n",
      "\n",
      "    427800\t  0.161215\t  0.161069\t  0.161085\t\tCURRENT LEARNING RATE: 0.0069213310432397505\n",
      "previous_iter_valid_loss : 0.16103814542293549\n",
      "\n",
      "    428000\t  0.161197\t  0.161038\t  0.161085\t\tCURRENT LEARNING RATE: 0.00690750221459153\n",
      "previous_iter_valid_loss : 0.1610899418592453\n",
      "\n",
      "    428200\t  0.161243\t  0.161090\t  0.161085\t\tCURRENT LEARNING RATE: 0.006893701015961378\n",
      "previous_iter_valid_loss : 0.16097614169120789\n",
      "\n",
      "\n",
      "Current valid loss: 0.16097614169120789;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "    428400\t  0.161107\t  0.160976\t  0.161085\t\tCURRENT LEARNING RATE: 0.006879927392144481\n",
      "previous_iter_valid_loss : 0.16117367148399353\n",
      "\n",
      "    428600\t  0.161334\t  0.161174\t  0.161084\t\tCURRENT LEARNING RATE: 0.00686618128804632\n",
      "previous_iter_valid_loss : 0.16106772422790527\n",
      "\n",
      "    428800\t  0.161179\t  0.161068\t  0.161085\t\tCURRENT LEARNING RATE: 0.0068524626486824725\n",
      "previous_iter_valid_loss : 0.16100648045539856\n",
      "\n",
      "    429000\t  0.161151\t  0.161006\t  0.161084\t\tCURRENT LEARNING RATE: 0.006838771419178356\n",
      "previous_iter_valid_loss : 0.1610972285270691\n",
      "\n",
      "    429200\t  0.161225\t  0.161097\t  0.161084\t\tCURRENT LEARNING RATE: 0.006825107544769035\n",
      "previous_iter_valid_loss : 0.16129140555858612\n",
      "\n",
      "    429400\t  0.161437\t  0.161291\t  0.161085\t\tCURRENT LEARNING RATE: 0.006811470970798986\n",
      "previous_iter_valid_loss : 0.16105087101459503\n",
      "\n",
      "    429600\t  0.161193\t  0.161051\t  0.161085\t\tCURRENT LEARNING RATE: 0.006797861642721909\n",
      "previous_iter_valid_loss : 0.16105394065380096\n",
      "\n",
      "    429800\t  0.161209\t  0.161054\t  0.161084\t\tCURRENT LEARNING RATE: 0.006784279506100467\n",
      "previous_iter_valid_loss : 0.16110803186893463\n",
      "\n",
      "    430000\t  0.161264\t  0.161108\t  0.161084\t\tCURRENT LEARNING RATE: 0.006770724506606095\n",
      "previous_iter_valid_loss : 0.16101109981536865\n",
      "\n",
      "    430200\t  0.161153\t  0.161011\t  0.161084\t\tCURRENT LEARNING RATE: 0.006757196590018771\n",
      "previous_iter_valid_loss : 0.16098225116729736\n",
      "\n",
      "    430400\t  0.161121\t  0.160982\t  0.161083\t\tCURRENT LEARNING RATE: 0.006743695702226822\n",
      "previous_iter_valid_loss : 0.16118375957012177\n",
      "\n",
      "    430600\t  0.161320\t  0.161184\t  0.161084\t\tCURRENT LEARNING RATE: 0.006730221789226674\n",
      "previous_iter_valid_loss : 0.16103330254554749\n",
      "\n",
      "    430800\t  0.161163\t  0.161033\t  0.161083\t\tCURRENT LEARNING RATE: 0.006716774797122657\n",
      "previous_iter_valid_loss : 0.1610403209924698\n",
      "\n",
      "    431000\t  0.161186\t  0.161040\t  0.161083\t\tCURRENT LEARNING RATE: 0.006703354672126778\n",
      "previous_iter_valid_loss : 0.16098140180110931\n",
      "\n",
      "    431200\t  0.161121\t  0.160981\t  0.161082\t\tCURRENT LEARNING RATE: 0.00668996136055853\n",
      "previous_iter_valid_loss : 0.16109049320220947\n",
      "\n",
      "    431400\t  0.161236\t  0.161090\t  0.161082\t\tCURRENT LEARNING RATE: 0.006676594808844646\n",
      "previous_iter_valid_loss : 0.16104242205619812\n",
      "\n",
      "    431600\t  0.161195\t  0.161042\t  0.161082\t\tCURRENT LEARNING RATE: 0.006663254963518899\n",
      "previous_iter_valid_loss : 0.161018967628479\n",
      "\n",
      "    431800\t  0.161153\t  0.161019\t  0.161082\t\tCURRENT LEARNING RATE: 0.006649941771221884\n",
      "previous_iter_valid_loss : 0.16099728643894196\n",
      "\n",
      "    432000\t  0.161126\t  0.160997\t  0.161082\t\tCURRENT LEARNING RATE: 0.006636655178700827\n",
      "previous_iter_valid_loss : 0.16098652780056\n",
      "\n",
      "    432200\t  0.161132\t  0.160987\t  0.161082\t\tCURRENT LEARNING RATE: 0.006623395132809333\n",
      "previous_iter_valid_loss : 0.16110292077064514\n",
      "\n",
      "    432400\t  0.161249\t  0.161103\t  0.161082\t\tCURRENT LEARNING RATE: 0.006610161580507201\n",
      "previous_iter_valid_loss : 0.16100388765335083\n",
      "\n",
      "    432600\t  0.161136\t  0.161004\t  0.161081\t\tCURRENT LEARNING RATE: 0.0065969544688602\n",
      "previous_iter_valid_loss : 0.1611126810312271\n",
      "\n",
      "    432800\t  0.161270\t  0.161113\t  0.161081\t\tCURRENT LEARNING RATE: 0.0065837737450398755\n",
      "previous_iter_valid_loss : 0.16105037927627563\n",
      "\n",
      "    433000\t  0.161224\t  0.161050\t  0.161081\t\tCURRENT LEARNING RATE: 0.00657061935632331\n",
      "previous_iter_valid_loss : 0.16105026006698608\n",
      "\n",
      "    433200\t  0.161222\t  0.161050\t  0.161081\t\tCURRENT LEARNING RATE: 0.00655749125009293\n",
      "previous_iter_valid_loss : 0.16100771725177765\n",
      "\n",
      "    433400\t  0.161173\t  0.161008\t  0.161080\t\tCURRENT LEARNING RATE: 0.006544389373836289\n",
      "previous_iter_valid_loss : 0.16102340817451477\n",
      "\n",
      "    433600\t  0.161189\t  0.161023\t  0.161080\t\tCURRENT LEARNING RATE: 0.006531313675145874\n",
      "previous_iter_valid_loss : 0.16106639802455902\n",
      "\n",
      "    433800\t  0.161222\t  0.161066\t  0.161081\t\tCURRENT LEARNING RATE: 0.006518264101718868\n",
      "previous_iter_valid_loss : 0.16105365753173828\n",
      "\n",
      "    434000\t  0.161224\t  0.161054\t  0.161080\t\tCURRENT LEARNING RATE: 0.00650524060135696\n",
      "previous_iter_valid_loss : 0.16104446351528168\n",
      "\n",
      "    434200\t  0.161191\t  0.161044\t  0.161080\t\tCURRENT LEARNING RATE: 0.0064922431219661255\n",
      "previous_iter_valid_loss : 0.16116736829280853\n",
      "\n",
      "    434400\t  0.161327\t  0.161167\t  0.161079\t\tCURRENT LEARNING RATE: 0.006479271611556441\n",
      "previous_iter_valid_loss : 0.1610625833272934\n",
      "\n",
      "    434600\t  0.161213\t  0.161063\t  0.161080\t\tCURRENT LEARNING RATE: 0.006466326018241842\n",
      "previous_iter_valid_loss : 0.16109444200992584\n",
      "\n",
      "    434800\t  0.161239\t  0.161094\t  0.161080\t\tCURRENT LEARNING RATE: 0.006453406290239936\n",
      "previous_iter_valid_loss : 0.16099713742733002\n",
      "\n",
      "    435000\t  0.161150\t  0.160997\t  0.161080\t\tCURRENT LEARNING RATE: 0.006440512375871792\n",
      "previous_iter_valid_loss : 0.16103671491146088\n",
      "\n",
      "    435200\t  0.161186\t  0.161037\t  0.161079\t\tCURRENT LEARNING RATE: 0.0064276442235617435\n",
      "previous_iter_valid_loss : 0.16099928319454193\n",
      "\n",
      "    435400\t  0.161129\t  0.160999\t  0.161079\t\tCURRENT LEARNING RATE: 0.00641480178183716\n",
      "previous_iter_valid_loss : 0.1610746681690216\n",
      "\n",
      "    435600\t  0.161214\t  0.161075\t  0.161078\t\tCURRENT LEARNING RATE: 0.006401984999328256\n",
      "previous_iter_valid_loss : 0.161030113697052\n",
      "\n",
      "    435800\t  0.161184\t  0.161030\t  0.161078\t\tCURRENT LEARNING RATE: 0.00638919382476788\n",
      "previous_iter_valid_loss : 0.1610548198223114\n",
      "\n",
      "    436000\t  0.161210\t  0.161055\t  0.161077\t\tCURRENT LEARNING RATE: 0.0063764282069913285\n",
      "previous_iter_valid_loss : 0.1610286831855774\n",
      "\n",
      "    436200\t  0.161176\t  0.161029\t  0.161078\t\tCURRENT LEARNING RATE: 0.006363688094936106\n",
      "previous_iter_valid_loss : 0.16107259690761566\n",
      "\n",
      "    436400\t  0.161231\t  0.161073\t  0.161078\t\tCURRENT LEARNING RATE: 0.006350973437641749\n",
      "previous_iter_valid_loss : 0.16106215119361877\n",
      "\n",
      "    436600\t  0.161199\t  0.161062\t  0.161078\t\tCURRENT LEARNING RATE: 0.006338284184249604\n",
      "previous_iter_valid_loss : 0.16099900007247925\n",
      "\n",
      "    436800\t  0.161146\t  0.160999\t  0.161078\t\tCURRENT LEARNING RATE: 0.006325620284002653\n",
      "previous_iter_valid_loss : 0.16100338101387024\n",
      "\n",
      "    437000\t  0.161156\t  0.161003\t  0.161078\t\tCURRENT LEARNING RATE: 0.006312981686245272\n",
      "previous_iter_valid_loss : 0.16103632748126984\n",
      "\n",
      "    437200\t  0.161201\t  0.161036\t  0.161078\t\tCURRENT LEARNING RATE: 0.006300368340423053\n",
      "previous_iter_valid_loss : 0.16102658212184906\n",
      "\n",
      "    437400\t  0.161175\t  0.161027\t  0.161077\t\tCURRENT LEARNING RATE: 0.006287780196082591\n",
      "previous_iter_valid_loss : 0.16105753183364868\n",
      "\n",
      "    437600\t  0.161225\t  0.161058\t  0.161077\t\tCURRENT LEARNING RATE: 0.006275217202871303\n",
      "previous_iter_valid_loss : 0.16103175282478333\n",
      "\n",
      "    437800\t  0.161177\t  0.161032\t  0.161077\t\tCURRENT LEARNING RATE: 0.0062626793105371925\n",
      "previous_iter_valid_loss : 0.16114945709705353\n",
      "\n",
      "    438000\t  0.161301\t  0.161149\t  0.161076\t\tCURRENT LEARNING RATE: 0.006250166468928675\n",
      "previous_iter_valid_loss : 0.16110269725322723\n",
      "\n",
      "    438200\t  0.161273\t  0.161103\t  0.161076\t\tCURRENT LEARNING RATE: 0.006237678627994361\n",
      "previous_iter_valid_loss : 0.16104499995708466\n",
      "\n",
      "    438400\t  0.161198\t  0.161045\t  0.161075\t\tCURRENT LEARNING RATE: 0.006225215737782882\n",
      "previous_iter_valid_loss : 0.16102632880210876\n",
      "\n",
      "    438600\t  0.161181\t  0.161026\t  0.161074\t\tCURRENT LEARNING RATE: 0.006212777748442654\n",
      "previous_iter_valid_loss : 0.16103696823120117\n",
      "\n",
      "    438800\t  0.161183\t  0.161037\t  0.161074\t\tCURRENT LEARNING RATE: 0.006200364610221703\n",
      "previous_iter_valid_loss : 0.1610880196094513\n",
      "\n",
      "    439000\t  0.161248\t  0.161088\t  0.161074\t\tCURRENT LEARNING RATE: 0.006187976273467456\n",
      "previous_iter_valid_loss : 0.16107873618602753\n",
      "\n",
      "    439200\t  0.161234\t  0.161079\t  0.161073\t\tCURRENT LEARNING RATE: 0.006175612688626557\n",
      "previous_iter_valid_loss : 0.1610735058784485\n",
      "\n",
      "    439400\t  0.161212\t  0.161074\t  0.161073\t\tCURRENT LEARNING RATE: 0.006163273806244648\n",
      "previous_iter_valid_loss : 0.1610301285982132\n",
      "\n",
      "    439600\t  0.161177\t  0.161030\t  0.161073\t\tCURRENT LEARNING RATE: 0.0061509595769661815\n",
      "previous_iter_valid_loss : 0.16100965440273285\n",
      "\n",
      "    439800\t  0.161153\t  0.161010\t  0.161072\t\tCURRENT LEARNING RATE: 0.006138669951534218\n",
      "previous_iter_valid_loss : 0.16105882823467255\n",
      "\n",
      "    440000\t  0.161214\t  0.161059\t  0.161072\t\tCURRENT LEARNING RATE: 0.006126404880790252\n",
      "previous_iter_valid_loss : 0.16106781363487244\n",
      "\n",
      "    440200\t  0.161230\t  0.161068\t  0.161072\t\tCURRENT LEARNING RATE: 0.0061141643156739775\n",
      "previous_iter_valid_loss : 0.1611582487821579\n",
      "\n",
      "    440400\t  0.161277\t  0.161158\t  0.161073\t\tCURRENT LEARNING RATE: 0.006101948207223117\n",
      "previous_iter_valid_loss : 0.1610272228717804\n",
      "\n",
      "    440600\t  0.161168\t  0.161027\t  0.161072\t\tCURRENT LEARNING RATE: 0.0060897565065732165\n",
      "previous_iter_valid_loss : 0.16102759540081024\n",
      "\n",
      "    440800\t  0.161168\t  0.161028\t  0.161072\t\tCURRENT LEARNING RATE: 0.006077589164957467\n",
      "previous_iter_valid_loss : 0.1610868275165558\n",
      "\n",
      "    441000\t  0.161245\t  0.161087\t  0.161072\t\tCURRENT LEARNING RATE: 0.006065446133706482\n",
      "previous_iter_valid_loss : 0.16105912625789642\n",
      "\n",
      "    441200\t  0.161203\t  0.161059\t  0.161072\t\tCURRENT LEARNING RATE: 0.0060533273642481185\n",
      "previous_iter_valid_loss : 0.16104145348072052\n",
      "\n",
      "    441400\t  0.161189\t  0.161041\t  0.161071\t\tCURRENT LEARNING RATE: 0.006041232808107277\n",
      "previous_iter_valid_loss : 0.1610632687807083\n",
      "\n",
      "    441600\t  0.161202\t  0.161063\t  0.161071\t\tCURRENT LEARNING RATE: 0.006029162416905729\n",
      "previous_iter_valid_loss : 0.16110558807849884\n",
      "\n",
      "    441800\t  0.161265\t  0.161106\t  0.161070\t\tCURRENT LEARNING RATE: 0.006017116142361887\n",
      "previous_iter_valid_loss : 0.16104093194007874\n",
      "\n",
      "    442000\t  0.161183\t  0.161041\t  0.161070\t\tCURRENT LEARNING RATE: 0.0060050939362906374\n",
      "previous_iter_valid_loss : 0.16101288795471191\n",
      "\n",
      "    442200\t  0.161159\t  0.161013\t  0.161070\t\tCURRENT LEARNING RATE: 0.005993095750603135\n",
      "previous_iter_valid_loss : 0.1610318273305893\n",
      "\n",
      "    442400\t  0.161171\t  0.161032\t  0.161070\t\tCURRENT LEARNING RATE: 0.0059811215373066304\n",
      "previous_iter_valid_loss : 0.16133899986743927\n",
      "\n",
      "    442600\t  0.161490\t  0.161339\t  0.161071\t\tCURRENT LEARNING RATE: 0.005969171248504251\n",
      "previous_iter_valid_loss : 0.1610683798789978\n",
      "\n",
      "    442800\t  0.161198\t  0.161068\t  0.161071\t\tCURRENT LEARNING RATE: 0.005957244836394824\n",
      "previous_iter_valid_loss : 0.16112020611763\n",
      "\n",
      "    443000\t  0.161249\t  0.161120\t  0.161071\t\tCURRENT LEARNING RATE: 0.005945342253272679\n",
      "previous_iter_valid_loss : 0.16100890934467316\n",
      "\n",
      "    443200\t  0.161132\t  0.161009\t  0.161071\t\tCURRENT LEARNING RATE: 0.00593346345152748\n",
      "previous_iter_valid_loss : 0.16111968457698822\n",
      "\n",
      "    443400\t  0.161266\t  0.161120\t  0.161071\t\tCURRENT LEARNING RATE: 0.0059216083836439995\n",
      "previous_iter_valid_loss : 0.1610555350780487\n",
      "\n",
      "    443600\t  0.161202\t  0.161056\t  0.161071\t\tCURRENT LEARNING RATE: 0.005909777002201948\n",
      "previous_iter_valid_loss : 0.16101941466331482\n",
      "\n",
      "    443800\t  0.161170\t  0.161019\t  0.161070\t\tCURRENT LEARNING RATE: 0.005897969259875781\n",
      "previous_iter_valid_loss : 0.16111020743846893\n",
      "\n",
      "    444000\t  0.161265\t  0.161110\t  0.161071\t\tCURRENT LEARNING RATE: 0.005886185109434522\n",
      "previous_iter_valid_loss : 0.160994753241539\n",
      "\n",
      "    444200\t  0.161134\t  0.160995\t  0.161070\t\tCURRENT LEARNING RATE: 0.005874424503741548\n",
      "previous_iter_valid_loss : 0.1609981507062912\n",
      "\n",
      "    444400\t  0.161154\t  0.160998\t  0.161070\t\tCURRENT LEARNING RATE: 0.005862687395754422\n",
      "previous_iter_valid_loss : 0.1610662192106247\n",
      "\n",
      "    444600\t  0.161216\t  0.161066\t  0.161070\t\tCURRENT LEARNING RATE: 0.005850973738524692\n",
      "previous_iter_valid_loss : 0.16099023818969727\n",
      "\n",
      "    444800\t  0.161134\t  0.160990\t  0.161070\t\tCURRENT LEARNING RATE: 0.005839283485197721\n",
      "previous_iter_valid_loss : 0.16101031005382538\n",
      "\n",
      "    445000\t  0.161150\t  0.161010\t  0.161070\t\tCURRENT LEARNING RATE: 0.0058276165890124776\n",
      "previous_iter_valid_loss : 0.16098424792289734\n",
      "\n",
      "    445200\t  0.161130\t  0.160984\t  0.161069\t\tCURRENT LEARNING RATE: 0.00581597300330136\n",
      "previous_iter_valid_loss : 0.16107800602912903\n",
      "\n",
      "    445400\t  0.161216\t  0.161078\t  0.161069\t\tCURRENT LEARNING RATE: 0.0058043526814900055\n",
      "previous_iter_valid_loss : 0.16099970042705536\n",
      "\n",
      "    445600\t  0.161146\t  0.161000\t  0.161069\t\tCURRENT LEARNING RATE: 0.005792755577097121\n",
      "previous_iter_valid_loss : 0.16103221476078033\n",
      "\n",
      "    445800\t  0.161203\t  0.161032\t  0.161069\t\tCURRENT LEARNING RATE: 0.005781181643734268\n",
      "previous_iter_valid_loss : 0.16097994148731232\n",
      "\n",
      "    446000\t  0.161112\t  0.160980\t  0.161069\t\tCURRENT LEARNING RATE: 0.0057696308351056986\n",
      "previous_iter_valid_loss : 0.16120855510234833\n",
      "\n",
      "    446200\t  0.161384\t  0.161209\t  0.161070\t\tCURRENT LEARNING RATE: 0.005758103105008157\n",
      "previous_iter_valid_loss : 0.16104567050933838\n",
      "\n",
      "    446400\t  0.161198\t  0.161046\t  0.161070\t\tCURRENT LEARNING RATE: 0.005746598407330719\n",
      "previous_iter_valid_loss : 0.16098366677761078\n",
      "\n",
      "    446600\t  0.161131\t  0.160984\t  0.161069\t\tCURRENT LEARNING RATE: 0.005735116696054572\n",
      "previous_iter_valid_loss : 0.16102072596549988\n",
      "\n",
      "    446800\t  0.161171\t  0.161021\t  0.161069\t\tCURRENT LEARNING RATE: 0.005723657925252855\n",
      "previous_iter_valid_loss : 0.16099773347377777\n",
      "\n",
      "    447000\t  0.161150\t  0.160998\t  0.161069\t\tCURRENT LEARNING RATE: 0.005712222049090466\n",
      "previous_iter_valid_loss : 0.1610119342803955\n",
      "\n",
      "    447200\t  0.161164\t  0.161012\t  0.161069\t\tCURRENT LEARNING RATE: 0.005700809021823896\n",
      "previous_iter_valid_loss : 0.1610822081565857\n",
      "\n",
      "    447400\t  0.161253\t  0.161082\t  0.161069\t\tCURRENT LEARNING RATE: 0.0056894187978010135\n",
      "previous_iter_valid_loss : 0.1610422432422638\n",
      "\n",
      "    447600\t  0.161203\t  0.161042\t  0.161069\t\tCURRENT LEARNING RATE: 0.005678051331460908\n",
      "previous_iter_valid_loss : 0.16107624769210815\n",
      "\n",
      "    447800\t  0.161238\t  0.161076\t  0.161069\t\tCURRENT LEARNING RATE: 0.0056667065773336935\n",
      "previous_iter_valid_loss : 0.16115759313106537\n",
      "\n",
      "    448000\t  0.161329\t  0.161158\t  0.161070\t\tCURRENT LEARNING RATE: 0.00565538449004035\n",
      "previous_iter_valid_loss : 0.16102072596549988\n",
      "\n",
      "    448200\t  0.161163\t  0.161021\t  0.161069\t\tCURRENT LEARNING RATE: 0.0056440850242925064\n",
      "previous_iter_valid_loss : 0.161089688539505\n",
      "\n",
      "    448400\t  0.161236\t  0.161090\t  0.161069\t\tCURRENT LEARNING RATE: 0.005632808134892286\n",
      "previous_iter_valid_loss : 0.16126880049705505\n",
      "\n",
      "    448600\t  0.161441\t  0.161269\t  0.161069\t\tCURRENT LEARNING RATE: 0.0056215537767321105\n",
      "previous_iter_valid_loss : 0.16102132201194763\n",
      "\n",
      "    448800\t  0.161181\t  0.161021\t  0.161069\t\tCURRENT LEARNING RATE: 0.005610321904794542\n",
      "previous_iter_valid_loss : 0.1611849069595337\n",
      "\n",
      "    449000\t  0.161372\t  0.161185\t  0.161070\t\tCURRENT LEARNING RATE: 0.005599112474152073\n",
      "previous_iter_valid_loss : 0.1610414683818817\n",
      "\n",
      "    449200\t  0.161212\t  0.161041\t  0.161070\t\tCURRENT LEARNING RATE: 0.005587925439966966\n",
      "previous_iter_valid_loss : 0.16106346249580383\n",
      "\n",
      "    449400\t  0.161232\t  0.161063\t  0.161070\t\tCURRENT LEARNING RATE: 0.005576760757491066\n",
      "previous_iter_valid_loss : 0.1611347496509552\n",
      "\n",
      "    449600\t  0.161304\t  0.161135\t  0.161071\t\tCURRENT LEARNING RATE: 0.005565618382065635\n",
      "previous_iter_valid_loss : 0.1609947681427002\n",
      "\n",
      "    449800\t  0.161154\t  0.160995\t  0.161070\t\tCURRENT LEARNING RATE: 0.005554498269121153\n",
      "previous_iter_valid_loss : 0.16115804016590118\n",
      "\n",
      "    450000\t  0.161311\t  0.161158\t  0.161071\t\tCURRENT LEARNING RATE: 0.005543400374177154\n",
      "previous_iter_valid_loss : 0.16113018989562988\n",
      "\n",
      "    450200\t  0.161293\t  0.161130\t  0.161070\t\tCURRENT LEARNING RATE: 0.005532324652842043\n",
      "previous_iter_valid_loss : 0.16121715307235718\n",
      "\n",
      "    450400\t  0.161378\t  0.161217\t  0.161071\t\tCURRENT LEARNING RATE: 0.005521271060812915\n",
      "previous_iter_valid_loss : 0.16106605529785156\n",
      "\n",
      "    450600\t  0.161209\t  0.161066\t  0.161071\t\tCURRENT LEARNING RATE: 0.005510239553875396\n",
      "previous_iter_valid_loss : 0.16109322011470795\n",
      "\n",
      "    450800\t  0.161269\t  0.161093\t  0.161071\t\tCURRENT LEARNING RATE: 0.0054992300879034405\n",
      "previous_iter_valid_loss : 0.16117891669273376\n",
      "\n",
      "    451000\t  0.161356\t  0.161179\t  0.161071\t\tCURRENT LEARNING RATE: 0.005488242618859169\n",
      "previous_iter_valid_loss : 0.16105172038078308\n",
      "\n",
      "    451200\t  0.161211\t  0.161052\t  0.161071\t\tCURRENT LEARNING RATE: 0.005477277102792685\n",
      "previous_iter_valid_loss : 0.16101209819316864\n",
      "\n",
      "    451400\t  0.161161\t  0.161012\t  0.161069\t\tCURRENT LEARNING RATE: 0.00546633349584192\n",
      "previous_iter_valid_loss : 0.1610994040966034\n",
      "\n",
      "    451600\t  0.161218\t  0.161099\t  0.161068\t\tCURRENT LEARNING RATE: 0.005455411754232428\n",
      "previous_iter_valid_loss : 0.16103693842887878\n",
      "\n",
      "    451800\t  0.161208\t  0.161037\t  0.161067\t\tCURRENT LEARNING RATE: 0.005444511834277225\n",
      "previous_iter_valid_loss : 0.1609741896390915\n",
      "\n",
      "\n",
      "Current valid loss: 0.1609741896390915;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "    452000\t  0.161116\t  0.160974\t  0.161067\t\tCURRENT LEARNING RATE: 0.005433633692376615\n",
      "previous_iter_valid_loss : 0.16107730567455292\n",
      "\n",
      "    452200\t  0.161222\t  0.161077\t  0.161066\t\tCURRENT LEARNING RATE: 0.005422777285018024\n",
      "previous_iter_valid_loss : 0.1610342115163803\n",
      "\n",
      "    452400\t  0.161185\t  0.161034\t  0.161065\t\tCURRENT LEARNING RATE: 0.005411942568775803\n",
      "previous_iter_valid_loss : 0.16106142103672028\n",
      "\n",
      "    452600\t  0.161198\t  0.161061\t  0.161065\t\tCURRENT LEARNING RATE: 0.005401129500311073\n",
      "previous_iter_valid_loss : 0.16109886765480042\n",
      "\n",
      "    452800\t  0.161244\t  0.161099\t  0.161065\t\tCURRENT LEARNING RATE: 0.005390338036371542\n",
      "previous_iter_valid_loss : 0.16104744374752045\n",
      "\n",
      "    453000\t  0.161201\t  0.161047\t  0.161065\t\tCURRENT LEARNING RATE: 0.005379568133791347\n",
      "previous_iter_valid_loss : 0.1610805094242096\n",
      "\n",
      "    453200\t  0.161218\t  0.161081\t  0.161065\t\tCURRENT LEARNING RATE: 0.00536881974949086\n",
      "previous_iter_valid_loss : 0.16108642518520355\n",
      "\n",
      "    453400\t  0.161246\t  0.161086\t  0.161065\t\tCURRENT LEARNING RATE: 0.0053580928404765304\n",
      "previous_iter_valid_loss : 0.16103395819664001\n",
      "\n",
      "    453600\t  0.161202\t  0.161034\t  0.161064\t\tCURRENT LEARNING RATE: 0.005347387363840702\n",
      "previous_iter_valid_loss : 0.1610596626996994\n",
      "\n",
      "    453800\t  0.161209\t  0.161060\t  0.161064\t\tCURRENT LEARNING RATE: 0.005336703276761463\n",
      "previous_iter_valid_loss : 0.16110862791538239\n",
      "\n",
      "    454000\t  0.161272\t  0.161109\t  0.161064\t\tCURRENT LEARNING RATE: 0.005326040536502446\n",
      "previous_iter_valid_loss : 0.16102361679077148\n",
      "\n",
      "    454200\t  0.161180\t  0.161024\t  0.161064\t\tCURRENT LEARNING RATE: 0.0053153991004126775\n",
      "previous_iter_valid_loss : 0.1610575020313263\n",
      "\n",
      "    454400\t  0.161201\t  0.161058\t  0.161064\t\tCURRENT LEARNING RATE: 0.005304778925926393\n",
      "previous_iter_valid_loss : 0.1610587239265442\n",
      "\n",
      "    454600\t  0.161223\t  0.161059\t  0.161064\t\tCURRENT LEARNING RATE: 0.00529417997056289\n",
      "previous_iter_valid_loss : 0.1611529439687729\n",
      "\n",
      "    454800\t  0.161318\t  0.161153\t  0.161064\t\tCURRENT LEARNING RATE: 0.005283602191926327\n",
      "previous_iter_valid_loss : 0.1610395908355713\n",
      "\n",
      "    455000\t  0.161187\t  0.161040\t  0.161064\t\tCURRENT LEARNING RATE: 0.0052730455477055784\n",
      "previous_iter_valid_loss : 0.16107846796512604\n",
      "\n",
      "    455200\t  0.161234\t  0.161078\t  0.161064\t\tCURRENT LEARNING RATE: 0.005262509995674045\n",
      "previous_iter_valid_loss : 0.16111049056053162\n",
      "\n",
      "    455400\t  0.161273\t  0.161110\t  0.161064\t\tCURRENT LEARNING RATE: 0.005251995493689517\n",
      "previous_iter_valid_loss : 0.1610330194234848\n",
      "\n",
      "    455600\t  0.161184\t  0.161033\t  0.161063\t\tCURRENT LEARNING RATE: 0.005241501999693966\n",
      "previous_iter_valid_loss : 0.16101287305355072\n",
      "\n",
      "    455800\t  0.161142\t  0.161013\t  0.161062\t\tCURRENT LEARNING RATE: 0.005231029471713402\n",
      "previous_iter_valid_loss : 0.16107302904129028\n",
      "\n",
      "    456000\t  0.161227\t  0.161073\t  0.161062\t\tCURRENT LEARNING RATE: 0.005220577867857695\n",
      "previous_iter_valid_loss : 0.16099296510219574\n",
      "\n",
      "    456200\t  0.161131\t  0.160993\t  0.161062\t\tCURRENT LEARNING RATE: 0.005210147146320425\n",
      "previous_iter_valid_loss : 0.16098302602767944\n",
      "\n",
      "    456400\t  0.161127\t  0.160983\t  0.161062\t\tCURRENT LEARNING RATE: 0.005199737265378687\n",
      "previous_iter_valid_loss : 0.16117914021015167\n",
      "\n",
      "    456600\t  0.161332\t  0.161179\t  0.161063\t\tCURRENT LEARNING RATE: 0.005189348183392944\n",
      "previous_iter_valid_loss : 0.16102334856987\n",
      "\n",
      "    456800\t  0.161176\t  0.161023\t  0.161063\t\tCURRENT LEARNING RATE: 0.005178979858806848\n",
      "previous_iter_valid_loss : 0.16105806827545166\n",
      "\n",
      "    457000\t  0.161209\t  0.161058\t  0.161063\t\tCURRENT LEARNING RATE: 0.005168632250147098\n",
      "previous_iter_valid_loss : 0.1610434651374817\n",
      "\n",
      "    457200\t  0.161191\t  0.161043\t  0.161062\t\tCURRENT LEARNING RATE: 0.00515830531602324\n",
      "previous_iter_valid_loss : 0.1611403077840805\n",
      "\n",
      "    457400\t  0.161311\t  0.161140\t  0.161062\t\tCURRENT LEARNING RATE: 0.005147999015127524\n",
      "previous_iter_valid_loss : 0.1610659509897232\n",
      "\n",
      "    457600\t  0.161211\t  0.161066\t  0.161062\t\tCURRENT LEARNING RATE: 0.005137713306234727\n",
      "previous_iter_valid_loss : 0.16102813184261322\n",
      "\n",
      "    457800\t  0.161169\t  0.161028\t  0.161062\t\tCURRENT LEARNING RATE: 0.005127448148202011\n",
      "previous_iter_valid_loss : 0.16099834442138672\n",
      "\n",
      "    458000\t  0.161146\t  0.160998\t  0.161062\t\tCURRENT LEARNING RATE: 0.005117203499968724\n",
      "previous_iter_valid_loss : 0.16100694239139557\n",
      "\n",
      "    458200\t  0.161132\t  0.161007\t  0.161062\t\tCURRENT LEARNING RATE: 0.00510697932055626\n",
      "previous_iter_valid_loss : 0.1610182523727417\n",
      "\n",
      "    458400\t  0.161157\t  0.161018\t  0.161062\t\tCURRENT LEARNING RATE: 0.005096775569067883\n",
      "previous_iter_valid_loss : 0.16103114187717438\n",
      "\n",
      "    458600\t  0.161182\t  0.161031\t  0.161062\t\tCURRENT LEARNING RATE: 0.005086592204688581\n",
      "previous_iter_valid_loss : 0.16103705763816833\n",
      "\n",
      "    458800\t  0.161184\t  0.161037\t  0.161062\t\tCURRENT LEARNING RATE: 0.0050764291866848815\n",
      "previous_iter_valid_loss : 0.16118760406970978\n",
      "\n",
      "    459000\t  0.161335\t  0.161188\t  0.161063\t\tCURRENT LEARNING RATE: 0.0050662864744046975\n",
      "previous_iter_valid_loss : 0.16101333498954773\n",
      "\n",
      "    459200\t  0.161149\t  0.161013\t  0.161062\t\tCURRENT LEARNING RATE: 0.005056164027277161\n",
      "previous_iter_valid_loss : 0.1609867513179779\n",
      "\n",
      "    459400\t  0.161127\t  0.160987\t  0.161062\t\tCURRENT LEARNING RATE: 0.00504606180481248\n",
      "previous_iter_valid_loss : 0.16103512048721313\n",
      "\n",
      "    459600\t  0.161179\t  0.161035\t  0.161062\t\tCURRENT LEARNING RATE: 0.005035979766601745\n",
      "previous_iter_valid_loss : 0.1609979122877121\n",
      "\n",
      "    459800\t  0.161136\t  0.160998\t  0.161061\t\tCURRENT LEARNING RATE: 0.005025917872316793\n",
      "previous_iter_valid_loss : 0.1610793024301529\n",
      "\n",
      "    460000\t  0.161233\t  0.161079\t  0.161061\t\tCURRENT LEARNING RATE: 0.005015876081710026\n",
      "previous_iter_valid_loss : 0.16109342873096466\n",
      "\n",
      "    460200\t  0.161241\t  0.161093\t  0.161061\t\tCURRENT LEARNING RATE: 0.005005854354614278\n",
      "previous_iter_valid_loss : 0.1610175371170044\n",
      "\n",
      "    460400\t  0.161163\t  0.161018\t  0.161060\t\tCURRENT LEARNING RATE: 0.004995852650942623\n",
      "previous_iter_valid_loss : 0.16109661757946014\n",
      "\n",
      "    460600\t  0.161249\t  0.161097\t  0.161061\t\tCURRENT LEARNING RATE: 0.004985870930688233\n",
      "previous_iter_valid_loss : 0.1609811931848526\n",
      "\n",
      "    460800\t  0.161124\t  0.160981\t  0.161060\t\tCURRENT LEARNING RATE: 0.00497590915392421\n",
      "previous_iter_valid_loss : 0.16103574633598328\n",
      "\n",
      "    461000\t  0.161201\t  0.161036\t  0.161060\t\tCURRENT LEARNING RATE: 0.00496596728080344\n",
      "previous_iter_valid_loss : 0.16101552546024323\n",
      "\n",
      "    461200\t  0.161185\t  0.161016\t  0.161060\t\tCURRENT LEARNING RATE: 0.004956045271558416\n",
      "previous_iter_valid_loss : 0.16106753051280975\n",
      "\n",
      "    461400\t  0.161245\t  0.161068\t  0.161060\t\tCURRENT LEARNING RATE: 0.004946143086501086\n",
      "previous_iter_valid_loss : 0.1610356569290161\n",
      "\n",
      "    461600\t  0.161214\t  0.161036\t  0.161060\t\tCURRENT LEARNING RATE: 0.004936260686022692\n",
      "previous_iter_valid_loss : 0.16111543774604797\n",
      "\n",
      "    461800\t  0.161245\t  0.161115\t  0.161061\t\tCURRENT LEARNING RATE: 0.0049263980305936286\n",
      "previous_iter_valid_loss : 0.1610127091407776\n",
      "\n",
      "    462000\t  0.161174\t  0.161013\t  0.161060\t\tCURRENT LEARNING RATE: 0.004916555080763256\n",
      "previous_iter_valid_loss : 0.16105781495571136\n",
      "\n",
      "    462200\t  0.161229\t  0.161058\t  0.161060\t\tCURRENT LEARNING RATE: 0.004906731797159761\n",
      "previous_iter_valid_loss : 0.16103196144104004\n",
      "\n",
      "    462400\t  0.161187\t  0.161032\t  0.161060\t\tCURRENT LEARNING RATE: 0.004896928140489994\n",
      "previous_iter_valid_loss : 0.16108863055706024\n",
      "\n",
      "    462600\t  0.161255\t  0.161089\t  0.161061\t\tCURRENT LEARNING RATE: 0.004887144071539322\n",
      "previous_iter_valid_loss : 0.16117385029792786\n",
      "\n",
      "    462800\t  0.161329\t  0.161174\t  0.161061\t\tCURRENT LEARNING RATE: 0.004877379551171452\n",
      "previous_iter_valid_loss : 0.16101056337356567\n",
      "\n",
      "    463000\t  0.161169\t  0.161011\t  0.161061\t\tCURRENT LEARNING RATE: 0.00486763454032829\n",
      "previous_iter_valid_loss : 0.161056786775589\n",
      "\n",
      "    463200\t  0.161219\t  0.161057\t  0.161061\t\tCURRENT LEARNING RATE: 0.0048579090000297745\n",
      "previous_iter_valid_loss : 0.1610039323568344\n",
      "\n",
      "    463400\t  0.161163\t  0.161004\t  0.161061\t\tCURRENT LEARNING RATE: 0.0048482028913737416\n",
      "previous_iter_valid_loss : 0.16102099418640137\n",
      "\n",
      "    463600\t  0.161164\t  0.161021\t  0.161061\t\tCURRENT LEARNING RATE: 0.004838516175535738\n",
      "previous_iter_valid_loss : 0.16107843816280365\n",
      "\n",
      "    463800\t  0.161256\t  0.161078\t  0.161061\t\tCURRENT LEARNING RATE: 0.004828848813768888\n",
      "previous_iter_valid_loss : 0.16110169887542725\n",
      "\n",
      "    464000\t  0.161270\t  0.161102\t  0.161061\t\tCURRENT LEARNING RATE: 0.004819200767403728\n",
      "previous_iter_valid_loss : 0.16112224757671356\n",
      "\n",
      "    464200\t  0.161294\t  0.161122\t  0.161062\t\tCURRENT LEARNING RATE: 0.004809571997848067\n",
      "previous_iter_valid_loss : 0.16098380088806152\n",
      "\n",
      "    464400\t  0.161129\t  0.160984\t  0.161061\t\tCURRENT LEARNING RATE: 0.00479996246658681\n",
      "previous_iter_valid_loss : 0.1611860990524292\n",
      "\n",
      "    464600\t  0.161351\t  0.161186\t  0.161062\t\tCURRENT LEARNING RATE: 0.004790372135181819\n",
      "previous_iter_valid_loss : 0.16104954481124878\n",
      "\n",
      "    464800\t  0.161198\t  0.161050\t  0.161061\t\tCURRENT LEARNING RATE: 0.004780800965271752\n",
      "previous_iter_valid_loss : 0.16098955273628235\n",
      "\n",
      "    465000\t  0.161143\t  0.160990\t  0.161061\t\tCURRENT LEARNING RATE: 0.004771248918571925\n",
      "previous_iter_valid_loss : 0.1610114723443985\n",
      "\n",
      "    465200\t  0.161160\t  0.161011\t  0.161061\t\tCURRENT LEARNING RATE: 0.0047617159568741334\n",
      "previous_iter_valid_loss : 0.1610640585422516\n",
      "\n",
      "    465400\t  0.161231\t  0.161064\t  0.161061\t\tCURRENT LEARNING RATE: 0.004752202042046519\n",
      "previous_iter_valid_loss : 0.16129682958126068\n",
      "\n",
      "    465600\t  0.161465\t  0.161297\t  0.161062\t\tCURRENT LEARNING RATE: 0.004742707136033404\n",
      "previous_iter_valid_loss : 0.16105791926383972\n",
      "\n",
      "    465800\t  0.161226\t  0.161058\t  0.161062\t\tCURRENT LEARNING RATE: 0.0047332312008551616\n",
      "previous_iter_valid_loss : 0.1610187143087387\n",
      "\n",
      "    466000\t  0.161165\t  0.161019\t  0.161062\t\tCURRENT LEARNING RATE: 0.004723774198608033\n",
      "previous_iter_valid_loss : 0.16117587685585022\n",
      "\n",
      "    466200\t  0.161344\t  0.161176\t  0.161062\t\tCURRENT LEARNING RATE: 0.004714336091463997\n",
      "previous_iter_valid_loss : 0.16116060316562653\n",
      "\n",
      "    466400\t  0.161281\t  0.161161\t  0.161062\t\tCURRENT LEARNING RATE: 0.00470491684167061\n",
      "previous_iter_valid_loss : 0.16100060939788818\n",
      "\n",
      "    466600\t  0.161165\t  0.161001\t  0.161062\t\tCURRENT LEARNING RATE: 0.004695516411550866\n",
      "previous_iter_valid_loss : 0.16111433506011963\n",
      "\n",
      "    466800\t  0.161259\t  0.161114\t  0.161063\t\tCURRENT LEARNING RATE: 0.004686134763503029\n",
      "previous_iter_valid_loss : 0.16104631125926971\n",
      "\n",
      "    467000\t  0.161211\t  0.161046\t  0.161062\t\tCURRENT LEARNING RATE: 0.004676771860000494\n",
      "previous_iter_valid_loss : 0.16099846363067627\n",
      "\n",
      "    467200\t  0.161164\t  0.160998\t  0.161061\t\tCURRENT LEARNING RATE: 0.0046674276635916305\n",
      "previous_iter_valid_loss : 0.1610235869884491\n",
      "\n",
      "    467400\t  0.161191\t  0.161024\t  0.161061\t\tCURRENT LEARNING RATE: 0.004658102136899649\n",
      "previous_iter_valid_loss : 0.16099202632904053\n",
      "\n",
      "    467600\t  0.161152\t  0.160992\t  0.161061\t\tCURRENT LEARNING RATE: 0.0046487952426224255\n",
      "previous_iter_valid_loss : 0.16104070842266083\n",
      "\n",
      "    467800\t  0.161195\t  0.161041\t  0.161061\t\tCURRENT LEARNING RATE: 0.004639506943532372\n",
      "previous_iter_valid_loss : 0.16101175546646118\n",
      "\n",
      "    468000\t  0.161166\t  0.161012\t  0.161061\t\tCURRENT LEARNING RATE: 0.004630237202476273\n",
      "previous_iter_valid_loss : 0.16111460328102112\n",
      "\n",
      "    468200\t  0.161279\t  0.161115\t  0.161061\t\tCURRENT LEARNING RATE: 0.004620985982375162\n",
      "previous_iter_valid_loss : 0.1609952300786972\n",
      "\n",
      "    468400\t  0.161129\t  0.160995\t  0.161061\t\tCURRENT LEARNING RATE: 0.004611753246224143\n",
      "previous_iter_valid_loss : 0.16098666191101074\n",
      "\n",
      "    468600\t  0.161140\t  0.160987\t  0.161060\t\tCURRENT LEARNING RATE: 0.004602538957092257\n",
      "previous_iter_valid_loss : 0.16113299131393433\n",
      "\n",
      "    468800\t  0.161297\t  0.161133\t  0.161061\t\tCURRENT LEARNING RATE: 0.004593343078122332\n",
      "previous_iter_valid_loss : 0.16097474098205566\n",
      "\n",
      "    469000\t  0.161119\t  0.160975\t  0.161061\t\tCURRENT LEARNING RATE: 0.0045841655725308485\n",
      "previous_iter_valid_loss : 0.1609860211610794\n",
      "\n",
      "    469200\t  0.161135\t  0.160986\t  0.161060\t\tCURRENT LEARNING RATE: 0.0045750064036077665\n",
      "previous_iter_valid_loss : 0.16110463440418243\n",
      "\n",
      "    469400\t  0.161270\t  0.161105\t  0.161059\t\tCURRENT LEARNING RATE: 0.004565865534716399\n",
      "previous_iter_valid_loss : 0.16108499467372894\n",
      "\n",
      "    469600\t  0.161260\t  0.161085\t  0.161059\t\tCURRENT LEARNING RATE: 0.004556742929293255\n",
      "previous_iter_valid_loss : 0.16100484132766724\n",
      "\n",
      "    469800\t  0.161161\t  0.161005\t  0.161059\t\tCURRENT LEARNING RATE: 0.004547638550847908\n",
      "previous_iter_valid_loss : 0.1610172539949417\n",
      "\n",
      "    470000\t  0.161174\t  0.161017\t  0.161058\t\tCURRENT LEARNING RATE: 0.004538552362962827\n",
      "previous_iter_valid_loss : 0.1610335409641266\n",
      "\n",
      "    470200\t  0.161185\t  0.161034\t  0.161059\t\tCURRENT LEARNING RATE: 0.00452948432929325\n",
      "previous_iter_valid_loss : 0.1610122174024582\n",
      "\n",
      "    470400\t  0.161169\t  0.161012\t  0.161059\t\tCURRENT LEARNING RATE: 0.004520434413567025\n",
      "previous_iter_valid_loss : 0.16101135313510895\n",
      "\n",
      "    470600\t  0.161164\t  0.161011\t  0.161058\t\tCURRENT LEARNING RATE: 0.004511402579584486\n",
      "previous_iter_valid_loss : 0.16104274988174438\n",
      "\n",
      "    470800\t  0.161176\t  0.161043\t  0.161058\t\tCURRENT LEARNING RATE: 0.00450238879121828\n",
      "previous_iter_valid_loss : 0.1609915941953659\n",
      "\n",
      "    471000\t  0.161141\t  0.160992\t  0.161058\t\tCURRENT LEARNING RATE: 0.0044933930124132415\n",
      "previous_iter_valid_loss : 0.16107220947742462\n",
      "\n",
      "    471200\t  0.161213\t  0.161072\t  0.161058\t\tCURRENT LEARNING RATE: 0.004484415207186241\n",
      "previous_iter_valid_loss : 0.1609809249639511\n",
      "\n",
      "    471400\t  0.161121\t  0.160981\t  0.161058\t\tCURRENT LEARNING RATE: 0.004475455339626052\n",
      "previous_iter_valid_loss : 0.16104662418365479\n",
      "\n",
      "    471600\t  0.161203\t  0.161047\t  0.161058\t\tCURRENT LEARNING RATE: 0.004466513373893188\n",
      "previous_iter_valid_loss : 0.16109433770179749\n",
      "\n",
      "    471800\t  0.161247\t  0.161094\t  0.161058\t\tCURRENT LEARNING RATE: 0.004457589274219777\n",
      "previous_iter_valid_loss : 0.1610463559627533\n",
      "\n",
      "    472000\t  0.161200\t  0.161046\t  0.161058\t\tCURRENT LEARNING RATE: 0.0044486830049094\n",
      "previous_iter_valid_loss : 0.16107481718063354\n",
      "\n",
      "    472200\t  0.161225\t  0.161075\t  0.161059\t\tCURRENT LEARNING RATE: 0.00443979453033698\n",
      "previous_iter_valid_loss : 0.161045640707016\n",
      "\n",
      "    472400\t  0.161176\t  0.161046\t  0.161058\t\tCURRENT LEARNING RATE: 0.0044309238149486\n",
      "previous_iter_valid_loss : 0.16114790737628937\n",
      "\n",
      "    472600\t  0.161308\t  0.161148\t  0.161059\t\tCURRENT LEARNING RATE: 0.004422070823261388\n",
      "previous_iter_valid_loss : 0.16105221211910248\n",
      "\n",
      "    472800\t  0.161188\t  0.161052\t  0.161059\t\tCURRENT LEARNING RATE: 0.004413235519863361\n",
      "previous_iter_valid_loss : 0.16112832725048065\n",
      "\n",
      "    473000\t  0.161303\t  0.161128\t  0.161059\t\tCURRENT LEARNING RATE: 0.0044044178694133025\n",
      "previous_iter_valid_loss : 0.16102340817451477\n",
      "\n",
      "    473200\t  0.161177\t  0.161023\t  0.161059\t\tCURRENT LEARNING RATE: 0.004395617836640594\n",
      "previous_iter_valid_loss : 0.16102047264575958\n",
      "\n",
      "    473400\t  0.161182\t  0.161020\t  0.161059\t\tCURRENT LEARNING RATE: 0.004386835386345092\n",
      "previous_iter_valid_loss : 0.16101613640785217\n",
      "\n",
      "    473600\t  0.161169\t  0.161016\t  0.161059\t\tCURRENT LEARNING RATE: 0.004378070483396981\n",
      "previous_iter_valid_loss : 0.1610640287399292\n",
      "\n",
      "    473800\t  0.161244\t  0.161064\t  0.161059\t\tCURRENT LEARNING RATE: 0.004369323092736645\n",
      "previous_iter_valid_loss : 0.16098831593990326\n",
      "\n",
      "    474000\t  0.161139\t  0.160988\t  0.161059\t\tCURRENT LEARNING RATE: 0.004360593179374506\n",
      "previous_iter_valid_loss : 0.16108693182468414\n",
      "\n",
      "    474200\t  0.161254\t  0.161087\t  0.161059\t\tCURRENT LEARNING RATE: 0.004351880708390898\n",
      "previous_iter_valid_loss : 0.16111810505390167\n",
      "\n",
      "    474400\t  0.161274\t  0.161118\t  0.161059\t\tCURRENT LEARNING RATE: 0.004343185644935923\n",
      "previous_iter_valid_loss : 0.1610250174999237\n",
      "\n",
      "    474600\t  0.161192\t  0.161025\t  0.161059\t\tCURRENT LEARNING RATE: 0.004334507954229322\n",
      "previous_iter_valid_loss : 0.1610197126865387\n",
      "\n",
      "    474800\t  0.161176\t  0.161020\t  0.161058\t\tCURRENT LEARNING RATE: 0.004325847601560317\n",
      "previous_iter_valid_loss : 0.16101592779159546\n",
      "\n",
      "    475000\t  0.161170\t  0.161016\t  0.161058\t\tCURRENT LEARNING RATE: 0.004317204552287486\n",
      "previous_iter_valid_loss : 0.16108131408691406\n",
      "\n",
      "    475200\t  0.161264\t  0.161081\t  0.161058\t\tCURRENT LEARNING RATE: 0.004308578771838621\n",
      "previous_iter_valid_loss : 0.16102541983127594\n",
      "\n",
      "    475400\t  0.161194\t  0.161025\t  0.161059\t\tCURRENT LEARNING RATE: 0.004299970225710584\n",
      "previous_iter_valid_loss : 0.16115041077136993\n",
      "\n",
      "    475600\t  0.161323\t  0.161150\t  0.161059\t\tCURRENT LEARNING RATE: 0.004291378879469188\n",
      "previous_iter_valid_loss : 0.16109859943389893\n",
      "\n",
      "    475800\t  0.161259\t  0.161099\t  0.161059\t\tCURRENT LEARNING RATE: 0.00428280469874903\n",
      "previous_iter_valid_loss : 0.1610780954360962\n",
      "\n",
      "    476000\t  0.161241\t  0.161078\t  0.161059\t\tCURRENT LEARNING RATE: 0.004274247649253379\n",
      "previous_iter_valid_loss : 0.16108787059783936\n",
      "\n",
      "    476200\t  0.161258\t  0.161088\t  0.161060\t\tCURRENT LEARNING RATE: 0.004265707696754019\n",
      "previous_iter_valid_loss : 0.16108359396457672\n",
      "\n",
      "    476400\t  0.161246\t  0.161084\t  0.161060\t\tCURRENT LEARNING RATE: 0.004257184807091138\n",
      "previous_iter_valid_loss : 0.16115978360176086\n",
      "\n",
      "    476600\t  0.161339\t  0.161160\t  0.161060\t\tCURRENT LEARNING RATE: 0.004248678946173161\n",
      "previous_iter_valid_loss : 0.1611466258764267\n",
      "\n",
      "    476800\t  0.161312\t  0.161147\t  0.161061\t\tCURRENT LEARNING RATE: 0.004240190079976634\n",
      "previous_iter_valid_loss : 0.16101934015750885\n",
      "\n",
      "    477000\t  0.161174\t  0.161019\t  0.161061\t\tCURRENT LEARNING RATE: 0.004231718174546077\n",
      "previous_iter_valid_loss : 0.16115963459014893\n",
      "\n",
      "    477200\t  0.161339\t  0.161160\t  0.161062\t\tCURRENT LEARNING RATE: 0.004223263195993864\n",
      "previous_iter_valid_loss : 0.16103540360927582\n",
      "\n",
      "    477400\t  0.161206\t  0.161035\t  0.161062\t\tCURRENT LEARNING RATE: 0.004214825110500066\n",
      "previous_iter_valid_loss : 0.16101999580860138\n",
      "\n",
      "    477600\t  0.161178\t  0.161020\t  0.161062\t\tCURRENT LEARNING RATE: 0.004206403884312329\n",
      "previous_iter_valid_loss : 0.16107134521007538\n",
      "\n",
      "    477800\t  0.161243\t  0.161071\t  0.161062\t\tCURRENT LEARNING RATE: 0.004197999483745735\n",
      "previous_iter_valid_loss : 0.16104041039943695\n",
      "\n",
      "    478000\t  0.161202\t  0.161040\t  0.161061\t\tCURRENT LEARNING RATE: 0.004189611875182677\n",
      "previous_iter_valid_loss : 0.16106408834457397\n",
      "\n",
      "    478200\t  0.161227\t  0.161064\t  0.161061\t\tCURRENT LEARNING RATE: 0.004181241025072706\n",
      "previous_iter_valid_loss : 0.16104945540428162\n",
      "\n",
      "    478400\t  0.161188\t  0.161049\t  0.161061\t\tCURRENT LEARNING RATE: 0.00417288689993241\n",
      "previous_iter_valid_loss : 0.16117636859416962\n",
      "\n",
      "    478600\t  0.161337\t  0.161176\t  0.161062\t\tCURRENT LEARNING RATE: 0.004164549466345274\n",
      "previous_iter_valid_loss : 0.1611013263463974\n",
      "\n",
      "    478800\t  0.161254\t  0.161101\t  0.161062\t\tCURRENT LEARNING RATE: 0.004156228690961559\n",
      "previous_iter_valid_loss : 0.16112017631530762\n",
      "\n",
      "    479000\t  0.161288\t  0.161120\t  0.161062\t\tCURRENT LEARNING RATE: 0.0041479245404981505\n",
      "previous_iter_valid_loss : 0.16102197766304016\n",
      "\n",
      "    479200\t  0.161188\t  0.161022\t  0.161062\t\tCURRENT LEARNING RATE: 0.004139636981738434\n",
      "previous_iter_valid_loss : 0.16105343401432037\n",
      "\n",
      "    479400\t  0.161204\t  0.161053\t  0.161062\t\tCURRENT LEARNING RATE: 0.004131365981532161\n",
      "previous_iter_valid_loss : 0.16111090779304504\n",
      "\n",
      "    479600\t  0.161287\t  0.161111\t  0.161062\t\tCURRENT LEARNING RATE: 0.004123111506795326\n",
      "previous_iter_valid_loss : 0.16107875108718872\n",
      "\n",
      "    479800\t  0.161236\t  0.161079\t  0.161063\t\tCURRENT LEARNING RATE: 0.004114873524510015\n",
      "previous_iter_valid_loss : 0.16109034419059753\n",
      "\n",
      "    480000\t  0.161247\t  0.161090\t  0.161063\t\tCURRENT LEARNING RATE: 0.004106652001724289\n",
      "previous_iter_valid_loss : 0.1610640585422516\n",
      "\n",
      "    480200\t  0.161236\t  0.161064\t  0.161063\t\tCURRENT LEARNING RATE: 0.004098446905552042\n",
      "previous_iter_valid_loss : 0.16102153062820435\n",
      "\n",
      "    480400\t  0.161186\t  0.161022\t  0.161062\t\tCURRENT LEARNING RATE: 0.004090258203172885\n",
      "previous_iter_valid_loss : 0.16099989414215088\n",
      "\n",
      "    480600\t  0.161171\t  0.161000\t  0.161062\t\tCURRENT LEARNING RATE: 0.004082085861831995\n",
      "previous_iter_valid_loss : 0.16104568541049957\n",
      "\n",
      "    480800\t  0.161205\t  0.161046\t  0.161062\t\tCURRENT LEARNING RATE: 0.004073929848839994\n",
      "previous_iter_valid_loss : 0.16105793416500092\n",
      "\n",
      "    481000\t  0.161211\t  0.161058\t  0.161062\t\tCURRENT LEARNING RATE: 0.004065790131572818\n",
      "previous_iter_valid_loss : 0.16103202104568481\n",
      "\n",
      "    481200\t  0.161199\t  0.161032\t  0.161062\t\tCURRENT LEARNING RATE: 0.004057666677471592\n",
      "previous_iter_valid_loss : 0.16107714176177979\n",
      "\n",
      "    481400\t  0.161244\t  0.161077\t  0.161062\t\tCURRENT LEARNING RATE: 0.004049559454042487\n",
      "previous_iter_valid_loss : 0.16107875108718872\n",
      "\n",
      "    481600\t  0.161243\t  0.161079\t  0.161062\t\tCURRENT LEARNING RATE: 0.004041468428856596\n",
      "previous_iter_valid_loss : 0.16105833649635315\n",
      "\n",
      "    481800\t  0.161223\t  0.161058\t  0.161062\t\tCURRENT LEARNING RATE: 0.004033393569549807\n",
      "previous_iter_valid_loss : 0.16101056337356567\n",
      "\n",
      "    482000\t  0.161186\t  0.161011\t  0.161062\t\tCURRENT LEARNING RATE: 0.004025334843822678\n",
      "previous_iter_valid_loss : 0.16102588176727295\n",
      "\n",
      "    482200\t  0.161202\t  0.161026\t  0.161062\t\tCURRENT LEARNING RATE: 0.00401729221944029\n",
      "previous_iter_valid_loss : 0.1609794646501541\n",
      "\n",
      "    482400\t  0.161136\t  0.160979\t  0.161061\t\tCURRENT LEARNING RATE: 0.004009265664232137\n",
      "previous_iter_valid_loss : 0.16100755333900452\n",
      "\n",
      "    482600\t  0.161165\t  0.161008\t  0.161060\t\tCURRENT LEARNING RATE: 0.004001255146091983\n",
      "previous_iter_valid_loss : 0.16115322709083557\n",
      "\n",
      "    482800\t  0.161322\t  0.161153\t  0.161060\t\tCURRENT LEARNING RATE: 0.003993260632977751\n",
      "previous_iter_valid_loss : 0.16118629276752472\n",
      "\n",
      "    483000\t  0.161365\t  0.161186\t  0.161060\t\tCURRENT LEARNING RATE: 0.003985282092911376\n",
      "previous_iter_valid_loss : 0.1610001176595688\n",
      "\n",
      "    483200\t  0.161138\t  0.161000\t  0.161060\t\tCURRENT LEARNING RATE: 0.003977319493978686\n",
      "previous_iter_valid_loss : 0.16110403835773468\n",
      "\n",
      "    483400\t  0.161278\t  0.161104\t  0.161060\t\tCURRENT LEARNING RATE: 0.003969372804329272\n",
      "previous_iter_valid_loss : 0.16102680563926697\n",
      "\n",
      "    483600\t  0.161189\t  0.161027\t  0.161060\t\tCURRENT LEARNING RATE: 0.003961441992176371\n",
      "previous_iter_valid_loss : 0.16099831461906433\n",
      "\n",
      "    483800\t  0.161160\t  0.160998\t  0.161060\t\tCURRENT LEARNING RATE: 0.003953527025796721\n",
      "previous_iter_valid_loss : 0.16104920208454132\n",
      "\n",
      "    484000\t  0.161191\t  0.161049\t  0.161060\t\tCURRENT LEARNING RATE: 0.003945627873530445\n",
      "previous_iter_valid_loss : 0.16099192202091217\n",
      "\n",
      "    484200\t  0.161138\t  0.160992\t  0.161060\t\tCURRENT LEARNING RATE: 0.003937744503780921\n",
      "previous_iter_valid_loss : 0.16098624467849731\n",
      "\n",
      "    484400\t  0.161150\t  0.160986\t  0.161060\t\tCURRENT LEARNING RATE: 0.003929876885014665\n",
      "previous_iter_valid_loss : 0.16110095381736755\n",
      "\n",
      "    484600\t  0.161251\t  0.161101\t  0.161060\t\tCURRENT LEARNING RATE: 0.00392202498576119\n",
      "previous_iter_valid_loss : 0.1610223799943924\n",
      "\n",
      "    484800\t  0.161153\t  0.161022\t  0.161060\t\tCURRENT LEARNING RATE: 0.003914188774612887\n",
      "previous_iter_valid_loss : 0.16100461781024933\n",
      "\n",
      "    485000\t  0.161151\t  0.161005\t  0.161060\t\tCURRENT LEARNING RATE: 0.003906368220224898\n",
      "previous_iter_valid_loss : 0.16105198860168457\n",
      "\n",
      "    485200\t  0.161202\t  0.161052\t  0.161060\t\tCURRENT LEARNING RATE: 0.003898563291315002\n",
      "previous_iter_valid_loss : 0.161001056432724\n",
      "\n",
      "    485400\t  0.161157\t  0.161001\t  0.161060\t\tCURRENT LEARNING RATE: 0.0038907739566634686\n",
      "previous_iter_valid_loss : 0.1610860526561737\n",
      "\n",
      "    485600\t  0.161234\t  0.161086\t  0.161060\t\tCURRENT LEARNING RATE: 0.0038830001851129503\n",
      "previous_iter_valid_loss : 0.1611199676990509\n",
      "\n",
      "    485800\t  0.161279\t  0.161120\t  0.161061\t\tCURRENT LEARNING RATE: 0.003875241945568346\n",
      "previous_iter_valid_loss : 0.1609918773174286\n",
      "\n",
      "    486000\t  0.161145\t  0.160992\t  0.161061\t\tCURRENT LEARNING RATE: 0.0038674992069966945\n",
      "previous_iter_valid_loss : 0.1610439121723175\n",
      "\n",
      "    486200\t  0.161216\t  0.161044\t  0.161060\t\tCURRENT LEARNING RATE: 0.0038597719384270276\n",
      "previous_iter_valid_loss : 0.16101455688476562\n",
      "\n",
      "    486400\t  0.161172\t  0.161015\t  0.161060\t\tCURRENT LEARNING RATE: 0.0038520601089502607\n",
      "previous_iter_valid_loss : 0.16106918454170227\n",
      "\n",
      "    486600\t  0.161245\t  0.161069\t  0.161060\t\tCURRENT LEARNING RATE: 0.0038443636877190626\n",
      "previous_iter_valid_loss : 0.16103263199329376\n",
      "\n",
      "    486800\t  0.161165\t  0.161033\t  0.161060\t\tCURRENT LEARNING RATE: 0.0038366826439477446\n",
      "previous_iter_valid_loss : 0.16100247204303741\n",
      "\n",
      "    487000\t  0.161155\t  0.161002\t  0.161060\t\tCURRENT LEARNING RATE: 0.0038290169469121175\n",
      "previous_iter_valid_loss : 0.1610652655363083\n",
      "\n",
      "    487200\t  0.161227\t  0.161065\t  0.161061\t\tCURRENT LEARNING RATE: 0.003821366565949384\n",
      "previous_iter_valid_loss : 0.16108745336532593\n",
      "\n",
      "    487400\t  0.161231\t  0.161087\t  0.161061\t\tCURRENT LEARNING RATE: 0.0038137314704580053\n",
      "previous_iter_valid_loss : 0.16100211441516876\n",
      "\n",
      "    487600\t  0.161135\t  0.161002\t  0.161061\t\tCURRENT LEARNING RATE: 0.0038061116298975972\n",
      "previous_iter_valid_loss : 0.1610238254070282\n",
      "\n",
      "    487800\t  0.161162\t  0.161024\t  0.161060\t\tCURRENT LEARNING RATE: 0.0037985070137887835\n",
      "previous_iter_valid_loss : 0.16103024780750275\n",
      "\n",
      "    488000\t  0.161183\t  0.161030\t  0.161060\t\tCURRENT LEARNING RATE: 0.00379091759171309\n",
      "previous_iter_valid_loss : 0.16098544001579285\n",
      "\n",
      "    488200\t  0.161111\t  0.160985\t  0.161059\t\tCURRENT LEARNING RATE: 0.003783343333312814\n",
      "previous_iter_valid_loss : 0.1609809696674347\n",
      "\n",
      "    488400\t  0.161122\t  0.160981\t  0.161059\t\tCURRENT LEARNING RATE: 0.003775784208290919\n",
      "previous_iter_valid_loss : 0.1610628068447113\n",
      "\n",
      "    488600\t  0.161222\t  0.161063\t  0.161058\t\tCURRENT LEARNING RATE: 0.0037682401864108923\n",
      "previous_iter_valid_loss : 0.1610075831413269\n",
      "\n",
      "    488800\t  0.161148\t  0.161008\t  0.161058\t\tCURRENT LEARNING RATE: 0.003760711237496635\n",
      "previous_iter_valid_loss : 0.16098280251026154\n",
      "\n",
      "    489000\t  0.161120\t  0.160983\t  0.161057\t\tCURRENT LEARNING RATE: 0.003753197331432339\n",
      "previous_iter_valid_loss : 0.1610543429851532\n",
      "\n",
      "    489200\t  0.161210\t  0.161054\t  0.161057\t\tCURRENT LEARNING RATE: 0.0037456984381623757\n",
      "previous_iter_valid_loss : 0.16101102530956268\n",
      "\n",
      "    489400\t  0.161165\t  0.161011\t  0.161057\t\tCURRENT LEARNING RATE: 0.0037382145276911596\n",
      "previous_iter_valid_loss : 0.16115006804466248\n",
      "\n",
      "    489600\t  0.161333\t  0.161150\t  0.161057\t\tCURRENT LEARNING RATE: 0.0037307455700830387\n",
      "previous_iter_valid_loss : 0.16102659702301025\n",
      "\n",
      "    489800\t  0.161191\t  0.161027\t  0.161057\t\tCURRENT LEARNING RATE: 0.003723291535462169\n",
      "previous_iter_valid_loss : 0.1609843373298645\n",
      "\n",
      "    490000\t  0.161118\t  0.160984\t  0.161056\t\tCURRENT LEARNING RATE: 0.003715852394012409\n",
      "previous_iter_valid_loss : 0.16103041172027588\n",
      "\n",
      "    490200\t  0.161186\t  0.161030\t  0.161055\t\tCURRENT LEARNING RATE: 0.0037084281159771794\n",
      "previous_iter_valid_loss : 0.1610114425420761\n",
      "\n",
      "    490400\t  0.161171\t  0.161011\t  0.161054\t\tCURRENT LEARNING RATE: 0.0037010186716593583\n",
      "previous_iter_valid_loss : 0.16116265952587128\n",
      "\n",
      "    490600\t  0.161337\t  0.161163\t  0.161055\t\tCURRENT LEARNING RATE: 0.003693624031421155\n",
      "previous_iter_valid_loss : 0.16103912889957428\n",
      "\n",
      "    490800\t  0.161203\t  0.161039\t  0.161055\t\tCURRENT LEARNING RATE: 0.003686244165684006\n",
      "previous_iter_valid_loss : 0.16104795038700104\n",
      "\n",
      "    491000\t  0.161189\t  0.161048\t  0.161054\t\tCURRENT LEARNING RATE: 0.003678879044928434\n",
      "previous_iter_valid_loss : 0.16100597381591797\n",
      "\n",
      "    491200\t  0.161150\t  0.161006\t  0.161054\t\tCURRENT LEARNING RATE: 0.0036715286396939474\n",
      "previous_iter_valid_loss : 0.16101238131523132\n",
      "\n",
      "    491400\t  0.161152\t  0.161012\t  0.161054\t\tCURRENT LEARNING RATE: 0.003664192920578912\n",
      "previous_iter_valid_loss : 0.1611267775297165\n",
      "\n",
      "    491600\t  0.161286\t  0.161127\t  0.161054\t\tCURRENT LEARNING RATE: 0.0036568718582404474\n",
      "previous_iter_valid_loss : 0.1610388457775116\n",
      "\n",
      "    491800\t  0.161189\t  0.161039\t  0.161054\t\tCURRENT LEARNING RATE: 0.0036495654233942914\n",
      "previous_iter_valid_loss : 0.16106396913528442\n",
      "\n",
      "    492000\t  0.161204\t  0.161064\t  0.161054\t\tCURRENT LEARNING RATE: 0.003642273586814695\n",
      "previous_iter_valid_loss : 0.1611371636390686\n",
      "\n",
      "    492200\t  0.161304\t  0.161137\t  0.161055\t\tCURRENT LEARNING RATE: 0.0036349963193342996\n",
      "previous_iter_valid_loss : 0.16099560260772705\n",
      "\n",
      "    492400\t  0.161134\t  0.160996\t  0.161054\t\tCURRENT LEARNING RATE: 0.003627733591844031\n",
      "previous_iter_valid_loss : 0.1611655205488205\n",
      "\n",
      "    492600\t  0.161326\t  0.161166\t  0.161055\t\tCURRENT LEARNING RATE: 0.003620485375292967\n",
      "previous_iter_valid_loss : 0.16099347174167633\n",
      "\n",
      "    492800\t  0.161143\t  0.160993\t  0.161054\t\tCURRENT LEARNING RATE: 0.0036132516406882313\n",
      "previous_iter_valid_loss : 0.16115015745162964\n",
      "\n",
      "    493000\t  0.161311\t  0.161150\t  0.161055\t\tCURRENT LEARNING RATE: 0.0036060323590948727\n",
      "previous_iter_valid_loss : 0.16097106039524078\n",
      "\n",
      "\n",
      "Current valid loss: 0.16097106039524078;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatam_4_layer5_hiddenLeakyReLU_activation512_batchsize500_Kiteration.dict\n",
      "    493200\t  0.161105\t  0.160971\t  0.161054\t\tCURRENT LEARNING RATE: 0.0035988275016357618\n",
      "previous_iter_valid_loss : 0.16100627183914185\n",
      "\n",
      "    493400\t  0.161139\t  0.161006\t  0.161054\t\tCURRENT LEARNING RATE: 0.003591637039491456\n",
      "previous_iter_valid_loss : 0.1611236333847046\n",
      "\n",
      "    493600\t  0.161266\t  0.161124\t  0.161054\t\tCURRENT LEARNING RATE: 0.003584460943900097\n",
      "previous_iter_valid_loss : 0.16101232171058655\n",
      "\n",
      "    493800\t  0.161175\t  0.161012\t  0.161054\t\tCURRENT LEARNING RATE: 0.0035772991861572896\n",
      "previous_iter_valid_loss : 0.16102463006973267\n",
      "\n",
      "    494000\t  0.161168\t  0.161025\t  0.161054\t\tCURRENT LEARNING RATE: 0.0035701517376159997\n",
      "previous_iter_valid_loss : 0.16099050641059875\n",
      "\n",
      "    494200\t  0.161134\t  0.160991\t  0.161054\t\tCURRENT LEARNING RATE: 0.0035630185696864207\n",
      "previous_iter_valid_loss : 0.16108059883117676\n",
      "\n",
      "    494400\t  0.161235\t  0.161081\t  0.161054\t\tCURRENT LEARNING RATE: 0.003555899653835871\n",
      "previous_iter_valid_loss : 0.1610114872455597\n",
      "\n",
      "    494600\t  0.161172\t  0.161011\t  0.161053\t\tCURRENT LEARNING RATE: 0.0035487949615886747\n",
      "previous_iter_valid_loss : 0.16101309657096863\n",
      "\n",
      "    494800\t  0.161168\t  0.161013\t  0.161053\t\tCURRENT LEARNING RATE: 0.0035417044645260592\n",
      "previous_iter_valid_loss : 0.1612648367881775\n",
      "\n",
      "    495000\t  0.161438\t  0.161265\t  0.161054\t\tCURRENT LEARNING RATE: 0.0035346281342860247\n",
      "previous_iter_valid_loss : 0.16106055676937103\n",
      "\n",
      "    495200\t  0.161225\t  0.161061\t  0.161054\t\tCURRENT LEARNING RATE: 0.00352756594256324\n",
      "previous_iter_valid_loss : 0.1611032783985138\n",
      "\n",
      "    495400\t  0.161275\t  0.161103\t  0.161054\t\tCURRENT LEARNING RATE: 0.003520517861108926\n",
      "previous_iter_valid_loss : 0.1610313504934311\n",
      "\n",
      "    495600\t  0.161189\t  0.161031\t  0.161054\t\tCURRENT LEARNING RATE: 0.003513483861730753\n",
      "previous_iter_valid_loss : 0.16106855869293213\n",
      "\n",
      "    495800\t  0.161231\t  0.161069\t  0.161054\t\tCURRENT LEARNING RATE: 0.0035064639162927123\n",
      "previous_iter_valid_loss : 0.160994753241539\n",
      "\n",
      "    496000\t  0.161142\t  0.160995\t  0.161054\t\tCURRENT LEARNING RATE: 0.0034994579967150114\n",
      "previous_iter_valid_loss : 0.16110162436962128\n",
      "\n",
      "    496200\t  0.161271\t  0.161102\t  0.161054\t\tCURRENT LEARNING RATE: 0.0034924660749739607\n",
      "previous_iter_valid_loss : 0.1609911322593689\n",
      "\n",
      "    496400\t  0.161139\t  0.160991\t  0.161054\t\tCURRENT LEARNING RATE: 0.0034854881231018695\n",
      "previous_iter_valid_loss : 0.16099441051483154\n",
      "\n",
      "    496600\t  0.161138\t  0.160994\t  0.161053\t\tCURRENT LEARNING RATE: 0.003478524113186918\n",
      "previous_iter_valid_loss : 0.16111062467098236\n",
      "\n",
      "    496800\t  0.161269\t  0.161111\t  0.161054\t\tCURRENT LEARNING RATE: 0.0034715740173730573\n",
      "previous_iter_valid_loss : 0.1610504388809204\n",
      "\n",
      "    497000\t  0.161210\t  0.161050\t  0.161054\t\tCURRENT LEARNING RATE: 0.0034646378078598914\n",
      "previous_iter_valid_loss : 0.1610075980424881\n",
      "\n",
      "    497200\t  0.161156\t  0.161008\t  0.161054\t\tCURRENT LEARNING RATE: 0.00345771545690258\n",
      "previous_iter_valid_loss : 0.16098572313785553\n",
      "\n",
      "    497400\t  0.161140\t  0.160986\t  0.161053\t\tCURRENT LEARNING RATE: 0.003450806936811706\n",
      "previous_iter_valid_loss : 0.1610262095928192\n",
      "\n",
      "    497600\t  0.161156\t  0.161026\t  0.161053\t\tCURRENT LEARNING RATE: 0.003443912219953181\n",
      "previous_iter_valid_loss : 0.16110068559646606\n",
      "\n",
      "    497800\t  0.161238\t  0.161101\t  0.161053\t\tCURRENT LEARNING RATE: 0.003437031278748124\n",
      "previous_iter_valid_loss : 0.16100789606571198\n",
      "\n",
      "    498000\t  0.161165\t  0.161008\t  0.161053\t\tCURRENT LEARNING RATE: 0.0034301640856727682\n",
      "previous_iter_valid_loss : 0.16097521781921387\n",
      "\n",
      "    498200\t  0.161102\t  0.160975\t  0.161053\t\tCURRENT LEARNING RATE: 0.003423310613258329\n",
      "previous_iter_valid_loss : 0.16107818484306335\n",
      "\n",
      "    498400\t  0.161234\t  0.161078\t  0.161053\t\tCURRENT LEARNING RATE: 0.0034164708340909066\n",
      "previous_iter_valid_loss : 0.1609775274991989\n",
      "\n",
      "    498600\t  0.161118\t  0.160978\t  0.161053\t\tCURRENT LEARNING RATE: 0.0034096447208113727\n",
      "previous_iter_valid_loss : 0.16105087101459503\n",
      "\n",
      "    498800\t  0.161172\t  0.161051\t  0.161053\t\tCURRENT LEARNING RATE: 0.0034028322461152716\n",
      "previous_iter_valid_loss : 0.16105712950229645\n",
      "\n",
      "    499000\t  0.161203\t  0.161057\t  0.161052\t\tCURRENT LEARNING RATE: 0.003396033382752692\n",
      "previous_iter_valid_loss : 0.16108675301074982\n",
      "\n",
      "    499200\t  0.161232\t  0.161087\t  0.161053\t\tCURRENT LEARNING RATE: 0.0033892481035281714\n",
      "previous_iter_valid_loss : 0.1610424965620041\n",
      "\n",
      "    499400\t  0.161175\t  0.161042\t  0.161053\t\tCURRENT LEARNING RATE: 0.003382476381300581\n",
      "previous_iter_valid_loss : 0.16098341345787048\n",
      "\n",
      "    499600\t  0.161128\t  0.160983\t  0.161053\t\tCURRENT LEARNING RATE: 0.003375718188983029\n",
      "previous_iter_valid_loss : 0.16099467873573303\n",
      "\n",
      "    499800\t  0.161144\t  0.160995\t  0.161053\n",
      "training target distribution using 'run' in 2038.6868 secs\n"
     ]
    }
   ],
   "source": [
    "optimizer_name=PARAMS_m['optimizer_name']\n",
    "print(type(optimizer_name))\n",
    "# optimizer_name = BEST_PARAMS[\"optimizer_name\"].to_string().split()[1]\n",
    "NITERATIONS=PARAMS_m['n_iterations']\n",
    "BATCHSIZE=PARAMS_m['batch_size']\n",
    "comment=''\n",
    "\n",
    "\n",
    "\n",
    "# N_epochs X N_train_examples = N_iterations X batch_size\n",
    "N_epochs = (NITERATIONS * BATCHSIZE) / int(train_x.shape[0])\n",
    "print(f\"training for {NITERATIONS} iteration, which is  {N_epochs} epochs\")\n",
    "\n",
    "\n",
    "filename_model = get_model_filename(target, PARAMS_m)\n",
    "trained_models_dir = \"trained_models\"\n",
    "mkdir(trained_models_dir)\n",
    "# on cluster, Im using another TRAIN directory\n",
    "PATH_model = os.path.join(\n",
    "    IQN_BASE, #the loaction of the repo\n",
    "    \"JupyterBook\", #up tp TRAIN could be combined in a srs dicretory\n",
    "    \"Cluster\", \n",
    "    \"TRAIN\",\n",
    "    trained_models_dir, #/trained_models \n",
    "    filename_model # utils.get_model_filename has the saved file format \n",
    ")\n",
    "\n",
    "#LOAD EITHER TRAINED OR UNTRAINED MODEL\n",
    "# to load untrained model (start training from scratch), uncomment the next line\n",
    "untrained_model = load_untrained_model(PARAMS_m)\n",
    "# to continune training of model (pickup where the previous training left off), uncomment below\n",
    "# trained_model =load_trained_model(PATH=PATH_model, PARAMS=PARAMS_m)\n",
    "\n",
    "IQN_trace = ([], [], [], [])\n",
    "traces_step = int(100)\n",
    "traces_window = traces_step\n",
    "IQN = run(\n",
    "    target=target,\n",
    "    model=untrained_model,\n",
    "    train_x=train_x_z_scaled,\n",
    "    train_t=train_t_z_scaled,\n",
    "    valid_x=test_x_z_scaled,\n",
    "    valid_t=test_t_z_scaled,\n",
    "    traces=IQN_trace,\n",
    "    PARAMS=PARAMS_m,\n",
    "    traces_step=traces_step,\n",
    "    traces_window=traces_window,\n",
    "    save_model=False,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "SAVE_LAST_MODEL=False\n",
    "if SAVE_LAST_MODEL:\n",
    "    # ## Save last iteration of trained model \n",
    "    #dont save the last model, it might be worse than previous iterations, which were automatically savedby model checkpoints\n",
    "\n",
    "    final_path = get_model_filename(target, PARAMS_m).split('.dict')[0]+'_FINAL.dict'\n",
    "\n",
    "    trained_models_dir = \"trained_models\"\n",
    "    mkdir(trained_models_dir)\n",
    "    # on cluster, Im using another TRAIN directory\n",
    "    PATH_final_model = os.path.join(\n",
    "    IQN_BASE, \"JupyterBook\", \"Cluster\", \"TRAIN\", trained_models_dir, final_path\n",
    "    )\n",
    "\n",
    "    save_model(IQN, PATH_final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbab706-934e-4bcb-81c1-d5ca6fae9c88",
   "metadata": {},
   "source": [
    "### 2.4: Train $p_T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "497e7a24-afc4-486f-9bf1-7c11cc1dbdf1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features:\n",
      " ['RecoDatam', 'genDatapT', 'genDataeta', 'genDataphi', 'genDatam', 'tau']\n",
      "\n",
      "Target =  RecoDatapT\n",
      "USING NEW DATASET\n",
      "\n",
      "spliting data for RecoDatapT\n",
      "train_t shape =  (8000000,) train_x shape =  (8000000, 6)\n",
      "\n",
      " Training features:\n",
      "\n",
      "[[ 2.59587    29.4452      0.828187    2.90213     2.85348     0.36130954]\n",
      " [ 5.35538    24.3193     -1.16351     0.636469    5.83685     0.12689925]\n",
      " [ 5.35538    24.3193     -1.16351     0.636469    5.83685     0.96230681]\n",
      " ...\n",
      " [ 6.25659    41.4192     -2.23358    -2.81921     7.19348     0.08421659]\n",
      " [ 6.11213    35.4637     -1.12318     0.356494    6.06597     0.05535172]\n",
      " [ 4.17483    26.5586     -1.09427    -1.49334     4.25409     0.07489863]]\n",
      "valid_t shape =  (1000000,) valid_x shape =  (1000000, 6)\n",
      "test_t shape =  (1000000,) test_x shape =  (1000000, 6)\n",
      "no need to train_test_split since we already have the split dataframes\n",
      "[ 5.55141126e+00  3.27223764e+01  6.98189368e-04 -8.95543973e-04\n",
      "  6.96116528e+00  5.00485136e-01] [ 2.66412454 15.19914133  2.20425356  1.81362773  2.78097831  0.28852734]\n",
      "[ 5.55556745e+00  3.26952341e+01 -1.78188172e-03 -3.83090331e-04\n",
      "  6.96299435e+00  4.99915289e-01] [ 2.66433986 14.93793254  2.20430976  1.81382516  2.78133203  0.28867295]\n",
      "32.881453465999996 16.02400426348493\n",
      "32.86720151648752 15.829355769531851\n",
      "NORMAL UNSCALED DICTIONARY\n",
      "{'genDatapT': {'mean': 32.695234084987476, 'std': 14.937932540562551}, 'genDataeta': {'mean': -0.0017818817154031672, 'std': 2.204309760627079}, 'genDataphi': {'mean': -0.0003830903308450233, 'std': 1.8138251604791067}, 'genDatam': {'mean': 6.962994352358474, 'std': 2.781332025286383}, 'RecoDatapT': {'mean': 32.86720151648752, 'std': 15.829355769531851}, 'RecoDataeta': {'mean': -0.0017898858568513964, 'std': 2.197968491495457}, 'RecoDataphi': {'mean': -0.0004719170328962474, 'std': 1.8144739820043825}, 'RecoDatam': {'mean': 5.555567451922438, 'std': 2.664339857066051}}\n",
      "\n",
      "\n",
      "\n",
      "[-1.81710707e+00  1.48455353e+01  5.96132264e-04 -2.50379668e+00\n",
      " -1.63658184e+00  5.00485136e-01] [0.17834627 6.89519305 1.2152514  0.65207164 0.17568487 0.28852734]\n",
      "[-1.81682884e+00  1.48332220e+01 -7.71183141e-04 -2.50361243e+00\n",
      " -1.63646629e+00  4.99915289e-01] [0.17836068 6.77669391 1.21528238 0.65214262 0.17570722 0.28867295]\n",
      "0.0009003493079555966 1.0122966781963252\n",
      "-1.2048033681821834e-15 1.0000000000000002\n",
      "<class 'str'>\n",
      "training for 500000 iteration, which is  64.0 epochs\n",
      "RegularizedRegressionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=6, out_features=6, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.3)\n",
      "    (2): Linear(in_features=6, out_features=6, bias=True)\n",
      "    (3): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.3)\n",
      "    (5): Linear(in_features=6, out_features=6, bias=True)\n",
      "    (6): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.3)\n",
      "    (8): Linear(in_features=6, out_features=6, bias=True)\n",
      "    (9): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.3)\n",
      "    (11): Linear(in_features=6, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "training IQN \n",
      "Iteration vs average loss\n",
      " iteration\t train-set\t  test-set\n",
      "\t\tCURRENT LEARNING RATE: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous_iter_valid_loss : 0.7253395915031433\n",
      "\n",
      "\n",
      "Current valid loss: 0.7253395915031433;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_4_layer6_hiddenLeakyReLU_activation1024_batchsize500_Kiteration.dict\n",
      "         0\t  0.726839\t  0.725340\n",
      "\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09037208557128906\n",
      "\n",
      "\n",
      "Current valid loss: 0.09037208557128906;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_4_layer6_hiddenLeakyReLU_activation1024_batchsize500_Kiteration.dict\n",
      "       200\t  0.090374\t  0.090372\t  0.090372\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.19729456305503845\n",
      "\n",
      "       400\t  0.196803\t  0.197295\t  0.197295\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.0894428938627243\n",
      "\n",
      "\n",
      "Current valid loss: 0.0894428938627243;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_4_layer6_hiddenLeakyReLU_activation1024_batchsize500_Kiteration.dict\n",
      "       600\t  0.089464\t  0.089443\t  0.089443\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08892212808132172\n",
      "\n",
      "\n",
      "Current valid loss: 0.08892212808132172;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_4_layer6_hiddenLeakyReLU_activation1024_batchsize500_Kiteration.dict\n",
      "       800\t  0.088953\t  0.088922\t  0.088922\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.11405529826879501\n",
      "\n",
      "      1000\t  0.114276\t  0.114055\t  0.114055\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.1609402447938919\n",
      "\n",
      "      1200\t  0.161535\t  0.160940\t  0.160940\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.081336610019207\n",
      "\n",
      "\n",
      "Current valid loss: 0.081336610019207;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_4_layer6_hiddenLeakyReLU_activation1024_batchsize500_Kiteration.dict\n",
      "      1400\t  0.081315\t  0.081337\t  0.081337\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08650776743888855\n",
      "\n",
      "      1600\t  0.086391\t  0.086508\t  0.086508\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08125465363264084\n",
      "\n",
      "\n",
      "Current valid loss: 0.08125465363264084;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_4_layer6_hiddenLeakyReLU_activation1024_batchsize500_Kiteration.dict\n",
      "      1800\t  0.081282\t  0.081255\t  0.081255\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08443493396043777\n",
      "\n",
      "      2000\t  0.084452\t  0.084435\t  0.084435\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09058771282434464\n",
      "\n",
      "      2200\t  0.090453\t  0.090588\t  0.090588\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09450387209653854\n",
      "\n",
      "      2400\t  0.094371\t  0.094504\t  0.094504\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.10639704763889313\n",
      "\n",
      "      2600\t  0.106527\t  0.106397\t  0.106397\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.11135931313037872\n",
      "\n",
      "      2800\t  0.111535\t  0.111359\t  0.111359\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09258069843053818\n",
      "\n",
      "      3000\t  0.092301\t  0.092581\t  0.092581\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09315382689237595\n",
      "\n",
      "      3200\t  0.093132\t  0.093154\t  0.093154\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.07851492613554001\n",
      "\n",
      "\n",
      "Current valid loss: 0.07851492613554001;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_4_layer6_hiddenLeakyReLU_activation1024_batchsize500_Kiteration.dict\n",
      "      3400\t  0.078422\t  0.078515\t  0.078515\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.07994622737169266\n",
      "\n",
      "      3600\t  0.079876\t  0.079946\t  0.079946\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.0792020857334137\n",
      "\n",
      "      3800\t  0.079100\t  0.079202\t  0.079202\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.09444626420736313\n",
      "\n",
      "      4000\t  0.094542\t  0.094446\t  0.094446\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.13892197608947754\n",
      "\n",
      "      4200\t  0.139306\t  0.138922\t  0.138922\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.10287129878997803\n",
      "\n",
      "      4400\t  0.102846\t  0.102871\t  0.102871\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.0772266611456871\n",
      "\n",
      "\n",
      "Current valid loss: 0.0772266611456871;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_4_layer6_hiddenLeakyReLU_activation1024_batchsize500_Kiteration.dict\n",
      "      4600\t  0.077116\t  0.077227\t  0.077227\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.08067851513624191\n",
      "\n",
      "      4800\t  0.080616\t  0.080679\t  0.080679\t\tCURRENT LEARNING RATE: 0.5\n",
      "previous_iter_valid_loss : 0.11335882544517517\n",
      "\n",
      "      5000\t  0.113065\t  0.113359\t  0.113359\t\tCURRENT LEARNING RATE: 0.47466443342144476\n",
      "previous_iter_valid_loss : 0.0935012623667717\n",
      "\n",
      "      5200\t  0.093214\t  0.093501\t  0.093501\t\tCURRENT LEARNING RATE: 0.47371605325089916\n",
      "previous_iter_valid_loss : 0.08210857957601547\n",
      "\n",
      "      5400\t  0.082079\t  0.082109\t  0.082109\t\tCURRENT LEARNING RATE: 0.47276956794519814\n",
      "previous_iter_valid_loss : 0.07830415666103363\n",
      "\n",
      "      5600\t  0.078106\t  0.078304\t  0.078304\t\tCURRENT LEARNING RATE: 0.47182497371839927\n",
      "previous_iter_valid_loss : 0.09218419343233109\n",
      "\n",
      "      5800\t  0.092201\t  0.092184\t  0.092184\t\tCURRENT LEARNING RATE: 0.47088226679212436\n",
      "previous_iter_valid_loss : 0.1007029339671135\n",
      "\n",
      "      6000\t  0.100459\t  0.100703\t  0.100703\t\tCURRENT LEARNING RATE: 0.46994144339554444\n",
      "previous_iter_valid_loss : 0.07947206497192383\n",
      "\n",
      "      6200\t  0.079381\t  0.079472\t  0.079472\t\tCURRENT LEARNING RATE: 0.46900249976536473\n",
      "previous_iter_valid_loss : 0.08829504996538162\n",
      "\n",
      "      6400\t  0.088267\t  0.088295\t  0.088295\t\tCURRENT LEARNING RATE: 0.4680654321458094\n",
      "previous_iter_valid_loss : 0.1127038225531578\n",
      "\n",
      "      6600\t  0.112443\t  0.112704\t  0.112704\t\tCURRENT LEARNING RATE: 0.46713023678860677\n",
      "previous_iter_valid_loss : 0.08363369107246399\n",
      "\n",
      "      6800\t  0.083718\t  0.083634\t  0.083634\t\tCURRENT LEARNING RATE: 0.46619690995297414\n",
      "previous_iter_valid_loss : 0.08629041910171509\n",
      "\n",
      "      7000\t  0.086303\t  0.086290\t  0.086290\t\tCURRENT LEARNING RATE: 0.46526544790560287\n",
      "previous_iter_valid_loss : 0.09405119717121124\n",
      "\n",
      "      7200\t  0.094110\t  0.094051\t  0.094051\t\tCURRENT LEARNING RATE: 0.4643358469206436\n",
      "previous_iter_valid_loss : 0.07598548382520676\n",
      "\n",
      "\n",
      "Current valid loss: 0.07598548382520676;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_4_layer6_hiddenLeakyReLU_activation1024_batchsize500_Kiteration.dict\n",
      "      7400\t  0.075855\t  0.075985\t  0.075985\t\tCURRENT LEARNING RATE: 0.4634081032796911\n",
      "previous_iter_valid_loss : 0.09579257667064667\n",
      "\n",
      "      7600\t  0.095484\t  0.095793\t  0.095793\t\tCURRENT LEARNING RATE: 0.46248221327176964\n",
      "previous_iter_valid_loss : 0.07963523268699646\n",
      "\n",
      "      7800\t  0.079450\t  0.079635\t  0.079635\t\tCURRENT LEARNING RATE: 0.4615581731933179\n",
      "previous_iter_valid_loss : 0.08074354380369186\n",
      "\n",
      "      8000\t  0.080686\t  0.080744\t  0.080744\t\tCURRENT LEARNING RATE: 0.46063597934817435\n",
      "previous_iter_valid_loss : 0.09867624938488007\n",
      "\n",
      "      8200\t  0.098429\t  0.098676\t  0.098676\t\tCURRENT LEARNING RATE: 0.45971562804756233\n",
      "previous_iter_valid_loss : 0.07767944037914276\n",
      "\n",
      "      8400\t  0.077711\t  0.077679\t  0.077679\t\tCURRENT LEARNING RATE: 0.45879711561007547\n",
      "previous_iter_valid_loss : 0.09058897197246552\n",
      "\n",
      "      8600\t  0.090409\t  0.090589\t  0.090589\t\tCURRENT LEARNING RATE: 0.4578804383616628\n",
      "previous_iter_valid_loss : 0.09570673108100891\n",
      "\n",
      "      8800\t  0.095628\t  0.095707\t  0.095707\t\tCURRENT LEARNING RATE: 0.4569655926356141\n",
      "previous_iter_valid_loss : 0.08867848664522171\n",
      "\n",
      "      9000\t  0.088704\t  0.088678\t  0.088678\t\tCURRENT LEARNING RATE: 0.4560525747725452\n",
      "previous_iter_valid_loss : 0.09247340261936188\n",
      "\n",
      "      9200\t  0.092504\t  0.092473\t  0.092473\t\tCURRENT LEARNING RATE: 0.4551413811203835\n",
      "previous_iter_valid_loss : 0.07989270985126495\n",
      "\n",
      "      9400\t  0.079700\t  0.079893\t  0.079893\t\tCURRENT LEARNING RATE: 0.4542320080343531\n",
      "previous_iter_valid_loss : 0.08531922101974487\n",
      "\n",
      "      9600\t  0.085275\t  0.085319\t  0.085319\t\tCURRENT LEARNING RATE: 0.45332445187696047\n",
      "previous_iter_valid_loss : 0.07861262559890747\n",
      "\n",
      "      9800\t  0.078514\t  0.078613\t  0.078613\t\tCURRENT LEARNING RATE: 0.45241870901797976\n",
      "previous_iter_valid_loss : 0.09460040926933289\n",
      "\n",
      "     10000\t  0.094313\t  0.094600\t  0.094600\t\tCURRENT LEARNING RATE: 0.4515147758344384\n",
      "previous_iter_valid_loss : 0.08119294047355652\n",
      "\n",
      "     10200\t  0.081169\t  0.081193\t  0.081193\t\tCURRENT LEARNING RATE: 0.4506126487106024\n",
      "previous_iter_valid_loss : 0.08103863894939423\n",
      "\n",
      "     10400\t  0.080824\t  0.081039\t  0.081039\t\tCURRENT LEARNING RATE: 0.449712324037962\n",
      "previous_iter_valid_loss : 0.08238470554351807\n",
      "\n",
      "     10600\t  0.082302\t  0.082385\t  0.082385\t\tCURRENT LEARNING RATE: 0.44881379821521744\n",
      "previous_iter_valid_loss : 0.08065546303987503\n",
      "\n",
      "     10800\t  0.080677\t  0.080655\t  0.080655\t\tCURRENT LEARNING RATE: 0.4479170676482641\n",
      "previous_iter_valid_loss : 0.08804209530353546\n",
      "\n",
      "     11000\t  0.088208\t  0.088042\t  0.088042\t\tCURRENT LEARNING RATE: 0.4470221287501786\n",
      "previous_iter_valid_loss : 0.07533640414476395\n",
      "\n",
      "\n",
      "Current valid loss: 0.07533640414476395;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_4_layer6_hiddenLeakyReLU_activation1024_batchsize500_Kiteration.dict\n",
      "     11200\t  0.075251\t  0.075336\t  0.075336\t\tCURRENT LEARNING RATE: 0.44612897794120415\n",
      "previous_iter_valid_loss : 0.07596022635698318\n",
      "\n",
      "     11400\t  0.075789\t  0.075960\t  0.075960\t\tCURRENT LEARNING RATE: 0.4452376116487363\n",
      "previous_iter_valid_loss : 0.10068009793758392\n",
      "\n",
      "     11600\t  0.100473\t  0.100680\t  0.100680\t\tCURRENT LEARNING RATE: 0.4443480263073087\n",
      "previous_iter_valid_loss : 0.08066967129707336\n",
      "\n",
      "     11800\t  0.080532\t  0.080670\t  0.080670\t\tCURRENT LEARNING RATE: 0.44346021835857874\n",
      "previous_iter_valid_loss : 0.07816553860902786\n",
      "\n",
      "     12000\t  0.077993\t  0.078166\t  0.078166\t\tCURRENT LEARNING RATE: 0.44257418425131356\n",
      "previous_iter_valid_loss : 0.0976162925362587\n",
      "\n",
      "     12200\t  0.097225\t  0.097616\t  0.097616\t\tCURRENT LEARNING RATE: 0.44168992044137545\n",
      "previous_iter_valid_loss : 0.08118240535259247\n",
      "\n",
      "     12400\t  0.080953\t  0.081182\t  0.081182\t\tCURRENT LEARNING RATE: 0.44080742339170803\n",
      "previous_iter_valid_loss : 0.08186676353216171\n",
      "\n",
      "     12600\t  0.081615\t  0.081867\t  0.081867\t\tCURRENT LEARNING RATE: 0.4399266895723219\n",
      "previous_iter_valid_loss : 0.07844797521829605\n",
      "\n",
      "     12800\t  0.078287\t  0.078448\t  0.078448\t\tCURRENT LEARNING RATE: 0.43904771546028065\n",
      "previous_iter_valid_loss : 0.08497157692909241\n",
      "\n",
      "     13000\t  0.084743\t  0.084972\t  0.084972\t\tCURRENT LEARNING RATE: 0.4381704975396866\n",
      "previous_iter_valid_loss : 0.07572290301322937\n",
      "\n",
      "     13200\t  0.075607\t  0.075723\t  0.075723\t\tCURRENT LEARNING RATE: 0.437295032301667\n",
      "previous_iter_valid_loss : 0.0800107941031456\n",
      "\n",
      "     13400\t  0.079910\t  0.080011\t  0.080011\t\tCURRENT LEARNING RATE: 0.43642131624435965\n",
      "previous_iter_valid_loss : 0.08604462444782257\n",
      "\n",
      "     13600\t  0.085757\t  0.086045\t  0.086045\t\tCURRENT LEARNING RATE: 0.4355493458728992\n",
      "previous_iter_valid_loss : 0.07695168256759644\n",
      "\n",
      "     13800\t  0.076840\t  0.076952\t  0.076952\t\tCURRENT LEARNING RATE: 0.43467911769940293\n",
      "previous_iter_valid_loss : 0.0825415775179863\n",
      "\n",
      "     14000\t  0.082320\t  0.082542\t  0.082542\t\tCURRENT LEARNING RATE: 0.433810628242957\n",
      "previous_iter_valid_loss : 0.08081548660993576\n",
      "\n",
      "     14200\t  0.080671\t  0.080815\t  0.080815\t\tCURRENT LEARNING RATE: 0.4329438740296025\n",
      "previous_iter_valid_loss : 0.08027877658605576\n",
      "\n",
      "     14400\t  0.080360\t  0.080279\t  0.080279\t\tCURRENT LEARNING RATE: 0.4320788515923214\n",
      "previous_iter_valid_loss : 0.09123367071151733\n",
      "\n",
      "     14600\t  0.090974\t  0.091234\t  0.091234\t\tCURRENT LEARNING RATE: 0.43121555747102275\n",
      "previous_iter_valid_loss : 0.08359639346599579\n",
      "\n",
      "     14800\t  0.083392\t  0.083596\t  0.083596\t\tCURRENT LEARNING RATE: 0.4303539882125289\n",
      "previous_iter_valid_loss : 0.08757348358631134\n",
      "\n",
      "     15000\t  0.087265\t  0.087573\t  0.087573\t\tCURRENT LEARNING RATE: 0.4294941403705617\n",
      "previous_iter_valid_loss : 0.08899527788162231\n",
      "\n",
      "     15200\t  0.088960\t  0.088995\t  0.088995\t\tCURRENT LEARNING RATE: 0.42863601050572875\n",
      "previous_iter_valid_loss : 0.07553116977214813\n",
      "\n",
      "     15400\t  0.075444\t  0.075531\t  0.075531\t\tCURRENT LEARNING RATE: 0.42777959518550923\n",
      "previous_iter_valid_loss : 0.07868394255638123\n",
      "\n",
      "     15600\t  0.078475\t  0.078684\t  0.078684\t\tCURRENT LEARNING RATE: 0.42692489098424086\n",
      "previous_iter_valid_loss : 0.09879223257303238\n",
      "\n",
      "     15800\t  0.098443\t  0.098792\t  0.098792\t\tCURRENT LEARNING RATE: 0.4260718944831057\n",
      "previous_iter_valid_loss : 0.08023978769779205\n",
      "\n",
      "     16000\t  0.080029\t  0.080240\t  0.080240\t\tCURRENT LEARNING RATE: 0.4252206022701165\n",
      "previous_iter_valid_loss : 0.07568059116601944\n",
      "\n",
      "     16200\t  0.075528\t  0.075681\t  0.075681\t\tCURRENT LEARNING RATE: 0.4243710109401034\n",
      "previous_iter_valid_loss : 0.09908003360033035\n",
      "\n",
      "     16400\t  0.098688\t  0.099080\t  0.099080\t\tCURRENT LEARNING RATE: 0.4235231170946998\n",
      "previous_iter_valid_loss : 0.0755963921546936\n",
      "\n",
      "     16600\t  0.075485\t  0.075596\t  0.075596\t\tCURRENT LEARNING RATE: 0.4226769173423294\n",
      "previous_iter_valid_loss : 0.09877835214138031\n",
      "\n",
      "     16800\t  0.098640\t  0.098778\t  0.098778\t\tCURRENT LEARNING RATE: 0.42183240829819185\n",
      "previous_iter_valid_loss : 0.1130271628499031\n",
      "\n",
      "     17000\t  0.112661\t  0.113027\t  0.113027\t\tCURRENT LEARNING RATE: 0.42098958658424995\n",
      "previous_iter_valid_loss : 0.08365149050951004\n",
      "\n",
      "     17200\t  0.083420\t  0.083651\t  0.083651\t\tCURRENT LEARNING RATE: 0.4201484488292157\n",
      "previous_iter_valid_loss : 0.07907865196466446\n",
      "\n",
      "     17400\t  0.078945\t  0.079079\t  0.079079\t\tCURRENT LEARNING RATE: 0.419308991668537\n",
      "previous_iter_valid_loss : 0.07608076930046082\n",
      "\n",
      "     17600\t  0.075918\t  0.076081\t  0.076081\t\tCURRENT LEARNING RATE: 0.41847121174438406\n",
      "previous_iter_valid_loss : 0.08477187156677246\n",
      "\n",
      "     17800\t  0.084549\t  0.084772\t  0.084772\t\tCURRENT LEARNING RATE: 0.417635105705636\n",
      "previous_iter_valid_loss : 0.08090606331825256\n",
      "\n",
      "     18000\t  0.080892\t  0.080906\t  0.080906\t\tCURRENT LEARNING RATE: 0.41680067020786765\n",
      "previous_iter_valid_loss : 0.11210432648658752\n",
      "\n",
      "     18200\t  0.111758\t  0.112104\t  0.112104\t\tCURRENT LEARNING RATE: 0.4159679019133359\n",
      "previous_iter_valid_loss : 0.08393601328134537\n",
      "\n",
      "     18400\t  0.083895\t  0.083936\t  0.083936\t\tCURRENT LEARNING RATE: 0.4151367974909663\n",
      "previous_iter_valid_loss : 0.09702126681804657\n",
      "\n",
      "     18600\t  0.097104\t  0.097021\t  0.097021\t\tCURRENT LEARNING RATE: 0.4143073536163403\n",
      "previous_iter_valid_loss : 0.07813951373100281\n",
      "\n",
      "     18800\t  0.078117\t  0.078140\t  0.078140\t\tCURRENT LEARNING RATE: 0.41347956697168115\n",
      "previous_iter_valid_loss : 0.0843975767493248\n",
      "\n",
      "     19000\t  0.084194\t  0.084398\t  0.084398\t\tCURRENT LEARNING RATE: 0.41265343424584117\n",
      "previous_iter_valid_loss : 0.080919548869133\n",
      "\n",
      "     19200\t  0.080792\t  0.080920\t  0.080920\t\tCURRENT LEARNING RATE: 0.41182895213428844\n",
      "previous_iter_valid_loss : 0.08333096653223038\n",
      "\n",
      "     19400\t  0.083217\t  0.083331\t  0.083331\t\tCURRENT LEARNING RATE: 0.41100611733909326\n",
      "previous_iter_valid_loss : 0.08506018668413162\n",
      "\n",
      "     19600\t  0.084856\t  0.085060\t  0.085060\t\tCURRENT LEARNING RATE: 0.41018492656891553\n",
      "previous_iter_valid_loss : 0.07881457358598709\n",
      "\n",
      "     19800\t  0.078716\t  0.078815\t  0.078815\t\tCURRENT LEARNING RATE: 0.4093653765389909\n",
      "previous_iter_valid_loss : 0.08120404928922653\n",
      "\n",
      "     20000\t  0.081239\t  0.081204\t  0.081204\t\tCURRENT LEARNING RATE: 0.4085474639711183\n",
      "previous_iter_valid_loss : 0.07810379564762115\n",
      "\n",
      "     20200\t  0.077980\t  0.078104\t  0.078104\t\tCURRENT LEARNING RATE: 0.40773118559364635\n",
      "previous_iter_valid_loss : 0.09697847068309784\n",
      "\n",
      "     20400\t  0.097026\t  0.096978\t  0.096978\t\tCURRENT LEARNING RATE: 0.40691653814146034\n",
      "previous_iter_valid_loss : 0.08699081093072891\n",
      "\n",
      "     20600\t  0.086998\t  0.086991\t  0.086991\t\tCURRENT LEARNING RATE: 0.40610351835596953\n",
      "previous_iter_valid_loss : 0.08306491374969482\n",
      "\n",
      "     20800\t  0.083080\t  0.083065\t  0.083065\t\tCURRENT LEARNING RATE: 0.40529212298509354\n",
      "previous_iter_valid_loss : 0.08751660585403442\n",
      "\n",
      "     21000\t  0.087290\t  0.087517\t  0.087517\t\tCURRENT LEARNING RATE: 0.4044823487832499\n",
      "previous_iter_valid_loss : 0.08130128681659698\n",
      "\n",
      "     21200\t  0.081231\t  0.081301\t  0.081301\t\tCURRENT LEARNING RATE: 0.40367419251134073\n",
      "previous_iter_valid_loss : 0.07996461540460587\n",
      "\n",
      "     21400\t  0.079891\t  0.079965\t  0.079965\t\tCURRENT LEARNING RATE: 0.4028676509367398\n",
      "previous_iter_valid_loss : 0.1066085621714592\n",
      "\n",
      "     21600\t  0.106197\t  0.106609\t  0.106609\t\tCURRENT LEARNING RATE: 0.4020627208332798\n",
      "previous_iter_valid_loss : 0.09143471717834473\n",
      "\n",
      "     21800\t  0.091414\t  0.091435\t  0.091435\t\tCURRENT LEARNING RATE: 0.40125939898123925\n",
      "previous_iter_valid_loss : 0.08357813954353333\n",
      "\n",
      "     22000\t  0.083471\t  0.083578\t  0.083578\t\tCURRENT LEARNING RATE: 0.4004576821673296\n",
      "previous_iter_valid_loss : 0.09705560654401779\n",
      "\n",
      "     22200\t  0.097173\t  0.097056\t  0.097056\t\tCURRENT LEARNING RATE: 0.39965756718468254\n",
      "previous_iter_valid_loss : 0.10190702229738235\n",
      "\n",
      "     22400\t  0.101963\t  0.101907\t  0.101907\t\tCURRENT LEARNING RATE: 0.3988590508328371\n",
      "previous_iter_valid_loss : 0.08857965469360352\n",
      "\n",
      "     22600\t  0.088369\t  0.088580\t  0.088580\t\tCURRENT LEARNING RATE: 0.3980621299177269\n",
      "previous_iter_valid_loss : 0.08820313960313797\n",
      "\n",
      "     22800\t  0.088212\t  0.088203\t  0.088203\t\tCURRENT LEARNING RATE: 0.397266801251667\n",
      "previous_iter_valid_loss : 0.08906928449869156\n",
      "\n",
      "     23000\t  0.088813\t  0.089069\t  0.089069\t\tCURRENT LEARNING RATE: 0.39647306165334184\n",
      "previous_iter_valid_loss : 0.09533998370170593\n",
      "\n",
      "     23200\t  0.095243\t  0.095340\t  0.095340\t\tCURRENT LEARNING RATE: 0.3956809079477919\n",
      "previous_iter_valid_loss : 0.08208390325307846\n",
      "\n",
      "     23400\t  0.082067\t  0.082084\t  0.082084\t\tCURRENT LEARNING RATE: 0.39489033696640136\n",
      "previous_iter_valid_loss : 0.08374564349651337\n",
      "\n",
      "     23600\t  0.083671\t  0.083746\t  0.083746\t\tCURRENT LEARNING RATE: 0.3941013455468852\n",
      "previous_iter_valid_loss : 0.09729322046041489\n",
      "\n",
      "     23800\t  0.097541\t  0.097293\t  0.097293\t\tCURRENT LEARNING RATE: 0.39331393053327673\n",
      "previous_iter_valid_loss : 0.08746566623449326\n",
      "\n",
      "     24000\t  0.087348\t  0.087466\t  0.087466\t\tCURRENT LEARNING RATE: 0.3925280887759148\n",
      "previous_iter_valid_loss : 0.09345024824142456\n",
      "\n",
      "     24200\t  0.093153\t  0.093450\t  0.093450\t\tCURRENT LEARNING RATE: 0.39174381713143125\n",
      "previous_iter_valid_loss : 0.08939113467931747\n",
      "\n",
      "     24400\t  0.089301\t  0.089391\t  0.089391\t\tCURRENT LEARNING RATE: 0.3909611124627386\n",
      "previous_iter_valid_loss : 0.08379755914211273\n",
      "\n",
      "     24600\t  0.083827\t  0.083798\t  0.083798\t\tCURRENT LEARNING RATE: 0.39017997163901713\n",
      "previous_iter_valid_loss : 0.08820799738168716\n",
      "\n",
      "     24800\t  0.088033\t  0.088208\t  0.088208\t\tCURRENT LEARNING RATE: 0.38940039153570244\n",
      "previous_iter_valid_loss : 0.0825725719332695\n",
      "\n",
      "     25000\t  0.082616\t  0.082573\t  0.082573\t\tCURRENT LEARNING RATE: 0.38862236903447306\n",
      "previous_iter_valid_loss : 0.09443085640668869\n",
      "\n",
      "     25200\t  0.094667\t  0.094431\t  0.094431\t\tCURRENT LEARNING RATE: 0.387845901023238\n",
      "previous_iter_valid_loss : 0.08108855038881302\n",
      "\n",
      "     25400\t  0.081042\t  0.081089\t  0.081089\t\tCURRENT LEARNING RATE: 0.3870709843961242\n",
      "previous_iter_valid_loss : 0.09611552953720093\n",
      "\n",
      "     25600\t  0.096088\t  0.096116\t  0.096116\t\tCURRENT LEARNING RATE: 0.386297616053464\n",
      "previous_iter_valid_loss : 0.08160601556301117\n",
      "\n",
      "     25800\t  0.081411\t  0.081606\t  0.081606\t\tCURRENT LEARNING RATE: 0.3855257929017831\n",
      "previous_iter_valid_loss : 0.0793200135231018\n",
      "\n",
      "     26000\t  0.079312\t  0.079320\t  0.079320\t\tCURRENT LEARNING RATE: 0.3847555118537879\n",
      "previous_iter_valid_loss : 0.07985750585794449\n",
      "\n",
      "     26200\t  0.079707\t  0.079858\t  0.079858\t\tCURRENT LEARNING RATE: 0.38398676982835306\n",
      "previous_iter_valid_loss : 0.08213718980550766\n",
      "\n",
      "     26400\t  0.081933\t  0.082137\t  0.082137\t\tCURRENT LEARNING RATE: 0.3832195637505096\n",
      "previous_iter_valid_loss : 0.08343250304460526\n",
      "\n",
      "     26600\t  0.083303\t  0.083433\t  0.083433\t\tCURRENT LEARNING RATE: 0.382453890551432\n",
      "previous_iter_valid_loss : 0.08199984580278397\n",
      "\n",
      "     26800\t  0.082067\t  0.082000\t  0.082000\t\tCURRENT LEARNING RATE: 0.3816897471684266\n",
      "previous_iter_valid_loss : 0.08697836101055145\n",
      "\n",
      "     27000\t  0.087010\t  0.086978\t  0.086978\t\tCURRENT LEARNING RATE: 0.3809271305449188\n",
      "previous_iter_valid_loss : 0.07847114652395248\n",
      "\n",
      "     27200\t  0.078370\t  0.078471\t  0.078471\t\tCURRENT LEARNING RATE: 0.38016603763044104\n",
      "previous_iter_valid_loss : 0.08092569559812546\n",
      "\n",
      "     27400\t  0.080969\t  0.080926\t  0.080926\t\tCURRENT LEARNING RATE: 0.37940646538062067\n",
      "previous_iter_valid_loss : 0.07940883934497833\n",
      "\n",
      "     27600\t  0.079414\t  0.079409\t  0.079409\t\tCURRENT LEARNING RATE: 0.37864841075716776\n",
      "previous_iter_valid_loss : 0.07752898335456848\n",
      "\n",
      "     27800\t  0.077507\t  0.077529\t  0.077529\t\tCURRENT LEARNING RATE: 0.37789187072786273\n",
      "previous_iter_valid_loss : 0.08532571792602539\n",
      "\n",
      "     28000\t  0.085248\t  0.085326\t  0.085326\t\tCURRENT LEARNING RATE: 0.3771368422665445\n",
      "previous_iter_valid_loss : 0.08118265867233276\n",
      "\n",
      "     28200\t  0.081246\t  0.081183\t  0.081183\t\tCURRENT LEARNING RATE: 0.3763833223530981\n",
      "previous_iter_valid_loss : 0.09406164288520813\n",
      "\n",
      "     28400\t  0.093917\t  0.094062\t  0.094062\t\tCURRENT LEARNING RATE: 0.375631307973443\n",
      "previous_iter_valid_loss : 0.08004887402057648\n",
      "\n",
      "     28600\t  0.079904\t  0.080049\t  0.080049\t\tCURRENT LEARNING RATE: 0.37488079611952063\n",
      "previous_iter_valid_loss : 0.07898778468370438\n",
      "\n",
      "     28800\t  0.078857\t  0.078988\t  0.078988\t\tCURRENT LEARNING RATE: 0.37413178378928263\n",
      "previous_iter_valid_loss : 0.07711529731750488\n",
      "\n",
      "     29000\t  0.077018\t  0.077115\t  0.077115\t\tCURRENT LEARNING RATE: 0.37338426798667856\n",
      "previous_iter_valid_loss : 0.09551160782575607\n",
      "\n",
      "     29200\t  0.095442\t  0.095512\t  0.095512\t\tCURRENT LEARNING RATE: 0.37263824572164433\n",
      "previous_iter_valid_loss : 0.08335953950881958\n",
      "\n",
      "     29400\t  0.083307\t  0.083360\t  0.083360\t\tCURRENT LEARNING RATE: 0.3718937140100898\n",
      "previous_iter_valid_loss : 0.0809970498085022\n",
      "\n",
      "     29600\t  0.080969\t  0.080997\t  0.080997\t\tCURRENT LEARNING RATE: 0.3711506698738872\n",
      "previous_iter_valid_loss : 0.08379406481981277\n",
      "\n",
      "     29800\t  0.083870\t  0.083794\t  0.083794\t\tCURRENT LEARNING RATE: 0.37040911034085894\n",
      "previous_iter_valid_loss : 0.0798066109418869\n",
      "\n",
      "     30000\t  0.079811\t  0.079807\t  0.079807\t\tCURRENT LEARNING RATE: 0.36966903244476595\n",
      "previous_iter_valid_loss : 0.07916951924562454\n",
      "\n",
      "     30200\t  0.079145\t  0.079170\t  0.079170\t\tCURRENT LEARNING RATE: 0.36893043322529556\n",
      "previous_iter_valid_loss : 0.08165764808654785\n",
      "\n",
      "     30400\t  0.081560\t  0.081658\t  0.081658\t\tCURRENT LEARNING RATE: 0.36819330972805003\n",
      "previous_iter_valid_loss : 0.07918167859315872\n",
      "\n",
      "     30600\t  0.079151\t  0.079182\t  0.079182\t\tCURRENT LEARNING RATE: 0.36745765900453436\n",
      "previous_iter_valid_loss : 0.08992639929056168\n",
      "\n",
      "     30800\t  0.089865\t  0.089926\t  0.089926\t\tCURRENT LEARNING RATE: 0.3667234781121446\n",
      "previous_iter_valid_loss : 0.07794839888811111\n",
      "\n",
      "     31000\t  0.077881\t  0.077948\t  0.077948\t\tCURRENT LEARNING RATE: 0.3659907641141563\n",
      "previous_iter_valid_loss : 0.09081212431192398\n",
      "\n",
      "     31200\t  0.090543\t  0.090812\t  0.090812\t\tCURRENT LEARNING RATE: 0.36525951407971247\n",
      "previous_iter_valid_loss : 0.07852224260568619\n",
      "\n",
      "     31400\t  0.078387\t  0.078522\t  0.078522\t\tCURRENT LEARNING RATE: 0.3645297250838119\n",
      "previous_iter_valid_loss : 0.07656273245811462\n",
      "\n",
      "     31600\t  0.076434\t  0.076563\t  0.076563\t\tCURRENT LEARNING RATE: 0.36380139420729773\n",
      "previous_iter_valid_loss : 0.08120640367269516\n",
      "\n",
      "     31800\t  0.080978\t  0.081206\t  0.081206\t\tCURRENT LEARNING RATE: 0.36307451853684547\n",
      "previous_iter_valid_loss : 0.08052994310855865\n",
      "\n",
      "     32000\t  0.080392\t  0.080530\t  0.080530\t\tCURRENT LEARNING RATE: 0.36234909516495145\n",
      "previous_iter_valid_loss : 0.07851029932498932\n",
      "\n",
      "     32200\t  0.078387\t  0.078510\t  0.078510\t\tCURRENT LEARNING RATE: 0.3616251211899212\n",
      "previous_iter_valid_loss : 0.08122935891151428\n",
      "\n",
      "     32400\t  0.081284\t  0.081229\t  0.081229\t\tCURRENT LEARNING RATE: 0.3609025937158579\n",
      "previous_iter_valid_loss : 0.08076173067092896\n",
      "\n",
      "     32600\t  0.080715\t  0.080762\t  0.080762\t\tCURRENT LEARNING RATE: 0.3601815098526507\n",
      "previous_iter_valid_loss : 0.07872950285673141\n",
      "\n",
      "     32800\t  0.078707\t  0.078730\t  0.078730\t\tCURRENT LEARNING RATE: 0.3594618667159631\n",
      "previous_iter_valid_loss : 0.07938462495803833\n",
      "\n",
      "     33000\t  0.079303\t  0.079385\t  0.079385\t\tCURRENT LEARNING RATE: 0.35874366142722164\n",
      "previous_iter_valid_loss : 0.09150546789169312\n",
      "\n",
      "     33200\t  0.091241\t  0.091505\t  0.091505\t\tCURRENT LEARNING RATE: 0.35802689111360425\n",
      "previous_iter_valid_loss : 0.08546507358551025\n",
      "\n",
      "     33400\t  0.085397\t  0.085465\t  0.085465\t\tCURRENT LEARNING RATE: 0.35731155290802863\n",
      "previous_iter_valid_loss : 0.08398088812828064\n",
      "\n",
      "     33600\t  0.083757\t  0.083981\t  0.083981\t\tCURRENT LEARNING RATE: 0.3565976439491411\n",
      "previous_iter_valid_loss : 0.07922451198101044\n",
      "\n",
      "     33800\t  0.079182\t  0.079225\t  0.079225\t\tCURRENT LEARNING RATE: 0.3558851613813048\n",
      "previous_iter_valid_loss : 0.07983149588108063\n",
      "\n",
      "     34000\t  0.079734\t  0.079831\t  0.079831\t\tCURRENT LEARNING RATE: 0.35517410235458863\n",
      "previous_iter_valid_loss : 0.09289299696683884\n",
      "\n",
      "     34200\t  0.092588\t  0.092893\t  0.092893\t\tCURRENT LEARNING RATE: 0.3544644640247554\n",
      "previous_iter_valid_loss : 0.08121423423290253\n",
      "\n",
      "     34400\t  0.081141\t  0.081214\t  0.081214\t\tCURRENT LEARNING RATE: 0.35375624355325086\n",
      "previous_iter_valid_loss : 0.09254622459411621\n",
      "\n",
      "     34600\t  0.092329\t  0.092546\t  0.092546\t\tCURRENT LEARNING RATE: 0.3530494381071922\n",
      "previous_iter_valid_loss : 0.1083838939666748\n",
      "\n",
      "     34800\t  0.108110\t  0.108384\t  0.108384\t\tCURRENT LEARNING RATE: 0.3523440448593567\n",
      "previous_iter_valid_loss : 0.09107005596160889\n",
      "\n",
      "     35000\t  0.090811\t  0.091070\t  0.091070\t\tCURRENT LEARNING RATE: 0.35164006098817047\n",
      "previous_iter_valid_loss : 0.0809788778424263\n",
      "\n",
      "     35200\t  0.080888\t  0.080979\t  0.080979\t\tCURRENT LEARNING RATE: 0.350937483677697\n",
      "previous_iter_valid_loss : 0.08358971774578094\n",
      "\n",
      "     35400\t  0.083479\t  0.083590\t  0.083590\t\tCURRENT LEARNING RATE: 0.3502363101176262\n",
      "previous_iter_valid_loss : 0.09410254657268524\n",
      "\n",
      "     35600\t  0.094150\t  0.094103\t  0.094103\t\tCURRENT LEARNING RATE: 0.34953653750326286\n",
      "previous_iter_valid_loss : 0.11431162059307098\n",
      "\n",
      "     35800\t  0.114597\t  0.114312\t  0.114312\t\tCURRENT LEARNING RATE: 0.3488381630355155\n",
      "previous_iter_valid_loss : 0.10362416505813599\n",
      "\n",
      "     36000\t  0.103434\t  0.103624\t  0.103624\t\tCURRENT LEARNING RATE: 0.3481411839208855\n",
      "previous_iter_valid_loss : 0.08072564005851746\n",
      "\n",
      "     36200\t  0.080816\t  0.080726\t  0.080726\t\tCURRENT LEARNING RATE: 0.3474455973714553\n",
      "previous_iter_valid_loss : 0.0952230840921402\n",
      "\n",
      "     36400\t  0.095131\t  0.095223\t  0.095223\t\tCURRENT LEARNING RATE: 0.3467514006048779\n",
      "previous_iter_valid_loss : 0.09064596891403198\n",
      "\n",
      "     36600\t  0.090540\t  0.090646\t  0.090646\t\tCURRENT LEARNING RATE: 0.3460585908443652\n",
      "previous_iter_valid_loss : 0.09207713603973389\n",
      "\n",
      "     36800\t  0.092074\t  0.092077\t  0.092077\t\tCURRENT LEARNING RATE: 0.34536716531867734\n",
      "previous_iter_valid_loss : 0.08990863710641861\n",
      "\n",
      "     37000\t  0.089929\t  0.089909\t  0.089909\t\tCURRENT LEARNING RATE: 0.3446771212621112\n",
      "previous_iter_valid_loss : 0.1100463718175888\n",
      "\n",
      "     37200\t  0.109905\t  0.110046\t  0.110046\t\tCURRENT LEARNING RATE: 0.34398845591448973\n",
      "previous_iter_valid_loss : 0.10922905057668686\n",
      "\n",
      "     37400\t  0.109300\t  0.109229\t  0.109229\t\tCURRENT LEARNING RATE: 0.3433011665211505\n",
      "previous_iter_valid_loss : 0.0853351503610611\n",
      "\n",
      "     37600\t  0.085254\t  0.085335\t  0.085335\t\tCURRENT LEARNING RATE: 0.34261525033293516\n",
      "previous_iter_valid_loss : 0.10753338038921356\n",
      "\n",
      "     37800\t  0.107757\t  0.107533\t  0.107533\t\tCURRENT LEARNING RATE: 0.3419307046061779\n",
      "previous_iter_valid_loss : 0.07938070595264435\n",
      "\n",
      "     38000\t  0.079358\t  0.079381\t  0.079381\t\tCURRENT LEARNING RATE: 0.34124752660269503\n",
      "previous_iter_valid_loss : 0.08731236308813095\n",
      "\n",
      "     38200\t  0.087294\t  0.087312\t  0.087312\t\tCURRENT LEARNING RATE: 0.34056571358977356\n",
      "previous_iter_valid_loss : 0.10917448252439499\n",
      "\n",
      "     38400\t  0.108959\t  0.109174\t  0.109174\t\tCURRENT LEARNING RATE: 0.3398852628401605\n",
      "previous_iter_valid_loss : 0.12986230850219727\n",
      "\n",
      "     38600\t  0.129779\t  0.129862\t  0.129862\t\tCURRENT LEARNING RATE: 0.339206171632052\n",
      "previous_iter_valid_loss : 0.1150311529636383\n",
      "\n",
      "     38800\t  0.115171\t  0.115031\t  0.115031\t\tCURRENT LEARNING RATE: 0.3385284372490823\n",
      "previous_iter_valid_loss : 0.08295764029026031\n",
      "\n",
      "     39000\t  0.083110\t  0.082958\t  0.082958\t\tCURRENT LEARNING RATE: 0.337852056980313\n",
      "previous_iter_valid_loss : 0.08281141519546509\n",
      "\n",
      "     39200\t  0.082764\t  0.082811\t  0.082811\t\tCURRENT LEARNING RATE: 0.3371770281202221\n",
      "previous_iter_valid_loss : 0.08371934294700623\n",
      "\n",
      "     39400\t  0.083874\t  0.083719\t  0.083719\t\tCURRENT LEARNING RATE: 0.3365033479686932\n",
      "previous_iter_valid_loss : 0.09479125589132309\n",
      "\n",
      "     39600\t  0.094961\t  0.094791\t  0.094791\t\tCURRENT LEARNING RATE: 0.3358310138310049\n",
      "previous_iter_valid_loss : 0.09383770823478699\n",
      "\n",
      "     39800\t  0.093717\t  0.093838\t  0.091849\t\tCURRENT LEARNING RATE: 0.33516002301781966\n",
      "previous_iter_valid_loss : 0.0792984887957573\n",
      "\n",
      "     40000\t  0.079206\t  0.079298\t  0.088618\t\tCURRENT LEARNING RATE: 0.33449037284517336\n",
      "previous_iter_valid_loss : 0.08369803428649902\n",
      "\n",
      "     40200\t  0.083626\t  0.083698\t  0.088585\t\tCURRENT LEARNING RATE: 0.33382206063446446\n",
      "previous_iter_valid_loss : 0.08325180411338806\n",
      "\n",
      "     40400\t  0.083123\t  0.083252\t  0.088015\t\tCURRENT LEARNING RATE: 0.3331550837124432\n",
      "previous_iter_valid_loss : 0.07908058166503906\n",
      "\n",
      "     40600\t  0.079019\t  0.079081\t  0.087963\t\tCURRENT LEARNING RATE: 0.33248943941120096\n",
      "previous_iter_valid_loss : 0.09151232987642288\n",
      "\n",
      "     40800\t  0.091471\t  0.091512\t  0.087976\t\tCURRENT LEARNING RATE: 0.3318251250681597\n",
      "previous_iter_valid_loss : 0.08103397488594055\n",
      "\n",
      "     41000\t  0.081046\t  0.081034\t  0.087811\t\tCURRENT LEARNING RATE: 0.33116213802606115\n",
      "previous_iter_valid_loss : 0.07845822721719742\n",
      "\n",
      "     41200\t  0.078410\t  0.078458\t  0.087398\t\tCURRENT LEARNING RATE: 0.33050047563295626\n",
      "previous_iter_valid_loss : 0.08133336156606674\n",
      "\n",
      "     41400\t  0.081328\t  0.081333\t  0.087398\t\tCURRENT LEARNING RATE: 0.3298401352421945\n",
      "previous_iter_valid_loss : 0.07844698429107666\n",
      "\n",
      "     41600\t  0.078473\t  0.078447\t  0.087358\t\tCURRENT LEARNING RATE: 0.3291811142124136\n",
      "previous_iter_valid_loss : 0.08217117935419083\n",
      "\n",
      "     41800\t  0.082202\t  0.082171\t  0.087363\t\tCURRENT LEARNING RATE: 0.3285234099075284\n",
      "previous_iter_valid_loss : 0.09044001251459122\n",
      "\n",
      "     42000\t  0.090539\t  0.090440\t  0.087393\t\tCURRENT LEARNING RATE: 0.3278670196967209\n",
      "previous_iter_valid_loss : 0.08556292206048965\n",
      "\n",
      "     42200\t  0.085478\t  0.085563\t  0.087368\t\tCURRENT LEARNING RATE: 0.3272119409544293\n",
      "previous_iter_valid_loss : 0.10641062259674072\n",
      "\n",
      "     42400\t  0.106421\t  0.106411\t  0.087427\t\tCURRENT LEARNING RATE: 0.3265581710603378\n",
      "previous_iter_valid_loss : 0.09002215415239334\n",
      "\n",
      "     42600\t  0.089877\t  0.090022\t  0.087345\t\tCURRENT LEARNING RATE: 0.325905707399366\n",
      "previous_iter_valid_loss : 0.07677002251148224\n",
      "\n",
      "     42800\t  0.076783\t  0.076770\t  0.087172\t\tCURRENT LEARNING RATE: 0.32525454736165826\n",
      "previous_iter_valid_loss : 0.07742520421743393\n",
      "\n",
      "     43000\t  0.077444\t  0.077425\t  0.087097\t\tCURRENT LEARNING RATE: 0.3246046883425737\n",
      "previous_iter_valid_loss : 0.09085977077484131\n",
      "\n",
      "     43200\t  0.090950\t  0.090860\t  0.087085\t\tCURRENT LEARNING RATE: 0.3239561277426753\n",
      "previous_iter_valid_loss : 0.07804646342992783\n",
      "\n",
      "     43400\t  0.078088\t  0.078046\t  0.087083\t\tCURRENT LEARNING RATE: 0.3233088629677198\n",
      "previous_iter_valid_loss : 0.093211330473423\n",
      "\n",
      "     43600\t  0.093075\t  0.093211\t  0.087149\t\tCURRENT LEARNING RATE: 0.3226628914286473\n",
      "previous_iter_valid_loss : 0.09407301247119904\n",
      "\n",
      "     43800\t  0.094071\t  0.094073\t  0.087223\t\tCURRENT LEARNING RATE: 0.3220182105415707\n",
      "previous_iter_valid_loss : 0.08948412537574768\n",
      "\n",
      "     44000\t  0.089406\t  0.089484\t  0.087199\t\tCURRENT LEARNING RATE: 0.3213748177277656\n",
      "previous_iter_valid_loss : 0.08162274956703186\n",
      "\n",
      "     44200\t  0.081520\t  0.081623\t  0.086912\t\tCURRENT LEARNING RATE: 0.3207327104136599\n",
      "previous_iter_valid_loss : 0.07785793393850327\n",
      "\n",
      "     44400\t  0.077858\t  0.077858\t  0.086787\t\tCURRENT LEARNING RATE: 0.32009188603082356\n",
      "previous_iter_valid_loss : 0.07779673486948013\n",
      "\n",
      "     44600\t  0.077694\t  0.077797\t  0.086790\t\tCURRENT LEARNING RATE: 0.3194523420159581\n",
      "previous_iter_valid_loss : 0.0880831703543663\n",
      "\n",
      "     44800\t  0.088055\t  0.088083\t  0.086827\t\tCURRENT LEARNING RATE: 0.31881407581088667\n",
      "previous_iter_valid_loss : 0.0801905021071434\n",
      "\n",
      "     45000\t  0.080350\t  0.080191\t  0.086661\t\tCURRENT LEARNING RATE: 0.31817708486254354\n",
      "previous_iter_valid_loss : 0.08302450180053711\n",
      "\n",
      "     45200\t  0.083031\t  0.083025\t  0.086609\t\tCURRENT LEARNING RATE: 0.31754136662296406\n",
      "previous_iter_valid_loss : 0.08924789726734161\n",
      "\n",
      "     45400\t  0.089600\t  0.089248\t  0.086644\t\tCURRENT LEARNING RATE: 0.3169069185492745\n",
      "previous_iter_valid_loss : 0.10246362537145615\n",
      "\n",
      "     45600\t  0.102522\t  0.102464\t  0.086765\t\tCURRENT LEARNING RATE: 0.3162737381036817\n",
      "previous_iter_valid_loss : 0.09962105005979538\n",
      "\n",
      "     45800\t  0.099449\t  0.099621\t  0.086802\t\tCURRENT LEARNING RATE: 0.315641822753463\n",
      "previous_iter_valid_loss : 0.08500292152166367\n",
      "\n",
      "     46000\t  0.085010\t  0.085003\t  0.086724\t\tCURRENT LEARNING RATE: 0.31501116997095613\n",
      "previous_iter_valid_loss : 0.09025561064481735\n",
      "\n",
      "     46200\t  0.090385\t  0.090256\t  0.086778\t\tCURRENT LEARNING RATE: 0.3143817772335492\n",
      "previous_iter_valid_loss : 0.1072758287191391\n",
      "\n",
      "     46400\t  0.107214\t  0.107276\t  0.086873\t\tCURRENT LEARNING RATE: 0.31375364202367034\n",
      "previous_iter_valid_loss : 0.10559447854757309\n",
      "\n",
      "     46600\t  0.105524\t  0.105594\t  0.086837\t\tCURRENT LEARNING RATE: 0.31312676182877797\n",
      "previous_iter_valid_loss : 0.092554472386837\n",
      "\n",
      "     46800\t  0.092720\t  0.092554\t  0.086882\t\tCURRENT LEARNING RATE: 0.3125011341413504\n",
      "previous_iter_valid_loss : 0.09107104688882828\n",
      "\n",
      "     47000\t  0.091004\t  0.091071\t  0.086906\t\tCURRENT LEARNING RATE: 0.3118767564588761\n",
      "previous_iter_valid_loss : 0.08089140057563782\n",
      "\n",
      "     47200\t  0.080876\t  0.080891\t  0.086840\t\tCURRENT LEARNING RATE: 0.3112536262838434\n",
      "previous_iter_valid_loss : 0.08131878077983856\n",
      "\n",
      "     47400\t  0.081250\t  0.081319\t  0.086867\t\tCURRENT LEARNING RATE: 0.3106317411237309\n",
      "previous_iter_valid_loss : 0.07744854688644409\n",
      "\n",
      "     47600\t  0.077481\t  0.077449\t  0.086775\t\tCURRENT LEARNING RATE: 0.310011098490997\n",
      "previous_iter_valid_loss : 0.08691037446260452\n",
      "\n",
      "     47800\t  0.086867\t  0.086910\t  0.086811\t\tCURRENT LEARNING RATE: 0.3093916959030704\n",
      "previous_iter_valid_loss : 0.0828624740242958\n",
      "\n",
      "     48000\t  0.082786\t  0.082862\t  0.086822\t\tCURRENT LEARNING RATE: 0.30877353088234\n",
      "previous_iter_valid_loss : 0.09085047990083694\n",
      "\n",
      "     48200\t  0.090783\t  0.090850\t  0.086783\t\tCURRENT LEARNING RATE: 0.30815660095614483\n",
      "previous_iter_valid_loss : 0.08156340569257736\n",
      "\n",
      "     48400\t  0.081550\t  0.081563\t  0.086802\t\tCURRENT LEARNING RATE: 0.30754090365676434\n",
      "previous_iter_valid_loss : 0.0943005159497261\n",
      "\n",
      "     48600\t  0.094043\t  0.094301\t  0.086821\t\tCURRENT LEARNING RATE: 0.30692643652140855\n",
      "previous_iter_valid_loss : 0.10241985321044922\n",
      "\n",
      "     48800\t  0.102242\t  0.102420\t  0.086854\t\tCURRENT LEARNING RATE: 0.30631319709220806\n",
      "previous_iter_valid_loss : 0.10285012423992157\n",
      "\n",
      "     49000\t  0.102946\t  0.102850\t  0.086925\t\tCURRENT LEARNING RATE: 0.30570118291620435\n",
      "previous_iter_valid_loss : 0.09592685848474503\n",
      "\n",
      "     49200\t  0.095676\t  0.095927\t  0.086942\t\tCURRENT LEARNING RATE: 0.3050903915453399\n",
      "previous_iter_valid_loss : 0.08267395943403244\n",
      "\n",
      "     49400\t  0.082571\t  0.082674\t  0.086956\t\tCURRENT LEARNING RATE: 0.3044808205364484\n",
      "previous_iter_valid_loss : 0.08700596541166306\n",
      "\n",
      "     49600\t  0.086923\t  0.087006\t  0.086965\t\tCURRENT LEARNING RATE: 0.3038724674512451\n",
      "previous_iter_valid_loss : 0.08276272565126419\n",
      "\n",
      "     49800\t  0.082561\t  0.082763\t  0.086985\t\tCURRENT LEARNING RATE: 0.3032653298563167\n",
      "previous_iter_valid_loss : 0.08376972377300262\n",
      "\n",
      "     50000\t  0.083700\t  0.083770\t  0.086931\t\tCURRENT LEARNING RATE: 0.30265940532311214\n",
      "previous_iter_valid_loss : 0.10630350559949875\n",
      "\n",
      "     50200\t  0.106028\t  0.106304\t  0.087057\t\tCURRENT LEARNING RATE: 0.30205469142793234\n",
      "previous_iter_valid_loss : 0.08527316898107529\n",
      "\n",
      "     50400\t  0.085321\t  0.085273\t  0.087078\t\tCURRENT LEARNING RATE: 0.30145118575192104\n",
      "previous_iter_valid_loss : 0.08326025307178497\n",
      "\n",
      "     50600\t  0.083216\t  0.083260\t  0.087082\t\tCURRENT LEARNING RATE: 0.3008488858810547\n",
      "previous_iter_valid_loss : 0.08777591586112976\n",
      "\n",
      "     50800\t  0.087956\t  0.087776\t  0.087118\t\tCURRENT LEARNING RATE: 0.30024778940613295\n",
      "previous_iter_valid_loss : 0.09251081198453903\n",
      "\n",
      "     51000\t  0.092712\t  0.092511\t  0.087140\t\tCURRENT LEARNING RATE: 0.2996478939227692\n",
      "previous_iter_valid_loss : 0.08163590729236603\n",
      "\n",
      "     51200\t  0.081762\t  0.081636\t  0.087172\t\tCURRENT LEARNING RATE: 0.29904919703138066\n",
      "previous_iter_valid_loss : 0.08513283729553223\n",
      "\n",
      "     51400\t  0.085162\t  0.085133\t  0.087218\t\tCURRENT LEARNING RATE: 0.298451696337179\n",
      "previous_iter_valid_loss : 0.08211751282215118\n",
      "\n",
      "     51600\t  0.082162\t  0.082118\t  0.087125\t\tCURRENT LEARNING RATE: 0.2978553894501606\n",
      "previous_iter_valid_loss : 0.07916897535324097\n",
      "\n",
      "     51800\t  0.079223\t  0.079169\t  0.087117\t\tCURRENT LEARNING RATE: 0.2972602739850972\n",
      "previous_iter_valid_loss : 0.09487250447273254\n",
      "\n",
      "     52000\t  0.095274\t  0.094873\t  0.087201\t\tCURRENT LEARNING RATE: 0.296666347561526\n",
      "previous_iter_valid_loss : 0.08671469986438751\n",
      "\n",
      "     52200\t  0.086938\t  0.086715\t  0.087146\t\tCURRENT LEARNING RATE: 0.29607360780374065\n",
      "previous_iter_valid_loss : 0.08689612150192261\n",
      "\n",
      "     52400\t  0.086834\t  0.086896\t  0.087175\t\tCURRENT LEARNING RATE: 0.2954820523407813\n",
      "previous_iter_valid_loss : 0.07951034605503082\n",
      "\n",
      "     52600\t  0.079471\t  0.079510\t  0.087163\t\tCURRENT LEARNING RATE: 0.2948916788064252\n",
      "previous_iter_valid_loss : 0.08681076765060425\n",
      "\n",
      "     52800\t  0.086572\t  0.086811\t  0.087205\t\tCURRENT LEARNING RATE: 0.2943024848391776\n",
      "previous_iter_valid_loss : 0.0898558720946312\n",
      "\n",
      "     53000\t  0.090129\t  0.089856\t  0.087229\t\tCURRENT LEARNING RATE: 0.2937144680822617\n",
      "previous_iter_valid_loss : 0.0838872566819191\n",
      "\n",
      "     53200\t  0.083719\t  0.083887\t  0.087270\t\tCURRENT LEARNING RATE: 0.2931276261836098\n",
      "previous_iter_valid_loss : 0.09530437737703323\n",
      "\n",
      "     53400\t  0.095553\t  0.095304\t  0.087347\t\tCURRENT LEARNING RATE: 0.29254195679585343\n",
      "previous_iter_valid_loss : 0.08878940343856812\n",
      "\n",
      "     53600\t  0.088958\t  0.088789\t  0.087360\t\tCURRENT LEARNING RATE: 0.29195745757631436\n",
      "previous_iter_valid_loss : 0.08253146708011627\n",
      "\n",
      "     53800\t  0.082416\t  0.082531\t  0.087388\t\tCURRENT LEARNING RATE: 0.2913741261869948\n",
      "previous_iter_valid_loss : 0.08623220771551132\n",
      "\n",
      "     54000\t  0.086347\t  0.086232\t  0.087407\t\tCURRENT LEARNING RATE: 0.29079196029456855\n",
      "previous_iter_valid_loss : 0.07900962233543396\n",
      "\n",
      "     54200\t  0.079008\t  0.079010\t  0.087398\t\tCURRENT LEARNING RATE: 0.2902109575703712\n",
      "previous_iter_valid_loss : 0.07875815778970718\n",
      "\n",
      "     54400\t  0.078799\t  0.078758\t  0.087390\t\tCURRENT LEARNING RATE: 0.289631115690391\n",
      "previous_iter_valid_loss : 0.08555981516838074\n",
      "\n",
      "     54600\t  0.085680\t  0.085560\t  0.087362\t\tCURRENT LEARNING RATE: 0.2890524323352598\n",
      "previous_iter_valid_loss : 0.07882020622491837\n",
      "\n",
      "     54800\t  0.078863\t  0.078820\t  0.087338\t\tCURRENT LEARNING RATE: 0.2884749051902433\n",
      "previous_iter_valid_loss : 0.08190485835075378\n",
      "\n",
      "     55000\t  0.081798\t  0.081905\t  0.087310\t\tCURRENT LEARNING RATE: 0.28789853194523224\n",
      "previous_iter_valid_loss : 0.09000871330499649\n",
      "\n",
      "     55200\t  0.089644\t  0.090009\t  0.087315\t\tCURRENT LEARNING RATE: 0.28732331029473285\n",
      "previous_iter_valid_loss : 0.08594146370887756\n",
      "\n",
      "     55400\t  0.085807\t  0.085941\t  0.087367\t\tCURRENT LEARNING RATE: 0.28674923793785767\n",
      "previous_iter_valid_loss : 0.08508510887622833\n",
      "\n",
      "     55600\t  0.084854\t  0.085085\t  0.087399\t\tCURRENT LEARNING RATE: 0.2861763125783166\n",
      "previous_iter_valid_loss : 0.08418132364749908\n",
      "\n",
      "     55800\t  0.084227\t  0.084181\t  0.087326\t\tCURRENT LEARNING RATE: 0.28560453192440743\n",
      "previous_iter_valid_loss : 0.0834241732954979\n",
      "\n",
      "     56000\t  0.083416\t  0.083424\t  0.087342\t\tCURRENT LEARNING RATE: 0.2850338936890067\n",
      "previous_iter_valid_loss : 0.09670063108205795\n",
      "\n",
      "     56200\t  0.096745\t  0.096701\t  0.087447\t\tCURRENT LEARNING RATE: 0.2844643955895609\n",
      "previous_iter_valid_loss : 0.07612942159175873\n",
      "\n",
      "     56400\t  0.076071\t  0.076129\t  0.087332\t\tCURRENT LEARNING RATE: 0.28389603534807667\n",
      "previous_iter_valid_loss : 0.08773645013570786\n",
      "\n",
      "     56600\t  0.087724\t  0.087736\t  0.087393\t\tCURRENT LEARNING RATE: 0.2833288106911123\n",
      "previous_iter_valid_loss : 0.07873336225748062\n",
      "\n",
      "     56800\t  0.078554\t  0.078733\t  0.087292\t\tCURRENT LEARNING RATE: 0.28276271934976854\n",
      "previous_iter_valid_loss : 0.0806373879313469\n",
      "\n",
      "     57000\t  0.080501\t  0.080637\t  0.087130\t\tCURRENT LEARNING RATE: 0.2821977590596792\n",
      "previous_iter_valid_loss : 0.07895292341709137\n",
      "\n",
      "     57200\t  0.078769\t  0.078953\t  0.087107\t\tCURRENT LEARNING RATE: 0.28163392756100236\n",
      "previous_iter_valid_loss : 0.090033158659935\n",
      "\n",
      "     57400\t  0.089769\t  0.090033\t  0.087162\t\tCURRENT LEARNING RATE: 0.2810712225984112\n",
      "previous_iter_valid_loss : 0.08618125319480896\n",
      "\n",
      "     57600\t  0.085933\t  0.086181\t  0.087212\t\tCURRENT LEARNING RATE: 0.2805096419210853\n",
      "previous_iter_valid_loss : 0.07826685160398483\n",
      "\n",
      "     57800\t  0.078142\t  0.078267\t  0.087180\t\tCURRENT LEARNING RATE: 0.279949183282701\n",
      "previous_iter_valid_loss : 0.07819357514381409\n",
      "\n",
      "     58000\t  0.078100\t  0.078194\t  0.087166\t\tCURRENT LEARNING RATE: 0.2793898444414232\n",
      "previous_iter_valid_loss : 0.08093201369047165\n",
      "\n",
      "     58200\t  0.080940\t  0.080932\t  0.087010\t\tCURRENT LEARNING RATE: 0.2788316231598956\n",
      "previous_iter_valid_loss : 0.0783892571926117\n",
      "\n",
      "     58400\t  0.078235\t  0.078389\t  0.086983\t\tCURRENT LEARNING RATE: 0.27827451720523244\n",
      "previous_iter_valid_loss : 0.07652638852596283\n",
      "\n",
      "     58600\t  0.076402\t  0.076526\t  0.086880\t\tCURRENT LEARNING RATE: 0.2777185243490091\n",
      "previous_iter_valid_loss : 0.08131364732980728\n",
      "\n",
      "     58800\t  0.081259\t  0.081314\t  0.086896\t\tCURRENT LEARNING RATE: 0.27716364236725355\n",
      "previous_iter_valid_loss : 0.08285578340291977\n",
      "\n",
      "     59000\t  0.082640\t  0.082856\t  0.086888\t\tCURRENT LEARNING RATE: 0.27660986904043694\n",
      "previous_iter_valid_loss : 0.08195244520902634\n",
      "\n",
      "     59200\t  0.081750\t  0.081952\t  0.086893\t\tCURRENT LEARNING RATE: 0.2760572021534653\n",
      "previous_iter_valid_loss : 0.09783901274204254\n",
      "\n",
      "     59400\t  0.097588\t  0.097839\t  0.086966\t\tCURRENT LEARNING RATE: 0.27550563949567036\n",
      "previous_iter_valid_loss : 0.08102327585220337\n",
      "\n",
      "     59600\t  0.080863\t  0.081023\t  0.086946\t\tCURRENT LEARNING RATE: 0.2749551788608008\n",
      "previous_iter_valid_loss : 0.0849929079413414\n",
      "\n",
      "     59800\t  0.085001\t  0.084993\t  0.086977\t\tCURRENT LEARNING RATE: 0.2744058180470132\n",
      "previous_iter_valid_loss : 0.08010601252317429\n",
      "\n",
      "     60000\t  0.079898\t  0.080106\t  0.086971\t\tCURRENT LEARNING RATE: 0.27385755485686375\n",
      "previous_iter_valid_loss : 0.08038129657506943\n",
      "\n",
      "     60200\t  0.080327\t  0.080381\t  0.086983\t\tCURRENT LEARNING RATE: 0.2733103870972988\n",
      "previous_iter_valid_loss : 0.0771949514746666\n",
      "\n",
      "     60400\t  0.077046\t  0.077195\t  0.086884\t\tCURRENT LEARNING RATE: 0.2727643125796467\n",
      "previous_iter_valid_loss : 0.08517799526453018\n",
      "\n",
      "     60600\t  0.084921\t  0.085178\t  0.086875\t\tCURRENT LEARNING RATE: 0.27221932911960856\n",
      "previous_iter_valid_loss : 0.08355160802602768\n",
      "\n",
      "     60800\t  0.083299\t  0.083552\t  0.086877\t\tCURRENT LEARNING RATE: 0.2716754345372499\n",
      "previous_iter_valid_loss : 0.07587917149066925\n",
      "\n",
      "     61000\t  0.075777\t  0.075879\t  0.086819\t\tCURRENT LEARNING RATE: 0.2711326266569916\n",
      "previous_iter_valid_loss : 0.0891648679971695\n",
      "\n",
      "     61200\t  0.088911\t  0.089165\t  0.086858\t\tCURRENT LEARNING RATE: 0.27059090330760144\n",
      "previous_iter_valid_loss : 0.08242351561784744\n",
      "\n",
      "     61400\t  0.082436\t  0.082424\t  0.086870\t\tCURRENT LEARNING RATE: 0.2700502623221853\n",
      "previous_iter_valid_loss : 0.07666639238595963\n",
      "\n",
      "     61600\t  0.076500\t  0.076666\t  0.086721\t\tCURRENT LEARNING RATE: 0.2695107015381785\n",
      "previous_iter_valid_loss : 0.0770765170454979\n",
      "\n",
      "     61800\t  0.077021\t  0.077077\t  0.086649\t\tCURRENT LEARNING RATE: 0.26897221879733724\n",
      "previous_iter_valid_loss : 0.08486615866422653\n",
      "\n",
      "     62000\t  0.084744\t  0.084866\t  0.086655\t\tCURRENT LEARNING RATE: 0.26843481194572977\n",
      "previous_iter_valid_loss : 0.08270881325006485\n",
      "\n",
      "     62200\t  0.082565\t  0.082709\t  0.086584\t\tCURRENT LEARNING RATE: 0.267898478833728\n",
      "previous_iter_valid_loss : 0.08141344040632248\n",
      "\n",
      "     62400\t  0.081370\t  0.081413\t  0.086481\t\tCURRENT LEARNING RATE: 0.26736321731599877\n",
      "previous_iter_valid_loss : 0.08159912377595901\n",
      "\n",
      "     62600\t  0.081468\t  0.081599\t  0.086446\t\tCURRENT LEARNING RATE: 0.2668290252514953\n",
      "previous_iter_valid_loss : 0.08396153151988983\n",
      "\n",
      "     62800\t  0.083740\t  0.083962\t  0.086425\t\tCURRENT LEARNING RATE: 0.2662959005034486\n",
      "previous_iter_valid_loss : 0.07673490047454834\n",
      "\n",
      "     63000\t  0.076666\t  0.076735\t  0.086363\t\tCURRENT LEARNING RATE: 0.26576384093935895\n",
      "previous_iter_valid_loss : 0.0780320093035698\n",
      "\n",
      "     63200\t  0.078029\t  0.078032\t  0.086277\t\tCURRENT LEARNING RATE: 0.26523284443098744\n",
      "previous_iter_valid_loss : 0.08002422749996185\n",
      "\n",
      "     63400\t  0.080016\t  0.080024\t  0.086267\t\tCURRENT LEARNING RATE: 0.2647029088543473\n",
      "previous_iter_valid_loss : 0.07799430936574936\n",
      "\n",
      "     63600\t  0.077840\t  0.077994\t  0.086238\t\tCURRENT LEARNING RATE: 0.2641740320896955\n",
      "previous_iter_valid_loss : 0.08099829405546188\n",
      "\n",
      "     63800\t  0.081048\t  0.080998\t  0.086156\t\tCURRENT LEARNING RATE: 0.2636462120215243\n",
      "previous_iter_valid_loss : 0.0855664387345314\n",
      "\n",
      "     64000\t  0.085463\t  0.085566\t  0.086147\t\tCURRENT LEARNING RATE: 0.2631194465385527\n",
      "previous_iter_valid_loss : 0.07822570949792862\n",
      "\n",
      "     64200\t  0.078217\t  0.078226\t  0.086071\t\tCURRENT LEARNING RATE: 0.26259373353371807\n",
      "previous_iter_valid_loss : 0.08279015868902206\n",
      "\n",
      "     64400\t  0.082611\t  0.082790\t  0.086038\t\tCURRENT LEARNING RATE: 0.2620690709041677\n",
      "previous_iter_valid_loss : 0.08821121603250504\n",
      "\n",
      "     64600\t  0.088269\t  0.088211\t  0.086060\t\tCURRENT LEARNING RATE: 0.2615454565512504\n",
      "previous_iter_valid_loss : 0.08524203300476074\n",
      "\n",
      "     64800\t  0.085060\t  0.085242\t  0.086045\t\tCURRENT LEARNING RATE: 0.261022888380508\n",
      "previous_iter_valid_loss : 0.08420603722333908\n",
      "\n",
      "     65000\t  0.084267\t  0.084206\t  0.086053\t\tCURRENT LEARNING RATE: 0.2605013643016672\n",
      "previous_iter_valid_loss : 0.08046779781579971\n",
      "\n",
      "     65200\t  0.080557\t  0.080468\t  0.085983\t\tCURRENT LEARNING RATE: 0.2599808822286309\n",
      "previous_iter_valid_loss : 0.07834984362125397\n",
      "\n",
      "     65400\t  0.078409\t  0.078350\t  0.085970\t\tCURRENT LEARNING RATE: 0.2594614400794702\n",
      "previous_iter_valid_loss : 0.07647935301065445\n",
      "\n",
      "     65600\t  0.076494\t  0.076479\t  0.085871\t\tCURRENT LEARNING RATE: 0.2589430357764157\n",
      "previous_iter_valid_loss : 0.08823304623365402\n",
      "\n",
      "     65800\t  0.088325\t  0.088233\t  0.085904\t\tCURRENT LEARNING RATE: 0.2584256672458496\n",
      "previous_iter_valid_loss : 0.07620410621166229\n",
      "\n",
      "     66000\t  0.076162\t  0.076204\t  0.085889\t\tCURRENT LEARNING RATE: 0.25790933241829705\n",
      "previous_iter_valid_loss : 0.07766155898571014\n",
      "\n",
      "     66200\t  0.077716\t  0.077662\t  0.085878\t\tCURRENT LEARNING RATE: 0.2573940292284181\n",
      "previous_iter_valid_loss : 0.0759912058711052\n",
      "\n",
      "     66400\t  0.075963\t  0.075991\t  0.085847\t\tCURRENT LEARNING RATE: 0.25687975561499915\n",
      "previous_iter_valid_loss : 0.08128079771995544\n",
      "\n",
      "     66600\t  0.081355\t  0.081281\t  0.085836\t\tCURRENT LEARNING RATE: 0.25636650952094525\n",
      "previous_iter_valid_loss : 0.07766524702310562\n",
      "\n",
      "     66800\t  0.077636\t  0.077665\t  0.085815\t\tCURRENT LEARNING RATE: 0.2558542888932712\n",
      "previous_iter_valid_loss : 0.07802596688270569\n",
      "\n",
      "     67000\t  0.078045\t  0.078026\t  0.085770\t\tCURRENT LEARNING RATE: 0.25534309168309394\n",
      "previous_iter_valid_loss : 0.07519274204969406\n",
      "\n",
      "\n",
      "Current valid loss: 0.07519274204969406;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_4_layer6_hiddenLeakyReLU_activation1024_batchsize500_Kiteration.dict\n",
      "     67200\t  0.075129\t  0.075193\t  0.085754\t\tCURRENT LEARNING RATE: 0.2548329158456238\n",
      "previous_iter_valid_loss : 0.07558761537075043\n",
      "\n",
      "     67400\t  0.075599\t  0.075588\t  0.085727\t\tCURRENT LEARNING RATE: 0.25432375934015683\n",
      "previous_iter_valid_loss : 0.07876895368099213\n",
      "\n",
      "     67600\t  0.078666\t  0.078769\t  0.085724\t\tCURRENT LEARNING RATE: 0.25381562013006637\n",
      "previous_iter_valid_loss : 0.07686276733875275\n",
      "\n",
      "     67800\t  0.076831\t  0.076863\t  0.085720\t\tCURRENT LEARNING RATE: 0.2533084961827948\n",
      "previous_iter_valid_loss : 0.07854892313480377\n",
      "\n",
      "     68000\t  0.078556\t  0.078549\t  0.085687\t\tCURRENT LEARNING RATE: 0.25280238546984574\n",
      "previous_iter_valid_loss : 0.0805220901966095\n",
      "\n",
      "     68200\t  0.080320\t  0.080522\t  0.085683\t\tCURRENT LEARNING RATE: 0.2522972859667756\n",
      "previous_iter_valid_loss : 0.07606472074985504\n",
      "\n",
      "     68400\t  0.075930\t  0.076065\t  0.085593\t\tCURRENT LEARNING RATE: 0.2517931956531857\n",
      "previous_iter_valid_loss : 0.09157535433769226\n",
      "\n",
      "     68600\t  0.091693\t  0.091575\t  0.085651\t\tCURRENT LEARNING RATE: 0.2512901125127142\n",
      "previous_iter_valid_loss : 0.0788474902510643\n",
      "\n",
      "     68800\t  0.078700\t  0.078847\t  0.085650\t\tCURRENT LEARNING RATE: 0.2507880345330278\n",
      "previous_iter_valid_loss : 0.07768768817186356\n",
      "\n",
      "     69000\t  0.077570\t  0.077688\t  0.085653\t\tCURRENT LEARNING RATE: 0.2502869597058139\n",
      "previous_iter_valid_loss : 0.08178988844156265\n",
      "\n",
      "     69200\t  0.081803\t  0.081790\t  0.085584\t\tCURRENT LEARNING RATE: 0.2497868860267725\n",
      "previous_iter_valid_loss : 0.08601543307304382\n",
      "\n",
      "     69400\t  0.086074\t  0.086015\t  0.085598\t\tCURRENT LEARNING RATE: 0.24928781149560827\n",
      "previous_iter_valid_loss : 0.08393214643001556\n",
      "\n",
      "     69600\t  0.083683\t  0.083932\t  0.085612\t\tCURRENT LEARNING RATE: 0.24878973411602243\n",
      "previous_iter_valid_loss : 0.08405745774507523\n",
      "\n",
      "     69800\t  0.083864\t  0.084057\t  0.085614\t\tCURRENT LEARNING RATE: 0.24829265189570476\n",
      "previous_iter_valid_loss : 0.07583945244550705\n",
      "\n",
      "     70000\t  0.075789\t  0.075839\t  0.085594\t\tCURRENT LEARNING RATE: 0.24779656284632573\n",
      "previous_iter_valid_loss : 0.07577237486839294\n",
      "\n",
      "     70200\t  0.075606\t  0.075772\t  0.085577\t\tCURRENT LEARNING RATE: 0.2473014649835285\n",
      "previous_iter_valid_loss : 0.08406803756952286\n",
      "\n",
      "     70400\t  0.084150\t  0.084068\t  0.085589\t\tCURRENT LEARNING RATE: 0.2468073563269209\n",
      "previous_iter_valid_loss : 0.0783725455403328\n",
      "\n",
      "     70600\t  0.078292\t  0.078373\t  0.085585\t\tCURRENT LEARNING RATE: 0.24631423490006774\n",
      "previous_iter_valid_loss : 0.07792908698320389\n",
      "\n",
      "     70800\t  0.077754\t  0.077929\t  0.085525\t\tCURRENT LEARNING RATE: 0.24582209873048255\n",
      "previous_iter_valid_loss : 0.07957412302494049\n",
      "\n",
      "     71000\t  0.079351\t  0.079574\t  0.085533\t\tCURRENT LEARNING RATE: 0.24533094584962006\n",
      "previous_iter_valid_loss : 0.07850755006074905\n",
      "\n",
      "     71200\t  0.078408\t  0.078508\t  0.085471\t\tCURRENT LEARNING RATE: 0.2448407742928681\n",
      "previous_iter_valid_loss : 0.08020002394914627\n",
      "\n",
      "     71400\t  0.080268\t  0.080200\t  0.085480\t\tCURRENT LEARNING RATE: 0.24435158209953975\n",
      "previous_iter_valid_loss : 0.0856618657708168\n",
      "\n",
      "     71600\t  0.085769\t  0.085662\t  0.085525\t\tCURRENT LEARNING RATE: 0.2438633673128656\n",
      "previous_iter_valid_loss : 0.08087711036205292\n",
      "\n",
      "     71800\t  0.080781\t  0.080877\t  0.085524\t\tCURRENT LEARNING RATE: 0.24337612797998584\n",
      "previous_iter_valid_loss : 0.08863946050405502\n",
      "\n",
      "     72000\t  0.088513\t  0.088639\t  0.085564\t\tCURRENT LEARNING RATE: 0.2428898621519425\n",
      "previous_iter_valid_loss : 0.07819408923387527\n",
      "\n",
      "     72200\t  0.078063\t  0.078194\t  0.085563\t\tCURRENT LEARNING RATE: 0.24240456788367162\n",
      "previous_iter_valid_loss : 0.07806636393070221\n",
      "\n",
      "     72400\t  0.078070\t  0.078066\t  0.085547\t\tCURRENT LEARNING RATE: 0.2419202432339955\n",
      "previous_iter_valid_loss : 0.08092926442623138\n",
      "\n",
      "     72600\t  0.081014\t  0.080929\t  0.085548\t\tCURRENT LEARNING RATE: 0.24143688626561488\n",
      "previous_iter_valid_loss : 0.07584188878536224\n",
      "\n",
      "     72800\t  0.075741\t  0.075842\t  0.085533\t\tCURRENT LEARNING RATE: 0.24095449504510122\n",
      "previous_iter_valid_loss : 0.08283527195453644\n",
      "\n",
      "     73000\t  0.082727\t  0.082835\t  0.085551\t\tCURRENT LEARNING RATE: 0.240473067642889\n",
      "previous_iter_valid_loss : 0.07838400453329086\n",
      "\n",
      "     73200\t  0.078313\t  0.078384\t  0.085485\t\tCURRENT LEARNING RATE: 0.239992602133268\n",
      "previous_iter_valid_loss : 0.0753551572561264\n",
      "\n",
      "     73400\t  0.075247\t  0.075355\t  0.085434\t\tCURRENT LEARNING RATE: 0.23951309659437556\n",
      "previous_iter_valid_loss : 0.07964423298835754\n",
      "\n",
      "     73600\t  0.079607\t  0.079644\t  0.085413\t\tCURRENT LEARNING RATE: 0.2390345491081888\n",
      "previous_iter_valid_loss : 0.0876348465681076\n",
      "\n",
      "     73800\t  0.087450\t  0.087635\t  0.085455\t\tCURRENT LEARNING RATE: 0.2385569577605172\n",
      "previous_iter_valid_loss : 0.08291563391685486\n",
      "\n",
      "     74000\t  0.082978\t  0.082916\t  0.085470\t\tCURRENT LEARNING RATE: 0.2380803206409947\n",
      "previous_iter_valid_loss : 0.08583350479602814\n",
      "\n",
      "     74200\t  0.085599\t  0.085834\t  0.085435\t\tCURRENT LEARNING RATE: 0.23760463584307223\n",
      "previous_iter_valid_loss : 0.07755444943904877\n",
      "\n",
      "     74400\t  0.077606\t  0.077554\t  0.085417\t\tCURRENT LEARNING RATE: 0.23712990146400995\n",
      "previous_iter_valid_loss : 0.07692793011665344\n",
      "\n",
      "     74600\t  0.076794\t  0.076928\t  0.085338\t\tCURRENT LEARNING RATE: 0.23665611560486965\n",
      "previous_iter_valid_loss : 0.08169256150722504\n",
      "\n",
      "     74800\t  0.081799\t  0.081693\t  0.085205\t\tCURRENT LEARNING RATE: 0.23618327637050734\n",
      "previous_iter_valid_loss : 0.08200018107891083\n",
      "\n",
      "     75000\t  0.082117\t  0.082000\t  0.085160\t\tCURRENT LEARNING RATE: 0.23571138186956545\n",
      "previous_iter_valid_loss : 0.07633781433105469\n",
      "\n",
      "     75200\t  0.076344\t  0.076338\t  0.085136\t\tCURRENT LEARNING RATE: 0.23524043021446528\n",
      "previous_iter_valid_loss : 0.08056916296482086\n",
      "\n",
      "     75400\t  0.080496\t  0.080569\t  0.085121\t\tCURRENT LEARNING RATE: 0.23477041952139963\n",
      "previous_iter_valid_loss : 0.0781422033905983\n",
      "\n",
      "     75600\t  0.078043\t  0.078142\t  0.085042\t\tCURRENT LEARNING RATE: 0.23430134791032511\n",
      "previous_iter_valid_loss : 0.08279137313365936\n",
      "\n",
      "     75800\t  0.082607\t  0.082791\t  0.084884\t\tCURRENT LEARNING RATE: 0.23383321350495462\n",
      "previous_iter_valid_loss : 0.07894401997327805\n",
      "\n",
      "     76000\t  0.078746\t  0.078944\t  0.084761\t\tCURRENT LEARNING RATE: 0.23336601443274993\n",
      "previous_iter_valid_loss : 0.09087026864290237\n",
      "\n",
      "     76200\t  0.090793\t  0.090870\t  0.084811\t\tCURRENT LEARNING RATE: 0.23289974882491413\n",
      "previous_iter_valid_loss : 0.08125071972608566\n",
      "\n",
      "     76400\t  0.081167\t  0.081251\t  0.084741\t\tCURRENT LEARNING RATE: 0.23243441481638413\n",
      "previous_iter_valid_loss : 0.07692421972751617\n",
      "\n",
      "     76600\t  0.076782\t  0.076924\t  0.084673\t\tCURRENT LEARNING RATE: 0.23197001054582336\n",
      "previous_iter_valid_loss : 0.07604299485683441\n",
      "\n",
      "     76800\t  0.076022\t  0.076043\t  0.084593\t\tCURRENT LEARNING RATE: 0.23150653415561404\n",
      "previous_iter_valid_loss : 0.08568692952394485\n",
      "\n",
      "     77000\t  0.085793\t  0.085687\t  0.084572\t\tCURRENT LEARNING RATE: 0.23104398379185\n",
      "previous_iter_valid_loss : 0.07831042259931564\n",
      "\n",
      "     77200\t  0.078327\t  0.078310\t  0.084413\t\tCURRENT LEARNING RATE: 0.2305823576043292\n",
      "previous_iter_valid_loss : 0.08126361668109894\n",
      "\n",
      "     77400\t  0.081173\t  0.081264\t  0.084273\t\tCURRENT LEARNING RATE: 0.23012165374654628\n",
      "previous_iter_valid_loss : 0.07994622737169266\n",
      "\n",
      "     77600\t  0.079868\t  0.079946\t  0.084246\t\tCURRENT LEARNING RATE: 0.22966187037568517\n",
      "previous_iter_valid_loss : 0.08357785642147064\n",
      "\n",
      "     77800\t  0.083389\t  0.083578\t  0.084126\t\tCURRENT LEARNING RATE: 0.22920300565261176\n",
      "previous_iter_valid_loss : 0.07883947342634201\n",
      "\n",
      "     78000\t  0.078748\t  0.078839\t  0.084124\t\tCURRENT LEARNING RATE: 0.22874505774186657\n",
      "previous_iter_valid_loss : 0.07742617279291153\n",
      "\n",
      "     78200\t  0.077273\t  0.077426\t  0.084074\t\tCURRENT LEARNING RATE: 0.22828802481165736\n",
      "previous_iter_valid_loss : 0.07529827952384949\n",
      "\n",
      "     78400\t  0.075149\t  0.075298\t  0.083905\t\tCURRENT LEARNING RATE: 0.22783190503385176\n",
      "previous_iter_valid_loss : 0.07524210959672928\n",
      "\n",
      "     78600\t  0.075116\t  0.075242\t  0.083632\t\tCURRENT LEARNING RATE: 0.22737669658397008\n",
      "previous_iter_valid_loss : 0.07540331035852432\n",
      "\n",
      "     78800\t  0.075338\t  0.075403\t  0.083434\t\tCURRENT LEARNING RATE: 0.22692239764117791\n",
      "previous_iter_valid_loss : 0.08003463596105576\n",
      "\n",
      "     79000\t  0.080035\t  0.080035\t  0.083419\t\tCURRENT LEARNING RATE: 0.22646900638827885\n",
      "previous_iter_valid_loss : 0.08002105355262756\n",
      "\n",
      "     79200\t  0.080040\t  0.080021\t  0.083405\t\tCURRENT LEARNING RATE: 0.22601652101170733\n",
      "previous_iter_valid_loss : 0.0766468271613121\n",
      "\n",
      "     79400\t  0.076626\t  0.076647\t  0.083370\t\tCURRENT LEARNING RATE: 0.22556493970152117\n",
      "previous_iter_valid_loss : 0.07463351637125015\n",
      "\n",
      "\n",
      "Current valid loss: 0.07463351637125015;  saved better model at /home/ali/Desktop/Pulled_Github_Repositories/torchQN/JupyterBook/Cluster/TRAIN/trained_models/Trained_IQNx4_RecoDatapT_4_layer6_hiddenLeakyReLU_activation1024_batchsize500_Kiteration.dict\n",
      "     79600\t  0.074582\t  0.074634\t  0.083269\t\tCURRENT LEARNING RATE: 0.22511426065139462\n",
      "previous_iter_valid_loss : 0.08093772083520889\n",
      "\n",
      "     79800\t  0.080779\t  0.080938\t  0.083204\t\tCURRENT LEARNING RATE: 0.22466448205861078\n",
      "previous_iter_valid_loss : 0.07828642427921295\n",
      "\n",
      "     80000\t  0.078245\t  0.078286\t  0.083199\t\tCURRENT LEARNING RATE: 0.22421560212405475\n",
      "previous_iter_valid_loss : 0.08300590515136719\n",
      "\n",
      "     80200\t  0.083130\t  0.083006\t  0.083196\t\tCURRENT LEARNING RATE: 0.22376761905220618\n",
      "previous_iter_valid_loss : 0.0799538642168045\n",
      "\n",
      "     80400\t  0.079998\t  0.079954\t  0.083179\t\tCURRENT LEARNING RATE: 0.22332053105113217\n",
      "previous_iter_valid_loss : 0.08094242960214615\n",
      "\n",
      "     80600\t  0.080840\t  0.080942\t  0.083189\t\tCURRENT LEARNING RATE: 0.2228743363324801\n",
      "previous_iter_valid_loss : 0.0833488404750824\n",
      "\n",
      "     80800\t  0.083103\t  0.083349\t  0.083148\t\tCURRENT LEARNING RATE: 0.22242903311147055\n",
      "previous_iter_valid_loss : 0.07988352328538895\n",
      "\n",
      "     81000\t  0.079877\t  0.079884\t  0.083142\t\tCURRENT LEARNING RATE: 0.22198461960689003\n",
      "previous_iter_valid_loss : 0.075401172041893\n",
      "\n",
      "     81200\t  0.075324\t  0.075401\t  0.083127\t\tCURRENT LEARNING RATE: 0.2215410940410839\n",
      "previous_iter_valid_loss : 0.07601428031921387\n",
      "\n",
      "     81400\t  0.075901\t  0.076014\t  0.083100\t\tCURRENT LEARNING RATE: 0.22109845463994934\n",
      "previous_iter_valid_loss : 0.07531873136758804\n",
      "\n",
      "     81600\t  0.075233\t  0.075319\t  0.083085\t\tCURRENT LEARNING RATE: 0.2206566996329281\n",
      "previous_iter_valid_loss : 0.08966878056526184\n",
      "\n",
      "     81800\t  0.089641\t  0.089669\t  0.083122\t\tCURRENT LEARNING RATE: 0.22021582725299965\n",
      "previous_iter_valid_loss : 0.09133268147706985\n",
      "\n",
      "     82000\t  0.091032\t  0.091333\t  0.083126\t\tCURRENT LEARNING RATE: 0.2197758357366738\n",
      "previous_iter_valid_loss : 0.07827981561422348\n",
      "\n",
      "     82200\t  0.078244\t  0.078280\t  0.083090\t\tCURRENT LEARNING RATE: 0.21933672332398393\n",
      "previous_iter_valid_loss : 0.08643233776092529\n",
      "\n",
      "     82400\t  0.086427\t  0.086432\t  0.082990\t\tCURRENT LEARNING RATE: 0.21889848825847982\n",
      "previous_iter_valid_loss : 0.0770283117890358\n",
      "\n",
      "     82600\t  0.077004\t  0.077028\t  0.082925\t\tCURRENT LEARNING RATE: 0.2184611287872206\n",
      "previous_iter_valid_loss : 0.07565462589263916\n",
      "\n",
      "     82800\t  0.075597\t  0.075655\t  0.082920\t\tCURRENT LEARNING RATE: 0.2180246431607678\n",
      "previous_iter_valid_loss : 0.07905686646699905\n",
      "\n",
      "     83000\t  0.079123\t  0.079057\t  0.082928\t\tCURRENT LEARNING RATE: 0.21758902963317836\n",
      "previous_iter_valid_loss : 0.07572945207357407\n",
      "\n",
      "     83200\t  0.075652\t  0.075729\t  0.082852\t\tCURRENT LEARNING RATE: 0.21715428646199755\n",
      "previous_iter_valid_loss : 0.08196774870157242\n",
      "\n",
      "     83400\t  0.081974\t  0.081968\t  0.082872\t\tCURRENT LEARNING RATE: 0.21672041190825214\n",
      "previous_iter_valid_loss : 0.07475065439939499\n",
      "\n",
      "     83600\t  0.074698\t  0.074751\t  0.082779\t\tCURRENT LEARNING RATE: 0.21628740423644333\n",
      "previous_iter_valid_loss : 0.07816114276647568\n",
      "\n",
      "     83800\t  0.078088\t  0.078161\t  0.082700\t\tCURRENT LEARNING RATE: 0.21585526171453986\n",
      "previous_iter_valid_loss : 0.08839654922485352\n",
      "\n",
      "     84000\t  0.088257\t  0.088397\t  0.082694\t\tCURRENT LEARNING RATE: 0.21542398261397103\n",
      "previous_iter_valid_loss : 0.08016136288642883\n",
      "\n",
      "     84200\t  0.080028\t  0.080161\t  0.082687\t\tCURRENT LEARNING RATE: 0.2149935652096199\n",
      "previous_iter_valid_loss : 0.08181221783161163\n",
      "\n",
      "     84400\t  0.081768\t  0.081812\t  0.082707\t\tCURRENT LEARNING RATE: 0.21456400777981627\n",
      "previous_iter_valid_loss : 0.07898297905921936\n",
      "\n",
      "     84600\t  0.079046\t  0.078983\t  0.082713\t\tCURRENT LEARNING RATE: 0.21413530860632984\n",
      "previous_iter_valid_loss : 0.08495768904685974\n",
      "\n",
      "     84800\t  0.084917\t  0.084958\t  0.082697\t\tCURRENT LEARNING RATE: 0.21370746597436335\n",
      "previous_iter_valid_loss : 0.0767827033996582\n",
      "\n",
      "     85000\t  0.076610\t  0.076783\t  0.082680\t\tCURRENT LEARNING RATE: 0.2132804781725457\n",
      "previous_iter_valid_loss : 0.07935759425163269\n",
      "\n",
      "     85200\t  0.079296\t  0.079358\t  0.082662\t\tCURRENT LEARNING RATE: 0.2128543434929251\n",
      "previous_iter_valid_loss : 0.07796458899974823\n",
      "\n",
      "     85400\t  0.077832\t  0.077965\t  0.082605\t\tCURRENT LEARNING RATE: 0.21242906023096228\n",
      "previous_iter_valid_loss : 0.07686003297567368\n",
      "\n",
      "     85600\t  0.076729\t  0.076860\t  0.082477\t\tCURRENT LEARNING RATE: 0.21200462668552364\n",
      "previous_iter_valid_loss : 0.07752479612827301\n",
      "\n",
      "     85800\t  0.077517\t  0.077525\t  0.082367\t\tCURRENT LEARNING RATE: 0.2115810411588744\n",
      "previous_iter_valid_loss : 0.08917701244354248\n",
      "\n",
      "     86000\t  0.089133\t  0.089177\t  0.082388\t\tCURRENT LEARNING RATE: 0.21115830195667193\n",
      "previous_iter_valid_loss : 0.08612467348575592\n",
      "\n",
      "     86200\t  0.085845\t  0.086125\t  0.082367\t\tCURRENT LEARNING RATE: 0.21073640738795882\n",
      "previous_iter_valid_loss : 0.0783374086022377\n",
      "\n",
      "     86400\t  0.078263\t  0.078337\t  0.082222\t\tCURRENT LEARNING RATE: 0.21031535576515623\n",
      "previous_iter_valid_loss : 0.08953781425952911\n",
      "\n",
      "     86600\t  0.089269\t  0.089538\t  0.082142\t\tCURRENT LEARNING RATE: 0.20989514540405713\n",
      "previous_iter_valid_loss : 0.07645553350448608\n",
      "\n",
      "     86800\t  0.076352\t  0.076456\t  0.082062\t\tCURRENT LEARNING RATE: 0.2094757746238195\n",
      "previous_iter_valid_loss : 0.07849906384944916\n",
      "\n",
      "     87000\t  0.078339\t  0.078499\t  0.081999\t\tCURRENT LEARNING RATE: 0.20905724174695967\n",
      "previous_iter_valid_loss : 0.08143731951713562\n",
      "\n",
      "     87200\t  0.081526\t  0.081437\t  0.082002\t\tCURRENT LEARNING RATE: 0.20863954509934557\n",
      "previous_iter_valid_loss : 0.08178315311670303\n",
      "\n",
      "     87400\t  0.081529\t  0.081783\t  0.082004\t\tCURRENT LEARNING RATE: 0.20822268301019004\n",
      "previous_iter_valid_loss : 0.08343511819839478\n",
      "\n",
      "     87600\t  0.083516\t  0.083435\t  0.082034\t\tCURRENT LEARNING RATE: 0.2078066538120442\n",
      "previous_iter_valid_loss : 0.0808505266904831\n",
      "\n",
      "     87800\t  0.080721\t  0.080851\t  0.082003\t\tCURRENT LEARNING RATE: 0.2073914558407907\n",
      "previous_iter_valid_loss : 0.08246871829032898\n",
      "\n",
      "     88000\t  0.082310\t  0.082469\t  0.082001\t\tCURRENT LEARNING RATE: 0.20697708743563706\n",
      "previous_iter_valid_loss : 0.08271326124668121\n",
      "\n",
      "     88200\t  0.082536\t  0.082713\t  0.081961\t\tCURRENT LEARNING RATE: 0.2065635469391091\n",
      "previous_iter_valid_loss : 0.08557898551225662\n",
      "\n",
      "     88400\t  0.085414\t  0.085579\t  0.081981\t\tCURRENT LEARNING RATE: 0.20615083269704437\n",
      "previous_iter_valid_loss : 0.08354421705007553\n",
      "\n",
      "     88600\t  0.083383\t  0.083544\t  0.081927\t\tCURRENT LEARNING RATE: 0.20573894305858528\n",
      "previous_iter_valid_loss : 0.07965674996376038\n",
      "\n",
      "     88800\t  0.079521\t  0.079657\t  0.081813\t\tCURRENT LEARNING RATE: 0.20532787637617275\n",
      "previous_iter_valid_loss : 0.07726599276065826\n",
      "\n",
      "     89000\t  0.077270\t  0.077266\t  0.081685\t\tCURRENT LEARNING RATE: 0.20491763100553947\n",
      "previous_iter_valid_loss : 0.08757707476615906\n",
      "\n",
      "     89200\t  0.087660\t  0.087577\t  0.081644\t\tCURRENT LEARNING RATE: 0.20450820530570346\n",
      "previous_iter_valid_loss : 0.07894781976938248\n",
      "\n",
      "     89400\t  0.079085\t  0.078948\t  0.081625\t\tCURRENT LEARNING RATE: 0.20409959763896135\n",
      "previous_iter_valid_loss : 0.08330877870321274\n",
      "\n",
      "     89600\t  0.083166\t  0.083309\t  0.081607\t\tCURRENT LEARNING RATE: 0.2036918063708819\n",
      "previous_iter_valid_loss : 0.08130980283021927\n",
      "\n",
      "     89800\t  0.081110\t  0.081310\t  0.081599\t\tCURRENT LEARNING RATE: 0.20328482987029955\n",
      "previous_iter_valid_loss : 0.08322665840387344\n",
      "\n",
      "     90000\t  0.083106\t  0.083227\t  0.081597\t\tCURRENT LEARNING RATE: 0.20287866650930772\n",
      "previous_iter_valid_loss : 0.08012700825929642\n",
      "\n",
      "     90200\t  0.080261\t  0.080127\t  0.081466\t\tCURRENT LEARNING RATE: 0.20247331466325244\n",
      "previous_iter_valid_loss : 0.08040829002857208\n",
      "\n",
      "     90400\t  0.080372\t  0.080408\t  0.081441\t\tCURRENT LEARNING RATE: 0.20206877271072576\n",
      "previous_iter_valid_loss : 0.080317422747612\n",
      "\n",
      "     90600\t  0.080512\t  0.080317\t  0.081427\t\tCURRENT LEARNING RATE: 0.20166503903355937\n",
      "previous_iter_valid_loss : 0.08328825235366821\n",
      "\n",
      "     90800\t  0.083108\t  0.083288\t  0.081404\t\tCURRENT LEARNING RATE: 0.20126211201681798\n",
      "previous_iter_valid_loss : 0.08526870608329773\n",
      "\n",
      "     91000\t  0.085428\t  0.085269\t  0.081368\t\tCURRENT LEARNING RATE: 0.200859990048793\n",
      "previous_iter_valid_loss : 0.08077502995729446\n",
      "\n",
      "     91200\t  0.080649\t  0.080775\t  0.081364\t\tCURRENT LEARNING RATE: 0.20045867152099606\n",
      "previous_iter_valid_loss : 0.08788833022117615\n",
      "\n",
      "     91400\t  0.088032\t  0.087888\t  0.081377\t\tCURRENT LEARNING RATE: 0.20005815482815248\n",
      "previous_iter_valid_loss : 0.08176375180482864\n",
      "\n",
      "     91600\t  0.081570\t  0.081764\t  0.081376\t\tCURRENT LEARNING RATE: 0.19965843836819494\n",
      "previous_iter_valid_loss : 0.07815267145633698\n",
      "\n",
      "     91800\t  0.078142\t  0.078153\t  0.081371\t\tCURRENT LEARNING RATE: 0.19925952054225707\n",
      "previous_iter_valid_loss : 0.08419773727655411\n",
      "\n",
      "     92000\t  0.084196\t  0.084198\t  0.081317\t\tCURRENT LEARNING RATE: 0.19886139975466707\n",
      "previous_iter_valid_loss : 0.08051387220621109\n",
      "\n",
      "     92200\t  0.080399\t  0.080514\t  0.081286\t\tCURRENT LEARNING RATE: 0.19846407441294123\n",
      "previous_iter_valid_loss : 0.08341404795646667\n",
      "\n",
      "     92400\t  0.083507\t  0.083414\t  0.081269\t\tCURRENT LEARNING RATE: 0.19806754292777767\n",
      "previous_iter_valid_loss : 0.07967257499694824\n",
      "\n",
      "     92600\t  0.079734\t  0.079673\t  0.081270\t\tCURRENT LEARNING RATE: 0.1976718037130499\n",
      "previous_iter_valid_loss : 0.08470427989959717\n",
      "\n",
      "     92800\t  0.084686\t  0.084704\t  0.081259\t\tCURRENT LEARNING RATE: 0.19727685518580054\n",
      "previous_iter_valid_loss : 0.08208709955215454\n",
      "\n",
      "     93000\t  0.081988\t  0.082087\t  0.081220\t\tCURRENT LEARNING RATE: 0.196882695766235\n",
      "previous_iter_valid_loss : 0.0810416117310524\n",
      "\n",
      "     93200\t  0.081021\t  0.081042\t  0.081206\t\tCURRENT LEARNING RATE: 0.19648932387771498\n",
      "previous_iter_valid_loss : 0.08355476707220078\n",
      "\n",
      "     93400\t  0.083589\t  0.083555\t  0.081147\t\tCURRENT LEARNING RATE: 0.19609673794675248\n",
      "previous_iter_valid_loss : 0.07727673649787903\n",
      "\n",
      "     93600\t  0.077210\t  0.077277\t  0.081090\t\tCURRENT LEARNING RATE: 0.19570493640300327\n",
      "previous_iter_valid_loss : 0.07761098444461823\n",
      "\n",
      "     93800\t  0.077564\t  0.077611\t  0.081065\t\tCURRENT LEARNING RATE: 0.19531391767926057\n",
      "previous_iter_valid_loss : 0.07784390449523926\n",
      "\n",
      "     94000\t  0.077834\t  0.077844\t  0.081023\t\tCURRENT LEARNING RATE: 0.19492368021144899\n",
      "previous_iter_valid_loss : 0.07864420115947723\n",
      "\n",
      "     94200\t  0.078534\t  0.078644\t  0.081021\t\tCURRENT LEARNING RATE: 0.19453422243861818\n",
      "previous_iter_valid_loss : 0.07817331701517105\n",
      "\n",
      "     94400\t  0.078125\t  0.078173\t  0.081018\t\tCURRENT LEARNING RATE: 0.1941455428029365\n",
      "previous_iter_valid_loss : 0.08065784722566605\n",
      "\n",
      "     94600\t  0.080494\t  0.080658\t  0.080994\t\tCURRENT LEARNING RATE: 0.19375763974968488\n",
      "previous_iter_valid_loss : 0.08112745732069016\n",
      "\n",
      "     94800\t  0.081076\t  0.081127\t  0.081005\t\tCURRENT LEARNING RATE: 0.19337051172725062\n",
      "previous_iter_valid_loss : 0.07537203282117844\n",
      "\n",
      "     95000\t  0.075232\t  0.075372\t  0.080973\t\tCURRENT LEARNING RATE: 0.19298415718712109\n",
      "previous_iter_valid_loss : 0.07783708721399307\n",
      "\n",
      "     95200\t  0.077648\t  0.077837\t  0.080912\t\tCURRENT LEARNING RATE: 0.1925985745838776\n",
      "previous_iter_valid_loss : 0.07556425780057907\n",
      "\n",
      "     95400\t  0.075405\t  0.075564\t  0.080860\t\tCURRENT LEARNING RATE: 0.19221376237518928\n",
      "previous_iter_valid_loss : 0.07800246775150299\n",
      "\n",
      "     95600\t  0.077922\t  0.078002\t  0.080825\t\tCURRENT LEARNING RATE: 0.1918297190218067\n",
      "previous_iter_valid_loss : 0.07640235871076584\n",
      "\n",
      "     95800\t  0.076352\t  0.076402\t  0.080786\t\tCURRENT LEARNING RATE: 0.19144644298755603\n",
      "previous_iter_valid_loss : 0.08762513846158981\n",
      "\n",
      "     96000\t  0.087470\t  0.087625\t  0.080807\t\tCURRENT LEARNING RATE: 0.19106393273933253\n",
      "previous_iter_valid_loss : 0.07765396684408188\n",
      "\n",
      "     96200\t  0.077543\t  0.077654\t  0.080711\t\tCURRENT LEARNING RATE: 0.19068218674709478\n",
      "previous_iter_valid_loss : 0.08178192377090454\n",
      "\n",
      "     96400\t  0.081648\t  0.081782\t  0.080740\t\tCURRENT LEARNING RATE: 0.19030120348385823\n",
      "previous_iter_valid_loss : 0.0756133422255516\n",
      "\n",
      "     96600\t  0.075530\t  0.075613\t  0.080679\t\tCURRENT LEARNING RATE: 0.18992098142568936\n",
      "previous_iter_valid_loss : 0.08019305020570755\n",
      "\n",
      "     96800\t  0.080049\t  0.080193\t  0.080686\t\tCURRENT LEARNING RATE: 0.18954151905169941\n",
      "previous_iter_valid_loss : 0.08391282707452774\n",
      "\n",
      "     97000\t  0.083749\t  0.083913\t  0.080703\t\tCURRENT LEARNING RATE: 0.1891628148440384\n",
      "previous_iter_valid_loss : 0.0915609672665596\n",
      "\n",
      "     97200\t  0.091602\t  0.091561\t  0.080766\t\tCURRENT LEARNING RATE: 0.18878486728788899\n",
      "previous_iter_valid_loss : 0.07902265340089798\n",
      "\n",
      "     97400\t  0.078956\t  0.079023\t  0.080711\t\tCURRENT LEARNING RATE: 0.18840767487146043\n",
      "previous_iter_valid_loss : 0.08666329830884933\n",
      "\n",
      "     97600\t  0.086687\t  0.086663\t  0.080713\t\tCURRENT LEARNING RATE: 0.18803123608598257\n",
      "previous_iter_valid_loss : 0.08399046957492828\n",
      "\n",
      "     97800\t  0.084098\t  0.083990\t  0.080742\t\tCURRENT LEARNING RATE: 0.18765554942569979\n",
      "previous_iter_valid_loss : 0.08147895336151123\n",
      "\n",
      "     98000\t  0.081567\t  0.081479\t  0.080758\t\tCURRENT LEARNING RATE: 0.1872806133878649\n",
      "previous_iter_valid_loss : 0.08058720082044601\n",
      "\n",
      "     98200\t  0.080519\t  0.080587\t  0.080757\t\tCURRENT LEARNING RATE: 0.18690642647273326\n",
      "previous_iter_valid_loss : 0.07625742256641388\n",
      "\n",
      "     98400\t  0.076117\t  0.076257\t  0.080746\t\tCURRENT LEARNING RATE: 0.1865329871835567\n",
      "previous_iter_valid_loss : 0.07796110212802887\n",
      "\n",
      "     98600\t  0.077727\t  0.077961\t  0.080753\t\tCURRENT LEARNING RATE: 0.1861602940265776\n",
      "previous_iter_valid_loss : 0.07993460446596146\n",
      "\n",
      "     98800\t  0.079748\t  0.079935\t  0.080746\t\tCURRENT LEARNING RATE: 0.18578834551102286\n",
      "previous_iter_valid_loss : 0.08352506160736084\n",
      "\n",
      "     99000\t  0.083234\t  0.083525\t  0.080749\t\tCURRENT LEARNING RATE: 0.18541714014909783\n",
      "previous_iter_valid_loss : 0.07532358169555664\n",
      "\n",
      "     99200\t  0.075186\t  0.075324\t  0.080716\t\tCURRENT LEARNING RATE: 0.18504667645598064\n",
      "previous_iter_valid_loss : 0.07750178128480911\n",
      "\n",
      "     99400\t  0.077344\t  0.077502\t  0.080615\t\tCURRENT LEARNING RATE: 0.184676952949816\n",
      "previous_iter_valid_loss : 0.07564123719930649\n",
      "\n",
      "     99600\t  0.075515\t  0.075641\t  0.080588\t\tCURRENT LEARNING RATE: 0.1843079681517094\n",
      "previous_iter_valid_loss : 0.07656129449605942\n",
      "\n",
      "     99800\t  0.076439\t  0.076561\t  0.080546\t\tCURRENT LEARNING RATE: 0.18393972058572117\n",
      "previous_iter_valid_loss : 0.08299889415502548\n",
      "\n",
      "    100000\t  0.083044\t  0.082999\t  0.080560\t\tCURRENT LEARNING RATE: 0.18357220877886052\n",
      "previous_iter_valid_loss : 0.08177980035543442\n",
      "\n",
      "    100200\t  0.081861\t  0.081780\t  0.080567\t\tCURRENT LEARNING RATE: 0.18320543126107974\n",
      "previous_iter_valid_loss : 0.07716624438762665\n",
      "\n",
      "    100400\t  0.077145\t  0.077166\t  0.080567\t\tCURRENT LEARNING RATE: 0.18283938656526827\n",
      "previous_iter_valid_loss : 0.07944534718990326\n",
      "\n",
      "    100600\t  0.079358\t  0.079445\t  0.080538\t\tCURRENT LEARNING RATE: 0.18247407322724687\n",
      "previous_iter_valid_loss : 0.07682294398546219\n",
      "\n",
      "    100800\t  0.076790\t  0.076823\t  0.080505\t\tCURRENT LEARNING RATE: 0.18210948978576166\n",
      "previous_iter_valid_loss : 0.07630185037851334\n",
      "\n",
      "    101000\t  0.076162\t  0.076302\t  0.080507\t\tCURRENT LEARNING RATE: 0.1817456347824784\n",
      "previous_iter_valid_loss : 0.07570655643939972\n",
      "\n",
      "    101200\t  0.075648\t  0.075707\t  0.080439\t\tCURRENT LEARNING RATE: 0.18138250676197662\n",
      "previous_iter_valid_loss : 0.0769362673163414\n",
      "\n",
      "    101400\t  0.076973\t  0.076936\t  0.080412\t\tCURRENT LEARNING RATE: 0.18102010427174373\n",
      "previous_iter_valid_loss : 0.07745841890573502\n",
      "\n",
      "    101600\t  0.077356\t  0.077458\t  0.080416\t\tCURRENT LEARNING RATE: 0.18065842586216926\n",
      "previous_iter_valid_loss : 0.08007359504699707\n",
      "\n",
      "    101800\t  0.079998\t  0.080074\t  0.080431\t\tCURRENT LEARNING RATE: 0.18029747008653915\n",
      "previous_iter_valid_loss : 0.08710157871246338\n",
      "\n",
      "    102000\t  0.087168\t  0.087102\t  0.080442\t\tCURRENT LEARNING RATE: 0.17993723550102977\n",
      "previous_iter_valid_loss : 0.07548170536756516\n",
      "\n",
      "    102200\t  0.075462\t  0.075482\t  0.080406\t\tCURRENT LEARNING RATE: 0.1795777206647023\n",
      "previous_iter_valid_loss : 0.07666592299938202\n",
      "\n",
      "    102400\t  0.076552\t  0.076666\t  0.080382\t\tCURRENT LEARNING RATE: 0.17921892413949694\n",
      "previous_iter_valid_loss : 0.08191560953855515\n",
      "\n",
      "    102600\t  0.081863\t  0.081916\t  0.080384\t\tCURRENT LEARNING RATE: 0.1788608444902271\n",
      "previous_iter_valid_loss : 0.0793764740228653\n",
      "\n",
      "    102800\t  0.079276\t  0.079376\t  0.080361\t\tCURRENT LEARNING RATE: 0.1785034802845737\n",
      "previous_iter_valid_loss : 0.08356636762619019\n",
      "\n",
      "    103000\t  0.083526\t  0.083566\t  0.080395\t\tCURRENT LEARNING RATE: 0.1781468300930794\n",
      "previous_iter_valid_loss : 0.08420100063085556\n",
      "\n",
      "    103200\t  0.084147\t  0.084201\t  0.080426\t\tCURRENT LEARNING RATE: 0.17779089248914307\n",
      "previous_iter_valid_loss : 0.07688818871974945\n",
      "\n",
      "    103400\t  0.076754\t  0.076888\t  0.080410\t\tCURRENT LEARNING RATE: 0.1774356660490137\n",
      "previous_iter_valid_loss : 0.08417384326457977\n",
      "\n",
      "    103600\t  0.084111\t  0.084174\t  0.080441\t\tCURRENT LEARNING RATE: 0.17708114935178512\n",
      "previous_iter_valid_loss : 0.07597345113754272\n",
      "\n",
      "    103800\t  0.075895\t  0.075973\t  0.080416\t\tCURRENT LEARNING RATE: 0.17672734097939008\n",
      "previous_iter_valid_loss : 0.08023016899824142\n",
      "\n",
      "    104000\t  0.080199\t  0.080230\t  0.080389\t\tCURRENT LEARNING RATE: 0.17637423951659456\n",
      "previous_iter_valid_loss : 0.07815920561552048\n",
      "\n",
      "    104200\t  0.078013\t  0.078159\t  0.080389\t\tCURRENT LEARNING RATE: 0.1760218435509923\n",
      "previous_iter_valid_loss : 0.08767534792423248\n",
      "\n",
      "    104400\t  0.087645\t  0.087675\t  0.080413\t\tCURRENT LEARNING RATE: 0.1756701516729989\n",
      "previous_iter_valid_loss : 0.08421740680932999\n",
      "\n",
      "    104600\t  0.084014\t  0.084217\t  0.080393\t\tCURRENT LEARNING RATE: 0.17531916247584647\n",
      "previous_iter_valid_loss : 0.07552143931388855\n",
      "\n",
      "    104800\t  0.075368\t  0.075521\t  0.080345\t\tCURRENT LEARNING RATE: 0.17496887455557766\n",
      "previous_iter_valid_loss : 0.07714150100946426\n",
      "\n",
      "    105000\t  0.076959\t  0.077142\t  0.080309\t\tCURRENT LEARNING RATE: 0.1746192865110404\n",
      "previous_iter_valid_loss : 0.07571487128734589\n",
      "\n",
      "    105200\t  0.075591\t  0.075715\t  0.080286\t\tCURRENT LEARNING RATE: 0.174270396943882\n",
      "previous_iter_valid_loss : 0.07616430521011353\n",
      "\n",
      "    105400\t  0.076024\t  0.076164\t  0.080275\t\tCURRENT LEARNING RATE: 0.1739222044585437\n",
      "previous_iter_valid_loss : 0.07993461191654205\n",
      "\n",
      "    105600\t  0.079814\t  0.079935\t  0.080292\t\tCURRENT LEARNING RATE: 0.17357470766225516\n",
      "previous_iter_valid_loss : 0.08135592192411423\n",
      "\n",
      "    105800\t  0.081198\t  0.081356\t  0.080258\t\tCURRENT LEARNING RATE: 0.1732279051650287\n",
      "previous_iter_valid_loss : 0.07683079689741135\n",
      "\n",
      "    106000\t  0.076770\t  0.076831\t  0.080261\t\tCURRENT LEARNING RATE: 0.17288179557965389\n",
      "previous_iter_valid_loss : 0.07651828229427338\n",
      "\n",
      "    106200\t  0.076447\t  0.076518\t  0.080255\t\tCURRENT LEARNING RATE: 0.17253637752169187\n",
      "previous_iter_valid_loss : 0.07960320264101028\n",
      "\n",
      "    106400\t  0.079418\t  0.079603\t  0.080273\t\tCURRENT LEARNING RATE: 0.17219164960947\n",
      "previous_iter_valid_loss : 0.08186396956443787\n",
      "\n",
      "    106600\t  0.081786\t  0.081864\t  0.080276\t\tCURRENT LEARNING RATE: 0.17184761046407618\n",
      "previous_iter_valid_loss : 0.0780843049287796\n",
      "\n",
      "    106800\t  0.078011\t  0.078084\t  0.080278\t\tCURRENT LEARNING RATE: 0.17150425870935332\n",
      "previous_iter_valid_loss : 0.08419313281774521\n",
      "\n",
      "    107000\t  0.083978\t  0.084193\t  0.080309\t\tCURRENT LEARNING RATE: 0.17116159297189398\n",
      "previous_iter_valid_loss : 0.08057896792888641\n",
      "\n",
      "    107200\t  0.080561\t  0.080579\t  0.080336\t\tCURRENT LEARNING RATE: 0.17081961188103473\n",
      "previous_iter_valid_loss : 0.07733476907014847\n",
      "\n",
      "    107400\t  0.077197\t  0.077335\t  0.080345\t\tCURRENT LEARNING RATE: 0.17047831406885078\n",
      "previous_iter_valid_loss : 0.07720833271741867\n",
      "\n",
      "    107600\t  0.077130\t  0.077208\t  0.080337\t\tCURRENT LEARNING RATE: 0.1701376981701504\n",
      "previous_iter_valid_loss : 0.07739559561014175\n",
      "\n",
      "    107800\t  0.077246\t  0.077396\t  0.080340\t\tCURRENT LEARNING RATE: 0.16979776282246956\n",
      "previous_iter_valid_loss : 0.0767950490117073\n",
      "\n",
      "    108000\t  0.076785\t  0.076795\t  0.080331\t\tCURRENT LEARNING RATE: 0.1694585066660664\n",
      "previous_iter_valid_loss : 0.08665931224822998\n",
      "\n",
      "    108200\t  0.086782\t  0.086659\t  0.080361\t\tCURRENT LEARNING RATE: 0.16911992834391584\n",
      "previous_iter_valid_loss : 0.0772549957036972\n",
      "\n",
      "    108400\t  0.077137\t  0.077255\t  0.080367\t\tCURRENT LEARNING RATE: 0.16878202650170418\n",
      "previous_iter_valid_loss : 0.07929424941539764\n",
      "\n",
      "    108600\t  0.079244\t  0.079294\t  0.080306\t\tCURRENT LEARNING RATE: 0.16844479978782353\n",
      "previous_iter_valid_loss : 0.08905012160539627\n",
      "\n",
      "    108800\t  0.088815\t  0.089050\t  0.080357\t\tCURRENT LEARNING RATE: 0.16810824685336667\n",
      "previous_iter_valid_loss : 0.08003101497888565\n",
      "\n",
      "    109000\t  0.079938\t  0.080031\t  0.080369\t\tCURRENT LEARNING RATE: 0.16777236635212134\n",
      "previous_iter_valid_loss : 0.07849324494600296\n",
      "\n",
      "    109200\t  0.078472\t  0.078493\t  0.080352\t\tCURRENT LEARNING RATE: 0.1674371569405651\n",
      "previous_iter_valid_loss : 0.08626586943864822\n",
      "\n",
      "    109400\t  0.086190\t  0.086266\t  0.080353\t\tCURRENT LEARNING RATE: 0.16710261727785988\n",
      "previous_iter_valid_loss : 0.07654984295368195\n",
      "\n",
      "    109600\t  0.076396\t  0.076550\t  0.080317\t\tCURRENT LEARNING RATE: 0.1667687460258466\n",
      "previous_iter_valid_loss : 0.089596226811409\n",
      "\n",
      "    109800\t  0.089479\t  0.089596\t  0.080344\t\tCURRENT LEARNING RATE: 0.16643554184903978\n",
      "previous_iter_valid_loss : 0.08018852025270462\n",
      "\n",
      "    110000\t  0.080070\t  0.080189\t  0.080366\t\tCURRENT LEARNING RATE: 0.16610300341462222\n",
      "previous_iter_valid_loss : 0.07875143736600876\n",
      "\n",
      "    110200\t  0.078633\t  0.078751\t  0.080381\t\tCURRENT LEARNING RATE: 0.16577112939243985\n",
      "previous_iter_valid_loss : 0.07909990847110748\n",
      "\n",
      "    110400\t  0.078958\t  0.079100\t  0.080356\t\tCURRENT LEARNING RATE: 0.16543991845499603\n",
      "previous_iter_valid_loss : 0.08076947927474976\n",
      "\n",
      "    110600\t  0.080694\t  0.080769\t  0.080368\t\tCURRENT LEARNING RATE: 0.16510936927744665\n",
      "previous_iter_valid_loss : 0.07829625904560089\n",
      "\n",
      "    110800\t  0.078239\t  0.078296\t  0.080370\t\tCURRENT LEARNING RATE: 0.16477948053759453\n",
      "previous_iter_valid_loss : 0.08051285892724991\n",
      "\n",
      "    111000\t  0.080385\t  0.080513\t  0.080375\t\tCURRENT LEARNING RATE: 0.16445025091588425\n",
      "previous_iter_valid_loss : 0.07872194051742554\n",
      "\n",
      "    111200\t  0.078597\t  0.078722\t  0.080376\t\tCURRENT LEARNING RATE: 0.16412167909539688\n",
      "previous_iter_valid_loss : 0.0757250115275383\n",
      "\n",
      "    111400\t  0.075563\t  0.075725\t  0.080353\t\tCURRENT LEARNING RATE: 0.16379376376184476\n",
      "previous_iter_valid_loss : 0.07661189138889313\n",
      "\n",
      "    111600\t  0.076473\t  0.076612\t  0.080308\t\tCURRENT LEARNING RATE: 0.16346650360356604\n",
      "previous_iter_valid_loss : 0.07664687186479568\n",
      "\n",
      "    111800\t  0.076555\t  0.076647\t  0.080287\t\tCURRENT LEARNING RATE: 0.16313989731151973\n",
      "previous_iter_valid_loss : 0.0866432636976242\n",
      "\n",
      "    112000\t  0.086635\t  0.086643\t  0.080277\t\tCURRENT LEARNING RATE: 0.16281394357928017\n",
      "previous_iter_valid_loss : 0.08152475208044052\n",
      "\n",
      "    112200\t  0.081313\t  0.081525\t  0.080294\t\tCURRENT LEARNING RATE: 0.162488641103032\n",
      "previous_iter_valid_loss : 0.0766310766339302\n",
      "\n",
      "    112400\t  0.076558\t  0.076631\t  0.080286\t\tCURRENT LEARNING RATE: 0.16216398858156494\n",
      "previous_iter_valid_loss : 0.08023857325315475\n",
      "\n",
      "    112600\t  0.080204\t  0.080239\t  0.080283\t\tCURRENT LEARNING RATE: 0.1618399847162684\n",
      "previous_iter_valid_loss : 0.0772143304347992\n",
      "\n",
      "    112800\t  0.077108\t  0.077214\t  0.080290\t\tCURRENT LEARNING RATE: 0.16151662821112647\n",
      "previous_iter_valid_loss : 0.08075516670942307\n",
      "\n",
      "    113000\t  0.080678\t  0.080755\t  0.080279\t\tCURRENT LEARNING RATE: 0.16119391777271277\n",
      "previous_iter_valid_loss : 0.07815488427877426\n",
      "\n",
      "    113200\t  0.078110\t  0.078155\t  0.080278\t\tCURRENT LEARNING RATE: 0.1608718521101851\n",
      "previous_iter_valid_loss : 0.0772341713309288\n",
      "\n",
      "    113400\t  0.077087\t  0.077234\t  0.080288\t\tCURRENT LEARNING RATE: 0.16055042993528035\n",
      "previous_iter_valid_loss : 0.07722154259681702\n",
      "\n",
      "    113600\t  0.077125\t  0.077222\t  0.080276\t\tCURRENT LEARNING RATE: 0.1602296499623094\n",
      "previous_iter_valid_loss : 0.07676287740468979\n",
      "\n",
      "    113800\t  0.076697\t  0.076763\t  0.080221\t\tCURRENT LEARNING RATE: 0.15990951090815197\n",
      "previous_iter_valid_loss : 0.07688786089420319\n",
      "\n",
      "    114000\t  0.076795\t  0.076888\t  0.080191\t\tCURRENT LEARNING RATE: 0.15959001149225135\n",
      "previous_iter_valid_loss : 0.0761636346578598\n",
      "\n",
      "    114200\t  0.076042\t  0.076164\t  0.080143\t\tCURRENT LEARNING RATE: 0.1592711504366095\n",
      "previous_iter_valid_loss : 0.07550335675477982\n",
      "\n",
      "    114400\t  0.075376\t  0.075503\t  0.080132\t\tCURRENT LEARNING RATE: 0.15895292646578177\n",
      "previous_iter_valid_loss : 0.07748590409755707\n",
      "\n",
      "    114600\t  0.077403\t  0.077486\t  0.080135\t\tCURRENT LEARNING RATE: 0.15863533830687182\n",
      "previous_iter_valid_loss : 0.07563047111034393\n",
      "\n",
      "    114800\t  0.075548\t  0.075630\t  0.080105\t\tCURRENT LEARNING RATE: 0.15831838468952664\n",
      "previous_iter_valid_loss : 0.07967675477266312\n",
      "\n",
      "    115000\t  0.079607\t  0.079677\t  0.080093\t\tCURRENT LEARNING RATE: 0.15800206434593128\n",
      "previous_iter_valid_loss : 0.0789448693394661\n",
      "\n",
      "    115200\t  0.078790\t  0.078945\t  0.080106\t\tCURRENT LEARNING RATE: 0.15768637601080399\n",
      "previous_iter_valid_loss : 0.07711923867464066\n",
      "\n",
      "    115400\t  0.077070\t  0.077119\t  0.080089\t\tCURRENT LEARNING RATE: 0.15737131842139096\n",
      "previous_iter_valid_loss : 0.07900507748126984\n",
      "\n",
      "    115600\t  0.078903\t  0.079005\t  0.080093\t\tCURRENT LEARNING RATE: 0.15705689031746148\n",
      "previous_iter_valid_loss : 0.07918419688940048\n",
      "\n",
      "    115800\t  0.079053\t  0.079184\t  0.080075\t\tCURRENT LEARNING RATE: 0.15674309044130266\n",
      "previous_iter_valid_loss : 0.0804261863231659\n",
      "\n",
      "    116000\t  0.080408\t  0.080426\t  0.080083\t\tCURRENT LEARNING RATE: 0.1564299175377146\n",
      "previous_iter_valid_loss : 0.07717680931091309\n",
      "\n",
      "    116200\t  0.077138\t  0.077177\t  0.080014\t\tCURRENT LEARNING RATE: 0.15611737035400527\n",
      "previous_iter_valid_loss : 0.07560831308364868\n",
      "\n",
      "    116400\t  0.075479\t  0.075608\t  0.079986\t\tCURRENT LEARNING RATE: 0.15580544763998552\n",
      "previous_iter_valid_loss : 0.0878332257270813\n",
      "\n",
      "    116600\t  0.087583\t  0.087833\t  0.080041\t\tCURRENT LEARNING RATE: 0.15549414814796406\n",
      "previous_iter_valid_loss : 0.07580657303333282\n",
      "\n",
      "    116800\t  0.075637\t  0.075807\t  0.080039\t\tCURRENT LEARNING RATE: 0.15518347063274252\n",
      "previous_iter_valid_loss : 0.07960193604230881\n",
      "\n",
      "    117000\t  0.079351\t  0.079602\t  0.080009\t\tCURRENT LEARNING RATE: 0.1548734138516104\n",
      "previous_iter_valid_loss : 0.07762517035007477\n",
      "\n",
      "    117200\t  0.077533\t  0.077625\t  0.080006\t\tCURRENT LEARNING RATE: 0.1545639765643402\n",
      "previous_iter_valid_loss : 0.08120529353618622\n",
      "\n",
      "    117400\t  0.081180\t  0.081205\t  0.080005\t\tCURRENT LEARNING RATE: 0.15425515753318236\n",
      "previous_iter_valid_loss : 0.07515424489974976\n",
      "\n",
      "    117600\t  0.075050\t  0.075154\t  0.079981\t\tCURRENT LEARNING RATE: 0.1539469555228603\n",
      "previous_iter_valid_loss : 0.08429466933012009\n",
      "\n",
      "    117800\t  0.084303\t  0.084295\t  0.079985\t\tCURRENT LEARNING RATE: 0.15363936930056563\n",
      "previous_iter_valid_loss : 0.0753374993801117\n",
      "\n",
      "    118000\t  0.075286\t  0.075337\t  0.079967\t\tCURRENT LEARNING RATE: 0.153332397635953\n",
      "previous_iter_valid_loss : 0.07925949990749359\n",
      "\n",
      "    118200\t  0.079135\t  0.079259\t  0.079977\t\tCURRENT LEARNING RATE: 0.15302603930113534\n",
      "previous_iter_valid_loss : 0.08491213619709015\n",
      "\n",
      "    118400\t  0.084891\t  0.084912\t  0.080025\t\tCURRENT LEARNING RATE: 0.15272029307067894\n",
      "previous_iter_valid_loss : 0.0775553435087204\n",
      "\n",
      "    118600\t  0.077448\t  0.077555\t  0.080036\t\tCURRENT LEARNING RATE: 0.15241515772159842\n",
      "previous_iter_valid_loss : 0.0755997821688652\n",
      "\n",
      "    118800\t  0.075463\t  0.075600\t  0.080037\t\tCURRENT LEARNING RATE: 0.15211063203335204\n",
      "previous_iter_valid_loss : 0.07541865110397339\n",
      "\n",
      "    119000\t  0.075342\t  0.075419\t  0.080014\t\tCURRENT LEARNING RATE: 0.15180671478783658\n",
      "previous_iter_valid_loss : 0.07580266892910004\n",
      "\n",
      "    119200\t  0.075749\t  0.075803\t  0.079993\t\tCURRENT LEARNING RATE: 0.1515034047693827\n",
      "previous_iter_valid_loss : 0.08237158507108688\n",
      "\n",
      "    119400\t  0.082173\t  0.082372\t  0.080022\t\tCURRENT LEARNING RATE: 0.1512007007647499\n",
      "previous_iter_valid_loss : 0.0782189816236496\n",
      "\n",
      "    119600\t  0.078049\t  0.078219\t  0.080040\t\tCURRENT LEARNING RATE: 0.15089860156312174\n",
      "previous_iter_valid_loss : 0.07824096828699112\n",
      "\n",
      "    119800\t  0.078113\t  0.078241\t  0.080026\t\tCURRENT LEARNING RATE: 0.15059710595610107\n",
      "previous_iter_valid_loss : 0.07640261203050613\n",
      "\n",
      "    120000\t  0.076354\t  0.076403\t  0.080017\t\tCURRENT LEARNING RATE: 0.150296212737705\n",
      "previous_iter_valid_loss : 0.07558123022317886\n",
      "\n",
      "    120200\t  0.075426\t  0.075581\t  0.079980\t\tCURRENT LEARNING RATE: 0.14999592070436024\n",
      "previous_iter_valid_loss : 0.07661613821983337\n",
      "\n",
      "    120400\t  0.076437\t  0.076616\t  0.079963\t\tCURRENT LEARNING RATE: 0.14969622865489834\n",
      "previous_iter_valid_loss : 0.07718213647603989\n",
      "\n",
      "    120600\t  0.077142\t  0.077182\t  0.079944\t\tCURRENT LEARNING RATE: 0.14939713539055063\n",
      "previous_iter_valid_loss : 0.07608206570148468\n",
      "\n",
      "    120800\t  0.075966\t  0.076082\t  0.079908\t\tCURRENT LEARNING RATE: 0.1490986397149437\n",
      "previous_iter_valid_loss : 0.0774453803896904\n",
      "\n",
      "    121000\t  0.077406\t  0.077445\t  0.079896\t\tCURRENT LEARNING RATE: 0.14880074043409441\n",
      "previous_iter_valid_loss : 0.07566779851913452\n",
      "\n",
      "    121200\t  0.075568\t  0.075668\t  0.079897\t\tCURRENT LEARNING RATE: 0.14850343635640526\n",
      "previous_iter_valid_loss : 0.08240243792533875\n",
      "\n",
      "    121400\t  0.082219\t  0.082402\t  0.079929\t\tCURRENT LEARNING RATE: 0.14820672629265955\n",
      "previous_iter_valid_loss : 0.08300460875034332\n",
      "\n",
      "    121600\t  0.083049\t  0.083005\t  0.079967\t\tCURRENT LEARNING RATE: 0.1479106090560166\n",
      "previous_iter_valid_loss : 0.0835714340209961\n",
      "\n",
      "    121800\t  0.083360\t  0.083571\t  0.079937\t\tCURRENT LEARNING RATE: 0.1476150834620071\n",
      "previous_iter_valid_loss : 0.07744081318378448\n",
      "\n",
      "    122000\t  0.077335\t  0.077441\t  0.079867\t\tCURRENT LEARNING RATE: 0.14732014832852827\n",
      "previous_iter_valid_loss : 0.07613294571638107\n",
      "\n",
      "    122200\t  0.075966\t  0.076133\t  0.079857\t\tCURRENT LEARNING RATE: 0.14702580247583918\n",
      "previous_iter_valid_loss : 0.07549440860748291\n",
      "\n",
      "    122400\t  0.075452\t  0.075494\t  0.079802\t\tCURRENT LEARNING RATE: 0.14673204472655604\n",
      "previous_iter_valid_loss : 0.07759732753038406\n",
      "\n",
      "    122600\t  0.077483\t  0.077597\t  0.079805\t\tCURRENT LEARNING RATE: 0.14643887390564744\n",
      "previous_iter_valid_loss : 0.07906775176525116\n",
      "\n",
      "    122800\t  0.078951\t  0.079068\t  0.079822\t\tCURRENT LEARNING RATE: 0.1461462888404297\n",
      "previous_iter_valid_loss : 0.07861895859241486\n",
      "\n",
      "    123000\t  0.078348\t  0.078619\t  0.079820\t\tCURRENT LEARNING RATE: 0.1458542883605622\n",
      "previous_iter_valid_loss : 0.07672356069087982\n",
      "\n",
      "    123200\t  0.076643\t  0.076724\t  0.079825\t\tCURRENT LEARNING RATE: 0.1455628712980426\n",
      "previous_iter_valid_loss : 0.07622577995061874\n",
      "\n",
      "    123400\t  0.076132\t  0.076226\t  0.079796\t\tCURRENT LEARNING RATE: 0.1452720364872023\n",
      "previous_iter_valid_loss : 0.07708101719617844\n",
      "\n",
      "    123600\t  0.076848\t  0.077081\t  0.079808\t\tCURRENT LEARNING RATE: 0.1449817827647016\n",
      "previous_iter_valid_loss : 0.0756753459572792\n",
      "\n",
      "    123800\t  0.075520\t  0.075675\t  0.079795\t\tCURRENT LEARNING RATE: 0.1446921089695253\n",
      "previous_iter_valid_loss : 0.07638218998908997\n",
      "\n",
      "    124000\t  0.076356\t  0.076382\t  0.079735\t\tCURRENT LEARNING RATE: 0.14440301394297783\n",
      "previous_iter_valid_loss : 0.08155348151922226\n",
      "\n",
      "    124200\t  0.081334\t  0.081553\t  0.079742\t\tCURRENT LEARNING RATE: 0.14411449652867864\n",
      "previous_iter_valid_loss : 0.0811649039387703\n",
      "\n",
      "    124400\t  0.080896\t  0.081165\t  0.079739\t\tCURRENT LEARNING RATE: 0.1438265555725577\n",
      "previous_iter_valid_loss : 0.07684291154146194\n",
      "\n",
      "    124600\t  0.076715\t  0.076843\t  0.079728\t\tCURRENT LEARNING RATE: 0.14353918992285084\n",
      "previous_iter_valid_loss : 0.07635703682899475\n",
      "\n",
      "    124800\t  0.076361\t  0.076357\t  0.079685\t\tCURRENT LEARNING RATE: 0.14325239843009505\n",
      "previous_iter_valid_loss : 0.07957249134778976\n",
      "\n",
      "    125000\t  0.079411\t  0.079572\t  0.079699\t\tCURRENT LEARNING RATE: 0.142966179947124\n",
      "previous_iter_valid_loss : 0.07520146667957306\n",
      "\n",
      "    125200\t  0.075107\t  0.075201\t  0.079678\t\tCURRENT LEARNING RATE: 0.14268053332906333\n",
      "previous_iter_valid_loss : 0.07574557512998581\n",
      "\n",
      "    125400\t  0.075684\t  0.075746\t  0.079667\t\tCURRENT LEARNING RATE: 0.14239545743332624\n",
      "previous_iter_valid_loss : 0.07725756615400314\n",
      "\n",
      "    125600\t  0.077175\t  0.077258\t  0.079669\t\tCURRENT LEARNING RATE: 0.14211095111960872\n",
      "previous_iter_valid_loss : 0.07672222703695297\n",
      "\n",
      "    125800\t  0.076674\t  0.076722\t  0.079665\t\tCURRENT LEARNING RATE: 0.1418270132498852\n",
      "previous_iter_valid_loss : 0.07887972891330719\n",
      "\n",
      "    126000\t  0.078889\t  0.078880\t  0.079614\t\tCURRENT LEARNING RATE: 0.14154364268840375\n",
      "previous_iter_valid_loss : 0.07600351423025131\n",
      "\n",
      "    126200\t  0.075941\t  0.076004\t  0.079563\t\tCURRENT LEARNING RATE: 0.1412608383016818\n",
      "previous_iter_valid_loss : 0.0774390771985054\n",
      "\n",
      "    126400\t  0.077353\t  0.077439\t  0.079559\t\tCURRENT LEARNING RATE: 0.14097859895850137\n",
      "previous_iter_valid_loss : 0.0808466374874115\n",
      "\n",
      "    126600\t  0.080721\t  0.080847\t  0.079515\t\tCURRENT LEARNING RATE: 0.14069692352990476\n",
      "previous_iter_valid_loss : 0.07632306218147278\n",
      "\n",
      "    126800\t  0.076308\t  0.076323\t  0.079514\t\tCURRENT LEARNING RATE: 0.1404158108891899\n",
      "previous_iter_valid_loss : 0.07617878168821335\n",
      "\n",
      "    127000\t  0.076109\t  0.076179\t  0.079503\t\tCURRENT LEARNING RATE: 0.14013525991190579\n",
      "previous_iter_valid_loss : 0.08578571677207947\n",
      "\n",
      "    127200\t  0.085610\t  0.085786\t  0.079525\t\tCURRENT LEARNING RATE: 0.13985526947584817\n",
      "previous_iter_valid_loss : 0.07632146030664444\n",
      "\n",
      "    127400\t  0.076218\t  0.076321\t  0.079497\t\tCURRENT LEARNING RATE: 0.13957583846105492\n",
      "previous_iter_valid_loss : 0.07833920419216156\n",
      "\n",
      "    127600\t  0.078350\t  0.078339\t  0.079472\t\tCURRENT LEARNING RATE: 0.13929696574980163\n",
      "previous_iter_valid_loss : 0.07861402630805969\n",
      "\n",
      "    127800\t  0.078663\t  0.078614\t  0.079461\t\tCURRENT LEARNING RATE: 0.13901865022659707\n",
      "previous_iter_valid_loss : 0.07670777291059494\n",
      "\n",
      "    128000\t  0.076665\t  0.076708\t  0.079432\t\tCURRENT LEARNING RATE: 0.13874089077817875\n",
      "previous_iter_valid_loss : 0.07582057267427444\n",
      "\n",
      "    128200\t  0.075796\t  0.075821\t  0.079397\t\tCURRENT LEARNING RATE: 0.13846368629350855\n",
      "previous_iter_valid_loss : 0.07605484873056412\n",
      "\n",
      "    128400\t  0.076029\t  0.076055\t  0.079350\t\tCURRENT LEARNING RATE: 0.13818703566376817\n",
      "previous_iter_valid_loss : 0.07910165190696716\n",
      "\n",
      "    128600\t  0.079086\t  0.079102\t  0.079327\t\tCURRENT LEARNING RATE: 0.13791093778235466\n",
      "previous_iter_valid_loss : 0.07660181075334549\n",
      "\n",
      "    128800\t  0.076485\t  0.076602\t  0.079312\t\tCURRENT LEARNING RATE: 0.13763539154487617\n",
      "previous_iter_valid_loss : 0.07691096514463425\n",
      "\n",
      "    129000\t  0.076894\t  0.076911\t  0.079310\t\tCURRENT LEARNING RATE: 0.13736039584914736\n",
      "previous_iter_valid_loss : 0.07771004736423492\n",
      "\n",
      "    129200\t  0.077631\t  0.077710\t  0.079261\t\tCURRENT LEARNING RATE: 0.1370859495951851\n",
      "previous_iter_valid_loss : 0.07787521183490753\n",
      "\n",
      "    129400\t  0.077756\t  0.077875\t  0.079256\t\tCURRENT LEARNING RATE: 0.13681205168520402\n",
      "previous_iter_valid_loss : 0.08072028309106827\n",
      "\n",
      "    129600\t  0.080770\t  0.080720\t  0.079243\t\tCURRENT LEARNING RATE: 0.1365387010236121\n",
      "previous_iter_valid_loss : 0.076911561191082\n",
      "\n",
      "    129800\t  0.076810\t  0.076912\t  0.079221\t\tCURRENT LEARNING RATE: 0.1362658965170063\n",
      "previous_iter_valid_loss : 0.0862090140581131\n",
      "\n",
      "    130000\t  0.086278\t  0.086209\t  0.079236\t\tCURRENT LEARNING RATE: 0.13599363707416826\n",
      "previous_iter_valid_loss : 0.07702033221721649\n",
      "\n",
      "    130200\t  0.076917\t  0.077020\t  0.079220\t\tCURRENT LEARNING RATE: 0.13572192160605986\n",
      "previous_iter_valid_loss : 0.0834459513425827\n",
      "\n",
      "    130400\t  0.083481\t  0.083446\t  0.079235\t\tCURRENT LEARNING RATE: 0.13545074902581883\n",
      "previous_iter_valid_loss : 0.0754091888666153\n",
      "\n",
      "    130600\t  0.075338\t  0.075409\t  0.079211\t\tCURRENT LEARNING RATE: 0.1351801182487545\n",
      "previous_iter_valid_loss : 0.0817880779504776\n",
      "\n",
      "    130800\t  0.081875\t  0.081788\t  0.079203\t\tCURRENT LEARNING RATE: 0.1349100281923434\n",
      "previous_iter_valid_loss : 0.07785122096538544\n",
      "\n",
      "    131000\t  0.077840\t  0.077851\t  0.079166\t\tCURRENT LEARNING RATE: 0.13464047777622498\n",
      "previous_iter_valid_loss : 0.07969427853822708\n",
      "\n",
      "    131200\t  0.079724\t  0.079694\t  0.079161\t\tCURRENT LEARNING RATE: 0.13437146592219718\n",
      "previous_iter_valid_loss : 0.08109244704246521\n",
      "\n",
      "    131400\t  0.081158\t  0.081092\t  0.079127\t\tCURRENT LEARNING RATE: 0.1341029915542122\n",
      "previous_iter_valid_loss : 0.07864535599946976\n",
      "\n",
      "    131600\t  0.078941\t  0.078645\t  0.079111\t\tCURRENT LEARNING RATE: 0.13383505359837228\n",
      "previous_iter_valid_loss : 0.09655048698186874\n",
      "\n",
      "    131800\t  0.096781\t  0.096550\t  0.079203\t\tCURRENT LEARNING RATE: 0.13356765098292517\n",
      "previous_iter_valid_loss : 0.07740285247564316\n",
      "\n",
      "    132000\t  0.077471\t  0.077403\t  0.079169\t\tCURRENT LEARNING RATE: 0.1333007826382601\n",
      "previous_iter_valid_loss : 0.07829740643501282\n",
      "\n",
      "    132200\t  0.078501\t  0.078297\t  0.079158\t\tCURRENT LEARNING RATE: 0.13303444749690332\n",
      "previous_iter_valid_loss : 0.07897379994392395\n",
      "\n",
      "    132400\t  0.079064\t  0.078974\t  0.079136\t\tCURRENT LEARNING RATE: 0.1327686444935139\n",
      "previous_iter_valid_loss : 0.08119527995586395\n",
      "\n",
      "    132600\t  0.081303\t  0.081195\t  0.079144\t\tCURRENT LEARNING RATE: 0.13250337256487946\n",
      "previous_iter_valid_loss : 0.07601644843816757\n",
      "\n",
      "    132800\t  0.076092\t  0.076016\t  0.079100\t\tCURRENT LEARNING RATE: 0.13223863064991198\n",
      "previous_iter_valid_loss : 0.07961969822645187\n",
      "\n",
      "    133000\t  0.079769\t  0.079620\t  0.079088\t\tCURRENT LEARNING RATE: 0.1319744176896434\n",
      "previous_iter_valid_loss : 0.09197602421045303\n",
      "\n",
      "    133200\t  0.092132\t  0.091976\t  0.079142\t\tCURRENT LEARNING RATE: 0.13171073262722155\n",
      "previous_iter_valid_loss : 0.07612407952547073\n",
      "\n",
      "    133400\t  0.076167\t  0.076124\t  0.079105\t\tCURRENT LEARNING RATE: 0.13144757440790583\n",
      "previous_iter_valid_loss : 0.08136213570833206\n",
      "\n",
      "    133600\t  0.081342\t  0.081362\t  0.079126\t\tCURRENT LEARNING RATE: 0.131184941979063\n",
      "previous_iter_valid_loss : 0.08070748299360275\n",
      "\n",
      "    133800\t  0.080580\t  0.080707\t  0.079141\t\tCURRENT LEARNING RATE: 0.130922834290163\n",
      "previous_iter_valid_loss : 0.07899172604084015\n",
      "\n",
      "    134000\t  0.078942\t  0.078992\t  0.079147\t\tCURRENT LEARNING RATE: 0.1306612502927747\n",
      "previous_iter_valid_loss : 0.08346863836050034\n",
      "\n",
      "    134200\t  0.083503\t  0.083469\t  0.079171\t\tCURRENT LEARNING RATE: 0.13040018894056182\n",
      "previous_iter_valid_loss : 0.07980113476514816\n",
      "\n",
      "    134400\t  0.079866\t  0.079801\t  0.079179\t\tCURRENT LEARNING RATE: 0.13013964918927856\n",
      "previous_iter_valid_loss : 0.07742113620042801\n",
      "\n",
      "    134600\t  0.077410\t  0.077421\t  0.079163\t\tCURRENT LEARNING RATE: 0.12987962999676556\n",
      "previous_iter_valid_loss : 0.07720912992954254\n",
      "\n",
      "    134800\t  0.077258\t  0.077209\t  0.079143\t\tCURRENT LEARNING RATE: 0.12962013032294575\n",
      "previous_iter_valid_loss : 0.07616089284420013\n",
      "\n",
      "    135000\t  0.076158\t  0.076161\t  0.079147\t\tCURRENT LEARNING RATE: 0.12936114912982002\n",
      "previous_iter_valid_loss : 0.07964248955249786\n",
      "\n",
      "    135200\t  0.079689\t  0.079642\t  0.079156\t\tCURRENT LEARNING RATE: 0.12910268538146333\n",
      "previous_iter_valid_loss : 0.08307555317878723\n",
      "\n",
      "    135400\t  0.083121\t  0.083076\t  0.079194\t\tCURRENT LEARNING RATE: 0.12884473804402027\n",
      "previous_iter_valid_loss : 0.08756726235151291\n",
      "\n",
      "    135600\t  0.087680\t  0.087567\t  0.079242\t\tCURRENT LEARNING RATE: 0.1285873060857012\n",
      "previous_iter_valid_loss : 0.09068699181079865\n",
      "\n",
      "    135800\t  0.090427\t  0.090687\t  0.079313\t\tCURRENT LEARNING RATE: 0.12833038847677794\n",
      "previous_iter_valid_loss : 0.0857599675655365\n",
      "\n",
      "    136000\t  0.085813\t  0.085760\t  0.079304\t\tCURRENT LEARNING RATE: 0.12807398418957966\n",
      "previous_iter_valid_loss : 0.11063676327466965\n",
      "\n",
      "    136200\t  0.111019\t  0.110637\t  0.079469\t\tCURRENT LEARNING RATE: 0.12781809219848891\n",
      "previous_iter_valid_loss : 0.07540377974510193\n",
      "\n",
      "    136400\t  0.075405\t  0.075404\t  0.079437\t\tCURRENT LEARNING RATE: 0.1275627114799374\n",
      "previous_iter_valid_loss : 0.07674618810415268\n",
      "\n",
      "    136600\t  0.076769\t  0.076746\t  0.079443\t\tCURRENT LEARNING RATE: 0.12730784101240186\n",
      "previous_iter_valid_loss : 0.07632451504468918\n",
      "\n",
      "    136800\t  0.076298\t  0.076325\t  0.079423\t\tCURRENT LEARNING RATE: 0.12705347977640014\n",
      "previous_iter_valid_loss : 0.08396454900503159\n",
      "\n",
      "    137000\t  0.084060\t  0.083965\t  0.079424\t\tCURRENT LEARNING RATE: 0.12679962675448692\n",
      "previous_iter_valid_loss : 0.07632111757993698\n",
      "\n",
      "    137200\t  0.076315\t  0.076321\t  0.079347\t\tCURRENT LEARNING RATE: 0.12654628093124978\n",
      "previous_iter_valid_loss : 0.07594411075115204\n",
      "\n",
      "    137400\t  0.075908\t  0.075944\t  0.079332\t\tCURRENT LEARNING RATE: 0.12629344129330514\n",
      "previous_iter_valid_loss : 0.07777921855449677\n",
      "\n",
      "    137600\t  0.077763\t  0.077779\t  0.079288\t\tCURRENT LEARNING RATE: 0.126041106829294\n",
      "previous_iter_valid_loss : 0.08162663131952286\n",
      "\n",
      "    137800\t  0.081629\t  0.081627\t  0.079276\t\tCURRENT LEARNING RATE: 0.12578927652987826\n",
      "previous_iter_valid_loss : 0.0770154520869255\n",
      "\n",
      "    138000\t  0.076965\t  0.077015\t  0.079253\t\tCURRENT LEARNING RATE: 0.12553794938773635\n",
      "previous_iter_valid_loss : 0.07735010981559753\n",
      "\n",
      "    138200\t  0.077318\t  0.077350\t  0.079237\t\tCURRENT LEARNING RATE: 0.1252871243975594\n",
      "previous_iter_valid_loss : 0.079979807138443\n",
      "\n",
      "    138400\t  0.079971\t  0.079980\t  0.079256\t\tCURRENT LEARNING RATE: 0.12503680055604707\n",
      "previous_iter_valid_loss : 0.07669860124588013\n",
      "\n",
      "    138600\t  0.076772\t  0.076699\t  0.079249\t\tCURRENT LEARNING RATE: 0.12478697686190367\n",
      "previous_iter_valid_loss : 0.08852449059486389\n",
      "\n",
      "    138800\t  0.088534\t  0.088524\t  0.079292\t\tCURRENT LEARNING RATE: 0.12453765231583411\n",
      "previous_iter_valid_loss : 0.08409938216209412\n",
      "\n",
      "    139000\t  0.084050\t  0.084099\t  0.079295\t\tCURRENT LEARNING RATE: 0.12428882592053986\n",
      "previous_iter_valid_loss : 0.07620174437761307\n",
      "\n",
      "    139200\t  0.076147\t  0.076202\t  0.079300\t\tCURRENT LEARNING RATE: 0.12404049668071501\n",
      "previous_iter_valid_loss : 0.07822628319263458\n",
      "\n",
      "    139400\t  0.078236\t  0.078226\t  0.079303\t\tCURRENT LEARNING RATE: 0.12379266360304228\n",
      "previous_iter_valid_loss : 0.07640181481838226\n",
      "\n",
      "    139600\t  0.076364\t  0.076402\t  0.079307\t\tCURRENT LEARNING RATE: 0.123545325696189\n",
      "previous_iter_valid_loss : 0.08133485168218613\n",
      "\n",
      "    139800\t  0.081407\t  0.081335\t  0.079331\t\tCURRENT LEARNING RATE: 0.12329848197080324\n",
      "previous_iter_valid_loss : 0.07859400659799576\n",
      "\n",
      "    140000\t  0.078607\t  0.078594\t  0.079309\t\tCURRENT LEARNING RATE: 0.12305213143950977\n",
      "previous_iter_valid_loss : 0.08220906555652618\n",
      "\n",
      "    140200\t  0.082386\t  0.082209\t  0.079311\t\tCURRENT LEARNING RATE: 0.12280627311690613\n",
      "previous_iter_valid_loss : 0.07602540403604507\n",
      "\n",
      "    140400\t  0.075936\t  0.076025\t  0.079305\t\tCURRENT LEARNING RATE: 0.12256090601955869\n",
      "previous_iter_valid_loss : 0.0763065293431282\n",
      "\n",
      "    140600\t  0.076289\t  0.076307\t  0.079290\t\tCURRENT LEARNING RATE: 0.12231602916599875\n",
      "previous_iter_valid_loss : 0.08047506213188171\n",
      "\n",
      "    140800\t  0.080532\t  0.080475\t  0.079308\t\tCURRENT LEARNING RATE: 0.12207164157671856\n",
      "previous_iter_valid_loss : 0.07635647803544998\n",
      "\n",
      "    141000\t  0.076307\t  0.076356\t  0.079308\t\tCURRENT LEARNING RATE: 0.12182774227416743\n",
      "previous_iter_valid_loss : 0.07854574173688889\n",
      "\n",
      "    141200\t  0.078547\t  0.078546\t  0.079322\t\tCURRENT LEARNING RATE: 0.12158433028274783\n",
      "previous_iter_valid_loss : 0.08078829199075699\n",
      "\n",
      "    141400\t  0.080784\t  0.080788\t  0.079342\t\tCURRENT LEARNING RATE: 0.12134140462881149\n",
      "previous_iter_valid_loss : 0.0810384675860405\n",
      "\n",
      "    141600\t  0.080960\t  0.081038\t  0.079360\t\tCURRENT LEARNING RATE: 0.12109896434065545\n",
      "previous_iter_valid_loss : 0.08978862315416336\n",
      "\n",
      "    141800\t  0.089939\t  0.089789\t  0.079408\t\tCURRENT LEARNING RATE: 0.12085700844851822\n",
      "previous_iter_valid_loss : 0.0787656381726265\n",
      "\n",
      "    142000\t  0.078682\t  0.078766\t  0.079366\t\tCURRENT LEARNING RATE: 0.12061553598457596\n",
      "previous_iter_valid_loss : 0.08695534616708755\n",
      "\n",
      "    142200\t  0.086988\t  0.086955\t  0.079424\t\tCURRENT LEARNING RATE: 0.12037454598293844\n",
      "previous_iter_valid_loss : 0.076227106153965\n",
      "\n",
      "    142400\t  0.076113\t  0.076227\t  0.079422\t\tCURRENT LEARNING RATE: 0.12013403747964535\n",
      "previous_iter_valid_loss : 0.07668502628803253\n",
      "\n",
      "    142600\t  0.076733\t  0.076685\t  0.079396\t\tCURRENT LEARNING RATE: 0.11989400951266235\n",
      "previous_iter_valid_loss : 0.09077224135398865\n",
      "\n",
      "    142800\t  0.090972\t  0.090772\t  0.079452\t\tCURRENT LEARNING RATE: 0.11965446112187728\n",
      "previous_iter_valid_loss : 0.07937078177928925\n",
      "\n",
      "    143000\t  0.079308\t  0.079371\t  0.079432\t\tCURRENT LEARNING RATE: 0.11941539134909622\n",
      "previous_iter_valid_loss : 0.07620790600776672\n",
      "\n",
      "    143200\t  0.076212\t  0.076208\t  0.079392\t\tCURRENT LEARNING RATE: 0.11917679923803978\n",
      "previous_iter_valid_loss : 0.08340863883495331\n",
      "\n",
      "    143400\t  0.083490\t  0.083409\t  0.079424\t\tCURRENT LEARNING RATE: 0.1189386838343392\n",
      "previous_iter_valid_loss : 0.08515661209821701\n",
      "\n",
      "    143600\t  0.085318\t  0.085157\t  0.079429\t\tCURRENT LEARNING RATE: 0.11870104418553254\n",
      "previous_iter_valid_loss : 0.07838217169046402\n",
      "\n",
      "    143800\t  0.078407\t  0.078382\t  0.079441\t\tCURRENT LEARNING RATE: 0.11846387934106088\n",
      "previous_iter_valid_loss : 0.07735048234462738\n",
      "\n",
      "    144000\t  0.077382\t  0.077350\t  0.079427\t\tCURRENT LEARNING RATE: 0.11822718835226455\n",
      "previous_iter_valid_loss : 0.07621028274297714\n",
      "\n",
      "    144200\t  0.076138\t  0.076210\t  0.079417\t\tCURRENT LEARNING RATE: 0.11799097027237926\n",
      "previous_iter_valid_loss : 0.07558261603116989\n",
      "\n",
      "    144400\t  0.075513\t  0.075583\t  0.079357\t\tCURRENT LEARNING RATE: 0.11775522415653238\n",
      "previous_iter_valid_loss : 0.07747390121221542\n",
      "\n",
      "    144600\t  0.077381\t  0.077474\t  0.079323\t\tCURRENT LEARNING RATE: 0.11751994906173914\n",
      "previous_iter_valid_loss : 0.07865864038467407\n",
      "\n",
      "    144800\t  0.078712\t  0.078659\t  0.079338\t\tCURRENT LEARNING RATE: 0.11728514404689883\n",
      "previous_iter_valid_loss : 0.07882854342460632\n",
      "\n",
      "    145000\t  0.078958\t  0.078829\t  0.079347\t\tCURRENT LEARNING RATE: 0.1170508081727911\n",
      "previous_iter_valid_loss : 0.07604801654815674\n",
      "\n",
      "    145200\t  0.076102\t  0.076048\t  0.079349\t\tCURRENT LEARNING RATE: 0.11681694050207211\n",
      "previous_iter_valid_loss : 0.083904929459095\n",
      "\n",
      "    145400\t  0.083820\t  0.083905\t  0.079387\t\tCURRENT LEARNING RATE: 0.1165835400992709\n",
      "previous_iter_valid_loss : 0.0771799385547638\n",
      "\n",
      "    145600\t  0.077202\t  0.077180\t  0.079374\t\tCURRENT LEARNING RATE: 0.11635060603078554\n",
      "previous_iter_valid_loss : 0.07679609209299088\n",
      "\n",
      "    145800\t  0.076677\t  0.076796\t  0.079351\t\tCURRENT LEARNING RATE: 0.11611813736487941\n",
      "previous_iter_valid_loss : 0.07518981397151947\n",
      "\n",
      "    146000\t  0.075112\t  0.075190\t  0.079343\t\tCURRENT LEARNING RATE: 0.11588613317167758\n",
      "previous_iter_valid_loss : 0.07663754373788834\n",
      "\n",
      "    146200\t  0.076598\t  0.076638\t  0.079343\t\tCURRENT LEARNING RATE: 0.11565459252316296\n",
      "previous_iter_valid_loss : 0.07625812292098999\n",
      "\n",
      "    146400\t  0.076223\t  0.076258\t  0.079326\t\tCURRENT LEARNING RATE: 0.11542351449317262\n",
      "previous_iter_valid_loss : 0.08362159132957458\n",
      "\n",
      "    146600\t  0.083487\t  0.083622\t  0.079335\t\tCURRENT LEARNING RATE: 0.11519289815739417\n",
      "previous_iter_valid_loss : 0.08544513583183289\n",
      "\n",
      "    146800\t  0.085322\t  0.085445\t  0.079372\t\tCURRENT LEARNING RATE: 0.11496274259336192\n",
      "previous_iter_valid_loss : 0.09412138909101486\n",
      "\n",
      "    147000\t  0.094012\t  0.094121\t  0.079422\t\tCURRENT LEARNING RATE: 0.11473304688045334\n",
      "previous_iter_valid_loss : 0.07923288643360138\n",
      "\n",
      "    147200\t  0.079149\t  0.079233\t  0.079415\t\tCURRENT LEARNING RATE: 0.11450381009988525\n",
      "previous_iter_valid_loss : 0.07893554866313934\n",
      "\n",
      "    147400\t  0.078941\t  0.078936\t  0.079423\t\tCURRENT LEARNING RATE: 0.11427503133471024\n",
      "previous_iter_valid_loss : 0.07584341615438461\n",
      "\n",
      "    147600\t  0.075814\t  0.075843\t  0.079416\t\tCURRENT LEARNING RATE: 0.11404670966981294\n",
      "previous_iter_valid_loss : 0.07688964158296585\n",
      "\n",
      "    147800\t  0.076830\t  0.076890\t  0.079414\t\tCURRENT LEARNING RATE: 0.11381884419190637\n",
      "previous_iter_valid_loss : 0.08048970252275467\n",
      "\n",
      "    148000\t  0.080447\t  0.080490\t  0.079432\t\tCURRENT LEARNING RATE: 0.11359143398952833\n",
      "previous_iter_valid_loss : 0.0782906785607338\n",
      "\n",
      "    148200\t  0.078285\t  0.078291\t  0.079390\t\tCURRENT LEARNING RATE: 0.11336447815303771\n",
      "previous_iter_valid_loss : 0.08372639864683151\n",
      "\n",
      "    148400\t  0.083520\t  0.083726\t  0.079423\t\tCURRENT LEARNING RATE: 0.11313797577461085\n",
      "previous_iter_valid_loss : 0.07865434139966965\n",
      "\n",
      "    148600\t  0.078601\t  0.078654\t  0.079419\t\tCURRENT LEARNING RATE: 0.11291192594823793\n",
      "previous_iter_valid_loss : 0.07580818980932236\n",
      "\n",
      "    148800\t  0.075674\t  0.075808\t  0.079353\t\tCURRENT LEARNING RATE: 0.11268632776971936\n",
      "previous_iter_valid_loss : 0.0774214044213295\n",
      "\n",
      "    149000\t  0.077364\t  0.077421\t  0.079340\t\tCURRENT LEARNING RATE: 0.11246118033666212\n",
      "previous_iter_valid_loss : 0.07762637734413147\n",
      "\n",
      "    149200\t  0.077583\t  0.077626\t  0.079336\t\tCURRENT LEARNING RATE: 0.11223648274847617\n",
      "previous_iter_valid_loss : 0.0756286084651947\n",
      "\n",
      "    149400\t  0.075588\t  0.075629\t  0.079283\t\tCURRENT LEARNING RATE: 0.11201223410637087\n",
      "previous_iter_valid_loss : 0.07981354743242264\n",
      "\n",
      "    149600\t  0.079763\t  0.079814\t  0.079299\t\tCURRENT LEARNING RATE: 0.11178843351335134\n",
      "previous_iter_valid_loss : 0.07541314512491226\n",
      "\n",
      "    149800\t  0.075337\t  0.075413\t  0.079228\t\tCURRENT LEARNING RATE: 0.11156508007421491\n",
      "previous_iter_valid_loss : 0.07968663424253464\n",
      "\n",
      "    150000\t  0.079758\t  0.079687\t  0.079225\t\tCURRENT LEARNING RATE: 0.11134217289554754\n",
      "previous_iter_valid_loss : 0.07844220846891403\n",
      "\n",
      "    150200\t  0.078493\t  0.078442\t  0.079224\t\tCURRENT LEARNING RATE: 0.1111197110857202\n",
      "previous_iter_valid_loss : 0.07753335684537888\n",
      "\n",
      "    150400\t  0.077527\t  0.077533\t  0.079216\t\tCURRENT LEARNING RATE: 0.11089769375488537\n",
      "previous_iter_valid_loss : 0.07602900266647339\n",
      "\n",
      "    150600\t  0.075919\t  0.076029\t  0.079192\t\tCURRENT LEARNING RATE: 0.11067612001497341\n",
      "previous_iter_valid_loss : 0.07747459411621094\n",
      "\n",
      "    150800\t  0.077420\t  0.077475\t  0.079188\t\tCURRENT LEARNING RATE: 0.1104549889796891\n",
      "previous_iter_valid_loss : 0.07865545153617859\n",
      "\n",
      "    151000\t  0.078731\t  0.078655\t  0.079179\t\tCURRENT LEARNING RATE: 0.11023429976450796\n",
      "previous_iter_valid_loss : 0.0778498649597168\n",
      "\n",
      "    151200\t  0.077852\t  0.077850\t  0.079175\t\tCURRENT LEARNING RATE: 0.11001405148667287\n",
      "previous_iter_valid_loss : 0.07655717432498932\n",
      "\n",
      "    151400\t  0.076512\t  0.076557\t  0.079179\t\tCURRENT LEARNING RATE: 0.10979424326519041\n",
      "previous_iter_valid_loss : 0.07567083090543747\n",
      "\n",
      "    151600\t  0.075699\t  0.075671\t  0.079174\t\tCURRENT LEARNING RATE: 0.1095748742208274\n",
      "previous_iter_valid_loss : 0.08164023607969284\n",
      "\n",
      "    151800\t  0.081736\t  0.081640\t  0.079199\t\tCURRENT LEARNING RATE: 0.10935594347610737\n",
      "previous_iter_valid_loss : 0.0752720832824707\n",
      "\n",
      "    152000\t  0.075245\t  0.075272\t  0.079142\t\tCURRENT LEARNING RATE: 0.10913745015530707\n",
      "previous_iter_valid_loss : 0.07503523677587509\n",
      "\n",
      "    152200\t  0.074975\t  0.075035\t  0.079110\t\tCURRENT LEARNING RATE: 0.10891939338445289\n",
      "previous_iter_valid_loss : 0.07709135115146637\n",
      "\n",
      "    152400\t  0.077089\t  0.077091\t  0.079112\t\tCURRENT LEARNING RATE: 0.10870177229131749\n",
      "previous_iter_valid_loss : 0.07532498240470886\n",
      "\n",
      "    152600\t  0.075295\t  0.075325\t  0.079087\t\tCURRENT LEARNING RATE: 0.10848458600541618\n",
      "previous_iter_valid_loss : 0.07638045400381088\n",
      "\n",
      "    152800\t  0.076395\t  0.076380\t  0.079083\t\tCURRENT LEARNING RATE: 0.10826783365800353\n",
      "previous_iter_valid_loss : 0.07769092172384262\n",
      "\n",
      "    153000\t  0.077691\t  0.077691\t  0.079068\t\tCURRENT LEARNING RATE: 0.10805151438206988\n",
      "previous_iter_valid_loss : 0.07541335374116898\n",
      "\n",
      "    153200\t  0.075369\t  0.075413\t  0.079054\t\tCURRENT LEARNING RATE: 0.10783562731233783\n",
      "previous_iter_valid_loss : 0.07483991980552673\n",
      "\n",
      "    153400\t  0.074795\t  0.074840\t  0.079042\t\tCURRENT LEARNING RATE: 0.10762017158525879\n",
      "previous_iter_valid_loss : 0.07804953306913376\n",
      "\n",
      "    153600\t  0.077970\t  0.078050\t  0.079046\t\tCURRENT LEARNING RATE: 0.1074051463390096\n",
      "previous_iter_valid_loss : 0.07633335143327713\n",
      "\n",
      "    153800\t  0.076273\t  0.076333\t  0.079044\t\tCURRENT LEARNING RATE: 0.10719055071348897\n",
      "previous_iter_valid_loss : 0.07709348201751709\n",
      "\n",
      "    154000\t  0.077027\t  0.077093\t  0.079045\t\tCURRENT LEARNING RATE: 0.10697638385031412\n",
      "previous_iter_valid_loss : 0.08250990509986877\n",
      "\n",
      "    154200\t  0.082499\t  0.082510\t  0.079077\t\tCURRENT LEARNING RATE: 0.1067626448928173\n",
      "previous_iter_valid_loss : 0.0808425173163414\n",
      "\n",
      "    154400\t  0.081033\t  0.080843\t  0.079104\t\tCURRENT LEARNING RATE: 0.10654933298604241\n",
      "previous_iter_valid_loss : 0.07552357763051987\n",
      "\n",
      "    154600\t  0.075387\t  0.075524\t  0.079094\t\tCURRENT LEARNING RATE: 0.10633644727674152\n",
      "previous_iter_valid_loss : 0.07679632306098938\n",
      "\n",
      "    154800\t  0.076667\t  0.076796\t  0.079100\t\tCURRENT LEARNING RATE: 0.10612398691337152\n",
      "previous_iter_valid_loss : 0.07657662779092789\n",
      "\n",
      "    155000\t  0.076528\t  0.076577\t  0.079084\t\tCURRENT LEARNING RATE: 0.10591195104609068\n",
      "previous_iter_valid_loss : 0.07946506142616272\n",
      "\n",
      "    155200\t  0.079333\t  0.079465\t  0.079087\t\tCURRENT LEARNING RATE: 0.10570033882675524\n",
      "previous_iter_valid_loss : 0.07606116682291031\n",
      "\n",
      "    155400\t  0.076018\t  0.076061\t  0.079082\t\tCURRENT LEARNING RATE: 0.10548914940891603\n",
      "previous_iter_valid_loss : 0.07711460441350937\n",
      "\n",
      "    155600\t  0.077050\t  0.077115\t  0.079072\t\tCURRENT LEARNING RATE: 0.10527838194781512\n",
      "previous_iter_valid_loss : 0.07655156403779984\n",
      "\n",
      "    155800\t  0.076440\t  0.076552\t  0.079059\t\tCURRENT LEARNING RATE: 0.10506803560038236\n",
      "previous_iter_valid_loss : 0.084810271859169\n",
      "\n",
      "    156000\t  0.084537\t  0.084810\t  0.079081\t\tCURRENT LEARNING RATE: 0.1048581095252321\n",
      "previous_iter_valid_loss : 0.0807463675737381\n",
      "\n",
      "    156200\t  0.080862\t  0.080746\t  0.079099\t\tCURRENT LEARNING RATE: 0.10464860288265976\n",
      "previous_iter_valid_loss : 0.07667507976293564\n",
      "\n",
      "    156400\t  0.076722\t  0.076675\t  0.079104\t\tCURRENT LEARNING RATE: 0.10443951483463847\n",
      "previous_iter_valid_loss : 0.07693786919116974\n",
      "\n",
      "    156600\t  0.076896\t  0.076938\t  0.079050\t\tCURRENT LEARNING RATE: 0.10423084454481576\n",
      "previous_iter_valid_loss : 0.0757824182510376\n",
      "\n",
      "    156800\t  0.075667\t  0.075782\t  0.079049\t\tCURRENT LEARNING RATE: 0.10402259117851023\n",
      "previous_iter_valid_loss : 0.08141572773456573\n",
      "\n",
      "    157000\t  0.081434\t  0.081416\t  0.079059\t\tCURRENT LEARNING RATE: 0.1038147539027081\n",
      "previous_iter_valid_loss : 0.0789981409907341\n",
      "\n",
      "    157200\t  0.078831\t  0.078998\t  0.079065\t\tCURRENT LEARNING RATE: 0.10360733188606\n",
      "previous_iter_valid_loss : 0.07935924082994461\n",
      "\n",
      "    157400\t  0.079504\t  0.079359\t  0.079056\t\tCURRENT LEARNING RATE: 0.10340032429887758\n",
      "previous_iter_valid_loss : 0.0757533460855484\n",
      "\n",
      "    157600\t  0.075627\t  0.075753\t  0.079059\t\tCURRENT LEARNING RATE: 0.10319373031313023\n",
      "previous_iter_valid_loss : 0.08094367384910583\n",
      "\n",
      "    157800\t  0.081025\t  0.080944\t  0.079042\t\tCURRENT LEARNING RATE: 0.10298754910244172\n",
      "previous_iter_valid_loss : 0.08409207314252853\n",
      "\n",
      "    158000\t  0.084100\t  0.084092\t  0.079086\t\tCURRENT LEARNING RATE: 0.10278177984208695\n",
      "previous_iter_valid_loss : 0.08182123303413391\n",
      "\n",
      "    158200\t  0.081679\t  0.081821\t  0.079099\t\tCURRENT LEARNING RATE: 0.10257642170898858\n",
      "previous_iter_valid_loss : 0.07665544003248215\n",
      "\n",
      "    158400\t  0.076660\t  0.076655\t  0.079058\t\tCURRENT LEARNING RATE: 0.10237147388171382\n",
      "previous_iter_valid_loss : 0.08418070524930954\n",
      "\n",
      "    158600\t  0.084235\t  0.084181\t  0.079091\t\tCURRENT LEARNING RATE: 0.10216693554047107\n",
      "previous_iter_valid_loss : 0.07825177907943726\n",
      "\n",
      "    158800\t  0.078090\t  0.078252\t  0.079104\t\tCURRENT LEARNING RATE: 0.10196280586710671\n",
      "previous_iter_valid_loss : 0.07525704056024551\n",
      "\n",
      "    159000\t  0.075275\t  0.075257\t  0.079103\t\tCURRENT LEARNING RATE: 0.10175908404510177\n",
      "previous_iter_valid_loss : 0.07828157395124435\n",
      "\n",
      "    159200\t  0.078208\t  0.078282\t  0.079116\t\tCURRENT LEARNING RATE: 0.10155576925956869\n",
      "previous_iter_valid_loss : 0.09542398899793625\n",
      "\n",
      "    159400\t  0.095482\t  0.095424\t  0.079181\t\tCURRENT LEARNING RATE: 0.10135286069724805\n",
      "previous_iter_valid_loss : 0.08406795561313629\n",
      "\n",
      "    159600\t  0.084215\t  0.084068\t  0.079210\t\tCURRENT LEARNING RATE: 0.10115035754650535\n",
      "previous_iter_valid_loss : 0.08179259300231934\n",
      "\n",
      "    159800\t  0.081932\t  0.081793\t  0.079228\t\tCURRENT LEARNING RATE: 0.10094825899732769\n",
      "previous_iter_valid_loss : 0.08035673946142197\n",
      "\n",
      "    160000\t  0.080337\t  0.080357\t  0.079248\t\tCURRENT LEARNING RATE: 0.10074656424132063\n",
      "previous_iter_valid_loss : 0.07509612292051315\n",
      "\n",
      "    160200\t  0.075074\t  0.075096\t  0.079245\t\tCURRENT LEARNING RATE: 0.10054527247170486\n",
      "previous_iter_valid_loss : 0.08333075791597366\n",
      "\n",
      "    160400\t  0.083233\t  0.083331\t  0.079279\t\tCURRENT LEARNING RATE: 0.10034438288331303\n",
      "previous_iter_valid_loss : 0.07640238106250763\n",
      "\n",
      "    160600\t  0.076518\t  0.076402\t  0.079275\t\tCURRENT LEARNING RATE: 0.10014389467258653\n",
      "previous_iter_valid_loss : 0.08539877831935883\n",
      "\n",
      "    160800\t  0.085484\t  0.085399\t  0.079322\t\tCURRENT LEARNING RATE: 0.09994380703757225\n",
      "previous_iter_valid_loss : 0.07832351326942444\n",
      "\n",
      "    161000\t  0.078299\t  0.078324\t  0.079326\t\tCURRENT LEARNING RATE: 0.09974411917791937\n",
      "previous_iter_valid_loss : 0.0752161517739296\n",
      "\n",
      "    161200\t  0.075248\t  0.075216\t  0.079324\t\tCURRENT LEARNING RATE: 0.0995448302948762\n",
      "previous_iter_valid_loss : 0.07535343617200851\n",
      "\n",
      "    161400\t  0.075236\t  0.075353\t  0.079288\t\tCURRENT LEARNING RATE: 0.09934593959128693\n",
      "previous_iter_valid_loss : 0.07988075166940689\n",
      "\n",
      "    161600\t  0.080009\t  0.079881\t  0.079273\t\tCURRENT LEARNING RATE: 0.09914744627158849\n",
      "previous_iter_valid_loss : 0.09298384934663773\n",
      "\n",
      "    161800\t  0.093060\t  0.092984\t  0.079320\t\tCURRENT LEARNING RATE: 0.09894934954180733\n",
      "previous_iter_valid_loss : 0.07565077394247055\n",
      "\n",
      "    162000\t  0.075627\t  0.075651\t  0.079311\t\tCURRENT LEARNING RATE: 0.09875164860955628\n",
      "previous_iter_valid_loss : 0.07620303332805634\n",
      "\n",
      "    162200\t  0.076253\t  0.076203\t  0.079311\t\tCURRENT LEARNING RATE: 0.09855434268403132\n",
      "previous_iter_valid_loss : 0.07949909567832947\n",
      "\n",
      "    162400\t  0.079491\t  0.079499\t  0.079331\t\tCURRENT LEARNING RATE: 0.09835743097600853\n",
      "previous_iter_valid_loss : 0.07958842068910599\n",
      "\n",
      "    162600\t  0.079523\t  0.079588\t  0.079341\t\tCURRENT LEARNING RATE: 0.09816091269784077\n",
      "previous_iter_valid_loss : 0.07778097689151764\n",
      "\n",
      "    162800\t  0.077707\t  0.077781\t  0.079335\t\tCURRENT LEARNING RATE: 0.09796478706345468\n",
      "previous_iter_valid_loss : 0.0820373073220253\n",
      "\n",
      "    163000\t  0.082131\t  0.082037\t  0.079352\t\tCURRENT LEARNING RATE: 0.09776905328834747\n",
      "previous_iter_valid_loss : 0.08354374766349792\n",
      "\n",
      "    163200\t  0.083393\t  0.083544\t  0.079386\t\tCURRENT LEARNING RATE: 0.09757371058958376\n",
      "previous_iter_valid_loss : 0.07577721029520035\n",
      "\n",
      "    163400\t  0.075829\t  0.075777\t  0.079384\t\tCURRENT LEARNING RATE: 0.09737875818579252\n",
      "previous_iter_valid_loss : 0.08240446448326111\n",
      "\n",
      "    163600\t  0.082652\t  0.082404\t  0.079410\t\tCURRENT LEARNING RATE: 0.09718419529716385\n",
      "previous_iter_valid_loss : 0.07910355925559998\n",
      "\n",
      "    163800\t  0.079236\t  0.079104\t  0.079427\t\tCURRENT LEARNING RATE: 0.09699002114544596\n",
      "previous_iter_valid_loss : 0.0764339342713356\n",
      "\n",
      "    164000\t  0.076401\t  0.076434\t  0.079428\t\tCURRENT LEARNING RATE: 0.09679623495394196\n",
      "previous_iter_valid_loss : 0.08674000948667526\n",
      "\n",
      "    164200\t  0.086630\t  0.086740\t  0.079454\t\tCURRENT LEARNING RATE: 0.09660283594750685\n",
      "previous_iter_valid_loss : 0.08436071872711182\n",
      "\n",
      "    164400\t  0.084515\t  0.084361\t  0.079470\t\tCURRENT LEARNING RATE: 0.09640982335254432\n",
      "previous_iter_valid_loss : 0.07835230231285095\n",
      "\n",
      "    164600\t  0.078236\t  0.078352\t  0.079477\t\tCURRENT LEARNING RATE: 0.09621719639700375\n",
      "previous_iter_valid_loss : 0.08194728195667267\n",
      "\n",
      "    164800\t  0.082077\t  0.081947\t  0.079505\t\tCURRENT LEARNING RATE: 0.09602495431037707\n",
      "previous_iter_valid_loss : 0.07629119604825974\n",
      "\n",
      "    165000\t  0.076255\t  0.076291\t  0.079489\t\tCURRENT LEARNING RATE: 0.09583309632369565\n",
      "previous_iter_valid_loss : 0.08206164091825485\n",
      "\n",
      "    165200\t  0.082295\t  0.082062\t  0.079523\t\tCURRENT LEARNING RATE: 0.0956416216695273\n",
      "previous_iter_valid_loss : 0.07686194032430649\n",
      "\n",
      "    165400\t  0.076907\t  0.076862\t  0.079529\t\tCURRENT LEARNING RATE: 0.09545052958197317\n",
      "previous_iter_valid_loss : 0.08032625168561935\n",
      "\n",
      "    165600\t  0.080281\t  0.080326\t  0.079544\t\tCURRENT LEARNING RATE: 0.09525981929666462\n",
      "previous_iter_valid_loss : 0.07730397582054138\n",
      "\n",
      "    165800\t  0.077278\t  0.077304\t  0.079547\t\tCURRENT LEARNING RATE: 0.09506949005076028\n",
      "previous_iter_valid_loss : 0.07504468411207199\n",
      "\n",
      "    166000\t  0.074985\t  0.075045\t  0.079528\t\tCURRENT LEARNING RATE: 0.09487954108294289\n",
      "previous_iter_valid_loss : 0.09872704744338989\n",
      "\n",
      "    166200\t  0.098456\t  0.098727\t  0.079641\t\tCURRENT LEARNING RATE: 0.09468997163341634\n",
      "previous_iter_valid_loss : 0.07617620378732681\n",
      "\n",
      "    166400\t  0.076073\t  0.076176\t  0.079635\t\tCURRENT LEARNING RATE: 0.09450078094390257\n",
      "previous_iter_valid_loss : 0.07574571669101715\n",
      "\n",
      "    166600\t  0.075747\t  0.075746\t  0.079610\t\tCURRENT LEARNING RATE: 0.0943119682576386\n",
      "previous_iter_valid_loss : 0.07876051217317581\n",
      "\n",
      "    166800\t  0.078668\t  0.078761\t  0.079622\t\tCURRENT LEARNING RATE: 0.0941235328193734\n",
      "previous_iter_valid_loss : 0.08318716287612915\n",
      "\n",
      "    167000\t  0.083287\t  0.083187\t  0.079657\t\tCURRENT LEARNING RATE: 0.09393547387536497\n",
      "previous_iter_valid_loss : 0.07569222897291183\n",
      "\n",
      "    167200\t  0.075666\t  0.075692\t  0.079606\t\tCURRENT LEARNING RATE: 0.09374779067337728\n",
      "previous_iter_valid_loss : 0.09150433540344238\n",
      "\n",
      "    167400\t  0.091216\t  0.091504\t  0.079682\t\tCURRENT LEARNING RATE: 0.0935604824626773\n",
      "previous_iter_valid_loss : 0.07587819546461105\n",
      "\n",
      "    167600\t  0.075796\t  0.075878\t  0.079670\t\tCURRENT LEARNING RATE: 0.0933735484940319\n",
      "previous_iter_valid_loss : 0.07560767233371735\n",
      "\n",
      "    167800\t  0.075629\t  0.075608\t  0.079655\t\tCURRENT LEARNING RATE: 0.09318698801970499\n",
      "previous_iter_valid_loss : 0.08863126486539841\n",
      "\n",
      "    168000\t  0.088777\t  0.088631\t  0.079714\t\tCURRENT LEARNING RATE: 0.0930008002934544\n",
      "previous_iter_valid_loss : 0.08164601027965546\n",
      "\n",
      "    168200\t  0.081640\t  0.081646\t  0.079744\t\tCURRENT LEARNING RATE: 0.09281498457052899\n",
      "previous_iter_valid_loss : 0.0782885029911995\n",
      "\n",
      "    168400\t  0.078357\t  0.078289\t  0.079755\t\tCURRENT LEARNING RATE: 0.09262954010766561\n",
      "previous_iter_valid_loss : 0.07539638876914978\n",
      "\n",
      "    168600\t  0.075381\t  0.075396\t  0.079736\t\tCURRENT LEARNING RATE: 0.09244446616308617\n",
      "previous_iter_valid_loss : 0.07993929088115692\n",
      "\n",
      "    168800\t  0.080075\t  0.079939\t  0.079753\t\tCURRENT LEARNING RATE: 0.09225976199649463\n",
      "previous_iter_valid_loss : 0.07592322677373886\n",
      "\n",
      "    169000\t  0.075934\t  0.075923\t  0.079748\t\tCURRENT LEARNING RATE: 0.0920754268690741\n",
      "previous_iter_valid_loss : 0.07799332588911057\n",
      "\n",
      "    169200\t  0.078035\t  0.077993\t  0.079749\t\tCURRENT LEARNING RATE: 0.09189146004348382\n",
      "previous_iter_valid_loss : 0.07819104939699173\n",
      "\n",
      "    169400\t  0.078180\t  0.078191\t  0.079751\t\tCURRENT LEARNING RATE: 0.09170786078385623\n",
      "previous_iter_valid_loss : 0.07598312944173813\n",
      "\n",
      "    169600\t  0.075920\t  0.075983\t  0.079727\t\tCURRENT LEARNING RATE: 0.09152462835579406\n",
      "previous_iter_valid_loss : 0.08430181443691254\n",
      "\n",
      "    169800\t  0.084129\t  0.084302\t  0.079764\t\tCURRENT LEARNING RATE: 0.09134176202636733\n",
      "previous_iter_valid_loss : 0.09384673088788986\n",
      "\n",
      "    170000\t  0.093777\t  0.093847\t  0.079802\t\tCURRENT LEARNING RATE: 0.0911592610641105\n",
      "previous_iter_valid_loss : 0.08657903224229813\n",
      "\n",
      "    170200\t  0.086414\t  0.086579\t  0.079850\t\tCURRENT LEARNING RATE: 0.09097712473901948\n",
      "previous_iter_valid_loss : 0.08242535591125488\n",
      "\n",
      "    170400\t  0.082382\t  0.082425\t  0.079845\t\tCURRENT LEARNING RATE: 0.0907953523225487\n",
      "previous_iter_valid_loss : 0.07831667363643646\n",
      "\n",
      "    170600\t  0.078458\t  0.078317\t  0.079860\t\tCURRENT LEARNING RATE: 0.0906139430876083\n",
      "previous_iter_valid_loss : 0.08541131019592285\n",
      "\n",
      "    170800\t  0.085487\t  0.085411\t  0.079878\t\tCURRENT LEARNING RATE: 0.09043289630856105\n",
      "previous_iter_valid_loss : 0.0759650468826294\n",
      "\n",
      "    171000\t  0.075940\t  0.075965\t  0.079868\t\tCURRENT LEARNING RATE: 0.09025221126121961\n",
      "previous_iter_valid_loss : 0.08375424146652222\n",
      "\n",
      "    171200\t  0.083642\t  0.083754\t  0.079889\t\tCURRENT LEARNING RATE: 0.09007188722284355\n",
      "previous_iter_valid_loss : 0.08834020048379898\n",
      "\n",
      "    171400\t  0.088304\t  0.088340\t  0.079925\t\tCURRENT LEARNING RATE: 0.08989192347213648\n",
      "previous_iter_valid_loss : 0.07840629667043686\n",
      "\n",
      "    171600\t  0.078357\t  0.078406\t  0.079924\t\tCURRENT LEARNING RATE: 0.08971231928924317\n",
      "previous_iter_valid_loss : 0.07622082531452179\n",
      "\n",
      "    171800\t  0.076160\t  0.076221\t  0.079822\t\tCURRENT LEARNING RATE: 0.08953307395574661\n",
      "previous_iter_valid_loss : 0.08047023415565491\n",
      "\n",
      "    172000\t  0.080308\t  0.080470\t  0.079837\t\tCURRENT LEARNING RATE: 0.08935418675466526\n",
      "previous_iter_valid_loss : 0.07673271745443344\n",
      "\n",
      "    172200\t  0.076696\t  0.076733\t  0.079830\t\tCURRENT LEARNING RATE: 0.08917565697045007\n",
      "previous_iter_valid_loss : 0.07766974717378616\n",
      "\n",
      "    172400\t  0.077613\t  0.077670\t  0.079823\t\tCURRENT LEARNING RATE: 0.08899748388898167\n",
      "previous_iter_valid_loss : 0.07783699780702591\n",
      "\n",
      "    172600\t  0.077749\t  0.077837\t  0.079806\t\tCURRENT LEARNING RATE: 0.08881966679756748\n",
      "previous_iter_valid_loss : 0.07897404581308365\n",
      "\n",
      "    172800\t  0.078997\t  0.078974\t  0.079821\t\tCURRENT LEARNING RATE: 0.08864220498493891\n",
      "previous_iter_valid_loss : 0.07613623887300491\n",
      "\n",
      "    173000\t  0.076138\t  0.076136\t  0.079804\t\tCURRENT LEARNING RATE: 0.08846509774124846\n",
      "previous_iter_valid_loss : 0.07804310321807861\n",
      "\n",
      "    173200\t  0.078009\t  0.078043\t  0.079734\t\tCURRENT LEARNING RATE: 0.08828834435806694\n",
      "previous_iter_valid_loss : 0.07927455008029938\n",
      "\n",
      "    173400\t  0.079131\t  0.079275\t  0.079750\t\tCURRENT LEARNING RATE: 0.08811194412838055\n",
      "previous_iter_valid_loss : 0.0760059729218483\n",
      "\n",
      "    173600\t  0.075942\t  0.076006\t  0.079723\t\tCURRENT LEARNING RATE: 0.08793589634658819\n",
      "previous_iter_valid_loss : 0.08134909719228745\n",
      "\n",
      "    173800\t  0.081248\t  0.081349\t  0.079726\t\tCURRENT LEARNING RATE: 0.08776020030849843\n",
      "previous_iter_valid_loss : 0.07829095423221588\n",
      "\n",
      "    174000\t  0.078343\t  0.078291\t  0.079723\t\tCURRENT LEARNING RATE: 0.08758485531132694\n",
      "previous_iter_valid_loss : 0.08650527149438858\n",
      "\n",
      "    174200\t  0.086589\t  0.086505\t  0.079738\t\tCURRENT LEARNING RATE: 0.08740986065369347\n",
      "previous_iter_valid_loss : 0.0817805603146553\n",
      "\n",
      "    174400\t  0.081829\t  0.081781\t  0.079748\t\tCURRENT LEARNING RATE: 0.08723521563561916\n",
      "previous_iter_valid_loss : 0.08430759608745575\n",
      "\n",
      "    174600\t  0.084428\t  0.084308\t  0.079782\t\tCURRENT LEARNING RATE: 0.0870609195585237\n",
      "previous_iter_valid_loss : 0.08666076511144638\n",
      "\n",
      "    174800\t  0.086521\t  0.086661\t  0.079829\t\tCURRENT LEARNING RATE: 0.08688697172522257\n",
      "previous_iter_valid_loss : 0.08015516400337219\n",
      "\n",
      "    175000\t  0.080302\t  0.080155\t  0.079849\t\tCURRENT LEARNING RATE: 0.08671337143992418\n",
      "previous_iter_valid_loss : 0.07675968110561371\n",
      "\n",
      "    175200\t  0.076613\t  0.076760\t  0.079835\t\tCURRENT LEARNING RATE: 0.08654011800822717\n",
      "previous_iter_valid_loss : 0.07718119770288467\n",
      "\n",
      "    175400\t  0.077203\t  0.077181\t  0.079806\t\tCURRENT LEARNING RATE: 0.08636721073711758\n",
      "previous_iter_valid_loss : 0.0797661542892456\n",
      "\n",
      "    175600\t  0.079792\t  0.079766\t  0.079767\t\tCURRENT LEARNING RATE: 0.08619464893496609\n",
      "previous_iter_valid_loss : 0.08650057762861252\n",
      "\n",
      "    175800\t  0.086357\t  0.086501\t  0.079746\t\tCURRENT LEARNING RATE: 0.08602243191152527\n",
      "previous_iter_valid_loss : 0.07599641382694244\n",
      "\n",
      "    176000\t  0.075964\t  0.075996\t  0.079697\t\tCURRENT LEARNING RATE: 0.08585055897792679\n",
      "previous_iter_valid_loss : 0.0802556723356247\n",
      "\n",
      "    176200\t  0.080107\t  0.080256\t  0.079545\t\tCURRENT LEARNING RATE: 0.08567902944667868\n",
      "previous_iter_valid_loss : 0.07980143278837204\n",
      "\n",
      "    176400\t  0.079618\t  0.079801\t  0.079567\t\tCURRENT LEARNING RATE: 0.08550784263166261\n",
      "previous_iter_valid_loss : 0.07525236159563065\n",
      "\n",
      "    176600\t  0.075161\t  0.075252\t  0.079559\t\tCURRENT LEARNING RATE: 0.08533699784813108\n",
      "previous_iter_valid_loss : 0.08113549649715424\n",
      "\n",
      "    176800\t  0.081219\t  0.081135\t  0.079583\t\tCURRENT LEARNING RATE: 0.08516649441270471\n",
      "previous_iter_valid_loss : 0.0771210789680481\n",
      "\n",
      "    177000\t  0.076926\t  0.077121\t  0.079549\t\tCURRENT LEARNING RATE: 0.08499633164336956\n",
      "previous_iter_valid_loss : 0.08268856257200241\n",
      "\n",
      "    177200\t  0.082725\t  0.082689\t  0.079581\t\tCURRENT LEARNING RATE: 0.0848265088594743\n",
      "previous_iter_valid_loss : 0.07927393913269043\n",
      "\n",
      "    177400\t  0.079414\t  0.079274\t  0.079598\t\tCURRENT LEARNING RATE: 0.08465702538172759\n",
      "previous_iter_valid_loss : 0.07869309931993484\n",
      "\n",
      "    177600\t  0.078558\t  0.078693\t  0.079602\t\tCURRENT LEARNING RATE: 0.08448788053219529\n",
      "previous_iter_valid_loss : 0.07502631843090057\n",
      "\n",
      "    177800\t  0.074918\t  0.075026\t  0.079569\t\tCURRENT LEARNING RATE: 0.08431907363429775\n",
      "previous_iter_valid_loss : 0.09002504497766495\n",
      "\n",
      "    178000\t  0.090254\t  0.090025\t  0.079634\t\tCURRENT LEARNING RATE: 0.08415060401280719\n",
      "previous_iter_valid_loss : 0.08266519755125046\n",
      "\n",
      "    178200\t  0.082679\t  0.082665\t  0.079661\t\tCURRENT LEARNING RATE: 0.08398247099384487\n",
      "previous_iter_valid_loss : 0.08131331205368042\n",
      "\n",
      "    178400\t  0.081396\t  0.081313\t  0.079668\t\tCURRENT LEARNING RATE: 0.0838146739048785\n",
      "previous_iter_valid_loss : 0.07697909325361252\n",
      "\n",
      "    178600\t  0.076964\t  0.076979\t  0.079669\t\tCURRENT LEARNING RATE: 0.0836472120747195\n",
      "previous_iter_valid_loss : 0.08773893117904663\n",
      "\n",
      "    178800\t  0.087903\t  0.087739\t  0.079665\t\tCURRENT LEARNING RATE: 0.08348008483352035\n",
      "previous_iter_valid_loss : 0.08108197152614594\n",
      "\n",
      "    179000\t  0.081221\t  0.081082\t  0.079650\t\tCURRENT LEARNING RATE: 0.08331329151277182\n",
      "previous_iter_valid_loss : 0.07655487209558487\n",
      "\n",
      "    179200\t  0.076526\t  0.076555\t  0.079652\t\tCURRENT LEARNING RATE: 0.08314683144530044\n",
      "previous_iter_valid_loss : 0.07821302860975266\n",
      "\n",
      "    179400\t  0.078254\t  0.078213\t  0.079652\t\tCURRENT LEARNING RATE: 0.08298070396526569\n",
      "previous_iter_valid_loss : 0.07997066527605057\n",
      "\n",
      "    179600\t  0.080003\t  0.079971\t  0.079669\t\tCURRENT LEARNING RATE: 0.08281490840815746\n",
      "previous_iter_valid_loss : 0.08090829849243164\n",
      "\n",
      "    179800\t  0.080750\t  0.080908\t  0.079667\t\tCURRENT LEARNING RATE: 0.08264944411079327\n",
      "previous_iter_valid_loss : 0.08087573200464249\n",
      "\n",
      "    180000\t  0.080925\t  0.080876\t  0.079679\t\tCURRENT LEARNING RATE: 0.08248431041131572\n",
      "previous_iter_valid_loss : 0.07611791044473648\n",
      "\n",
      "    180200\t  0.076066\t  0.076118\t  0.079648\t\tCURRENT LEARNING RATE: 0.0823195066491898\n",
      "previous_iter_valid_loss : 0.07585541903972626\n",
      "\n",
      "    180400\t  0.075794\t  0.075855\t  0.079647\t\tCURRENT LEARNING RATE: 0.08215503216520023\n",
      "previous_iter_valid_loss : 0.07941915839910507\n",
      "\n",
      "    180600\t  0.079490\t  0.079419\t  0.079663\t\tCURRENT LEARNING RATE: 0.08199088630144886\n",
      "previous_iter_valid_loss : 0.07744590938091278\n",
      "\n",
      "    180800\t  0.077478\t  0.077446\t  0.079648\t\tCURRENT LEARNING RATE: 0.08182706840135202\n",
      "previous_iter_valid_loss : 0.07756597548723221\n",
      "\n",
      "    181000\t  0.077422\t  0.077566\t  0.079654\t\tCURRENT LEARNING RATE: 0.0816635778096379\n",
      "previous_iter_valid_loss : 0.07808871567249298\n",
      "\n",
      "    181200\t  0.078001\t  0.078089\t  0.079652\t\tCURRENT LEARNING RATE: 0.08150041387234389\n",
      "previous_iter_valid_loss : 0.08238402009010315\n",
      "\n",
      "    181400\t  0.082530\t  0.082384\t  0.079660\t\tCURRENT LEARNING RATE: 0.08133757593681404\n",
      "previous_iter_valid_loss : 0.07983104884624481\n",
      "\n",
      "    181600\t  0.079752\t  0.079831\t  0.079654\t\tCURRENT LEARNING RATE: 0.08117506335169639\n",
      "previous_iter_valid_loss : 0.07762105017900467\n",
      "\n",
      "    181800\t  0.077623\t  0.077621\t  0.079593\t\tCURRENT LEARNING RATE: 0.08101287546694037\n",
      "previous_iter_valid_loss : 0.0794219821691513\n",
      "\n",
      "    182000\t  0.079577\t  0.079422\t  0.079596\t\tCURRENT LEARNING RATE: 0.08085101163379425\n",
      "previous_iter_valid_loss : 0.07560990005731583\n",
      "\n",
      "    182200\t  0.075485\t  0.075610\t  0.079539\t\tCURRENT LEARNING RATE: 0.08068947120480247\n",
      "previous_iter_valid_loss : 0.07628751546144485\n",
      "\n",
      "    182400\t  0.076199\t  0.076288\t  0.079540\t\tCURRENT LEARNING RATE: 0.08052825353380308\n",
      "previous_iter_valid_loss : 0.077656090259552\n",
      "\n",
      "    182600\t  0.077681\t  0.077656\t  0.079544\t\tCURRENT LEARNING RATE: 0.08036735797592519\n",
      "previous_iter_valid_loss : 0.07563309371471405\n",
      "\n",
      "    182800\t  0.075546\t  0.075633\t  0.079469\t\tCURRENT LEARNING RATE: 0.08020678388758637\n",
      "previous_iter_valid_loss : 0.07596354931592941\n",
      "\n",
      "    183000\t  0.075886\t  0.075964\t  0.079452\t\tCURRENT LEARNING RATE: 0.08004653062649005\n",
      "previous_iter_valid_loss : 0.0761614665389061\n",
      "\n",
      "    183200\t  0.076140\t  0.076161\t  0.079451\t\tCURRENT LEARNING RATE: 0.07988659755162296\n",
      "previous_iter_valid_loss : 0.07590152323246002\n",
      "\n",
      "    183400\t  0.075824\t  0.075902\t  0.079414\t\tCURRENT LEARNING RATE: 0.07972698402325258\n",
      "previous_iter_valid_loss : 0.08227375894784927\n",
      "\n",
      "    183600\t  0.082194\t  0.082274\t  0.079400\t\tCURRENT LEARNING RATE: 0.07956768940292461\n",
      "previous_iter_valid_loss : 0.08312790095806122\n",
      "\n",
      "    183800\t  0.083186\t  0.083128\t  0.079423\t\tCURRENT LEARNING RATE: 0.07940871305346034\n",
      "previous_iter_valid_loss : 0.0882478579878807\n",
      "\n",
      "    184000\t  0.088411\t  0.088248\t  0.079478\t\tCURRENT LEARNING RATE: 0.07925005433895416\n",
      "previous_iter_valid_loss : 0.07935986667871475\n",
      "\n",
      "    184200\t  0.079323\t  0.079360\t  0.079493\t\tCURRENT LEARNING RATE: 0.07909171262477101\n",
      "previous_iter_valid_loss : 0.07763812690973282\n",
      "\n",
      "    184400\t  0.077657\t  0.077638\t  0.079504\t\tCURRENT LEARNING RATE: 0.0789336872775438\n",
      "previous_iter_valid_loss : 0.07537908107042313\n",
      "\n",
      "    184600\t  0.075254\t  0.075379\t  0.079493\t\tCURRENT LEARNING RATE: 0.07877597766517096\n",
      "previous_iter_valid_loss : 0.07910411059856415\n",
      "\n",
      "    184800\t  0.079150\t  0.079104\t  0.079496\t\tCURRENT LEARNING RATE: 0.0786185831568138\n",
      "previous_iter_valid_loss : 0.08099301904439926\n",
      "\n",
      "    185000\t  0.080748\t  0.080993\t  0.079506\t\tCURRENT LEARNING RATE: 0.0784615031228941\n",
      "previous_iter_valid_loss : 0.080181784927845\n",
      "\n",
      "    185200\t  0.080222\t  0.080182\t  0.079527\t\tCURRENT LEARNING RATE: 0.0783047369350915\n",
      "previous_iter_valid_loss : 0.08638691902160645\n",
      "\n",
      "    185400\t  0.086563\t  0.086387\t  0.079539\t\tCURRENT LEARNING RATE: 0.07814828396634106\n",
      "previous_iter_valid_loss : 0.0765070766210556\n",
      "\n",
      "    185600\t  0.076422\t  0.076507\t  0.079536\t\tCURRENT LEARNING RATE: 0.07799214359083068\n",
      "previous_iter_valid_loss : 0.09525101631879807\n",
      "\n",
      "    185800\t  0.094934\t  0.095251\t  0.079628\t\tCURRENT LEARNING RATE: 0.07783631518399865\n",
      "previous_iter_valid_loss : 0.08320137858390808\n",
      "\n",
      "    186000\t  0.082948\t  0.083201\t  0.079668\t\tCURRENT LEARNING RATE: 0.07768079812253113\n",
      "previous_iter_valid_loss : 0.08759468048810959\n",
      "\n",
      "    186200\t  0.087585\t  0.087595\t  0.079723\t\tCURRENT LEARNING RATE: 0.07752559178435968\n",
      "previous_iter_valid_loss : 0.09330648928880692\n",
      "\n",
      "    186400\t  0.093368\t  0.093306\t  0.079808\t\tCURRENT LEARNING RATE: 0.07737069554865875\n",
      "previous_iter_valid_loss : 0.07742930948734283\n",
      "\n",
      "    186600\t  0.077331\t  0.077429\t  0.079777\t\tCURRENT LEARNING RATE: 0.07721610879584316\n",
      "previous_iter_valid_loss : 0.07873266935348511\n",
      "\n",
      "    186800\t  0.078768\t  0.078733\t  0.079744\t\tCURRENT LEARNING RATE: 0.0770618309075657\n",
      "previous_iter_valid_loss : 0.07612054795026779\n",
      "\n",
      "    187000\t  0.076013\t  0.076121\t  0.079654\t\tCURRENT LEARNING RATE: 0.07690786126671463\n",
      "previous_iter_valid_loss : 0.10319415479898453\n",
      "\n",
      "    187200\t  0.102901\t  0.103194\t  0.079774\t\tCURRENT LEARNING RATE: 0.07675419925741117\n",
      "previous_iter_valid_loss : 0.07757018506526947\n",
      "\n",
      "    187400\t  0.077484\t  0.077570\t  0.079767\t\tCURRENT LEARNING RATE: 0.0766008442650071\n",
      "previous_iter_valid_loss : 0.08212757855653763\n",
      "\n",
      "    187600\t  0.082133\t  0.082128\t  0.079798\t\tCURRENT LEARNING RATE: 0.0764477956760822\n",
      "previous_iter_valid_loss : 0.07565369457006454\n",
      "\n",
      "    187800\t  0.075524\t  0.075654\t  0.079792\t\tCURRENT LEARNING RATE: 0.07629505287844195\n",
      "previous_iter_valid_loss : 0.08117470145225525\n",
      "\n",
      "    188000\t  0.081043\t  0.081175\t  0.079796\t\tCURRENT LEARNING RATE: 0.07614261526111492\n",
      "previous_iter_valid_loss : 0.0839618369936943\n",
      "\n",
      "    188200\t  0.083811\t  0.083962\t  0.079824\t\tCURRENT LEARNING RATE: 0.07599048221435047\n",
      "previous_iter_valid_loss : 0.07816699892282486\n",
      "\n",
      "    188400\t  0.078172\t  0.078167\t  0.079796\t\tCURRENT LEARNING RATE: 0.0758386531296162\n",
      "previous_iter_valid_loss : 0.0809118002653122\n",
      "\n",
      "    188600\t  0.081041\t  0.080912\t  0.079807\t\tCURRENT LEARNING RATE: 0.07568712739959556\n",
      "previous_iter_valid_loss : 0.08010989427566528\n",
      "\n",
      "    188800\t  0.080047\t  0.080110\t  0.079829\t\tCURRENT LEARNING RATE: 0.07553590441818543\n",
      "previous_iter_valid_loss : 0.07597635686397552\n",
      "\n",
      "    189000\t  0.075863\t  0.075976\t  0.079822\t\tCURRENT LEARNING RATE: 0.0753849835804937\n",
      "previous_iter_valid_loss : 0.0761009156703949\n",
      "\n",
      "    189200\t  0.075969\t  0.076101\t  0.079814\t\tCURRENT LEARNING RATE: 0.0752343642828368\n",
      "previous_iter_valid_loss : 0.08766090869903564\n",
      "\n",
      "    189400\t  0.087715\t  0.087661\t  0.079874\t\tCURRENT LEARNING RATE: 0.07508404592273733\n",
      "previous_iter_valid_loss : 0.0800112634897232\n",
      "\n",
      "    189600\t  0.079838\t  0.080011\t  0.079875\t\tCURRENT LEARNING RATE: 0.07493402789892167\n",
      "previous_iter_valid_loss : 0.12292062491178513\n",
      "\n",
      "    189800\t  0.122652\t  0.122921\t  0.080113\t\tCURRENT LEARNING RATE: 0.07478430961131753\n",
      "previous_iter_valid_loss : 0.08267898112535477\n",
      "\n",
      "    190000\t  0.082728\t  0.082679\t  0.080128\t\tCURRENT LEARNING RATE: 0.07463489046105154\n",
      "previous_iter_valid_loss : 0.07839971780776978\n",
      "\n",
      "    190200\t  0.078347\t  0.078400\t  0.080127\t\tCURRENT LEARNING RATE: 0.07448576985044691\n",
      "previous_iter_valid_loss : 0.08040757477283478\n",
      "\n",
      "    190400\t  0.080368\t  0.080408\t  0.080142\t\tCURRENT LEARNING RATE: 0.074336947183021\n",
      "previous_iter_valid_loss : 0.07751895487308502\n",
      "\n",
      "    190600\t  0.077362\t  0.077519\t  0.080149\t\tCURRENT LEARNING RATE: 0.07418842186348293\n",
      "previous_iter_valid_loss : 0.07663507759571075\n",
      "\n",
      "    190800\t  0.076503\t  0.076635\t  0.080145\t\tCURRENT LEARNING RATE: 0.07404019329773123\n",
      "previous_iter_valid_loss : 0.0897408276796341\n",
      "\n",
      "    191000\t  0.089523\t  0.089741\t  0.080201\t\tCURRENT LEARNING RATE: 0.07389226089285145\n",
      "previous_iter_valid_loss : 0.07918626070022583\n",
      "\n",
      "    191200\t  0.079288\t  0.079186\t  0.080207\t\tCURRENT LEARNING RATE: 0.07374462405711375\n",
      "previous_iter_valid_loss : 0.0763189047574997\n",
      "\n",
      "    191400\t  0.076118\t  0.076319\t  0.080206\t\tCURRENT LEARNING RATE: 0.07359728219997062\n",
      "previous_iter_valid_loss : 0.07968459278345108\n",
      "\n",
      "    191600\t  0.079616\t  0.079685\t  0.080226\t\tCURRENT LEARNING RATE: 0.07345023473205442\n",
      "previous_iter_valid_loss : 0.0806518942117691\n",
      "\n",
      "    191800\t  0.080489\t  0.080652\t  0.080221\t\tCURRENT LEARNING RATE: 0.07330348106517508\n",
      "previous_iter_valid_loss : 0.09084615856409073\n",
      "\n",
      "    192000\t  0.090598\t  0.090846\t  0.080299\t\tCURRENT LEARNING RATE: 0.07315702061231773\n",
      "previous_iter_valid_loss : 0.09870287030935287\n",
      "\n",
      "    192200\t  0.099115\t  0.098703\t  0.080417\t\tCURRENT LEARNING RATE: 0.07301085278764037\n",
      "previous_iter_valid_loss : 0.07762658596038818\n",
      "\n",
      "    192400\t  0.077375\t  0.077627\t  0.080420\t\tCURRENT LEARNING RATE: 0.07286497700647152\n",
      "previous_iter_valid_loss : 0.07811914384365082\n",
      "\n",
      "    192600\t  0.078082\t  0.078119\t  0.080434\t\tCURRENT LEARNING RATE: 0.07271939268530785\n",
      "previous_iter_valid_loss : 0.07622290402650833\n",
      "\n",
      "    192800\t  0.076125\t  0.076223\t  0.080433\t\tCURRENT LEARNING RATE: 0.07257409924181187\n",
      "previous_iter_valid_loss : 0.08039774745702744\n",
      "\n",
      "    193000\t  0.080296\t  0.080398\t  0.080447\t\tCURRENT LEARNING RATE: 0.07242909609480963\n",
      "previous_iter_valid_loss : 0.07707113772630692\n",
      "\n",
      "    193200\t  0.076905\t  0.077071\t  0.080455\t\tCURRENT LEARNING RATE: 0.07228438266428834\n",
      "previous_iter_valid_loss : 0.0783403068780899\n",
      "\n",
      "    193400\t  0.078193\t  0.078340\t  0.080473\t\tCURRENT LEARNING RATE: 0.07213995837139409\n",
      "previous_iter_valid_loss : 0.08398260176181793\n",
      "\n",
      "    193600\t  0.083667\t  0.083983\t  0.080502\t\tCURRENT LEARNING RATE: 0.0719958226384295\n",
      "previous_iter_valid_loss : 0.12370266765356064\n",
      "\n",
      "    193800\t  0.123979\t  0.123703\t  0.080739\t\tCURRENT LEARNING RATE: 0.07185197488885146\n",
      "previous_iter_valid_loss : 0.08018916100263596\n",
      "\n",
      "    194000\t  0.080173\t  0.080189\t  0.080755\t\tCURRENT LEARNING RATE: 0.07170841454726878\n",
      "previous_iter_valid_loss : 0.09248971194028854\n",
      "\n",
      "    194200\t  0.092196\t  0.092490\t  0.080804\t\tCURRENT LEARNING RATE: 0.07156514103943991\n",
      "previous_iter_valid_loss : 0.07766900956630707\n",
      "\n",
      "    194400\t  0.077587\t  0.077669\t  0.080789\t\tCURRENT LEARNING RATE: 0.07142215379227061\n",
      "previous_iter_valid_loss : 0.10600142925977707\n",
      "\n",
      "    194600\t  0.106010\t  0.106001\t  0.080941\t\tCURRENT LEARNING RATE: 0.07127945223381171\n",
      "previous_iter_valid_loss : 0.08552209287881851\n",
      "\n",
      "    194800\t  0.085455\t  0.085522\t  0.080985\t\tCURRENT LEARNING RATE: 0.0711370357932568\n",
      "previous_iter_valid_loss : 0.07737590372562408\n",
      "\n",
      "    195000\t  0.077356\t  0.077376\t  0.080989\t\tCURRENT LEARNING RATE: 0.07099490390093989\n",
      "previous_iter_valid_loss : 0.07813053578138351\n",
      "\n",
      "    195200\t  0.078072\t  0.078131\t  0.080982\t\tCURRENT LEARNING RATE: 0.07085305598833325\n",
      "previous_iter_valid_loss : 0.07651487737894058\n",
      "\n",
      "    195400\t  0.076294\t  0.076515\t  0.080984\t\tCURRENT LEARNING RATE: 0.07071149148804504\n",
      "previous_iter_valid_loss : 0.07636912912130356\n",
      "\n",
      "    195600\t  0.076203\t  0.076369\t  0.080980\t\tCURRENT LEARNING RATE: 0.07057020983381705\n",
      "previous_iter_valid_loss : 0.07894308120012283\n",
      "\n",
      "    195800\t  0.078810\t  0.078943\t  0.080992\t\tCURRENT LEARNING RATE: 0.0704292104605225\n",
      "previous_iter_valid_loss : 0.07939302176237106\n",
      "\n",
      "    196000\t  0.079302\t  0.079393\t  0.080965\t\tCURRENT LEARNING RATE: 0.0702884928041637\n",
      "previous_iter_valid_loss : 0.07724378257989883\n",
      "\n",
      "    196200\t  0.077174\t  0.077244\t  0.080948\t\tCURRENT LEARNING RATE: 0.07014805630186982\n",
      "previous_iter_valid_loss : 0.0874805822968483\n",
      "\n",
      "    196400\t  0.087715\t  0.087481\t  0.081002\t\tCURRENT LEARNING RATE: 0.0700079003918947\n",
      "previous_iter_valid_loss : 0.07997453957796097\n",
      "\n",
      "    196600\t  0.079895\t  0.079975\t  0.081017\t\tCURRENT LEARNING RATE: 0.06986802451361447\n",
      "previous_iter_valid_loss : 0.08392397314310074\n",
      "\n",
      "    196800\t  0.083882\t  0.083924\t  0.081058\t\tCURRENT LEARNING RATE: 0.06972842810752547\n",
      "previous_iter_valid_loss : 0.08369018882513046\n",
      "\n",
      "    197000\t  0.084018\t  0.083690\t  0.081069\t\tCURRENT LEARNING RATE: 0.06958911061524187\n",
      "previous_iter_valid_loss : 0.0998712107539177\n",
      "\n",
      "    197200\t  0.099916\t  0.099871\t  0.081173\t\tCURRENT LEARNING RATE: 0.0694500714794935\n",
      "previous_iter_valid_loss : 0.08101048320531845\n",
      "\n",
      "    197400\t  0.080941\t  0.081010\t  0.081182\t\tCURRENT LEARNING RATE: 0.06931131014412366\n",
      "previous_iter_valid_loss : 0.08707704395055771\n",
      "\n",
      "    197600\t  0.087296\t  0.087077\t  0.081238\t\tCURRENT LEARNING RATE: 0.06917282605408681\n",
      "previous_iter_valid_loss : 0.07895871251821518\n",
      "\n",
      "    197800\t  0.078918\t  0.078959\t  0.081228\t\tCURRENT LEARNING RATE: 0.06903461865544641\n",
      "previous_iter_valid_loss : 0.08270801603794098\n",
      "\n",
      "    198000\t  0.082702\t  0.082708\t  0.081221\t\tCURRENT LEARNING RATE: 0.06889668739537268\n",
      "previous_iter_valid_loss : 0.07697340846061707\n",
      "\n",
      "    198200\t  0.076865\t  0.076973\t  0.081197\t\tCURRENT LEARNING RATE: 0.06875903172214037\n",
      "previous_iter_valid_loss : 0.0779905915260315\n",
      "\n",
      "    198400\t  0.078025\t  0.077991\t  0.081204\t\tCURRENT LEARNING RATE: 0.06862165108512666\n",
      "previous_iter_valid_loss : 0.0870746374130249\n",
      "\n",
      "    198600\t  0.086891\t  0.087075\t  0.081218\t\tCURRENT LEARNING RATE: 0.06848454493480877\n",
      "previous_iter_valid_loss : 0.09472869336605072\n",
      "\n",
      "    198800\t  0.094641\t  0.094729\t  0.081301\t\tCURRENT LEARNING RATE: 0.06834771272276192\n",
      "previous_iter_valid_loss : 0.07548865675926208\n",
      "\n",
      "    199000\t  0.075359\t  0.075489\t  0.081302\t\tCURRENT LEARNING RATE: 0.06821115390165712\n",
      "previous_iter_valid_loss : 0.07951903343200684\n",
      "\n",
      "    199200\t  0.079471\t  0.079519\t  0.081308\t\tCURRENT LEARNING RATE: 0.06807486792525885\n",
      "previous_iter_valid_loss : 0.07583881169557571\n",
      "\n",
      "    199400\t  0.075738\t  0.075839\t  0.081210\t\tCURRENT LEARNING RATE: 0.06793885424842307\n",
      "previous_iter_valid_loss : 0.08860301226377487\n",
      "\n",
      "    199600\t  0.088769\t  0.088603\t  0.081233\t\tCURRENT LEARNING RATE: 0.06780311232709485\n",
      "previous_iter_valid_loss : 0.08041365444660187\n",
      "\n",
      "    199800\t  0.080426\t  0.080414\t  0.081226\t\tCURRENT LEARNING RATE: 0.06766764161830635\n",
      "previous_iter_valid_loss : 0.07615736126899719\n",
      "\n",
      "    200000\t  0.076076\t  0.076157\t  0.081205\t\tCURRENT LEARNING RATE: 0.06753244158017456\n",
      "previous_iter_valid_loss : 0.07911752909421921\n",
      "\n",
      "    200200\t  0.079010\t  0.079118\t  0.081225\t\tCURRENT LEARNING RATE: 0.0673975116718991\n",
      "previous_iter_valid_loss : 0.1339280754327774\n",
      "\n",
      "    200400\t  0.133767\t  0.133928\t  0.081478\t\tCURRENT LEARNING RATE: 0.06726285135376023\n",
      "previous_iter_valid_loss : 0.08560315519571304\n",
      "\n",
      "    200600\t  0.085635\t  0.085603\t  0.081524\t\tCURRENT LEARNING RATE: 0.06712846008711643\n",
      "previous_iter_valid_loss : 0.0923580750823021\n",
      "\n",
      "    200800\t  0.092148\t  0.092358\t  0.081559\t\tCURRENT LEARNING RATE: 0.06699433733440249\n",
      "previous_iter_valid_loss : 0.0898527055978775\n",
      "\n",
      "    201000\t  0.089581\t  0.089853\t  0.081617\t\tCURRENT LEARNING RATE: 0.0668604825591272\n",
      "previous_iter_valid_loss : 0.10084227472543716\n",
      "\n",
      "    201200\t  0.101018\t  0.100842\t  0.081745\t\tCURRENT LEARNING RATE: 0.06672689522587133\n",
      "previous_iter_valid_loss : 0.07835636287927628\n",
      "\n",
      "    201400\t  0.078264\t  0.078356\t  0.081760\t\tCURRENT LEARNING RATE: 0.0665935748002853\n",
      "previous_iter_valid_loss : 0.07908021658658981\n",
      "\n",
      "    201600\t  0.079021\t  0.079080\t  0.081756\t\tCURRENT LEARNING RATE: 0.06646052074908729\n",
      "previous_iter_valid_loss : 0.08563689887523651\n",
      "\n",
      "    201800\t  0.085393\t  0.085637\t  0.081719\t\tCURRENT LEARNING RATE: 0.06632773254006086\n",
      "previous_iter_valid_loss : 0.07624880969524384\n",
      "\n",
      "    202000\t  0.076047\t  0.076249\t  0.081722\t\tCURRENT LEARNING RATE: 0.06619520964205305\n",
      "previous_iter_valid_loss : 0.08898951858282089\n",
      "\n",
      "    202200\t  0.088819\t  0.088990\t  0.081786\t\tCURRENT LEARNING RATE: 0.06606295152497205\n",
      "previous_iter_valid_loss : 0.0930657610297203\n",
      "\n",
      "    202400\t  0.092824\t  0.093066\t  0.081854\t\tCURRENT LEARNING RATE: 0.06593095765978527\n",
      "previous_iter_valid_loss : 0.08011322468519211\n",
      "\n",
      "    202600\t  0.080143\t  0.080113\t  0.081856\t\tCURRENT LEARNING RATE: 0.065799227518517\n",
      "previous_iter_valid_loss : 0.0785822942852974\n",
      "\n",
      "    202800\t  0.078491\t  0.078582\t  0.081860\t\tCURRENT LEARNING RATE: 0.06566776057424656\n",
      "previous_iter_valid_loss : 0.10158463567495346\n",
      "\n",
      "    203000\t  0.101638\t  0.101585\t  0.081958\t\tCURRENT LEARNING RATE: 0.06553655630110594\n",
      "previous_iter_valid_loss : 0.07864491641521454\n",
      "\n",
      "    203200\t  0.078442\t  0.078645\t  0.081934\t\tCURRENT LEARNING RATE: 0.06540561417427794\n",
      "previous_iter_valid_loss : 0.07679510116577148\n",
      "\n",
      "    203400\t  0.076729\t  0.076795\t  0.081939\t\tCURRENT LEARNING RATE: 0.06527493366999382\n",
      "previous_iter_valid_loss : 0.09116063266992569\n",
      "\n",
      "    203600\t  0.091149\t  0.091161\t  0.081982\t\tCURRENT LEARNING RATE: 0.06514451426553144\n",
      "previous_iter_valid_loss : 0.08060585707426071\n",
      "\n",
      "    203800\t  0.080724\t  0.080606\t  0.081990\t\tCURRENT LEARNING RATE: 0.06501435543921295\n",
      "previous_iter_valid_loss : 0.10960142314434052\n",
      "\n",
      "    204000\t  0.109310\t  0.109601\t  0.082156\t\tCURRENT LEARNING RATE: 0.06488445667040293\n",
      "previous_iter_valid_loss : 0.0793008953332901\n",
      "\n",
      "    204200\t  0.079304\t  0.079301\t  0.082119\t\tCURRENT LEARNING RATE: 0.06475481743950609\n",
      "previous_iter_valid_loss : 0.07696611434221268\n",
      "\n",
      "    204400\t  0.076859\t  0.076966\t  0.082082\t\tCURRENT LEARNING RATE: 0.06462543722796536\n",
      "previous_iter_valid_loss : 0.07818013429641724\n",
      "\n",
      "    204600\t  0.077987\t  0.078180\t  0.082081\t\tCURRENT LEARNING RATE: 0.0644963155182597\n",
      "previous_iter_valid_loss : 0.0783003494143486\n",
      "\n",
      "    204800\t  0.078277\t  0.078300\t  0.082063\t\tCURRENT LEARNING RATE: 0.06436745179390212\n",
      "previous_iter_valid_loss : 0.08615951240062714\n",
      "\n",
      "    205000\t  0.085901\t  0.086160\t  0.082112\t\tCURRENT LEARNING RATE: 0.06423884553943751\n",
      "previous_iter_valid_loss : 0.0778428465127945\n",
      "\n",
      "    205200\t  0.077736\t  0.077843\t  0.082091\t\tCURRENT LEARNING RATE: 0.06411049624044075\n",
      "previous_iter_valid_loss : 0.08069043606519699\n",
      "\n",
      "    205400\t  0.080482\t  0.080690\t  0.082110\t\tCURRENT LEARNING RATE: 0.0639824033835144\n",
      "previous_iter_valid_loss : 0.07967735081911087\n",
      "\n",
      "    205600\t  0.079647\t  0.079677\t  0.082107\t\tCURRENT LEARNING RATE: 0.06385456645628691\n",
      "previous_iter_valid_loss : 0.07582364231348038\n",
      "\n",
      "    205800\t  0.075717\t  0.075824\t  0.082099\t\tCURRENT LEARNING RATE: 0.06372698494741037\n",
      "previous_iter_valid_loss : 0.08693931251764297\n",
      "\n",
      "    206000\t  0.086882\t  0.086939\t  0.082159\t\tCURRENT LEARNING RATE: 0.0635996583465586\n",
      "previous_iter_valid_loss : 0.08825448155403137\n",
      "\n",
      "    206200\t  0.088285\t  0.088254\t  0.082106\t\tCURRENT LEARNING RATE: 0.06347258614442501\n",
      "previous_iter_valid_loss : 0.07652294635772705\n",
      "\n",
      "    206400\t  0.076395\t  0.076523\t  0.082108\t\tCURRENT LEARNING RATE: 0.06334576783272065\n",
      "previous_iter_valid_loss : 0.1009574681520462\n",
      "\n",
      "    206600\t  0.101595\t  0.100957\t  0.082234\t\tCURRENT LEARNING RATE: 0.06321920290417204\n",
      "previous_iter_valid_loss : 0.0981752797961235\n",
      "\n",
      "    206800\t  0.097976\t  0.098175\t  0.082331\t\tCURRENT LEARNING RATE: 0.06309289085251939\n",
      "previous_iter_valid_loss : 0.09746123850345612\n",
      "\n",
      "    207000\t  0.097527\t  0.097461\t  0.082403\t\tCURRENT LEARNING RATE: 0.06296683117251423\n",
      "previous_iter_valid_loss : 0.08405006676912308\n",
      "\n",
      "    207200\t  0.084028\t  0.084050\t  0.082444\t\tCURRENT LEARNING RATE: 0.06284102335991774\n",
      "previous_iter_valid_loss : 0.07825421541929245\n",
      "\n",
      "    207400\t  0.078294\t  0.078254\t  0.082378\t\tCURRENT LEARNING RATE: 0.06271546691149846\n",
      "previous_iter_valid_loss : 0.07720943540334702\n",
      "\n",
      "    207600\t  0.077243\t  0.077209\t  0.082385\t\tCURRENT LEARNING RATE: 0.06259016132503047\n",
      "previous_iter_valid_loss : 0.07788221538066864\n",
      "\n",
      "    207800\t  0.077893\t  0.077882\t  0.082396\t\tCURRENT LEARNING RATE: 0.06246510609929121\n",
      "previous_iter_valid_loss : 0.0762978121638298\n",
      "\n",
      "    208000\t  0.076201\t  0.076298\t  0.082335\t\tCURRENT LEARNING RATE: 0.062340300734059655\n",
      "previous_iter_valid_loss : 0.0802946537733078\n",
      "\n",
      "    208200\t  0.080434\t  0.080295\t  0.082328\t\tCURRENT LEARNING RATE: 0.06221574473011413\n",
      "previous_iter_valid_loss : 0.09157466888427734\n",
      "\n",
      "    208400\t  0.091560\t  0.091575\t  0.082394\t\tCURRENT LEARNING RATE: 0.06209143758923051\n",
      "previous_iter_valid_loss : 0.08792543411254883\n",
      "\n",
      "    208600\t  0.088099\t  0.087925\t  0.082457\t\tCURRENT LEARNING RATE: 0.06196737881418001\n",
      "previous_iter_valid_loss : 0.09298200905323029\n",
      "\n",
      "    208800\t  0.093021\t  0.092982\t  0.082522\t\tCURRENT LEARNING RATE: 0.061843567908727415\n",
      "previous_iter_valid_loss : 0.09031590819358826\n",
      "\n",
      "    209000\t  0.090101\t  0.090316\t  0.082594\t\tCURRENT LEARNING RATE: 0.06172000437762889\n",
      "previous_iter_valid_loss : 0.07956067472696304\n",
      "\n",
      "    209200\t  0.079411\t  0.079561\t  0.082602\t\tCURRENT LEARNING RATE: 0.06159668772663019\n",
      "previous_iter_valid_loss : 0.08666753023862839\n",
      "\n",
      "    209400\t  0.086513\t  0.086668\t  0.082644\t\tCURRENT LEARNING RATE: 0.0614736174624645\n",
      "previous_iter_valid_loss : 0.07794098556041718\n",
      "\n",
      "    209600\t  0.077983\t  0.077941\t  0.082654\t\tCURRENT LEARNING RATE: 0.06135079309285065\n",
      "previous_iter_valid_loss : 0.07856158167123795\n",
      "\n",
      "    209800\t  0.078545\t  0.078562\t  0.082625\t\tCURRENT LEARNING RATE: 0.06122821412649095\n",
      "previous_iter_valid_loss : 0.08654288202524185\n",
      "\n",
      "    210000\t  0.086864\t  0.086543\t  0.082589\t\tCURRENT LEARNING RATE: 0.06110588007306942\n",
      "previous_iter_valid_loss : 0.08106561750173569\n",
      "\n",
      "    210200\t  0.080984\t  0.081066\t  0.082561\t\tCURRENT LEARNING RATE: 0.06098379044324963\n",
      "previous_iter_valid_loss : 0.08079253137111664\n",
      "\n",
      "    210400\t  0.080974\t  0.080793\t  0.082553\t\tCURRENT LEARNING RATE: 0.060861944748672944\n",
      "previous_iter_valid_loss : 0.08954010158777237\n",
      "\n",
      "    210600\t  0.089663\t  0.089540\t  0.082609\t\tCURRENT LEARNING RATE: 0.06074034250195638\n",
      "previous_iter_valid_loss : 0.07780226320028305\n",
      "\n",
      "    210800\t  0.077694\t  0.077802\t  0.082571\t\tCURRENT LEARNING RATE: 0.06061898321669084\n",
      "previous_iter_valid_loss : 0.0835021510720253\n",
      "\n",
      "    211000\t  0.083625\t  0.083502\t  0.082609\t\tCURRENT LEARNING RATE: 0.06049786640743896\n",
      "previous_iter_valid_loss : 0.08451543003320694\n",
      "\n",
      "    211200\t  0.084372\t  0.084515\t  0.082613\t\tCURRENT LEARNING RATE: 0.060376991589733406\n",
      "previous_iter_valid_loss : 0.08976079523563385\n",
      "\n",
      "    211400\t  0.089837\t  0.089761\t  0.082620\t\tCURRENT LEARNING RATE: 0.06025635828007469\n",
      "previous_iter_valid_loss : 0.08282364159822464\n",
      "\n",
      "    211600\t  0.082842\t  0.082824\t  0.082642\t\tCURRENT LEARNING RATE: 0.060135965995929457\n",
      "previous_iter_valid_loss : 0.09900613874197006\n",
      "\n",
      "    211800\t  0.099330\t  0.099006\t  0.082756\t\tCURRENT LEARNING RATE: 0.06001581425572836\n",
      "previous_iter_valid_loss : 0.10017848759889603\n",
      "\n",
      "    212000\t  0.100452\t  0.100178\t  0.082854\t\tCURRENT LEARNING RATE: 0.05989590257886434\n",
      "previous_iter_valid_loss : 0.08873742073774338\n",
      "\n",
      "    212200\t  0.088891\t  0.088737\t  0.082914\t\tCURRENT LEARNING RATE: 0.05977623048569047\n",
      "previous_iter_valid_loss : 0.07713942229747772\n",
      "\n",
      "    212400\t  0.077139\t  0.077139\t  0.082912\t\tCURRENT LEARNING RATE: 0.05965679749751826\n",
      "previous_iter_valid_loss : 0.07929986715316772\n",
      "\n",
      "    212600\t  0.079225\t  0.079300\t  0.082919\t\tCURRENT LEARNING RATE: 0.05953760313661557\n",
      "previous_iter_valid_loss : 0.08233364671468735\n",
      "\n",
      "    212800\t  0.082404\t  0.082334\t  0.082936\t\tCURRENT LEARNING RATE: 0.05941864692620483\n",
      "previous_iter_valid_loss : 0.07860337197780609\n",
      "\n",
      "    213000\t  0.078552\t  0.078603\t  0.082948\t\tCURRENT LEARNING RATE: 0.05929992839046099\n",
      "previous_iter_valid_loss : 0.08323584496974945\n",
      "\n",
      "    213200\t  0.083375\t  0.083236\t  0.082974\t\tCURRENT LEARNING RATE: 0.05918144705450981\n",
      "previous_iter_valid_loss : 0.08435762673616409\n",
      "\n",
      "    213400\t  0.084560\t  0.084358\t  0.082999\t\tCURRENT LEARNING RATE: 0.05906320244442573\n",
      "previous_iter_valid_loss : 0.08524800091981888\n",
      "\n",
      "    213600\t  0.085716\t  0.085248\t  0.083046\t\tCURRENT LEARNING RATE: 0.0589451940872302\n",
      "previous_iter_valid_loss : 0.07686023414134979\n",
      "\n",
      "    213800\t  0.076753\t  0.076860\t  0.083023\t\tCURRENT LEARNING RATE: 0.05882742151088959\n",
      "previous_iter_valid_loss : 0.0824262797832489\n",
      "\n",
      "    214000\t  0.082756\t  0.082426\t  0.083044\t\tCURRENT LEARNING RATE: 0.05870988424431349\n",
      "previous_iter_valid_loss : 0.08164477348327637\n",
      "\n",
      "    214200\t  0.081476\t  0.081645\t  0.083020\t\tCURRENT LEARNING RATE: 0.058592581817352614\n",
      "previous_iter_valid_loss : 0.0811435654759407\n",
      "\n",
      "    214400\t  0.081109\t  0.081144\t  0.083016\t\tCURRENT LEARNING RATE: 0.05847551376079716\n",
      "previous_iter_valid_loss : 0.07838534563779831\n",
      "\n",
      "    214600\t  0.078252\t  0.078385\t  0.082987\t\tCURRENT LEARNING RATE: 0.05835867960637469\n",
      "previous_iter_valid_loss : 0.08276883512735367\n",
      "\n",
      "    214800\t  0.083025\t  0.082769\t  0.082967\t\tCURRENT LEARNING RATE: 0.05824207888674848\n",
      "previous_iter_valid_loss : 0.07942760735750198\n",
      "\n",
      "    215000\t  0.079494\t  0.079428\t  0.082964\t\tCURRENT LEARNING RATE: 0.05812571113551546\n",
      "previous_iter_valid_loss : 0.08774816989898682\n",
      "\n",
      "    215200\t  0.087715\t  0.087748\t  0.083019\t\tCURRENT LEARNING RATE: 0.0580095758872045\n",
      "previous_iter_valid_loss : 0.07880263775587082\n",
      "\n",
      "    215400\t  0.078667\t  0.078803\t  0.083027\t\tCURRENT LEARNING RATE: 0.0578936726772744\n",
      "previous_iter_valid_loss : 0.07638285309076309\n",
      "\n",
      "    215600\t  0.076390\t  0.076383\t  0.083010\t\tCURRENT LEARNING RATE: 0.05777800104211224\n",
      "previous_iter_valid_loss : 0.08122313767671585\n",
      "\n",
      "    215800\t  0.081230\t  0.081223\t  0.082983\t\tCURRENT LEARNING RATE: 0.05766256051903126\n",
      "previous_iter_valid_loss : 0.07979241758584976\n",
      "\n",
      "    216000\t  0.079648\t  0.079792\t  0.083002\t\tCURRENT LEARNING RATE: 0.05754735064626926\n",
      "previous_iter_valid_loss : 0.07785789668560028\n",
      "\n",
      "    216200\t  0.077749\t  0.077858\t  0.082990\t\tCURRENT LEARNING RATE: 0.05743237096298654\n",
      "previous_iter_valid_loss : 0.08013579994440079\n",
      "\n",
      "    216400\t  0.080127\t  0.080136\t  0.082992\t\tCURRENT LEARNING RATE: 0.05731762100926429\n",
      "previous_iter_valid_loss : 0.08198153227567673\n",
      "\n",
      "    216600\t  0.081871\t  0.081982\t  0.083026\t\tCURRENT LEARNING RATE: 0.057203100326102464\n",
      "previous_iter_valid_loss : 0.08486020565032959\n",
      "\n",
      "    216800\t  0.085020\t  0.084860\t  0.083044\t\tCURRENT LEARNING RATE: 0.05708880845541825\n",
      "previous_iter_valid_loss : 0.07731297612190247\n",
      "\n",
      "    217000\t  0.077266\t  0.077313\t  0.083045\t\tCURRENT LEARNING RATE: 0.05697474494004394\n",
      "previous_iter_valid_loss : 0.07846531271934509\n",
      "\n",
      "    217200\t  0.078456\t  0.078465\t  0.083024\t\tCURRENT LEARNING RATE: 0.05686090932372539\n",
      "previous_iter_valid_loss : 0.07603011280298233\n",
      "\n",
      "    217400\t  0.075991\t  0.076030\t  0.083008\t\tCURRENT LEARNING RATE: 0.056747301151119915\n",
      "previous_iter_valid_loss : 0.07914488017559052\n",
      "\n",
      "    217600\t  0.079124\t  0.079145\t  0.083010\t\tCURRENT LEARNING RATE: 0.05663391996779474\n",
      "previous_iter_valid_loss : 0.08247411251068115\n",
      "\n",
      "    217800\t  0.082468\t  0.082474\t  0.083048\t\tCURRENT LEARNING RATE: 0.056520765320224924\n",
      "previous_iter_valid_loss : 0.11988690495491028\n",
      "\n",
      "    218000\t  0.120100\t  0.119887\t  0.083197\t\tCURRENT LEARNING RATE: 0.05640783675579177\n",
      "previous_iter_valid_loss : 0.08108735829591751\n",
      "\n",
      "    218200\t  0.081002\t  0.081087\t  0.083189\t\tCURRENT LEARNING RATE: 0.05629513382278083\n",
      "previous_iter_valid_loss : 0.09897635877132416\n",
      "\n",
      "    218400\t  0.099294\t  0.098976\t  0.083277\t\tCURRENT LEARNING RATE: 0.05618265607038026\n",
      "previous_iter_valid_loss : 0.08173594623804092\n",
      "\n",
      "    218600\t  0.081771\t  0.081736\t  0.083301\t\tCURRENT LEARNING RATE: 0.05607040304867886\n",
      "previous_iter_valid_loss : 0.07833781838417053\n",
      "\n",
      "    218800\t  0.078334\t  0.078338\t  0.083254\t\tCURRENT LEARNING RATE: 0.05595837430866444\n",
      "previous_iter_valid_loss : 0.07619567215442657\n",
      "\n",
      "    219000\t  0.076174\t  0.076196\t  0.083230\t\tCURRENT LEARNING RATE: 0.05584656940222184\n",
      "previous_iter_valid_loss : 0.10049279034137726\n",
      "\n",
      "    219200\t  0.100634\t  0.100493\t  0.083349\t\tCURRENT LEARNING RATE: 0.05573498788213134\n",
      "previous_iter_valid_loss : 0.0780504122376442\n",
      "\n",
      "    219400\t  0.078098\t  0.078050\t  0.083349\t\tCURRENT LEARNING RATE: 0.05562362930206665\n",
      "previous_iter_valid_loss : 0.07683282345533371\n",
      "\n",
      "    219600\t  0.076769\t  0.076833\t  0.083333\t\tCURRENT LEARNING RATE: 0.055512493216593364\n",
      "previous_iter_valid_loss : 0.07826969027519226\n",
      "\n",
      "    219800\t  0.078302\t  0.078270\t  0.083320\t\tCURRENT LEARNING RATE: 0.055401579181166935\n",
      "previous_iter_valid_loss : 0.09223928302526474\n",
      "\n",
      "    220000\t  0.092276\t  0.092239\t  0.083376\t\tCURRENT LEARNING RATE: 0.05529088675213112\n",
      "previous_iter_valid_loss : 0.08014336228370667\n",
      "\n",
      "    220200\t  0.080094\t  0.080143\t  0.083397\t\tCURRENT LEARNING RATE: 0.05518041548671601\n",
      "previous_iter_valid_loss : 0.08311568200588226\n",
      "\n",
      "    220400\t  0.083093\t  0.083116\t  0.083433\t\tCURRENT LEARNING RATE: 0.05507016494303645\n",
      "previous_iter_valid_loss : 0.0823737159371376\n",
      "\n",
      "    220600\t  0.082648\t  0.082374\t  0.083448\t\tCURRENT LEARNING RATE: 0.05496013468009006\n",
      "previous_iter_valid_loss : 0.08025514334440231\n",
      "\n",
      "    220800\t  0.080277\t  0.080255\t  0.083462\t\tCURRENT LEARNING RATE: 0.054850324257755705\n",
      "previous_iter_valid_loss : 0.08411523699760437\n",
      "\n",
      "    221000\t  0.084462\t  0.084115\t  0.083494\t\tCURRENT LEARNING RATE: 0.05474073323679148\n",
      "previous_iter_valid_loss : 0.08826212584972382\n",
      "\n",
      "    221200\t  0.088259\t  0.088262\t  0.083545\t\tCURRENT LEARNING RATE: 0.054631361178833215\n",
      "previous_iter_valid_loss : 0.08546538650989532\n",
      "\n",
      "    221400\t  0.085475\t  0.085465\t  0.083561\t\tCURRENT LEARNING RATE: 0.05452220764639249\n",
      "previous_iter_valid_loss : 0.07823127508163452\n",
      "\n",
      "    221600\t  0.078199\t  0.078231\t  0.083553\t\tCURRENT LEARNING RATE: 0.054413272202855065\n",
      "previous_iter_valid_loss : 0.10357291996479034\n",
      "\n",
      "    221800\t  0.104071\t  0.103573\t  0.083682\t\tCURRENT LEARNING RATE: 0.05430455441247898\n",
      "previous_iter_valid_loss : 0.08385352790355682\n",
      "\n",
      "    222000\t  0.083864\t  0.083854\t  0.083705\t\tCURRENT LEARNING RATE: 0.05419605384039298\n",
      "previous_iter_valid_loss : 0.07836593687534332\n",
      "\n",
      "    222200\t  0.078334\t  0.078366\t  0.083718\t\tCURRENT LEARNING RATE: 0.05408777005259457\n",
      "previous_iter_valid_loss : 0.08287320286035538\n",
      "\n",
      "    222400\t  0.083020\t  0.082873\t  0.083751\t\tCURRENT LEARNING RATE: 0.05397970261594851\n",
      "previous_iter_valid_loss : 0.08910088986158371\n",
      "\n",
      "    222600\t  0.089367\t  0.089101\t  0.083809\t\tCURRENT LEARNING RATE: 0.053871851098184875\n",
      "previous_iter_valid_loss : 0.09703471511602402\n",
      "\n",
      "    222800\t  0.096814\t  0.097035\t  0.083916\t\tCURRENT LEARNING RATE: 0.053764215067897476\n",
      "previous_iter_valid_loss : 0.08013130724430084\n",
      "\n",
      "    223000\t  0.079971\t  0.080131\t  0.083936\t\tCURRENT LEARNING RATE: 0.053656794094542014\n",
      "previous_iter_valid_loss : 0.08342675864696503\n",
      "\n",
      "    223200\t  0.083343\t  0.083427\t  0.083973\t\tCURRENT LEARNING RATE: 0.0535495877484345\n",
      "previous_iter_valid_loss : 0.08259046822786331\n",
      "\n",
      "    223400\t  0.082604\t  0.082590\t  0.084006\t\tCURRENT LEARNING RATE: 0.05344259560074935\n",
      "previous_iter_valid_loss : 0.08444773405790329\n",
      "\n",
      "    223600\t  0.084736\t  0.084448\t  0.084017\t\tCURRENT LEARNING RATE: 0.05333581722351788\n",
      "previous_iter_valid_loss : 0.08000509440898895\n",
      "\n",
      "    223800\t  0.080150\t  0.080005\t  0.084001\t\tCURRENT LEARNING RATE: 0.0532292521896264\n",
      "previous_iter_valid_loss : 0.08864915370941162\n",
      "\n",
      "    224000\t  0.088770\t  0.088649\t  0.084003\t\tCURRENT LEARNING RATE: 0.05312290007281467\n",
      "previous_iter_valid_loss : 0.08119621127843857\n",
      "\n",
      "    224200\t  0.081054\t  0.081196\t  0.084013\t\tCURRENT LEARNING RATE: 0.05301676044767405\n",
      "previous_iter_valid_loss : 0.08511614799499512\n",
      "\n",
      "    224400\t  0.085343\t  0.085116\t  0.084050\t\tCURRENT LEARNING RATE: 0.052910832889645924\n",
      "previous_iter_valid_loss : 0.08089729398488998\n",
      "\n",
      "    224600\t  0.080895\t  0.080897\t  0.084078\t\tCURRENT LEARNING RATE: 0.052805116975019877\n",
      "previous_iter_valid_loss : 0.0813528522849083\n",
      "\n",
      "    224800\t  0.081451\t  0.081353\t  0.084089\t\tCURRENT LEARNING RATE: 0.052699612280932166\n",
      "previous_iter_valid_loss : 0.10534224659204483\n",
      "\n",
      "    225000\t  0.105382\t  0.105342\t  0.084211\t\tCURRENT LEARNING RATE: 0.052594318385363846\n",
      "previous_iter_valid_loss : 0.08702412247657776\n",
      "\n",
      "    225200\t  0.087023\t  0.087024\t  0.084245\t\tCURRENT LEARNING RATE: 0.05248923486713917\n",
      "previous_iter_valid_loss : 0.08005604892969131\n",
      "\n",
      "    225400\t  0.080406\t  0.080056\t  0.084213\t\tCURRENT LEARNING RATE: 0.05238436130592397\n",
      "previous_iter_valid_loss : 0.08112123608589172\n",
      "\n",
      "    225600\t  0.081338\t  0.081121\t  0.084236\t\tCURRENT LEARNING RATE: 0.052279697282223814\n",
      "previous_iter_valid_loss : 0.08285536617040634\n",
      "\n",
      "    225800\t  0.083246\t  0.082855\t  0.084174\t\tCURRENT LEARNING RATE: 0.05217524237738252\n",
      "previous_iter_valid_loss : 0.08191166818141937\n",
      "\n",
      "    226000\t  0.082198\t  0.081912\t  0.084168\t\tCURRENT LEARNING RATE: 0.052070996173580276\n",
      "previous_iter_valid_loss : 0.08843382447957993\n",
      "\n",
      "    226200\t  0.089277\t  0.088434\t  0.084172\t\tCURRENT LEARNING RATE: 0.05196695825383218\n",
      "previous_iter_valid_loss : 0.08956608921289444\n",
      "\n",
      "    226400\t  0.089910\t  0.089566\t  0.084153\t\tCURRENT LEARNING RATE: 0.051863128201986367\n",
      "previous_iter_valid_loss : 0.07921239733695984\n",
      "\n",
      "    226600\t  0.079721\t  0.079212\t  0.084162\t\tCURRENT LEARNING RATE: 0.05175950560272253\n",
      "previous_iter_valid_loss : 0.08493033051490784\n",
      "\n",
      "    226800\t  0.085246\t  0.084930\t  0.084193\t\tCURRENT LEARNING RATE: 0.0516560900415501\n",
      "previous_iter_valid_loss : 0.08420190960168839\n",
      "\n",
      "    227000\t  0.084536\t  0.084202\t  0.084234\t\tCURRENT LEARNING RATE: 0.05155288110480673\n",
      "previous_iter_valid_loss : 0.08968034386634827\n",
      "\n",
      "    227200\t  0.090353\t  0.089680\t  0.084166\t\tCURRENT LEARNING RATE: 0.0514498783796565\n",
      "previous_iter_valid_loss : 0.08236542344093323\n",
      "\n",
      "    227400\t  0.082738\t  0.082365\t  0.084190\t\tCURRENT LEARNING RATE: 0.0513470814540884\n",
      "previous_iter_valid_loss : 0.08294274657964706\n",
      "\n",
      "    227600\t  0.083526\t  0.082943\t  0.084194\t\tCURRENT LEARNING RATE: 0.05124448991691456\n",
      "previous_iter_valid_loss : 0.08362606167793274\n",
      "\n",
      "    227800\t  0.084101\t  0.083626\t  0.084234\t\tCURRENT LEARNING RATE: 0.05114210335776874\n",
      "previous_iter_valid_loss : 0.08988619595766068\n",
      "\n",
      "    228000\t  0.090503\t  0.089886\t  0.084277\t\tCURRENT LEARNING RATE: 0.051039921367104515\n",
      "previous_iter_valid_loss : 0.10030404478311539\n",
      "\n",
      "    228200\t  0.100640\t  0.100304\t  0.084359\t\tCURRENT LEARNING RATE: 0.05093794353619384\n",
      "previous_iter_valid_loss : 0.0786391869187355\n",
      "\n",
      "    228400\t  0.079155\t  0.078639\t  0.084362\t\tCURRENT LEARNING RATE: 0.0508361694571252\n",
      "previous_iter_valid_loss : 0.08448318392038345\n",
      "\n",
      "    228600\t  0.085038\t  0.084483\t  0.084379\t\tCURRENT LEARNING RATE: 0.05073459872280219\n",
      "previous_iter_valid_loss : 0.07909410446882248\n",
      "\n",
      "    228800\t  0.079658\t  0.079094\t  0.084374\t\tCURRENT LEARNING RATE: 0.0506332309269417\n",
      "previous_iter_valid_loss : 0.08820292353630066\n",
      "\n",
      "    229000\t  0.088680\t  0.088203\t  0.084435\t\tCURRENT LEARNING RATE: 0.05053206566407245\n",
      "previous_iter_valid_loss : 0.08100516349077225\n",
      "\n",
      "    229200\t  0.081539\t  0.081005\t  0.084460\t\tCURRENT LEARNING RATE: 0.05043110252953321\n",
      "previous_iter_valid_loss : 0.08305817097425461\n",
      "\n",
      "    229400\t  0.083673\t  0.083058\t  0.084437\t\tCURRENT LEARNING RATE: 0.05033034111947135\n",
      "previous_iter_valid_loss : 0.0831194743514061\n",
      "\n",
      "    229600\t  0.083705\t  0.083119\t  0.084453\t\tCURRENT LEARNING RATE: 0.05022978103084105\n",
      "previous_iter_valid_loss : 0.11950615793466568\n",
      "\n",
      "    229800\t  0.120228\t  0.119506\t  0.084435\t\tCURRENT LEARNING RATE: 0.050129421861401874\n",
      "previous_iter_valid_loss : 0.08530326932668686\n",
      "\n",
      "    230000\t  0.085604\t  0.085303\t  0.084449\t\tCURRENT LEARNING RATE: 0.05002926320971696\n",
      "previous_iter_valid_loss : 0.09192065894603729\n",
      "\n",
      "    230200\t  0.092252\t  0.091921\t  0.084516\t\tCURRENT LEARNING RATE: 0.049929304675151616\n",
      "previous_iter_valid_loss : 0.08044013381004333\n",
      "\n",
      "    230400\t  0.081083\t  0.080440\t  0.084516\t\tCURRENT LEARNING RATE: 0.04982954585787151\n",
      "previous_iter_valid_loss : 0.08771109580993652\n",
      "\n",
      "    230600\t  0.088327\t  0.087711\t  0.084567\t\tCURRENT LEARNING RATE: 0.04972998635884131\n",
      "previous_iter_valid_loss : 0.08732108026742935\n",
      "\n",
      "    230800\t  0.087949\t  0.087321\t  0.084621\t\tCURRENT LEARNING RATE: 0.04963062577982283\n",
      "previous_iter_valid_loss : 0.07934878766536713\n",
      "\n",
      "    231000\t  0.079893\t  0.079349\t  0.084569\t\tCURRENT LEARNING RATE: 0.04953146372337366\n",
      "previous_iter_valid_loss : 0.08551917225122452\n",
      "\n",
      "    231200\t  0.086344\t  0.085519\t  0.084600\t\tCURRENT LEARNING RATE: 0.049432499792845405\n",
      "previous_iter_valid_loss : 0.07787548005580902\n",
      "\n",
      "    231400\t  0.078452\t  0.077875\t  0.084608\t\tCURRENT LEARNING RATE: 0.04933373359238225\n",
      "previous_iter_valid_loss : 0.07966489344835281\n",
      "\n",
      "    231600\t  0.080255\t  0.079665\t  0.084608\t\tCURRENT LEARNING RATE: 0.049235164726919224\n",
      "previous_iter_valid_loss : 0.08146969228982925\n",
      "\n",
      "    231800\t  0.082096\t  0.081470\t  0.084612\t\tCURRENT LEARNING RATE: 0.04913679280218077\n",
      "previous_iter_valid_loss : 0.0786500945687294\n",
      "\n",
      "    232000\t  0.079214\t  0.078650\t  0.084551\t\tCURRENT LEARNING RATE: 0.04903861742467903\n",
      "previous_iter_valid_loss : 0.09098608046770096\n",
      "\n",
      "    232200\t  0.091618\t  0.090986\t  0.084513\t\tCURRENT LEARNING RATE: 0.048940638201712384\n",
      "previous_iter_valid_loss : 0.08370485156774521\n",
      "\n",
      "    232400\t  0.084227\t  0.083705\t  0.084543\t\tCURRENT LEARNING RATE: 0.04884285474136378\n",
      "previous_iter_valid_loss : 0.07971662282943726\n",
      "\n",
      "    232600\t  0.080281\t  0.079717\t  0.084551\t\tCURRENT LEARNING RATE: 0.04874526665249929\n",
      "previous_iter_valid_loss : 0.07768040895462036\n",
      "\n",
      "    232800\t  0.077931\t  0.077680\t  0.084558\t\tCURRENT LEARNING RATE: 0.04864787354476638\n",
      "previous_iter_valid_loss : 0.07920316606760025\n",
      "\n",
      "    233000\t  0.079570\t  0.079203\t  0.084552\t\tCURRENT LEARNING RATE: 0.04855067502859254\n",
      "previous_iter_valid_loss : 0.08125501126050949\n",
      "\n",
      "    233200\t  0.081450\t  0.081255\t  0.084573\t\tCURRENT LEARNING RATE: 0.04845367071518352\n",
      "previous_iter_valid_loss : 0.1198793426156044\n",
      "\n",
      "    233400\t  0.120481\t  0.119879\t  0.084781\t\tCURRENT LEARNING RATE: 0.04835686021652199\n",
      "previous_iter_valid_loss : 0.08040846884250641\n",
      "\n",
      "    233600\t  0.080828\t  0.080408\t  0.084763\t\tCURRENT LEARNING RATE: 0.048260243145365776\n",
      "previous_iter_valid_loss : 0.08210984617471695\n",
      "\n",
      "    233800\t  0.082844\t  0.082110\t  0.084555\t\tCURRENT LEARNING RATE: 0.04816381911524652\n",
      "previous_iter_valid_loss : 0.08016592264175415\n",
      "\n",
      "    234000\t  0.080769\t  0.080166\t  0.084555\t\tCURRENT LEARNING RATE: 0.04806758774046791\n",
      "previous_iter_valid_loss : 0.07733418047428131\n",
      "\n",
      "    234200\t  0.077763\t  0.077334\t  0.084479\t\tCURRENT LEARNING RATE: 0.04797154863610439\n",
      "previous_iter_valid_loss : 0.07815972715616226\n",
      "\n",
      "    234400\t  0.078534\t  0.078160\t  0.084482\t\tCURRENT LEARNING RATE: 0.04787570141799934\n",
      "previous_iter_valid_loss : 0.07796607911586761\n",
      "\n",
      "    234600\t  0.078427\t  0.077966\t  0.084342\t\tCURRENT LEARNING RATE: 0.047780045702763826\n",
      "previous_iter_valid_loss : 0.0795544683933258\n",
      "\n",
      "    234800\t  0.079912\t  0.079554\t  0.084312\t\tCURRENT LEARNING RATE: 0.04768458110777481\n",
      "previous_iter_valid_loss : 0.07784998416900635\n",
      "\n",
      "    235000\t  0.078341\t  0.077850\t  0.084314\t\tCURRENT LEARNING RATE: 0.047589307251173815\n",
      "previous_iter_valid_loss : 0.07961491495370865\n",
      "\n",
      "    235200\t  0.080002\t  0.079615\t  0.084321\t\tCURRENT LEARNING RATE: 0.04749422375186527\n",
      "previous_iter_valid_loss : 0.0789717361330986\n",
      "\n",
      "    235400\t  0.079279\t  0.078972\t  0.084334\t\tCURRENT LEARNING RATE: 0.04739933022951507\n",
      "previous_iter_valid_loss : 0.07749634236097336\n",
      "\n",
      "    235600\t  0.077895\t  0.077496\t  0.084339\t\tCURRENT LEARNING RATE: 0.047304626304548965\n",
      "previous_iter_valid_loss : 0.08372482657432556\n",
      "\n",
      "    235800\t  0.084156\t  0.083725\t  0.084363\t\tCURRENT LEARNING RATE: 0.047210111598151173\n",
      "previous_iter_valid_loss : 0.08297542482614517\n",
      "\n",
      "    236000\t  0.083601\t  0.082975\t  0.084381\t\tCURRENT LEARNING RATE: 0.0471157857322627\n",
      "previous_iter_valid_loss : 0.08837726712226868\n",
      "\n",
      "    236200\t  0.088899\t  0.088377\t  0.084437\t\tCURRENT LEARNING RATE: 0.04702164832958\n",
      "previous_iter_valid_loss : 0.07884964346885681\n",
      "\n",
      "    236400\t  0.079450\t  0.078850\t  0.084394\t\tCURRENT LEARNING RATE: 0.046927699013553294\n",
      "previous_iter_valid_loss : 0.08327682316303253\n",
      "\n",
      "    236600\t  0.083799\t  0.083277\t  0.084410\t\tCURRENT LEARNING RATE: 0.046833937408385234\n",
      "previous_iter_valid_loss : 0.0786377340555191\n",
      "\n",
      "    236800\t  0.079020\t  0.078638\t  0.084384\t\tCURRENT LEARNING RATE: 0.04674036313902923\n",
      "previous_iter_valid_loss : 0.07962147891521454\n",
      "\n",
      "    237000\t  0.080146\t  0.079621\t  0.084363\t\tCURRENT LEARNING RATE: 0.046646975831188126\n",
      "previous_iter_valid_loss : 0.09186004102230072\n",
      "\n",
      "    237200\t  0.091871\t  0.091860\t  0.084323\t\tCURRENT LEARNING RATE: 0.04655377511131252\n",
      "previous_iter_valid_loss : 0.07796262204647064\n",
      "\n",
      "    237400\t  0.078041\t  0.077963\t  0.084308\t\tCURRENT LEARNING RATE: 0.04646076060659945\n",
      "previous_iter_valid_loss : 0.08788388967514038\n",
      "\n",
      "    237600\t  0.088077\t  0.087884\t  0.084312\t\tCURRENT LEARNING RATE: 0.04636793194499073\n",
      "previous_iter_valid_loss : 0.08124986290931702\n",
      "\n",
      "    237800\t  0.081349\t  0.081250\t  0.084324\t\tCURRENT LEARNING RATE: 0.046275288755171645\n",
      "previous_iter_valid_loss : 0.07814141362905502\n",
      "\n",
      "    238000\t  0.078196\t  0.078141\t  0.084301\t\tCURRENT LEARNING RATE: 0.04618283066656925\n",
      "previous_iter_valid_loss : 0.08837363868951797\n",
      "\n",
      "    238200\t  0.088618\t  0.088374\t  0.084358\t\tCURRENT LEARNING RATE: 0.046090557309351125\n",
      "previous_iter_valid_loss : 0.07828927040100098\n",
      "\n",
      "    238400\t  0.078401\t  0.078289\t  0.084359\t\tCURRENT LEARNING RATE: 0.04599846831442367\n",
      "previous_iter_valid_loss : 0.08711160719394684\n",
      "\n",
      "    238600\t  0.087450\t  0.087112\t  0.084359\t\tCURRENT LEARNING RATE: 0.04590656331343083\n",
      "previous_iter_valid_loss : 0.08213730156421661\n",
      "\n",
      "    238800\t  0.082376\t  0.082137\t  0.084297\t\tCURRENT LEARNING RATE: 0.04581484193875242\n",
      "previous_iter_valid_loss : 0.09243486821651459\n",
      "\n",
      "    239000\t  0.092308\t  0.092435\t  0.084381\t\tCURRENT LEARNING RATE: 0.04572330382350288\n",
      "previous_iter_valid_loss : 0.08474042266607285\n",
      "\n",
      "    239200\t  0.084625\t  0.084740\t  0.084407\t\tCURRENT LEARNING RATE: 0.045631948601529575\n",
      "previous_iter_valid_loss : 0.08996842056512833\n",
      "\n",
      "    239400\t  0.089824\t  0.089968\t  0.084478\t\tCURRENT LEARNING RATE: 0.04554077590741154\n",
      "previous_iter_valid_loss : 0.07813868671655655\n",
      "\n",
      "    239600\t  0.078138\t  0.078139\t  0.084426\t\tCURRENT LEARNING RATE: 0.04544978537645784\n",
      "previous_iter_valid_loss : 0.07947022467851639\n",
      "\n",
      "    239800\t  0.079768\t  0.079470\t  0.084421\t\tCURRENT LEARNING RATE: 0.045358976644706256\n",
      "previous_iter_valid_loss : 0.0779615044593811\n",
      "\n",
      "    240000\t  0.078057\t  0.077962\t  0.084430\t\tCURRENT LEARNING RATE: 0.04526834934892172\n",
      "previous_iter_valid_loss : 0.08954863250255585\n",
      "\n",
      "    240200\t  0.089545\t  0.089549\t  0.084482\t\tCURRENT LEARNING RATE: 0.04517790312659495\n",
      "previous_iter_valid_loss : 0.09373829513788223\n",
      "\n",
      "    240400\t  0.093704\t  0.093738\t  0.084281\t\tCURRENT LEARNING RATE: 0.0450876376159409\n",
      "previous_iter_valid_loss : 0.083084337413311\n",
      "\n",
      "    240600\t  0.083357\t  0.083084\t  0.084269\t\tCURRENT LEARNING RATE: 0.044997552455897455\n",
      "previous_iter_valid_loss : 0.08195681124925613\n",
      "\n",
      "    240800\t  0.082393\t  0.081957\t  0.084217\t\tCURRENT LEARNING RATE: 0.044907647286123814\n",
      "previous_iter_valid_loss : 0.08279607445001602\n",
      "\n",
      "    241000\t  0.082946\t  0.082796\t  0.084181\t\tCURRENT LEARNING RATE: 0.04481792174699921\n",
      "previous_iter_valid_loss : 0.07838757336139679\n",
      "\n",
      "    241200\t  0.078410\t  0.078388\t  0.084069\t\tCURRENT LEARNING RATE: 0.044728375479621336\n",
      "previous_iter_valid_loss : 0.08003684133291245\n",
      "\n",
      "    241400\t  0.080244\t  0.080037\t  0.084077\t\tCURRENT LEARNING RATE: 0.044639008125805034\n",
      "previous_iter_valid_loss : 0.08066333830356598\n",
      "\n",
      "    241600\t  0.080996\t  0.080663\t  0.084085\t\tCURRENT LEARNING RATE: 0.044549819328080734\n",
      "previous_iter_valid_loss : 0.09131810069084167\n",
      "\n",
      "    241800\t  0.091460\t  0.091318\t  0.084114\t\tCURRENT LEARNING RATE: 0.04446080872969317\n",
      "previous_iter_valid_loss : 0.0778890922665596\n",
      "\n",
      "    242000\t  0.078084\t  0.077889\t  0.084122\t\tCURRENT LEARNING RATE: 0.044371975974599784\n",
      "previous_iter_valid_loss : 0.07787887752056122\n",
      "\n",
      "    242200\t  0.078180\t  0.077879\t  0.084066\t\tCURRENT LEARNING RATE: 0.04428332070746948\n",
      "previous_iter_valid_loss : 0.09030871838331223\n",
      "\n",
      "    242400\t  0.090687\t  0.090309\t  0.084053\t\tCURRENT LEARNING RATE: 0.044194842573681024\n",
      "previous_iter_valid_loss : 0.0769650787115097\n",
      "\n",
      "    242600\t  0.077191\t  0.076965\t  0.084037\t\tCURRENT LEARNING RATE: 0.04410654121932182\n",
      "previous_iter_valid_loss : 0.07924506813287735\n",
      "\n",
      "    242800\t  0.079666\t  0.079245\t  0.084040\t\tCURRENT LEARNING RATE: 0.044018416291186274\n",
      "previous_iter_valid_loss : 0.07892556488513947\n",
      "\n",
      "    243000\t  0.079209\t  0.078926\t  0.083927\t\tCURRENT LEARNING RATE: 0.0439304674367746\n",
      "previous_iter_valid_loss : 0.07963825762271881\n",
      "\n",
      "    243200\t  0.079822\t  0.079638\t  0.083932\t\tCURRENT LEARNING RATE: 0.04384269430429124\n",
      "previous_iter_valid_loss : 0.08379409462213516\n",
      "\n",
      "    243400\t  0.083889\t  0.083794\t  0.083967\t\tCURRENT LEARNING RATE: 0.04375509654264356\n",
      "previous_iter_valid_loss : 0.08307379484176636\n",
      "\n",
      "    243600\t  0.083356\t  0.083074\t  0.083926\t\tCURRENT LEARNING RATE: 0.04366767380144038\n",
      "previous_iter_valid_loss : 0.0781293734908104\n",
      "\n",
      "    243800\t  0.078386\t  0.078129\t  0.083914\t\tCURRENT LEARNING RATE: 0.04358042573099065\n",
      "previous_iter_valid_loss : 0.07884291559457779\n",
      "\n",
      "    244000\t  0.078899\t  0.078843\t  0.083760\t\tCURRENT LEARNING RATE: 0.04349335198230193\n",
      "previous_iter_valid_loss : 0.07883115857839584\n",
      "\n",
      "    244200\t  0.079070\t  0.078831\t  0.083758\t\tCURRENT LEARNING RATE: 0.043406452207079144\n",
      "previous_iter_valid_loss : 0.07945758104324341\n",
      "\n",
      "    244400\t  0.079486\t  0.079458\t  0.083770\t\tCURRENT LEARNING RATE: 0.04331972605772305\n",
      "previous_iter_valid_loss : 0.08923722803592682\n",
      "\n",
      "    244600\t  0.089188\t  0.089237\t  0.083826\t\tCURRENT LEARNING RATE: 0.04323317318732896\n",
      "previous_iter_valid_loss : 0.07769725471735\n",
      "\n",
      "    244800\t  0.077818\t  0.077697\t  0.083823\t\tCURRENT LEARNING RATE: 0.04314679324968525\n",
      "previous_iter_valid_loss : 0.07852111011743546\n",
      "\n",
      "    245000\t  0.078694\t  0.078521\t  0.083784\t\tCURRENT LEARNING RATE: 0.04306058589927208\n",
      "previous_iter_valid_loss : 0.08033629506826401\n",
      "\n",
      "    245200\t  0.080469\t  0.080336\t  0.083797\t\tCURRENT LEARNING RATE: 0.042974550791259905\n",
      "previous_iter_valid_loss : 0.07694955915212631\n",
      "\n",
      "    245400\t  0.077015\t  0.076950\t  0.083778\t\tCURRENT LEARNING RATE: 0.04288868758150822\n",
      "previous_iter_valid_loss : 0.07820944488048553\n",
      "\n",
      "    245600\t  0.078385\t  0.078209\t  0.083771\t\tCURRENT LEARNING RATE: 0.042802995926564016\n",
      "previous_iter_valid_loss : 0.07728828489780426\n",
      "\n",
      "    245800\t  0.077349\t  0.077288\t  0.083778\t\tCURRENT LEARNING RATE: 0.042717475483660616\n",
      "previous_iter_valid_loss : 0.08471154421567917\n",
      "\n",
      "    246000\t  0.084903\t  0.084712\t  0.083767\t\tCURRENT LEARNING RATE: 0.042632125910716086\n",
      "previous_iter_valid_loss : 0.08111149817705154\n",
      "\n",
      "    246200\t  0.081256\t  0.081111\t  0.083731\t\tCURRENT LEARNING RATE: 0.04254694686633206\n",
      "previous_iter_valid_loss : 0.08856531232595444\n",
      "\n",
      "    246400\t  0.088687\t  0.088565\t  0.083792\t\tCURRENT LEARNING RATE: 0.042461938009792206\n",
      "previous_iter_valid_loss : 0.08457793295383453\n",
      "\n",
      "    246600\t  0.084628\t  0.084578\t  0.083710\t\tCURRENT LEARNING RATE: 0.042377099001061035\n",
      "previous_iter_valid_loss : 0.10071904957294464\n",
      "\n",
      "    246800\t  0.100513\t  0.100719\t  0.083722\t\tCURRENT LEARNING RATE: 0.042292429500782346\n",
      "previous_iter_valid_loss : 0.07783123105764389\n",
      "\n",
      "    247000\t  0.077785\t  0.077831\t  0.083624\t\tCURRENT LEARNING RATE: 0.04220792917027807\n",
      "previous_iter_valid_loss : 0.09087871760129929\n",
      "\n",
      "    247200\t  0.091019\t  0.090879\t  0.083658\t\tCURRENT LEARNING RATE: 0.042123597671546734\n",
      "previous_iter_valid_loss : 0.07677710056304932\n",
      "\n",
      "    247400\t  0.076745\t  0.076777\t  0.083651\t\tCURRENT LEARNING RATE: 0.04203943466726227\n",
      "previous_iter_valid_loss : 0.07728421688079834\n",
      "\n",
      "    247600\t  0.077277\t  0.077284\t  0.083651\t\tCURRENT LEARNING RATE: 0.0419554398207725\n",
      "previous_iter_valid_loss : 0.08245786279439926\n",
      "\n",
      "    247800\t  0.082516\t  0.082458\t  0.083674\t\tCURRENT LEARNING RATE: 0.04187161279609798\n",
      "previous_iter_valid_loss : 0.09388760477304459\n",
      "\n",
      "    248000\t  0.094016\t  0.093888\t  0.083762\t\tCURRENT LEARNING RATE: 0.04178795325793045\n",
      "previous_iter_valid_loss : 0.08033163845539093\n",
      "\n",
      "    248200\t  0.080386\t  0.080332\t  0.083762\t\tCURRENT LEARNING RATE: 0.041704460871631696\n",
      "previous_iter_valid_loss : 0.08833029866218567\n",
      "\n",
      "    248400\t  0.088230\t  0.088330\t  0.083746\t\tCURRENT LEARNING RATE: 0.041621135303232006\n",
      "previous_iter_valid_loss : 0.07650412619113922\n",
      "\n",
      "    248600\t  0.076508\t  0.076504\t  0.083689\t\tCURRENT LEARNING RATE: 0.04153797621942905\n",
      "previous_iter_valid_loss : 0.07926817983388901\n",
      "\n",
      "    248800\t  0.079271\t  0.079268\t  0.083620\t\tCURRENT LEARNING RATE: 0.04145498328758633\n",
      "previous_iter_valid_loss : 0.08240748196840286\n",
      "\n",
      "    249000\t  0.082193\t  0.082407\t  0.083581\t\tCURRENT LEARNING RATE: 0.04137215617573206\n",
      "previous_iter_valid_loss : 0.08265826851129532\n",
      "\n",
      "    249200\t  0.082734\t  0.082658\t  0.083596\t\tCURRENT LEARNING RATE: 0.041289494552557635\n",
      "previous_iter_valid_loss : 0.08020555973052979\n",
      "\n",
      "    249400\t  0.080031\t  0.080206\t  0.083564\t\tCURRENT LEARNING RATE: 0.041206998087416485\n",
      "previous_iter_valid_loss : 0.07848931849002838\n",
      "\n",
      "    249600\t  0.078538\t  0.078489\t  0.083567\t\tCURRENT LEARNING RATE: 0.04112466645032262\n",
      "previous_iter_valid_loss : 0.07800845056772232\n",
      "\n",
      "    249800\t  0.078038\t  0.078008\t  0.083564\t\tCURRENT LEARNING RATE: 0.0410424993119494\n",
      "previous_iter_valid_loss : 0.08358711004257202\n",
      "\n",
      "    250000\t  0.083631\t  0.083587\t  0.083549\t\tCURRENT LEARNING RATE: 0.04096049634362815\n",
      "previous_iter_valid_loss : 0.07874488830566406\n",
      "\n",
      "    250200\t  0.078760\t  0.078745\t  0.083538\t\tCURRENT LEARNING RATE: 0.040878657217346875\n",
      "previous_iter_valid_loss : 0.07698262482881546\n",
      "\n",
      "    250400\t  0.077079\t  0.076983\t  0.083519\t\tCURRENT LEARNING RATE: 0.04079698160574899\n",
      "previous_iter_valid_loss : 0.08017958700656891\n",
      "\n",
      "    250600\t  0.080382\t  0.080180\t  0.083472\t\tCURRENT LEARNING RATE: 0.040715469182131904\n",
      "previous_iter_valid_loss : 0.0829562172293663\n",
      "\n",
      "    250800\t  0.082992\t  0.082956\t  0.083498\t\tCURRENT LEARNING RATE: 0.04063411962044585\n",
      "previous_iter_valid_loss : 0.08528637140989304\n",
      "\n",
      "    251000\t  0.085191\t  0.085286\t  0.083507\t\tCURRENT LEARNING RATE: 0.04055293259529245\n",
      "previous_iter_valid_loss : 0.08672904968261719\n",
      "\n",
      "    251200\t  0.086908\t  0.086729\t  0.083518\t\tCURRENT LEARNING RATE: 0.040471907781923507\n",
      "previous_iter_valid_loss : 0.09058573096990585\n",
      "\n",
      "    251400\t  0.090743\t  0.090586\t  0.083522\t\tCURRENT LEARNING RATE: 0.04039104485623964\n",
      "previous_iter_valid_loss : 0.07837360352277756\n",
      "\n",
      "    251600\t  0.078271\t  0.078374\t  0.083499\t\tCURRENT LEARNING RATE: 0.040310343494789076\n",
      "previous_iter_valid_loss : 0.07701101899147034\n",
      "\n",
      "    251800\t  0.076999\t  0.077011\t  0.083389\t\tCURRENT LEARNING RATE: 0.04022980337476622\n",
      "previous_iter_valid_loss : 0.08005372434854507\n",
      "\n",
      "    252000\t  0.080178\t  0.080054\t  0.083289\t\tCURRENT LEARNING RATE: 0.04014942417401051\n",
      "previous_iter_valid_loss : 0.07922062277793884\n",
      "\n",
      "    252200\t  0.079174\t  0.079221\t  0.083241\t\tCURRENT LEARNING RATE: 0.040069205571005025\n",
      "previous_iter_valid_loss : 0.08105825632810593\n",
      "\n",
      "    252400\t  0.081214\t  0.081058\t  0.083261\t\tCURRENT LEARNING RATE: 0.039989147244875255\n",
      "previous_iter_valid_loss : 0.10454429686069489\n",
      "\n",
      "    252600\t  0.104453\t  0.104544\t  0.083387\t\tCURRENT LEARNING RATE: 0.03990924887538777\n",
      "previous_iter_valid_loss : 0.07901712507009506\n",
      "\n",
      "    252800\t  0.079302\t  0.079017\t  0.083371\t\tCURRENT LEARNING RATE: 0.03982951014294902\n",
      "previous_iter_valid_loss : 0.0778341069817543\n",
      "\n",
      "    253000\t  0.077952\t  0.077834\t  0.083367\t\tCURRENT LEARNING RATE: 0.03974993072860393\n",
      "previous_iter_valid_loss : 0.07747180014848709\n",
      "\n",
      "    253200\t  0.077571\t  0.077472\t  0.083338\t\tCURRENT LEARNING RATE: 0.03967051031403477\n",
      "previous_iter_valid_loss : 0.08089378476142883\n",
      "\n",
      "    253400\t  0.081107\t  0.080894\t  0.083321\t\tCURRENT LEARNING RATE: 0.03959124858155974\n",
      "previous_iter_valid_loss : 0.08253193646669388\n",
      "\n",
      "    253600\t  0.082623\t  0.082532\t  0.083307\t\tCURRENT LEARNING RATE: 0.03951214521413184\n",
      "previous_iter_valid_loss : 0.08172870427370071\n",
      "\n",
      "    253800\t  0.082059\t  0.081729\t  0.083331\t\tCURRENT LEARNING RATE: 0.03943319989533747\n",
      "previous_iter_valid_loss : 0.07807034254074097\n",
      "\n",
      "    254000\t  0.078465\t  0.078070\t  0.083310\t\tCURRENT LEARNING RATE: 0.03935441230939527\n",
      "previous_iter_valid_loss : 0.08298744261264801\n",
      "\n",
      "    254200\t  0.083746\t  0.082987\t  0.083316\t\tCURRENT LEARNING RATE: 0.03927578214115477\n",
      "previous_iter_valid_loss : 0.07780884951353073\n",
      "\n",
      "    254400\t  0.078209\t  0.077809\t  0.083300\t\tCURRENT LEARNING RATE: 0.03919730907609521\n",
      "previous_iter_valid_loss : 0.07897984236478806\n",
      "\n",
      "    254600\t  0.079277\t  0.078980\t  0.083303\t\tCURRENT LEARNING RATE: 0.03911899280032421\n",
      "previous_iter_valid_loss : 0.08317825198173523\n",
      "\n",
      "    254800\t  0.083656\t  0.083178\t  0.083305\t\tCURRENT LEARNING RATE: 0.039040833000576584\n",
      "previous_iter_valid_loss : 0.08187133818864822\n",
      "\n",
      "    255000\t  0.082331\t  0.081871\t  0.083317\t\tCURRENT LEARNING RATE: 0.038962829364213\n",
      "previous_iter_valid_loss : 0.07732460647821426\n",
      "\n",
      "    255200\t  0.077727\t  0.077325\t  0.083265\t\tCURRENT LEARNING RATE: 0.03888498157921883\n",
      "previous_iter_valid_loss : 0.07865717262029648\n",
      "\n",
      "    255400\t  0.079301\t  0.078657\t  0.083264\t\tCURRENT LEARNING RATE: 0.03880728933420281\n",
      "previous_iter_valid_loss : 0.08253469318151474\n",
      "\n",
      "    255600\t  0.082973\t  0.082535\t  0.083295\t\tCURRENT LEARNING RATE: 0.03872975231839589\n",
      "previous_iter_valid_loss : 0.08248288929462433\n",
      "\n",
      "    255800\t  0.082796\t  0.082483\t  0.083301\t\tCURRENT LEARNING RATE: 0.03865237022164987\n",
      "previous_iter_valid_loss : 0.07832937687635422\n",
      "\n",
      "    256000\t  0.078772\t  0.078329\t  0.083294\t\tCURRENT LEARNING RATE: 0.03857514273443629\n",
      "previous_iter_valid_loss : 0.07868178188800812\n",
      "\n",
      "    256200\t  0.079014\t  0.078682\t  0.083298\t\tCURRENT LEARNING RATE: 0.03849806954784506\n",
      "previous_iter_valid_loss : 0.07907991856336594\n",
      "\n",
      "    256400\t  0.079336\t  0.079080\t  0.083293\t\tCURRENT LEARNING RATE: 0.038421150353583365\n",
      "previous_iter_valid_loss : 0.07993804663419724\n",
      "\n",
      "    256600\t  0.080351\t  0.079938\t  0.083282\t\tCURRENT LEARNING RATE: 0.0383443848439743\n",
      "previous_iter_valid_loss : 0.08665050566196442\n",
      "\n",
      "    256800\t  0.087160\t  0.086651\t  0.083291\t\tCURRENT LEARNING RATE: 0.03826777271195576\n",
      "previous_iter_valid_loss : 0.0770411565899849\n",
      "\n",
      "    257000\t  0.077528\t  0.077041\t  0.083290\t\tCURRENT LEARNING RATE: 0.03819131365107906\n",
      "previous_iter_valid_loss : 0.08023271709680557\n",
      "\n",
      "    257200\t  0.080774\t  0.080233\t  0.083299\t\tCURRENT LEARNING RATE: 0.038115007355507914\n",
      "previous_iter_valid_loss : 0.07885036617517471\n",
      "\n",
      "    257400\t  0.079391\t  0.078850\t  0.083313\t\tCURRENT LEARNING RATE: 0.03803885352001699\n",
      "previous_iter_valid_loss : 0.0801214873790741\n",
      "\n",
      "    257600\t  0.080639\t  0.080121\t  0.083318\t\tCURRENT LEARNING RATE: 0.03796285183999089\n",
      "previous_iter_valid_loss : 0.09174215793609619\n",
      "\n",
      "    257800\t  0.092461\t  0.091742\t  0.083364\t\tCURRENT LEARNING RATE: 0.03788700201142274\n",
      "previous_iter_valid_loss : 0.08579108864068985\n",
      "\n",
      "    258000\t  0.086266\t  0.085791\t  0.083194\t\tCURRENT LEARNING RATE: 0.03781130373091317\n",
      "previous_iter_valid_loss : 0.07707799971103668\n",
      "\n",
      "    258200\t  0.077524\t  0.077078\t  0.083174\t\tCURRENT LEARNING RATE: 0.03773575669566892\n",
      "previous_iter_valid_loss : 0.08100833743810654\n",
      "\n",
      "    258400\t  0.081565\t  0.081008\t  0.083084\t\tCURRENT LEARNING RATE: 0.03766036060350179\n",
      "previous_iter_valid_loss : 0.07990597188472748\n",
      "\n",
      "    258600\t  0.080370\t  0.079906\t  0.083075\t\tCURRENT LEARNING RATE: 0.03758511515282727\n",
      "previous_iter_valid_loss : 0.07685912400484085\n",
      "\n",
      "    258800\t  0.077433\t  0.076859\t  0.083067\t\tCURRENT LEARNING RATE: 0.03751002004266349\n",
      "previous_iter_valid_loss : 0.08189527690410614\n",
      "\n",
      "    259000\t  0.082445\t  0.081895\t  0.083096\t\tCURRENT LEARNING RATE: 0.03743507497262987\n",
      "previous_iter_valid_loss : 0.08025307953357697\n",
      "\n",
      "    259200\t  0.080816\t  0.080253\t  0.082994\t\tCURRENT LEARNING RATE: 0.03736027964294608\n",
      "previous_iter_valid_loss : 0.07778275012969971\n",
      "\n",
      "    259400\t  0.078388\t  0.077783\t  0.082993\t\tCURRENT LEARNING RATE: 0.037285633754430655\n",
      "previous_iter_valid_loss : 0.0854836255311966\n",
      "\n",
      "    259600\t  0.086102\t  0.085484\t  0.083036\t\tCURRENT LEARNING RATE: 0.03721113700849998\n",
      "previous_iter_valid_loss : 0.07702188193798065\n",
      "\n",
      "    259800\t  0.077597\t  0.077022\t  0.083030\t\tCURRENT LEARNING RATE: 0.03713678910716694\n",
      "previous_iter_valid_loss : 0.086941659450531\n",
      "\n",
      "    260000\t  0.087405\t  0.086942\t  0.083004\t\tCURRENT LEARNING RATE: 0.03706258975303985\n",
      "previous_iter_valid_loss : 0.08234041184186935\n",
      "\n",
      "    260200\t  0.082978\t  0.082340\t  0.083015\t\tCURRENT LEARNING RATE: 0.03698853864932118\n",
      "previous_iter_valid_loss : 0.07947501540184021\n",
      "\n",
      "    260400\t  0.080124\t  0.079475\t  0.082996\t\tCURRENT LEARNING RATE: 0.03691463549980645\n",
      "previous_iter_valid_loss : 0.08027056604623795\n",
      "\n",
      "    260600\t  0.080873\t  0.080271\t  0.082986\t\tCURRENT LEARNING RATE: 0.036840880008882915\n",
      "previous_iter_valid_loss : 0.08610176295042038\n",
      "\n",
      "    260800\t  0.087258\t  0.086102\t  0.083015\t\tCURRENT LEARNING RATE: 0.03676727188152855\n",
      "previous_iter_valid_loss : 0.07685133814811707\n",
      "\n",
      "    261000\t  0.077369\t  0.076851\t  0.082979\t\tCURRENT LEARNING RATE: 0.03669381082331072\n",
      "previous_iter_valid_loss : 0.07738050073385239\n",
      "\n",
      "    261200\t  0.077966\t  0.077381\t  0.082924\t\tCURRENT LEARNING RATE: 0.03662049654038512\n",
      "previous_iter_valid_loss : 0.08235535025596619\n",
      "\n",
      "    261400\t  0.083054\t  0.082355\t  0.082909\t\tCURRENT LEARNING RATE: 0.036547328739494504\n",
      "previous_iter_valid_loss : 0.08157816529273987\n",
      "\n",
      "    261600\t  0.082087\t  0.081578\t  0.082926\t\tCURRENT LEARNING RATE: 0.036474307127967585\n",
      "previous_iter_valid_loss : 0.08813970535993576\n",
      "\n",
      "    261800\t  0.088689\t  0.088140\t  0.082848\t\tCURRENT LEARNING RATE: 0.036401431413717794\n",
      "previous_iter_valid_loss : 0.08188164979219437\n",
      "\n",
      "    262000\t  0.082551\t  0.081882\t  0.082839\t\tCURRENT LEARNING RATE: 0.03632870130524221\n",
      "previous_iter_valid_loss : 0.09738393872976303\n",
      "\n",
      "    262200\t  0.098499\t  0.097384\t  0.082934\t\tCURRENT LEARNING RATE: 0.036256116511620265\n",
      "previous_iter_valid_loss : 0.07693340629339218\n",
      "\n",
      "    262400\t  0.077522\t  0.076933\t  0.082904\t\tCURRENT LEARNING RATE: 0.03618367674251273\n",
      "previous_iter_valid_loss : 0.08288628607988358\n",
      "\n",
      "    262600\t  0.083842\t  0.082886\t  0.082873\t\tCURRENT LEARNING RATE: 0.03611138170816039\n",
      "previous_iter_valid_loss : 0.07957196235656738\n",
      "\n",
      "    262800\t  0.080276\t  0.079572\t  0.082786\t\tCURRENT LEARNING RATE: 0.03603923111938305\n",
      "previous_iter_valid_loss : 0.08284856379032135\n",
      "\n",
      "    263000\t  0.083686\t  0.082849\t  0.082799\t\tCURRENT LEARNING RATE: 0.03596722468757822\n",
      "previous_iter_valid_loss : 0.0769614651799202\n",
      "\n",
      "    263200\t  0.077586\t  0.076961\t  0.082767\t\tCURRENT LEARNING RATE: 0.03589536212472012\n",
      "previous_iter_valid_loss : 0.08278355747461319\n",
      "\n",
      "    263400\t  0.083408\t  0.082784\t  0.082768\t\tCURRENT LEARNING RATE: 0.03582364314335836\n",
      "previous_iter_valid_loss : 0.08158990740776062\n",
      "\n",
      "    263600\t  0.082189\t  0.081590\t  0.082754\t\tCURRENT LEARNING RATE: 0.03575206745661695\n",
      "previous_iter_valid_loss : 0.08215335011482239\n",
      "\n",
      "    263800\t  0.082860\t  0.082153\t  0.082764\t\tCURRENT LEARNING RATE: 0.03568063477819303\n",
      "previous_iter_valid_loss : 0.0779556930065155\n",
      "\n",
      "    264000\t  0.078740\t  0.077956\t  0.082711\t\tCURRENT LEARNING RATE: 0.0356093448223558\n",
      "previous_iter_valid_loss : 0.08447456359863281\n",
      "\n",
      "    264200\t  0.085342\t  0.084475\t  0.082727\t\tCURRENT LEARNING RATE: 0.03553819730394533\n",
      "previous_iter_valid_loss : 0.08237957954406738\n",
      "\n",
      "    264400\t  0.083096\t  0.082380\t  0.082714\t\tCURRENT LEARNING RATE: 0.03546719193837147\n",
      "previous_iter_valid_loss : 0.07839419692754745\n",
      "\n",
      "    264600\t  0.079213\t  0.078394\t  0.082701\t\tCURRENT LEARNING RATE: 0.03539632844161265\n",
      "previous_iter_valid_loss : 0.08671464025974274\n",
      "\n",
      "    264800\t  0.087748\t  0.086715\t  0.082728\t\tCURRENT LEARNING RATE: 0.0353256065302148\n",
      "previous_iter_valid_loss : 0.08026327937841415\n",
      "\n",
      "    265000\t  0.080941\t  0.080263\t  0.082602\t\tCURRENT LEARNING RATE: 0.03525502592129015\n",
      "previous_iter_valid_loss : 0.0816473588347435\n",
      "\n",
      "    265200\t  0.082458\t  0.081647\t  0.082576\t\tCURRENT LEARNING RATE: 0.03518458633251621\n",
      "previous_iter_valid_loss : 0.07827629894018173\n",
      "\n",
      "    265400\t  0.079058\t  0.078276\t  0.082567\t\tCURRENT LEARNING RATE: 0.03511428748213451\n",
      "previous_iter_valid_loss : 0.08305198699235916\n",
      "\n",
      "    265600\t  0.083943\t  0.083052\t  0.082576\t\tCURRENT LEARNING RATE: 0.035044129088949556\n",
      "previous_iter_valid_loss : 0.08000506460666656\n",
      "\n",
      "    265800\t  0.080809\t  0.080005\t  0.082562\t\tCURRENT LEARNING RATE: 0.03497411087232768\n",
      "previous_iter_valid_loss : 0.08552274107933044\n",
      "\n",
      "    266000\t  0.086744\t  0.085523\t  0.082580\t\tCURRENT LEARNING RATE: 0.034904232552195935\n",
      "previous_iter_valid_loss : 0.08275289833545685\n",
      "\n",
      "    266200\t  0.083557\t  0.082753\t  0.082552\t\tCURRENT LEARNING RATE: 0.03483449384904092\n",
      "previous_iter_valid_loss : 0.0811399295926094\n",
      "\n",
      "    266400\t  0.082062\t  0.081140\t  0.082510\t\tCURRENT LEARNING RATE: 0.034764894483907766\n",
      "previous_iter_valid_loss : 0.081416554749012\n",
      "\n",
      "    266600\t  0.082331\t  0.081417\t  0.082521\t\tCURRENT LEARNING RATE: 0.03469543417839888\n",
      "previous_iter_valid_loss : 0.0805802196264267\n",
      "\n",
      "    266800\t  0.081784\t  0.080580\t  0.082499\t\tCURRENT LEARNING RATE: 0.034626112654673\n",
      "previous_iter_valid_loss : 0.08483376353979111\n",
      "\n",
      "    267000\t  0.086069\t  0.084834\t  0.082502\t\tCURRENT LEARNING RATE: 0.03455692963544387\n",
      "previous_iter_valid_loss : 0.07931681722402573\n",
      "\n",
      "    267200\t  0.080174\t  0.079317\t  0.082450\t\tCURRENT LEARNING RATE: 0.03448788484397939\n",
      "previous_iter_valid_loss : 0.07846322655677795\n",
      "\n",
      "    267400\t  0.079403\t  0.078463\t  0.082431\t\tCURRENT LEARNING RATE: 0.034418978004100244\n",
      "previous_iter_valid_loss : 0.07835397124290466\n",
      "\n",
      "    267600\t  0.079262\t  0.078354\t  0.082408\t\tCURRENT LEARNING RATE: 0.034350208840179024\n",
      "previous_iter_valid_loss : 0.08082646876573563\n",
      "\n",
      "    267800\t  0.081715\t  0.080826\t  0.082394\t\tCURRENT LEARNING RATE: 0.034281577077138956\n",
      "previous_iter_valid_loss : 0.0797257125377655\n",
      "\n",
      "    268000\t  0.080660\t  0.079726\t  0.082343\t\tCURRENT LEARNING RATE: 0.034213082440452916\n",
      "previous_iter_valid_loss : 0.08077175915241241\n",
      "\n",
      "    268200\t  0.081845\t  0.080772\t  0.082245\t\tCURRENT LEARNING RATE: 0.03414472465614224\n",
      "previous_iter_valid_loss : 0.07886616885662079\n",
      "\n",
      "    268400\t  0.079782\t  0.078866\t  0.082246\t\tCURRENT LEARNING RATE: 0.03407650345077573\n",
      "previous_iter_valid_loss : 0.07928083091974258\n",
      "\n",
      "    268600\t  0.080229\t  0.079281\t  0.082220\t\tCURRENT LEARNING RATE: 0.03400841855146844\n",
      "previous_iter_valid_loss : 0.0937044695019722\n",
      "\n",
      "    268800\t  0.095023\t  0.093704\t  0.082293\t\tCURRENT LEARNING RATE: 0.03394046968588072\n",
      "previous_iter_valid_loss : 0.08352042734622955\n",
      "\n",
      "    269000\t  0.084682\t  0.083520\t  0.082270\t\tCURRENT LEARNING RATE: 0.033872656582216984\n",
      "previous_iter_valid_loss : 0.07779551297426224\n",
      "\n",
      "    269200\t  0.078832\t  0.077796\t  0.082254\t\tCURRENT LEARNING RATE: 0.03380497896922475\n",
      "previous_iter_valid_loss : 0.08951815962791443\n",
      "\n",
      "    269400\t  0.090533\t  0.089518\t  0.082286\t\tCURRENT LEARNING RATE: 0.03373743657619345\n",
      "previous_iter_valid_loss : 0.08196943998336792\n",
      "\n",
      "    269600\t  0.082898\t  0.081969\t  0.082281\t\tCURRENT LEARNING RATE: 0.03367002913295346\n",
      "previous_iter_valid_loss : 0.07722562551498413\n",
      "\n",
      "    269800\t  0.078169\t  0.077226\t  0.082069\t\tCURRENT LEARNING RATE: 0.03360275636987488\n",
      "previous_iter_valid_loss : 0.0796564519405365\n",
      "\n",
      "    270000\t  0.080706\t  0.079656\t  0.082041\t\tCURRENT LEARNING RATE: 0.03353561801786659\n",
      "previous_iter_valid_loss : 0.0784706175327301\n",
      "\n",
      "    270200\t  0.079594\t  0.078471\t  0.081974\t\tCURRENT LEARNING RATE: 0.033468613808375076\n",
      "previous_iter_valid_loss : 0.0846838653087616\n",
      "\n",
      "    270400\t  0.085800\t  0.084684\t  0.081995\t\tCURRENT LEARNING RATE: 0.033401743473383434\n",
      "previous_iter_valid_loss : 0.07797020673751831\n",
      "\n",
      "    270600\t  0.078952\t  0.077970\t  0.081946\t\tCURRENT LEARNING RATE: 0.03333500674541021\n",
      "previous_iter_valid_loss : 0.07754846662282944\n",
      "\n",
      "    270800\t  0.078486\t  0.077548\t  0.081897\t\tCURRENT LEARNING RATE: 0.03326840335750843\n",
      "previous_iter_valid_loss : 0.07839076220989227\n",
      "\n",
      "    271000\t  0.079379\t  0.078391\t  0.081892\t\tCURRENT LEARNING RATE: 0.033201933043264416\n",
      "previous_iter_valid_loss : 0.08216938376426697\n",
      "\n",
      "    271200\t  0.083291\t  0.082169\t  0.081876\t\tCURRENT LEARNING RATE: 0.03313559553679686\n",
      "previous_iter_valid_loss : 0.07681072503328323\n",
      "\n",
      "    271400\t  0.077726\t  0.076811\t  0.081870\t\tCURRENT LEARNING RATE: 0.033069390572755625\n",
      "previous_iter_valid_loss : 0.07790054380893707\n",
      "\n",
      "    271600\t  0.078824\t  0.077901\t  0.081862\t\tCURRENT LEARNING RATE: 0.03300331788632078\n",
      "previous_iter_valid_loss : 0.0784611850976944\n",
      "\n",
      "    271800\t  0.079348\t  0.078461\t  0.081847\t\tCURRENT LEARNING RATE: 0.032937377213201474\n",
      "previous_iter_valid_loss : 0.08972106128931046\n",
      "\n",
      "    272000\t  0.090595\t  0.089721\t  0.081902\t\tCURRENT LEARNING RATE: 0.03287156828963495\n",
      "previous_iter_valid_loss : 0.07977171987295151\n",
      "\n",
      "    272200\t  0.080680\t  0.079772\t  0.081846\t\tCURRENT LEARNING RATE: 0.0328058908523854\n",
      "previous_iter_valid_loss : 0.07727240025997162\n",
      "\n",
      "    272400\t  0.078276\t  0.077272\t  0.081814\t\tCURRENT LEARNING RATE: 0.032740344638743014\n",
      "previous_iter_valid_loss : 0.07689084112644196\n",
      "\n",
      "    272600\t  0.077838\t  0.076891\t  0.081800\t\tCURRENT LEARNING RATE: 0.032674929386522826\n",
      "previous_iter_valid_loss : 0.07814721763134003\n",
      "\n",
      "    272800\t  0.078998\t  0.078147\t  0.081802\t\tCURRENT LEARNING RATE: 0.03260964483406376\n",
      "previous_iter_valid_loss : 0.08191706240177155\n",
      "\n",
      "    273000\t  0.082947\t  0.081917\t  0.081815\t\tCURRENT LEARNING RATE: 0.0325444907202275\n",
      "previous_iter_valid_loss : 0.0804639458656311\n",
      "\n",
      "    273200\t  0.081372\t  0.080464\t  0.081811\t\tCURRENT LEARNING RATE: 0.032479466784397525\n",
      "previous_iter_valid_loss : 0.07768656313419342\n",
      "\n",
      "    273400\t  0.078666\t  0.077687\t  0.081601\t\tCURRENT LEARNING RATE: 0.03241457276647798\n",
      "previous_iter_valid_loss : 0.08191108703613281\n",
      "\n",
      "    273600\t  0.082767\t  0.081911\t  0.081608\t\tCURRENT LEARNING RATE: 0.032349808406892736\n",
      "previous_iter_valid_loss : 0.07893945276737213\n",
      "\n",
      "    273800\t  0.079822\t  0.078939\t  0.081592\t\tCURRENT LEARNING RATE: 0.032285173446584235\n",
      "previous_iter_valid_loss : 0.07791563868522644\n",
      "\n",
      "    274000\t  0.078824\t  0.077916\t  0.081581\t\tCURRENT LEARNING RATE: 0.03222066762701259\n",
      "previous_iter_valid_loss : 0.0773165374994278\n",
      "\n",
      "    274200\t  0.078360\t  0.077317\t  0.081581\t\tCURRENT LEARNING RATE: 0.03215629069015439\n",
      "previous_iter_valid_loss : 0.08311603218317032\n",
      "\n",
      "    274400\t  0.084064\t  0.083116\t  0.081606\t\tCURRENT LEARNING RATE: 0.03209204237850184\n",
      "previous_iter_valid_loss : 0.07795961946249008\n",
      "\n",
      "    274600\t  0.079046\t  0.077960\t  0.081606\t\tCURRENT LEARNING RATE: 0.032027922435061584\n",
      "previous_iter_valid_loss : 0.07687252014875412\n",
      "\n",
      "    274800\t  0.077867\t  0.076873\t  0.081592\t\tCURRENT LEARNING RATE: 0.031963930603353785\n",
      "previous_iter_valid_loss : 0.08113279938697815\n",
      "\n",
      "    275000\t  0.082212\t  0.081133\t  0.081609\t\tCURRENT LEARNING RATE: 0.03190006662741102\n",
      "previous_iter_valid_loss : 0.07740837335586548\n",
      "\n",
      "    275200\t  0.078415\t  0.077408\t  0.081598\t\tCURRENT LEARNING RATE: 0.03183633025177728\n",
      "previous_iter_valid_loss : 0.07877464592456818\n",
      "\n",
      "    275400\t  0.079857\t  0.078775\t  0.081597\t\tCURRENT LEARNING RATE: 0.03177272122150701\n",
      "previous_iter_valid_loss : 0.08383045345544815\n",
      "\n",
      "    275600\t  0.084885\t  0.083830\t  0.081628\t\tCURRENT LEARNING RATE: 0.03170923928216398\n",
      "previous_iter_valid_loss : 0.07719980180263519\n",
      "\n",
      "    275800\t  0.078082\t  0.077200\t  0.081596\t\tCURRENT LEARNING RATE: 0.031645884179820366\n",
      "previous_iter_valid_loss : 0.0950188860297203\n",
      "\n",
      "    276000\t  0.096374\t  0.095019\t  0.081656\t\tCURRENT LEARNING RATE: 0.031582655661055656\n",
      "previous_iter_valid_loss : 0.07956377416849136\n",
      "\n",
      "    276200\t  0.080436\t  0.079564\t  0.081612\t\tCURRENT LEARNING RATE: 0.031519553472955715\n",
      "previous_iter_valid_loss : 0.07757070660591125\n",
      "\n",
      "    276400\t  0.078458\t  0.077571\t  0.081605\t\tCURRENT LEARNING RATE: 0.03145657736311167\n",
      "previous_iter_valid_loss : 0.07913431525230408\n",
      "\n",
      "    276600\t  0.080084\t  0.079134\t  0.081585\t\tCURRENT LEARNING RATE: 0.031393727079619044\n",
      "previous_iter_valid_loss : 0.07713990658521652\n",
      "\n",
      "    276800\t  0.078129\t  0.077140\t  0.081577\t\tCURRENT LEARNING RATE: 0.031331002371076576\n",
      "previous_iter_valid_loss : 0.07849807292222977\n",
      "\n",
      "    277000\t  0.079487\t  0.078498\t  0.081572\t\tCURRENT LEARNING RATE: 0.031268402986585384\n",
      "previous_iter_valid_loss : 0.07869350165128708\n",
      "\n",
      "    277200\t  0.079835\t  0.078694\t  0.081506\t\tCURRENT LEARNING RATE: 0.03120592867574781\n",
      "previous_iter_valid_loss : 0.0770382434129715\n",
      "\n",
      "    277400\t  0.077961\t  0.077038\t  0.081501\t\tCURRENT LEARNING RATE: 0.031143579188666563\n",
      "previous_iter_valid_loss : 0.07738642394542694\n",
      "\n",
      "    277600\t  0.078410\t  0.077386\t  0.081449\t\tCURRENT LEARNING RATE: 0.031081354275943582\n",
      "previous_iter_valid_loss : 0.07933453470468521\n",
      "\n",
      "    277800\t  0.080227\t  0.079335\t  0.081439\t\tCURRENT LEARNING RATE: 0.03101925368867916\n",
      "previous_iter_valid_loss : 0.08277401328086853\n",
      "\n",
      "    278000\t  0.084121\t  0.082774\t  0.081462\t\tCURRENT LEARNING RATE: 0.030957277178470837\n",
      "previous_iter_valid_loss : 0.07747991383075714\n",
      "\n",
      "    278200\t  0.078403\t  0.077480\t  0.081408\t\tCURRENT LEARNING RATE: 0.030895424497412522\n",
      "previous_iter_valid_loss : 0.0775134488940239\n",
      "\n",
      "    278400\t  0.078487\t  0.077513\t  0.081404\t\tCURRENT LEARNING RATE: 0.030833695398093372\n",
      "previous_iter_valid_loss : 0.07828826457262039\n",
      "\n",
      "    278600\t  0.079407\t  0.078288\t  0.081360\t\tCURRENT LEARNING RATE: 0.030772089633596945\n",
      "previous_iter_valid_loss : 0.07701621949672699\n",
      "\n",
      "    278800\t  0.077969\t  0.077016\t  0.081334\t\tCURRENT LEARNING RATE: 0.030710606957500063\n",
      "previous_iter_valid_loss : 0.08172563463449478\n",
      "\n",
      "    279000\t  0.082864\t  0.081726\t  0.081281\t\tCURRENT LEARNING RATE: 0.030649247123871976\n",
      "previous_iter_valid_loss : 0.07750628888607025\n",
      "\n",
      "    279200\t  0.078483\t  0.077506\t  0.081244\t\tCURRENT LEARNING RATE: 0.030588009887273233\n",
      "previous_iter_valid_loss : 0.08376440405845642\n",
      "\n",
      "    279400\t  0.084704\t  0.083764\t  0.081213\t\tCURRENT LEARNING RATE: 0.03052689500275484\n",
      "previous_iter_valid_loss : 0.0790221244096756\n",
      "\n",
      "    279600\t  0.080054\t  0.079022\t  0.081218\t\tCURRENT LEARNING RATE: 0.030465902225857145\n",
      "previous_iter_valid_loss : 0.0769721269607544\n",
      "\n",
      "    279800\t  0.078076\t  0.076972\t  0.081205\t\tCURRENT LEARNING RATE: 0.030405031312608986\n",
      "previous_iter_valid_loss : 0.07811421155929565\n",
      "\n",
      "    280000\t  0.079139\t  0.078114\t  0.081206\t\tCURRENT LEARNING RATE: 0.03034428201952661\n",
      "previous_iter_valid_loss : 0.07786761224269867\n",
      "\n",
      "    280200\t  0.078860\t  0.077868\t  0.081148\t\tCURRENT LEARNING RATE: 0.030283654103612778\n",
      "previous_iter_valid_loss : 0.07707654684782028\n",
      "\n",
      "    280400\t  0.078074\t  0.077077\t  0.081064\t\tCURRENT LEARNING RATE: 0.03022314732235573\n",
      "previous_iter_valid_loss : 0.0803331509232521\n",
      "\n",
      "    280600\t  0.081589\t  0.080333\t  0.081051\t\tCURRENT LEARNING RATE: 0.030162761433728282\n",
      "previous_iter_valid_loss : 0.07690885663032532\n",
      "\n",
      "    280800\t  0.077952\t  0.076909\t  0.081025\t\tCURRENT LEARNING RATE: 0.03010249619618677\n",
      "previous_iter_valid_loss : 0.07730525732040405\n",
      "\n",
      "    281000\t  0.078306\t  0.077305\t  0.080998\t\tCURRENT LEARNING RATE: 0.030042351368670193\n",
      "previous_iter_valid_loss : 0.07930922508239746\n",
      "\n",
      "    281200\t  0.080242\t  0.079309\t  0.081003\t\tCURRENT LEARNING RATE: 0.029982326710599135\n",
      "previous_iter_valid_loss : 0.08058205991983414\n",
      "\n",
      "    281400\t  0.081538\t  0.080582\t  0.081005\t\tCURRENT LEARNING RATE: 0.029922421981874912\n",
      "previous_iter_valid_loss : 0.0862896516919136\n",
      "\n",
      "    281600\t  0.087432\t  0.086290\t  0.081033\t\tCURRENT LEARNING RATE: 0.029862636942878495\n",
      "previous_iter_valid_loss : 0.0786648541688919\n",
      "\n",
      "    281800\t  0.079678\t  0.078665\t  0.080970\t\tCURRENT LEARNING RATE: 0.029802971354469684\n",
      "previous_iter_valid_loss : 0.08234001696109772\n",
      "\n",
      "    282000\t  0.083277\t  0.082340\t  0.080992\t\tCURRENT LEARNING RATE: 0.02974342497798601\n",
      "previous_iter_valid_loss : 0.07708191126585007\n",
      "\n",
      "    282200\t  0.078171\t  0.077082\t  0.080988\t\tCURRENT LEARNING RATE: 0.029683997575241924\n",
      "previous_iter_valid_loss : 0.0771542638540268\n",
      "\n",
      "    282400\t  0.078185\t  0.077154\t  0.080923\t\tCURRENT LEARNING RATE: 0.0296246889085277\n",
      "previous_iter_valid_loss : 0.07808142155408859\n",
      "\n",
      "    282600\t  0.079136\t  0.078081\t  0.080928\t\tCURRENT LEARNING RATE: 0.029565498740608626\n",
      "previous_iter_valid_loss : 0.07960550487041473\n",
      "\n",
      "    282800\t  0.080759\t  0.079606\t  0.080930\t\tCURRENT LEARNING RATE: 0.02950642683472392\n",
      "previous_iter_valid_loss : 0.0835820734500885\n",
      "\n",
      "    283000\t  0.084665\t  0.083582\t  0.080953\t\tCURRENT LEARNING RATE: 0.02944747295458591\n",
      "previous_iter_valid_loss : 0.07796092331409454\n",
      "\n",
      "    283200\t  0.078972\t  0.077961\t  0.080945\t\tCURRENT LEARNING RATE: 0.029388636864378967\n",
      "previous_iter_valid_loss : 0.08743895590305328\n",
      "\n",
      "    283400\t  0.088577\t  0.087439\t  0.080963\t\tCURRENT LEARNING RATE: 0.02932991832875868\n",
      "previous_iter_valid_loss : 0.07846611738204956\n",
      "\n",
      "    283600\t  0.079554\t  0.078466\t  0.080940\t\tCURRENT LEARNING RATE: 0.0292713171128508\n",
      "previous_iter_valid_loss : 0.0778547078371048\n",
      "\n",
      "    283800\t  0.078887\t  0.077855\t  0.080939\t\tCURRENT LEARNING RATE: 0.029212832982250414\n",
      "previous_iter_valid_loss : 0.08082696795463562\n",
      "\n",
      "    284000\t  0.081785\t  0.080827\t  0.080949\t\tCURRENT LEARNING RATE: 0.029154465703020896\n",
      "previous_iter_valid_loss : 0.0764189064502716\n",
      "\n",
      "    284200\t  0.077418\t  0.076419\t  0.080937\t\tCURRENT LEARNING RATE: 0.029096215041693074\n",
      "previous_iter_valid_loss : 0.08171165734529495\n",
      "\n",
      "    284400\t  0.082532\t  0.081712\t  0.080948\t\tCURRENT LEARNING RATE: 0.0290380807652642\n",
      "previous_iter_valid_loss : 0.08246549218893051\n",
      "\n",
      "    284600\t  0.083367\t  0.082465\t  0.080914\t\tCURRENT LEARNING RATE: 0.028980062641197117\n",
      "previous_iter_valid_loss : 0.078334279358387\n",
      "\n",
      "    284800\t  0.079320\t  0.078334\t  0.080917\t\tCURRENT LEARNING RATE: 0.028922160437419228\n",
      "previous_iter_valid_loss : 0.07913212478160858\n",
      "\n",
      "    285000\t  0.080022\t  0.079132\t  0.080920\t\tCURRENT LEARNING RATE: 0.028864373922321666\n",
      "previous_iter_valid_loss : 0.07744959741830826\n",
      "\n",
      "    285200\t  0.078517\t  0.077450\t  0.080906\t\tCURRENT LEARNING RATE: 0.02880670286475826\n",
      "previous_iter_valid_loss : 0.08648302406072617\n",
      "\n",
      "    285400\t  0.087660\t  0.086483\t  0.080953\t\tCURRENT LEARNING RATE: 0.028749147034044742\n",
      "previous_iter_valid_loss : 0.08240695297718048\n",
      "\n",
      "    285600\t  0.083465\t  0.082407\t  0.080974\t\tCURRENT LEARNING RATE: 0.028691706199957676\n",
      "previous_iter_valid_loss : 0.08210095763206482\n",
      "\n",
      "    285800\t  0.083227\t  0.082101\t  0.080999\t\tCURRENT LEARNING RATE: 0.02863438013273368\n",
      "previous_iter_valid_loss : 0.07760198414325714\n",
      "\n",
      "    286000\t  0.078529\t  0.077602\t  0.080963\t\tCURRENT LEARNING RATE: 0.02857716860306838\n",
      "previous_iter_valid_loss : 0.07792986184358597\n",
      "\n",
      "    286200\t  0.078974\t  0.077930\t  0.080947\t\tCURRENT LEARNING RATE: 0.028520071382115608\n",
      "previous_iter_valid_loss : 0.07778763025999069\n",
      "\n",
      "    286400\t  0.078867\t  0.077788\t  0.080893\t\tCURRENT LEARNING RATE: 0.028463088241486377\n",
      "previous_iter_valid_loss : 0.07788199186325073\n",
      "\n",
      "    286600\t  0.078926\t  0.077882\t  0.080860\t\tCURRENT LEARNING RATE: 0.028406218953248078\n",
      "previous_iter_valid_loss : 0.08046241849660873\n",
      "\n",
      "    286800\t  0.081739\t  0.080462\t  0.080758\t\tCURRENT LEARNING RATE: 0.02834946328992345\n",
      "previous_iter_valid_loss : 0.08713959902524948\n",
      "\n",
      "    287000\t  0.088268\t  0.087140\t  0.080805\t\tCURRENT LEARNING RATE: 0.028292821024489802\n",
      "previous_iter_valid_loss : 0.07703573256731033\n",
      "\n",
      "    287200\t  0.078178\t  0.077036\t  0.080736\t\tCURRENT LEARNING RATE: 0.028236291930377955\n",
      "previous_iter_valid_loss : 0.08214402943849564\n",
      "\n",
      "    287400\t  0.083499\t  0.082144\t  0.080763\t\tCURRENT LEARNING RATE: 0.028179875781471495\n",
      "previous_iter_valid_loss : 0.07915806025266647\n",
      "\n",
      "    287600\t  0.080313\t  0.079158\t  0.080772\t\tCURRENT LEARNING RATE: 0.02812357235210572\n",
      "previous_iter_valid_loss : 0.0862332135438919\n",
      "\n",
      "    287800\t  0.087391\t  0.086233\t  0.080791\t\tCURRENT LEARNING RATE: 0.028067381417066863\n",
      "previous_iter_valid_loss : 0.07740503549575806\n",
      "\n",
      "    288000\t  0.078584\t  0.077405\t  0.080708\t\tCURRENT LEARNING RATE: 0.028011302751591086\n",
      "previous_iter_valid_loss : 0.07770707458257675\n",
      "\n",
      "    288200\t  0.078780\t  0.077707\t  0.080695\t\tCURRENT LEARNING RATE: 0.027955336131363678\n",
      "previous_iter_valid_loss : 0.07735307514667511\n",
      "\n",
      "    288400\t  0.078462\t  0.077353\t  0.080640\t\tCURRENT LEARNING RATE: 0.027899481332518055\n",
      "previous_iter_valid_loss : 0.07696004211902618\n",
      "\n",
      "    288600\t  0.078082\t  0.076960\t  0.080643\t\tCURRENT LEARNING RATE: 0.027843738131634974\n",
      "previous_iter_valid_loss : 0.07824943214654922\n",
      "\n",
      "    288800\t  0.079306\t  0.078249\t  0.080638\t\tCURRENT LEARNING RATE: 0.02778810630574153\n",
      "previous_iter_valid_loss : 0.07782867550849915\n",
      "\n",
      "    289000\t  0.078999\t  0.077829\t  0.080615\t\tCURRENT LEARNING RATE: 0.027732585632310375\n",
      "previous_iter_valid_loss : 0.0838199034333229\n",
      "\n",
      "    289200\t  0.084712\t  0.083820\t  0.080620\t\tCURRENT LEARNING RATE: 0.027677175889258714\n",
      "previous_iter_valid_loss : 0.0791197344660759\n",
      "\n",
      "    289400\t  0.080244\t  0.079120\t  0.080615\t\tCURRENT LEARNING RATE: 0.027621876854947523\n",
      "previous_iter_valid_loss : 0.07745449990034103\n",
      "\n",
      "    289600\t  0.078534\t  0.077454\t  0.080610\t\tCURRENT LEARNING RATE: 0.02756668830818057\n",
      "previous_iter_valid_loss : 0.0791981965303421\n",
      "\n",
      "    289800\t  0.080417\t  0.079198\t  0.080616\t\tCURRENT LEARNING RATE: 0.027511610028203615\n",
      "previous_iter_valid_loss : 0.07771995663642883\n",
      "\n",
      "    290000\t  0.078973\t  0.077720\t  0.080586\t\tCURRENT LEARNING RATE: 0.027456641794703446\n",
      "previous_iter_valid_loss : 0.08425088226795197\n",
      "\n",
      "    290200\t  0.085571\t  0.084251\t  0.080614\t\tCURRENT LEARNING RATE: 0.027401783387807077\n",
      "previous_iter_valid_loss : 0.08214116841554642\n",
      "\n",
      "    290400\t  0.083237\t  0.082141\t  0.080640\t\tCURRENT LEARNING RATE: 0.02734703458808078\n",
      "previous_iter_valid_loss : 0.08240371197462082\n",
      "\n",
      "    290600\t  0.083609\t  0.082404\t  0.080651\t\tCURRENT LEARNING RATE: 0.027292395176529313\n",
      "previous_iter_valid_loss : 0.08379018306732178\n",
      "\n",
      "    290800\t  0.084940\t  0.083790\t  0.080655\t\tCURRENT LEARNING RATE: 0.02723786493459493\n",
      "previous_iter_valid_loss : 0.08069628477096558\n",
      "\n",
      "    291000\t  0.081941\t  0.080696\t  0.080632\t\tCURRENT LEARNING RATE: 0.02718344364415661\n",
      "previous_iter_valid_loss : 0.07694240659475327\n",
      "\n",
      "    291200\t  0.078226\t  0.076942\t  0.080583\t\tCURRENT LEARNING RATE: 0.027129131087529106\n",
      "previous_iter_valid_loss : 0.07765882462263107\n",
      "\n",
      "    291400\t  0.078731\t  0.077659\t  0.080519\t\tCURRENT LEARNING RATE: 0.027074927047462134\n",
      "previous_iter_valid_loss : 0.08043284714221954\n",
      "\n",
      "    291600\t  0.081500\t  0.080433\t  0.080529\t\tCURRENT LEARNING RATE: 0.027020831307139438\n",
      "previous_iter_valid_loss : 0.07780854403972626\n",
      "\n",
      "    291800\t  0.079053\t  0.077809\t  0.080533\t\tCURRENT LEARNING RATE: 0.02696684365017801\n",
      "previous_iter_valid_loss : 0.07872667908668518\n",
      "\n",
      "    292000\t  0.079893\t  0.078727\t  0.080526\t\tCURRENT LEARNING RATE: 0.026912963860627127\n",
      "previous_iter_valid_loss : 0.07753051817417145\n",
      "\n",
      "    292200\t  0.078631\t  0.077531\t  0.080518\t\tCURRENT LEARNING RATE: 0.026859191722967583\n",
      "previous_iter_valid_loss : 0.07698918879032135\n",
      "\n",
      "    292400\t  0.078143\t  0.076989\t  0.080497\t\tCURRENT LEARNING RATE: 0.026805527022110733\n",
      "previous_iter_valid_loss : 0.07778185606002808\n",
      "\n",
      "    292600\t  0.078918\t  0.077782\t  0.080364\t\tCURRENT LEARNING RATE: 0.02675196954339772\n",
      "previous_iter_valid_loss : 0.08070826530456543\n",
      "\n",
      "    292800\t  0.081952\t  0.080708\t  0.080372\t\tCURRENT LEARNING RATE: 0.026698519072598542\n",
      "previous_iter_valid_loss : 0.07989417761564255\n",
      "\n",
      "    293000\t  0.081090\t  0.079894\t  0.080382\t\tCURRENT LEARNING RATE: 0.026645175395911262\n",
      "previous_iter_valid_loss : 0.07993525266647339\n",
      "\n",
      "    293200\t  0.081068\t  0.079935\t  0.080395\t\tCURRENT LEARNING RATE: 0.02659193829996108\n",
      "previous_iter_valid_loss : 0.08155987411737442\n",
      "\n",
      "    293400\t  0.082834\t  0.081560\t  0.080398\t\tCURRENT LEARNING RATE: 0.026538807571799567\n",
      "previous_iter_valid_loss : 0.07883162051439285\n",
      "\n",
      "    293600\t  0.079820\t  0.078832\t  0.080380\t\tCURRENT LEARNING RATE: 0.026485782998903713\n",
      "previous_iter_valid_loss : 0.07759375125169754\n",
      "\n",
      "    293800\t  0.078723\t  0.077594\t  0.080359\t\tCURRENT LEARNING RATE: 0.026432864369175184\n",
      "previous_iter_valid_loss : 0.07969815284013748\n",
      "\n",
      "    294000\t  0.080840\t  0.079698\t  0.080367\t\tCURRENT LEARNING RATE: 0.026380051470939362\n",
      "previous_iter_valid_loss : 0.0771387368440628\n",
      "\n",
      "    294200\t  0.078228\t  0.077139\t  0.080338\t\tCURRENT LEARNING RATE: 0.026327344092944606\n",
      "previous_iter_valid_loss : 0.07896562665700912\n",
      "\n",
      "    294400\t  0.080041\t  0.078966\t  0.080344\t\tCURRENT LEARNING RATE: 0.02627474202436132\n",
      "previous_iter_valid_loss : 0.08514460921287537\n",
      "\n",
      "    294600\t  0.086193\t  0.085145\t  0.080374\t\tCURRENT LEARNING RATE: 0.02622224505478117\n",
      "previous_iter_valid_loss : 0.07727404683828354\n",
      "\n",
      "    294800\t  0.078416\t  0.077274\t  0.080345\t\tCURRENT LEARNING RATE: 0.02616985297421619\n",
      "previous_iter_valid_loss : 0.07778047025203705\n",
      "\n",
      "    295000\t  0.079037\t  0.077780\t  0.080324\t\tCURRENT LEARNING RATE: 0.026117565573098016\n",
      "previous_iter_valid_loss : 0.0798046737909317\n",
      "\n",
      "    295200\t  0.081051\t  0.079805\t  0.080337\t\tCURRENT LEARNING RATE: 0.026065382642276945\n",
      "previous_iter_valid_loss : 0.07778607308864594\n",
      "\n",
      "    295400\t  0.079031\t  0.077786\t  0.080332\t\tCURRENT LEARNING RATE: 0.026013303973021207\n",
      "previous_iter_valid_loss : 0.07753200083971024\n",
      "\n",
      "    295600\t  0.078762\t  0.077532\t  0.080307\t\tCURRENT LEARNING RATE: 0.025961329357016037\n",
      "previous_iter_valid_loss : 0.07766062021255493\n",
      "\n",
      "    295800\t  0.078840\t  0.077661\t  0.080283\t\tCURRENT LEARNING RATE: 0.025909458586362916\n",
      "previous_iter_valid_loss : 0.07991626113653183\n",
      "\n",
      "    296000\t  0.081124\t  0.079916\t  0.080291\t\tCURRENT LEARNING RATE: 0.02585769145357868\n",
      "previous_iter_valid_loss : 0.08193019032478333\n",
      "\n",
      "    296200\t  0.083116\t  0.081930\t  0.080307\t\tCURRENT LEARNING RATE: 0.025806027751594744\n",
      "previous_iter_valid_loss : 0.07786811143159866\n",
      "\n",
      "    296400\t  0.079011\t  0.077868\t  0.080301\t\tCURRENT LEARNING RATE: 0.025754467273756212\n",
      "previous_iter_valid_loss : 0.0834445208311081\n",
      "\n",
      "    296600\t  0.084688\t  0.083445\t  0.080319\t\tCURRENT LEARNING RATE: 0.025703009813821127\n",
      "previous_iter_valid_loss : 0.07755409926176071\n",
      "\n",
      "    296800\t  0.078766\t  0.077554\t  0.080273\t\tCURRENT LEARNING RATE: 0.025651655165959554\n",
      "previous_iter_valid_loss : 0.07927758246660233\n",
      "\n",
      "    297000\t  0.080582\t  0.079278\t  0.080285\t\tCURRENT LEARNING RATE: 0.02560040312475286\n",
      "previous_iter_valid_loss : 0.07757512480020523\n",
      "\n",
      "    297200\t  0.078966\t  0.077575\t  0.080271\t\tCURRENT LEARNING RATE: 0.02554925348519279\n",
      "previous_iter_valid_loss : 0.07744549214839935\n",
      "\n",
      "    297400\t  0.078616\t  0.077445\t  0.080264\t\tCURRENT LEARNING RATE: 0.025498206042680733\n",
      "previous_iter_valid_loss : 0.07824718952178955\n",
      "\n",
      "    297600\t  0.079443\t  0.078247\t  0.080255\t\tCURRENT LEARNING RATE: 0.025447260593026835\n",
      "previous_iter_valid_loss : 0.07762680947780609\n",
      "\n",
      "    297800\t  0.078857\t  0.077627\t  0.080184\t\tCURRENT LEARNING RATE: 0.02539641693244925\n",
      "previous_iter_valid_loss : 0.07806900143623352\n",
      "\n",
      "    298000\t  0.079330\t  0.078069\t  0.080146\t\tCURRENT LEARNING RATE: 0.025345674857573247\n",
      "previous_iter_valid_loss : 0.08012297749519348\n",
      "\n",
      "    298200\t  0.081428\t  0.080123\t  0.080161\t\tCURRENT LEARNING RATE: 0.02529503416543048\n",
      "previous_iter_valid_loss : 0.07657621055841446\n",
      "\n",
      "    298400\t  0.077736\t  0.076576\t  0.080139\t\tCURRENT LEARNING RATE: 0.025244494653458086\n",
      "previous_iter_valid_loss : 0.07644522935152054\n",
      "\n",
      "    298600\t  0.077617\t  0.076445\t  0.080122\t\tCURRENT LEARNING RATE: 0.02519405611949798\n",
      "previous_iter_valid_loss : 0.0790015310049057\n",
      "\n",
      "    298800\t  0.080125\t  0.079002\t  0.080132\t\tCURRENT LEARNING RATE: 0.025143718361795932\n",
      "previous_iter_valid_loss : 0.08191190659999847\n",
      "\n",
      "    299000\t  0.083264\t  0.081912\t  0.080132\t\tCURRENT LEARNING RATE: 0.025093481179000867\n",
      "previous_iter_valid_loss : 0.07937589287757874\n",
      "\n",
      "    299200\t  0.080598\t  0.079376\t  0.080128\t\tCURRENT LEARNING RATE: 0.025043344370163964\n",
      "previous_iter_valid_loss : 0.0788557231426239\n",
      "\n",
      "    299400\t  0.079951\t  0.078856\t  0.080133\t\tCURRENT LEARNING RATE: 0.024993307734737947\n",
      "previous_iter_valid_loss : 0.07930785417556763\n",
      "\n",
      "    299600\t  0.080542\t  0.079308\t  0.080102\t\tCURRENT LEARNING RATE: 0.02494337107257618\n",
      "previous_iter_valid_loss : 0.07853285223245621\n",
      "\n",
      "    299800\t  0.079743\t  0.078533\t  0.080110\t\tCURRENT LEARNING RATE: 0.024893534183931972\n",
      "previous_iter_valid_loss : 0.07691773772239685\n",
      "\n",
      "    300000\t  0.078191\t  0.076918\t  0.080060\t\tCURRENT LEARNING RATE: 0.02484379686945769\n",
      "previous_iter_valid_loss : 0.0773111954331398\n",
      "\n",
      "    300200\t  0.078538\t  0.077311\t  0.080035\t\tCURRENT LEARNING RATE: 0.024794158930204\n",
      "previous_iter_valid_loss : 0.08010908961296082\n",
      "\n",
      "    300400\t  0.081329\t  0.080109\t  0.080038\t\tCURRENT LEARNING RATE: 0.024744620167619105\n",
      "previous_iter_valid_loss : 0.08417995274066925\n",
      "\n",
      "    300600\t  0.085474\t  0.084180\t  0.080057\t\tCURRENT LEARNING RATE: 0.024695180383547857\n",
      "previous_iter_valid_loss : 0.0786028727889061\n",
      "\n",
      "    300800\t  0.079751\t  0.078603\t  0.080020\t\tCURRENT LEARNING RATE: 0.024645839380231085\n",
      "previous_iter_valid_loss : 0.0766870304942131\n",
      "\n",
      "    301000\t  0.077982\t  0.076687\t  0.080019\t\tCURRENT LEARNING RATE: 0.02459659696030468\n",
      "previous_iter_valid_loss : 0.07714991271495819\n",
      "\n",
      "    301200\t  0.078348\t  0.077150\t  0.080018\t\tCURRENT LEARNING RATE: 0.024547452926798927\n",
      "previous_iter_valid_loss : 0.07846556603908539\n",
      "\n",
      "    301400\t  0.079813\t  0.078466\t  0.079999\t\tCURRENT LEARNING RATE: 0.0244984070831376\n",
      "previous_iter_valid_loss : 0.07690935581922531\n",
      "\n",
      "    301600\t  0.078225\t  0.076909\t  0.079975\t\tCURRENT LEARNING RATE: 0.02444945923313728\n",
      "previous_iter_valid_loss : 0.07739292830228806\n",
      "\n",
      "    301800\t  0.078564\t  0.077393\t  0.079921\t\tCURRENT LEARNING RATE: 0.02440060918100648\n",
      "previous_iter_valid_loss : 0.07704386115074158\n",
      "\n",
      "    302000\t  0.078236\t  0.077044\t  0.079897\t\tCURRENT LEARNING RATE: 0.024351856731344948\n",
      "previous_iter_valid_loss : 0.07945715636014938\n",
      "\n",
      "    302200\t  0.080724\t  0.079457\t  0.079808\t\tCURRENT LEARNING RATE: 0.024303201689142802\n",
      "previous_iter_valid_loss : 0.07773590087890625\n",
      "\n",
      "    302400\t  0.079080\t  0.077736\t  0.079812\t\tCURRENT LEARNING RATE: 0.024254643859779827\n",
      "previous_iter_valid_loss : 0.082441046833992\n",
      "\n",
      "    302600\t  0.083519\t  0.082441\t  0.079809\t\tCURRENT LEARNING RATE: 0.02420618304902462\n",
      "previous_iter_valid_loss : 0.07901936769485474\n",
      "\n",
      "    302800\t  0.080306\t  0.079019\t  0.079807\t\tCURRENT LEARNING RATE: 0.024157819063033895\n",
      "previous_iter_valid_loss : 0.0769045501947403\n",
      "\n",
      "    303000\t  0.078097\t  0.076905\t  0.079777\t\tCURRENT LEARNING RATE: 0.02410955170835162\n",
      "previous_iter_valid_loss : 0.07866606116294861\n",
      "\n",
      "    303200\t  0.079933\t  0.078666\t  0.079785\t\tCURRENT LEARNING RATE: 0.024061380791908338\n",
      "previous_iter_valid_loss : 0.08247020840644836\n",
      "\n",
      "    303400\t  0.083993\t  0.082470\t  0.079784\t\tCURRENT LEARNING RATE: 0.024013306121020293\n",
      "previous_iter_valid_loss : 0.08166759461164474\n",
      "\n",
      "    303600\t  0.083202\t  0.081668\t  0.079784\t\tCURRENT LEARNING RATE: 0.02396532750338876\n",
      "previous_iter_valid_loss : 0.07901934534311295\n",
      "\n",
      "    303800\t  0.080571\t  0.079019\t  0.079769\t\tCURRENT LEARNING RATE: 0.023917444747099184\n",
      "previous_iter_valid_loss : 0.08235148340463638\n",
      "\n",
      "    304000\t  0.083650\t  0.082351\t  0.079791\t\tCURRENT LEARNING RATE: 0.023869657660620498\n",
      "previous_iter_valid_loss : 0.07674695551395416\n",
      "\n",
      "    304200\t  0.077972\t  0.076747\t  0.079752\t\tCURRENT LEARNING RATE: 0.023821966052804268\n",
      "previous_iter_valid_loss : 0.07704858481884003\n",
      "\n",
      "    304400\t  0.078275\t  0.077049\t  0.079725\t\tCURRENT LEARNING RATE: 0.023774369732884024\n",
      "previous_iter_valid_loss : 0.07932087033987045\n",
      "\n",
      "    304600\t  0.080749\t  0.079321\t  0.079730\t\tCURRENT LEARNING RATE: 0.0237268685104744\n",
      "previous_iter_valid_loss : 0.07919537276029587\n",
      "\n",
      "    304800\t  0.080667\t  0.079195\t  0.079692\t\tCURRENT LEARNING RATE: 0.023679462195570464\n",
      "previous_iter_valid_loss : 0.07738789916038513\n",
      "\n",
      "    305000\t  0.078735\t  0.077388\t  0.079678\t\tCURRENT LEARNING RATE: 0.023632150598546873\n",
      "previous_iter_valid_loss : 0.07632192224264145\n",
      "\n",
      "    305200\t  0.077668\t  0.076322\t  0.079651\t\tCURRENT LEARNING RATE: 0.023584933530157195\n",
      "previous_iter_valid_loss : 0.07834410667419434\n",
      "\n",
      "    305400\t  0.079596\t  0.078344\t  0.079652\t\tCURRENT LEARNING RATE: 0.023537810801533075\n",
      "previous_iter_valid_loss : 0.08032646030187607\n",
      "\n",
      "    305600\t  0.082118\t  0.080326\t  0.079638\t\tCURRENT LEARNING RATE: 0.023490782224183555\n",
      "previous_iter_valid_loss : 0.08165523409843445\n",
      "\n",
      "    305800\t  0.082853\t  0.081655\t  0.079646\t\tCURRENT LEARNING RATE: 0.023443847609994243\n",
      "previous_iter_valid_loss : 0.08064378052949905\n",
      "\n",
      "    306000\t  0.081997\t  0.080644\t  0.079622\t\tCURRENT LEARNING RATE: 0.02339700677122664\n",
      "previous_iter_valid_loss : 0.07797686010599136\n",
      "\n",
      "    306200\t  0.079221\t  0.077977\t  0.079598\t\tCURRENT LEARNING RATE: 0.023350259520517305\n",
      "previous_iter_valid_loss : 0.07849323004484177\n",
      "\n",
      "    306400\t  0.080087\t  0.078493\t  0.079585\t\tCURRENT LEARNING RATE: 0.0233036056708772\n",
      "previous_iter_valid_loss : 0.07927404344081879\n",
      "\n",
      "    306600\t  0.080814\t  0.079274\t  0.079574\t\tCURRENT LEARNING RATE: 0.023257045035690836\n",
      "previous_iter_valid_loss : 0.0816725566983223\n",
      "\n",
      "    306800\t  0.083127\t  0.081673\t  0.079579\t\tCURRENT LEARNING RATE: 0.023210577428715636\n",
      "previous_iter_valid_loss : 0.07976999878883362\n",
      "\n",
      "    307000\t  0.081129\t  0.079770\t  0.079554\t\tCURRENT LEARNING RATE: 0.023164202664081087\n",
      "previous_iter_valid_loss : 0.07723812758922577\n",
      "\n",
      "    307200\t  0.078568\t  0.077238\t  0.079544\t\tCURRENT LEARNING RATE: 0.023117920556288092\n",
      "previous_iter_valid_loss : 0.07733947038650513\n",
      "\n",
      "    307400\t  0.078823\t  0.077339\t  0.079538\t\tCURRENT LEARNING RATE: 0.023071730920208134\n",
      "previous_iter_valid_loss : 0.07708552479743958\n",
      "\n",
      "    307600\t  0.078505\t  0.077086\t  0.079532\t\tCURRENT LEARNING RATE: 0.023025633571082633\n",
      "previous_iter_valid_loss : 0.08392737805843353\n",
      "\n",
      "    307800\t  0.085498\t  0.083927\t  0.079547\t\tCURRENT LEARNING RATE: 0.022979628324522102\n",
      "previous_iter_valid_loss : 0.08164962381124496\n",
      "\n",
      "    308000\t  0.083069\t  0.081650\t  0.079557\t\tCURRENT LEARNING RATE: 0.02293371499650552\n",
      "previous_iter_valid_loss : 0.0826312005519867\n",
      "\n",
      "    308200\t  0.083992\t  0.082631\t  0.079566\t\tCURRENT LEARNING RATE: 0.022887893403379496\n",
      "previous_iter_valid_loss : 0.07792025059461594\n",
      "\n",
      "    308400\t  0.079436\t  0.077920\t  0.079562\t\tCURRENT LEARNING RATE: 0.02284216336185761\n",
      "previous_iter_valid_loss : 0.07778278738260269\n",
      "\n",
      "    308600\t  0.079354\t  0.077783\t  0.079554\t\tCURRENT LEARNING RATE: 0.022796524689019618\n",
      "previous_iter_valid_loss : 0.07961884140968323\n",
      "\n",
      "    308800\t  0.080980\t  0.079619\t  0.079484\t\tCURRENT LEARNING RATE: 0.022750977202310785\n",
      "previous_iter_valid_loss : 0.07697725296020508\n",
      "\n",
      "    309000\t  0.078449\t  0.076977\t  0.079451\t\tCURRENT LEARNING RATE: 0.02270552071954109\n",
      "previous_iter_valid_loss : 0.07714439928531647\n",
      "\n",
      "    309200\t  0.078619\t  0.077144\t  0.079448\t\tCURRENT LEARNING RATE: 0.022660155058884555\n",
      "previous_iter_valid_loss : 0.0771927759051323\n",
      "\n",
      "    309400\t  0.078743\t  0.077193\t  0.079386\t\tCURRENT LEARNING RATE: 0.02261488003887846\n",
      "previous_iter_valid_loss : 0.07879871875047684\n",
      "\n",
      "    309600\t  0.080221\t  0.078799\t  0.079370\t\tCURRENT LEARNING RATE: 0.02256969547842268\n",
      "previous_iter_valid_loss : 0.07711878418922424\n",
      "\n",
      "    309800\t  0.078576\t  0.077119\t  0.079370\t\tCURRENT LEARNING RATE: 0.0225246011967789\n",
      "previous_iter_valid_loss : 0.07777948677539825\n",
      "\n",
      "    310000\t  0.079290\t  0.077779\t  0.079360\t\tCURRENT LEARNING RATE: 0.02247959701356995\n",
      "previous_iter_valid_loss : 0.07957784086465836\n",
      "\n",
      "    310200\t  0.081260\t  0.079578\t  0.079366\t\tCURRENT LEARNING RATE: 0.022434682748779015\n",
      "previous_iter_valid_loss : 0.07712382823228836\n",
      "\n",
      "    310400\t  0.078602\t  0.077124\t  0.079328\t\tCURRENT LEARNING RATE: 0.022389858222749002\n",
      "previous_iter_valid_loss : 0.07722827792167664\n",
      "\n",
      "    310600\t  0.078676\t  0.077228\t  0.079324\t\tCURRENT LEARNING RATE: 0.02234512325618172\n",
      "previous_iter_valid_loss : 0.07744475454092026\n",
      "\n",
      "    310800\t  0.078967\t  0.077445\t  0.079324\t\tCURRENT LEARNING RATE: 0.022300477670137268\n",
      "previous_iter_valid_loss : 0.07789607346057892\n",
      "\n",
      "    311000\t  0.079493\t  0.077896\t  0.079321\t\tCURRENT LEARNING RATE: 0.02225592128603322\n",
      "previous_iter_valid_loss : 0.07815643399953842\n",
      "\n",
      "    311200\t  0.079856\t  0.078156\t  0.079301\t\tCURRENT LEARNING RATE: 0.022211453925643998\n",
      "previous_iter_valid_loss : 0.07813523709774017\n",
      "\n",
      "    311400\t  0.079682\t  0.078135\t  0.079308\t\tCURRENT LEARNING RATE: 0.022167075411100086\n",
      "previous_iter_valid_loss : 0.07821410894393921\n",
      "\n",
      "    311600\t  0.079673\t  0.078214\t  0.079309\t\tCURRENT LEARNING RATE: 0.022122785564887386\n",
      "previous_iter_valid_loss : 0.0899539589881897\n",
      "\n",
      "    311800\t  0.091423\t  0.089954\t  0.079367\t\tCURRENT LEARNING RATE: 0.02207858420984643\n",
      "previous_iter_valid_loss : 0.07781953364610672\n",
      "\n",
      "    312000\t  0.079406\t  0.077820\t  0.079307\t\tCURRENT LEARNING RATE: 0.022034471169171763\n",
      "previous_iter_valid_loss : 0.07781278342008591\n",
      "\n",
      "    312200\t  0.079092\t  0.077813\t  0.079298\t\tCURRENT LEARNING RATE: 0.021990446266411143\n",
      "previous_iter_valid_loss : 0.0799708440899849\n",
      "\n",
      "    312400\t  0.081304\t  0.079971\t  0.079311\t\tCURRENT LEARNING RATE: 0.02194650932546492\n",
      "previous_iter_valid_loss : 0.08250987529754639\n",
      "\n",
      "    312600\t  0.083968\t  0.082510\t  0.079339\t\tCURRENT LEARNING RATE: 0.021902660170585245\n",
      "previous_iter_valid_loss : 0.07868228852748871\n",
      "\n",
      "    312800\t  0.080212\t  0.078682\t  0.079342\t\tCURRENT LEARNING RATE: 0.02185889862637547\n",
      "previous_iter_valid_loss : 0.0801653191447258\n",
      "\n",
      "    313000\t  0.081571\t  0.080165\t  0.079333\t\tCURRENT LEARNING RATE: 0.021815224517789337\n",
      "previous_iter_valid_loss : 0.07836120575666428\n",
      "\n",
      "    313200\t  0.080000\t  0.078361\t  0.079323\t\tCURRENT LEARNING RATE: 0.02177163767013037\n",
      "previous_iter_valid_loss : 0.07688085734844208\n",
      "\n",
      "    313400\t  0.078373\t  0.076881\t  0.079318\t\tCURRENT LEARNING RATE: 0.021728137909051103\n",
      "previous_iter_valid_loss : 0.0785263404250145\n",
      "\n",
      "    313600\t  0.080007\t  0.078526\t  0.079302\t\tCURRENT LEARNING RATE: 0.021684725060552454\n",
      "previous_iter_valid_loss : 0.08304185420274734\n",
      "\n",
      "    313800\t  0.084406\t  0.083042\t  0.079322\t\tCURRENT LEARNING RATE: 0.021641398950982948\n",
      "previous_iter_valid_loss : 0.07902079820632935\n",
      "\n",
      "    314000\t  0.080542\t  0.079021\t  0.079328\t\tCURRENT LEARNING RATE: 0.02159815940703811\n",
      "previous_iter_valid_loss : 0.07815010845661163\n",
      "\n",
      "    314200\t  0.079697\t  0.078150\t  0.079332\t\tCURRENT LEARNING RATE: 0.021555006255759693\n",
      "previous_iter_valid_loss : 0.08109977096319199\n",
      "\n",
      "    314400\t  0.082516\t  0.081100\t  0.079322\t\tCURRENT LEARNING RATE: 0.021511939324535045\n",
      "previous_iter_valid_loss : 0.07669699937105179\n",
      "\n",
      "    314600\t  0.078291\t  0.076697\t  0.079315\t\tCURRENT LEARNING RATE: 0.021468958441096368\n",
      "previous_iter_valid_loss : 0.07922648638486862\n",
      "\n",
      "    314800\t  0.080574\t  0.079226\t  0.079327\t\tCURRENT LEARNING RATE: 0.021426063433520093\n",
      "previous_iter_valid_loss : 0.0808316320180893\n",
      "\n",
      "    315000\t  0.082383\t  0.080832\t  0.079326\t\tCURRENT LEARNING RATE: 0.02138325413022611\n",
      "previous_iter_valid_loss : 0.07692965120077133\n",
      "\n",
      "    315200\t  0.078460\t  0.076930\t  0.079323\t\tCURRENT LEARNING RATE: 0.021340530359977166\n",
      "previous_iter_valid_loss : 0.07842545211315155\n",
      "\n",
      "    315400\t  0.079905\t  0.078425\t  0.079322\t\tCURRENT LEARNING RATE: 0.021297891951878107\n",
      "previous_iter_valid_loss : 0.07783100754022598\n",
      "\n",
      "    315600\t  0.079178\t  0.077831\t  0.079292\t\tCURRENT LEARNING RATE: 0.021255338735375263\n",
      "previous_iter_valid_loss : 0.07923775911331177\n",
      "\n",
      "    315800\t  0.080674\t  0.079238\t  0.079302\t\tCURRENT LEARNING RATE: 0.021212870540255693\n",
      "previous_iter_valid_loss : 0.07786563783884048\n",
      "\n",
      "    316000\t  0.079226\t  0.077866\t  0.079216\t\tCURRENT LEARNING RATE: 0.021170487196646572\n",
      "previous_iter_valid_loss : 0.07654528319835663\n",
      "\n",
      "    316200\t  0.077939\t  0.076545\t  0.079201\t\tCURRENT LEARNING RATE: 0.021128188535014462\n",
      "previous_iter_valid_loss : 0.07647420465946198\n",
      "\n",
      "    316400\t  0.077872\t  0.076474\t  0.079195\t\tCURRENT LEARNING RATE: 0.021085974386164667\n",
      "previous_iter_valid_loss : 0.07697363197803497\n",
      "\n",
      "    316600\t  0.078457\t  0.076974\t  0.079185\t\tCURRENT LEARNING RATE: 0.021043844581240527\n",
      "previous_iter_valid_loss : 0.07758509367704391\n",
      "\n",
      "    316800\t  0.078846\t  0.077585\t  0.079187\t\tCURRENT LEARNING RATE: 0.021001798951722776\n",
      "previous_iter_valid_loss : 0.07658972591161728\n",
      "\n",
      "    317000\t  0.077829\t  0.076590\t  0.079177\t\tCURRENT LEARNING RATE: 0.020959837329428826\n",
      "previous_iter_valid_loss : 0.07754135131835938\n",
      "\n",
      "    317200\t  0.078792\t  0.077541\t  0.079171\t\tCURRENT LEARNING RATE: 0.02091795954651215\n",
      "previous_iter_valid_loss : 0.07863987982273102\n",
      "\n",
      "    317400\t  0.080125\t  0.078640\t  0.079179\t\tCURRENT LEARNING RATE: 0.02087616543546154\n",
      "previous_iter_valid_loss : 0.07701610773801804\n",
      "\n",
      "    317600\t  0.078412\t  0.077016\t  0.079178\t\tCURRENT LEARNING RATE: 0.02083445482910052\n",
      "previous_iter_valid_loss : 0.07824943959712982\n",
      "\n",
      "    317800\t  0.079503\t  0.078249\t  0.079172\t\tCURRENT LEARNING RATE: 0.02079282756058658\n",
      "previous_iter_valid_loss : 0.07654447108507156\n",
      "\n",
      "    318000\t  0.077832\t  0.076544\t  0.079141\t\tCURRENT LEARNING RATE: 0.02075128346341062\n",
      "previous_iter_valid_loss : 0.07644660025835037\n",
      "\n",
      "    318200\t  0.077768\t  0.076447\t  0.079136\t\tCURRENT LEARNING RATE: 0.020709822371396173\n",
      "previous_iter_valid_loss : 0.07813611626625061\n",
      "\n",
      "    318400\t  0.079472\t  0.078136\t  0.079139\t\tCURRENT LEARNING RATE: 0.020668444118698833\n",
      "previous_iter_valid_loss : 0.07768432796001434\n",
      "\n",
      "    318600\t  0.079124\t  0.077684\t  0.079136\t\tCURRENT LEARNING RATE: 0.020627148539805514\n",
      "previous_iter_valid_loss : 0.07629940658807755\n",
      "\n",
      "    318800\t  0.077696\t  0.076299\t  0.079132\t\tCURRENT LEARNING RATE: 0.02058593546953387\n",
      "previous_iter_valid_loss : 0.07632272690534592\n",
      "\n",
      "    319000\t  0.077506\t  0.076323\t  0.079105\t\tCURRENT LEARNING RATE: 0.02054480474303154\n",
      "previous_iter_valid_loss : 0.07680626213550568\n",
      "\n",
      "    319200\t  0.078196\t  0.076806\t  0.079102\t\tCURRENT LEARNING RATE: 0.020503756195775585\n",
      "previous_iter_valid_loss : 0.0760979875922203\n",
      "\n",
      "    319400\t  0.077346\t  0.076098\t  0.079064\t\tCURRENT LEARNING RATE: 0.020462789663571745\n",
      "previous_iter_valid_loss : 0.07651279866695404\n",
      "\n",
      "    319600\t  0.077844\t  0.076513\t  0.079051\t\tCURRENT LEARNING RATE: 0.02042190498255385\n",
      "previous_iter_valid_loss : 0.07705261558294296\n",
      "\n",
      "    319800\t  0.078378\t  0.077053\t  0.079051\t\tCURRENT LEARNING RATE: 0.020381101989183106\n",
      "previous_iter_valid_loss : 0.0769788920879364\n",
      "\n",
      "    320000\t  0.078230\t  0.076979\t  0.079046\t\tCURRENT LEARNING RATE: 0.0203403805202475\n",
      "previous_iter_valid_loss : 0.07953806966543198\n",
      "\n",
      "    320200\t  0.080842\t  0.079538\t  0.079054\t\tCURRENT LEARNING RATE: 0.02029974041286109\n",
      "previous_iter_valid_loss : 0.07590509206056595\n",
      "\n",
      "    320400\t  0.077071\t  0.075905\t  0.079048\t\tCURRENT LEARNING RATE: 0.020259181504463403\n",
      "previous_iter_valid_loss : 0.08025234937667847\n",
      "\n",
      "    320600\t  0.081294\t  0.080252\t  0.079048\t\tCURRENT LEARNING RATE: 0.02021870363281874\n",
      "previous_iter_valid_loss : 0.07952587306499481\n",
      "\n",
      "    320800\t  0.080862\t  0.079526\t  0.079061\t\tCURRENT LEARNING RATE: 0.020178306636015574\n",
      "previous_iter_valid_loss : 0.079330213367939\n",
      "\n",
      "    321000\t  0.080627\t  0.079330\t  0.079071\t\tCURRENT LEARNING RATE: 0.02013799035246585\n",
      "previous_iter_valid_loss : 0.07699305564165115\n",
      "\n",
      "    321200\t  0.078395\t  0.076993\t  0.079059\t\tCURRENT LEARNING RATE: 0.020097754620904393\n",
      "previous_iter_valid_loss : 0.07640311121940613\n",
      "\n",
      "    321400\t  0.077765\t  0.076403\t  0.079039\t\tCURRENT LEARNING RATE: 0.020057599280388208\n",
      "previous_iter_valid_loss : 0.07902628183364868\n",
      "\n",
      "    321600\t  0.080587\t  0.079026\t  0.079002\t\tCURRENT LEARNING RATE: 0.020017524170295897\n",
      "previous_iter_valid_loss : 0.0805605798959732\n",
      "\n",
      "    321800\t  0.082064\t  0.080561\t  0.079012\t\tCURRENT LEARNING RATE: 0.019977529130326948\n",
      "previous_iter_valid_loss : 0.07630734145641327\n",
      "\n",
      "    322000\t  0.077774\t  0.076307\t  0.078982\t\tCURRENT LEARNING RATE: 0.019937614000501168\n",
      "previous_iter_valid_loss : 0.07651923596858978\n",
      "\n",
      "    322200\t  0.077839\t  0.076519\t  0.078979\t\tCURRENT LEARNING RATE: 0.019897778621157963\n",
      "previous_iter_valid_loss : 0.08155601471662521\n",
      "\n",
      "    322400\t  0.083051\t  0.081556\t  0.079001\t\tCURRENT LEARNING RATE: 0.019858022832955784\n",
      "previous_iter_valid_loss : 0.07648535817861557\n",
      "\n",
      "    322600\t  0.078090\t  0.076485\t  0.078993\t\tCURRENT LEARNING RATE: 0.0198183464768714\n",
      "previous_iter_valid_loss : 0.07684243470430374\n",
      "\n",
      "    322800\t  0.078295\t  0.076842\t  0.078979\t\tCURRENT LEARNING RATE: 0.019778749394199362\n",
      "previous_iter_valid_loss : 0.07724562287330627\n",
      "\n",
      "    323000\t  0.078776\t  0.077246\t  0.078947\t\tCURRENT LEARNING RATE: 0.019739231426551263\n",
      "previous_iter_valid_loss : 0.07666488736867905\n",
      "\n",
      "    323200\t  0.078284\t  0.076665\t  0.078941\t\tCURRENT LEARNING RATE: 0.019699792415855195\n",
      "previous_iter_valid_loss : 0.07626810669898987\n",
      "\n",
      "    323400\t  0.077835\t  0.076268\t  0.078885\t\tCURRENT LEARNING RATE: 0.019660432204355052\n",
      "previous_iter_valid_loss : 0.0784318819642067\n",
      "\n",
      "    323600\t  0.080103\t  0.078432\t  0.078885\t\tCURRENT LEARNING RATE: 0.019621150634609945\n",
      "previous_iter_valid_loss : 0.07637537270784378\n",
      "\n",
      "    323800\t  0.077882\t  0.076375\t  0.078877\t\tCURRENT LEARNING RATE: 0.019581947549493533\n",
      "previous_iter_valid_loss : 0.08026807010173798\n",
      "\n",
      "    324000\t  0.082176\t  0.080268\t  0.078875\t\tCURRENT LEARNING RATE: 0.019542822792193434\n",
      "previous_iter_valid_loss : 0.07665430009365082\n",
      "\n",
      "    324200\t  0.078358\t  0.076654\t  0.078876\t\tCURRENT LEARNING RATE: 0.019503776206210556\n",
      "previous_iter_valid_loss : 0.07727523148059845\n",
      "\n",
      "    324400\t  0.078779\t  0.077275\t  0.078854\t\tCURRENT LEARNING RATE: 0.019464807635358513\n",
      "previous_iter_valid_loss : 0.07629624754190445\n",
      "\n",
      "    324600\t  0.077864\t  0.076296\t  0.078823\t\tCURRENT LEARNING RATE: 0.019425916923762956\n",
      "previous_iter_valid_loss : 0.07681082934141159\n",
      "\n",
      "    324800\t  0.078404\t  0.076811\t  0.078815\t\tCURRENT LEARNING RATE: 0.019387103915861004\n",
      "previous_iter_valid_loss : 0.07651859521865845\n",
      "\n",
      "    325000\t  0.078111\t  0.076519\t  0.078802\t\tCURRENT LEARNING RATE: 0.019348368456400568\n",
      "previous_iter_valid_loss : 0.07640884816646576\n",
      "\n",
      "    325200\t  0.078039\t  0.076409\t  0.078797\t\tCURRENT LEARNING RATE: 0.019309710390439744\n",
      "previous_iter_valid_loss : 0.07647568732500076\n",
      "\n",
      "    325400\t  0.078083\t  0.076476\t  0.078747\t\tCURRENT LEARNING RATE: 0.019271129563346236\n",
      "previous_iter_valid_loss : 0.07702737301588058\n",
      "\n",
      "    325600\t  0.078754\t  0.077027\t  0.078720\t\tCURRENT LEARNING RATE: 0.01923262582079667\n",
      "previous_iter_valid_loss : 0.07751039415597916\n",
      "\n",
      "    325800\t  0.079576\t  0.077510\t  0.078697\t\tCURRENT LEARNING RATE: 0.019194199008776038\n",
      "previous_iter_valid_loss : 0.08227241039276123\n",
      "\n",
      "    326000\t  0.084078\t  0.082272\t  0.078720\t\tCURRENT LEARNING RATE: 0.019155848973577024\n",
      "previous_iter_valid_loss : 0.0775509923696518\n",
      "\n",
      "    326200\t  0.079221\t  0.077551\t  0.078718\t\tCURRENT LEARNING RATE: 0.019117575561799455\n",
      "previous_iter_valid_loss : 0.07797738164663315\n",
      "\n",
      "    326400\t  0.079638\t  0.077977\t  0.078719\t\tCURRENT LEARNING RATE: 0.019079378620349613\n",
      "previous_iter_valid_loss : 0.08027315884828568\n",
      "\n",
      "    326600\t  0.081962\t  0.080273\t  0.078731\t\tCURRENT LEARNING RATE: 0.019041257996439704\n",
      "previous_iter_valid_loss : 0.07626301050186157\n",
      "\n",
      "    326800\t  0.077822\t  0.076263\t  0.078710\t\tCURRENT LEARNING RATE: 0.019003213537587157\n",
      "previous_iter_valid_loss : 0.0763801708817482\n",
      "\n",
      "    327000\t  0.077876\t  0.076380\t  0.078657\t\tCURRENT LEARNING RATE: 0.018965245091614107\n",
      "previous_iter_valid_loss : 0.07731377333402634\n",
      "\n",
      "    327200\t  0.078911\t  0.077314\t  0.078658\t\tCURRENT LEARNING RATE: 0.018927352506646705\n",
      "previous_iter_valid_loss : 0.0803804099559784\n",
      "\n",
      "    327400\t  0.082192\t  0.080380\t  0.078649\t\tCURRENT LEARNING RATE: 0.01888953563111457\n",
      "previous_iter_valid_loss : 0.07767406105995178\n",
      "\n",
      "    327600\t  0.079359\t  0.077674\t  0.078642\t\tCURRENT LEARNING RATE: 0.018851794313750142\n",
      "previous_iter_valid_loss : 0.0799894854426384\n",
      "\n",
      "    327800\t  0.081909\t  0.079989\t  0.078611\t\tCURRENT LEARNING RATE: 0.01881412840358811\n",
      "previous_iter_valid_loss : 0.07616306841373444\n",
      "\n",
      "    328000\t  0.077773\t  0.076163\t  0.078604\t\tCURRENT LEARNING RATE: 0.01877653774996477\n",
      "previous_iter_valid_loss : 0.07870489358901978\n",
      "\n",
      "    328200\t  0.080434\t  0.078705\t  0.078609\t\tCURRENT LEARNING RATE: 0.018739022202517473\n",
      "previous_iter_valid_loss : 0.0779557004570961\n",
      "\n",
      "    328400\t  0.079735\t  0.077956\t  0.078612\t\tCURRENT LEARNING RATE: 0.018701581611183963\n",
      "previous_iter_valid_loss : 0.07748869806528091\n",
      "\n",
      "    328600\t  0.079107\t  0.077489\t  0.078615\t\tCURRENT LEARNING RATE: 0.01866421582620184\n",
      "previous_iter_valid_loss : 0.07719513773918152\n",
      "\n",
      "    328800\t  0.078825\t  0.077195\t  0.078610\t\tCURRENT LEARNING RATE: 0.018626924698107904\n",
      "previous_iter_valid_loss : 0.07649333775043488\n",
      "\n",
      "    329000\t  0.078313\t  0.076493\t  0.078603\t\tCURRENT LEARNING RATE: 0.0185897080777376\n",
      "previous_iter_valid_loss : 0.07928887754678726\n",
      "\n",
      "    329200\t  0.080923\t  0.079289\t  0.078580\t\tCURRENT LEARNING RATE: 0.018552565816224387\n",
      "previous_iter_valid_loss : 0.07660726457834244\n",
      "\n",
      "    329400\t  0.078235\t  0.076607\t  0.078568\t\tCURRENT LEARNING RATE: 0.018515497764999184\n",
      "previous_iter_valid_loss : 0.0763588547706604\n",
      "\n",
      "    329600\t  0.077917\t  0.076359\t  0.078562\t\tCURRENT LEARNING RATE: 0.01847850377578972\n",
      "previous_iter_valid_loss : 0.07725053280591965\n",
      "\n",
      "    329800\t  0.078825\t  0.077251\t  0.078553\t\tCURRENT LEARNING RATE: 0.018441583700620007\n",
      "previous_iter_valid_loss : 0.07636881619691849\n",
      "\n",
      "    330000\t  0.077913\t  0.076369\t  0.078546\t\tCURRENT LEARNING RATE: 0.018404737391809676\n",
      "previous_iter_valid_loss : 0.0763811394572258\n",
      "\n",
      "    330200\t  0.078020\t  0.076381\t  0.078506\t\tCURRENT LEARNING RATE: 0.01836796470197346\n",
      "previous_iter_valid_loss : 0.07635650783777237\n",
      "\n",
      "    330400\t  0.077913\t  0.076357\t  0.078478\t\tCURRENT LEARNING RATE: 0.01833126548402053\n",
      "previous_iter_valid_loss : 0.07707992196083069\n",
      "\n",
      "    330600\t  0.078860\t  0.077080\t  0.078451\t\tCURRENT LEARNING RATE: 0.018294639591153992\n",
      "previous_iter_valid_loss : 0.08284486830234528\n",
      "\n",
      "    330800\t  0.084654\t  0.082845\t  0.078446\t\tCURRENT LEARNING RATE: 0.0182580868768702\n",
      "previous_iter_valid_loss : 0.07839524745941162\n",
      "\n",
      "    331000\t  0.080049\t  0.078395\t  0.078435\t\tCURRENT LEARNING RATE: 0.01822160719495827\n",
      "previous_iter_valid_loss : 0.07700281590223312\n",
      "\n",
      "    331200\t  0.078693\t  0.077003\t  0.078435\t\tCURRENT LEARNING RATE: 0.018185200399499404\n",
      "previous_iter_valid_loss : 0.07648871093988419\n",
      "\n",
      "    331400\t  0.078051\t  0.076489\t  0.078429\t\tCURRENT LEARNING RATE: 0.018148866344866392\n",
      "previous_iter_valid_loss : 0.0774935856461525\n",
      "\n",
      "    331600\t  0.079354\t  0.077494\t  0.078414\t\tCURRENT LEARNING RATE: 0.018112604885722954\n",
      "previous_iter_valid_loss : 0.07817965000867844\n",
      "\n",
      "    331800\t  0.079698\t  0.078180\t  0.078416\t\tCURRENT LEARNING RATE: 0.018076415877023213\n",
      "previous_iter_valid_loss : 0.07699913531541824\n",
      "\n",
      "    332000\t  0.078285\t  0.076999\t  0.078408\t\tCURRENT LEARNING RATE: 0.018040299174011076\n",
      "previous_iter_valid_loss : 0.07633654773235321\n",
      "\n",
      "    332200\t  0.077719\t  0.076337\t  0.078402\t\tCURRENT LEARNING RATE: 0.018004254632219694\n",
      "previous_iter_valid_loss : 0.07816631346940994\n",
      "\n",
      "    332400\t  0.079776\t  0.078166\t  0.078408\t\tCURRENT LEARNING RATE: 0.01796828210747084\n",
      "previous_iter_valid_loss : 0.07711640745401382\n",
      "\n",
      "    332600\t  0.078757\t  0.077116\t  0.078404\t\tCURRENT LEARNING RATE: 0.01793238145587438\n",
      "previous_iter_valid_loss : 0.07859273254871368\n",
      "\n",
      "    332800\t  0.080250\t  0.078593\t  0.078394\t\tCURRENT LEARNING RATE: 0.01789655253382765\n",
      "previous_iter_valid_loss : 0.07751965522766113\n",
      "\n",
      "    333000\t  0.079004\t  0.077520\t  0.078382\t\tCURRENT LEARNING RATE: 0.017860795198014923\n",
      "previous_iter_valid_loss : 0.07638169825077057\n",
      "\n",
      "    333200\t  0.078045\t  0.076382\t  0.078364\t\tCURRENT LEARNING RATE: 0.017825109305406792\n",
      "previous_iter_valid_loss : 0.07913611084222794\n",
      "\n",
      "    333400\t  0.080754\t  0.079136\t  0.078352\t\tCURRENT LEARNING RATE: 0.01778949471325966\n",
      "previous_iter_valid_loss : 0.07617292553186417\n",
      "\n",
      "    333600\t  0.077770\t  0.076173\t  0.078339\t\tCURRENT LEARNING RATE: 0.017753951279115093\n",
      "previous_iter_valid_loss : 0.07634507864713669\n",
      "\n",
      "    333800\t  0.078122\t  0.076345\t  0.078332\t\tCURRENT LEARNING RATE: 0.01771847886079932\n",
      "previous_iter_valid_loss : 0.07644553482532501\n",
      "\n",
      "    334000\t  0.078190\t  0.076446\t  0.078316\t\tCURRENT LEARNING RATE: 0.01768307731642261\n",
      "previous_iter_valid_loss : 0.07606860250234604\n",
      "\n",
      "    334200\t  0.077726\t  0.076069\t  0.078311\t\tCURRENT LEARNING RATE: 0.017647746504378746\n",
      "previous_iter_valid_loss : 0.0761195570230484\n",
      "\n",
      "    334400\t  0.077683\t  0.076120\t  0.078297\t\tCURRENT LEARNING RATE: 0.017612486283344428\n",
      "previous_iter_valid_loss : 0.07871514558792114\n",
      "\n",
      "    334600\t  0.080318\t  0.078715\t  0.078264\t\tCURRENT LEARNING RATE: 0.01757729651227873\n",
      "previous_iter_valid_loss : 0.07634595036506653\n",
      "\n",
      "    334800\t  0.078087\t  0.076346\t  0.078260\t\tCURRENT LEARNING RATE: 0.017542177050422512\n",
      "previous_iter_valid_loss : 0.07679346948862076\n",
      "\n",
      "    335000\t  0.078449\t  0.076793\t  0.078255\t\tCURRENT LEARNING RATE: 0.017507127757297892\n",
      "previous_iter_valid_loss : 0.07671882957220078\n",
      "\n",
      "    335200\t  0.078531\t  0.076719\t  0.078239\t\tCURRENT LEARNING RATE: 0.017472148492707635\n",
      "previous_iter_valid_loss : 0.07633194327354431\n",
      "\n",
      "    335400\t  0.077943\t  0.076332\t  0.078232\t\tCURRENT LEARNING RATE: 0.017437239116734657\n",
      "previous_iter_valid_loss : 0.08065953105688095\n",
      "\n",
      "    335600\t  0.082414\t  0.080660\t  0.078248\t\tCURRENT LEARNING RATE: 0.017402399489741385\n",
      "previous_iter_valid_loss : 0.07615076750516891\n",
      "\n",
      "    335800\t  0.077961\t  0.076151\t  0.078240\t\tCURRENT LEARNING RATE: 0.01736762947236928\n",
      "previous_iter_valid_loss : 0.0764787346124649\n",
      "\n",
      "    336000\t  0.078349\t  0.076479\t  0.078223\t\tCURRENT LEARNING RATE: 0.01733292892553822\n",
      "previous_iter_valid_loss : 0.07646974176168442\n",
      "\n",
      "    336200\t  0.078177\t  0.076470\t  0.078196\t\tCURRENT LEARNING RATE: 0.017298297710445977\n",
      "previous_iter_valid_loss : 0.07625526934862137\n",
      "\n",
      "    336400\t  0.077951\t  0.076255\t  0.078188\t\tCURRENT LEARNING RATE: 0.017263735688567632\n",
      "previous_iter_valid_loss : 0.07634866237640381\n",
      "\n",
      "    336600\t  0.078131\t  0.076349\t  0.078152\t\tCURRENT LEARNING RATE: 0.017229242721655068\n",
      "previous_iter_valid_loss : 0.0764046385884285\n",
      "\n",
      "    336800\t  0.078136\t  0.076405\t  0.078146\t\tCURRENT LEARNING RATE: 0.017194818671736355\n",
      "previous_iter_valid_loss : 0.0764445960521698\n",
      "\n",
      "    337000\t  0.078371\t  0.076445\t  0.078132\t\tCURRENT LEARNING RATE: 0.017160463401115263\n",
      "previous_iter_valid_loss : 0.08005009591579437\n",
      "\n",
      "    337200\t  0.082025\t  0.080050\t  0.078145\t\tCURRENT LEARNING RATE: 0.01712617677237065\n",
      "previous_iter_valid_loss : 0.078184112906456\n",
      "\n",
      "    337400\t  0.080048\t  0.078184\t  0.078148\t\tCURRENT LEARNING RATE: 0.017091958648355967\n",
      "previous_iter_valid_loss : 0.0775650143623352\n",
      "\n",
      "    337600\t  0.079518\t  0.077565\t  0.078145\t\tCURRENT LEARNING RATE: 0.01705780889219866\n",
      "previous_iter_valid_loss : 0.07684876769781113\n",
      "\n",
      "    337800\t  0.078718\t  0.076849\t  0.078141\t\tCURRENT LEARNING RATE: 0.017023727367299672\n",
      "previous_iter_valid_loss : 0.07874276489019394\n",
      "\n",
      "    338000\t  0.080519\t  0.078743\t  0.078144\t\tCURRENT LEARNING RATE: 0.016989713937332847\n",
      "previous_iter_valid_loss : 0.07724752277135849\n",
      "\n",
      "    338200\t  0.078965\t  0.077248\t  0.078130\t\tCURRENT LEARNING RATE: 0.016955768466244428\n",
      "previous_iter_valid_loss : 0.07632855325937271\n",
      "\n",
      "    338400\t  0.078262\t  0.076329\t  0.078129\t\tCURRENT LEARNING RATE: 0.016921890818252475\n",
      "previous_iter_valid_loss : 0.07662060111761093\n",
      "\n",
      "    338600\t  0.078389\t  0.076621\t  0.078130\t\tCURRENT LEARNING RATE: 0.016888080857846367\n",
      "previous_iter_valid_loss : 0.07925699651241302\n",
      "\n",
      "    338800\t  0.080978\t  0.079257\t  0.078131\t\tCURRENT LEARNING RATE: 0.016854338449786198\n",
      "previous_iter_valid_loss : 0.07703094184398651\n",
      "\n",
      "    339000\t  0.078697\t  0.077031\t  0.078107\t\tCURRENT LEARNING RATE: 0.01682066345910231\n",
      "previous_iter_valid_loss : 0.07743357121944427\n",
      "\n",
      "    339200\t  0.079255\t  0.077434\t  0.078097\t\tCURRENT LEARNING RATE: 0.016787055751094678\n",
      "previous_iter_valid_loss : 0.07641911506652832\n",
      "\n",
      "    339400\t  0.078152\t  0.076419\t  0.078085\t\tCURRENT LEARNING RATE: 0.01675351519133244\n",
      "previous_iter_valid_loss : 0.0839219018816948\n",
      "\n",
      "    339600\t  0.085728\t  0.083922\t  0.078108\t\tCURRENT LEARNING RATE: 0.0167200416456533\n",
      "previous_iter_valid_loss : 0.07998310774564743\n",
      "\n",
      "    339800\t  0.081918\t  0.079983\t  0.078115\t\tCURRENT LEARNING RATE: 0.01668663498016304\n",
      "previous_iter_valid_loss : 0.07670945674180984\n",
      "\n",
      "    340000\t  0.078577\t  0.076709\t  0.078114\t\tCURRENT LEARNING RATE: 0.016653295061234946\n",
      "previous_iter_valid_loss : 0.07706718891859055\n",
      "\n",
      "    340200\t  0.078922\t  0.077067\t  0.078113\t\tCURRENT LEARNING RATE: 0.016620021755509307\n",
      "previous_iter_valid_loss : 0.07664673775434494\n",
      "\n",
      "    340400\t  0.078614\t  0.076647\t  0.078095\t\tCURRENT LEARNING RATE: 0.01658681492989284\n",
      "previous_iter_valid_loss : 0.07704270631074905\n",
      "\n",
      "    340600\t  0.078934\t  0.077043\t  0.078060\t\tCURRENT LEARNING RATE: 0.01655367445155822\n",
      "previous_iter_valid_loss : 0.07910464704036713\n",
      "\n",
      "    340800\t  0.081181\t  0.079105\t  0.078062\t\tCURRENT LEARNING RATE: 0.016520600187943466\n",
      "previous_iter_valid_loss : 0.07713993638753891\n",
      "\n",
      "    341000\t  0.079119\t  0.077140\t  0.078064\t\tCURRENT LEARNING RATE: 0.0164875920067515\n",
      "previous_iter_valid_loss : 0.07673812657594681\n",
      "\n",
      "    341200\t  0.078632\t  0.076738\t  0.078062\t\tCURRENT LEARNING RATE: 0.01645464977594954\n",
      "previous_iter_valid_loss : 0.07692436873912811\n",
      "\n",
      "    341400\t  0.078938\t  0.076924\t  0.078055\t\tCURRENT LEARNING RATE: 0.01642177336376863\n",
      "previous_iter_valid_loss : 0.07738632708787918\n",
      "\n",
      "    341600\t  0.079358\t  0.077386\t  0.078057\t\tCURRENT LEARNING RATE: 0.016388962638703063\n",
      "previous_iter_valid_loss : 0.07673980295658112\n",
      "\n",
      "    341800\t  0.078734\t  0.076740\t  0.078054\t\tCURRENT LEARNING RATE: 0.01635621746950991\n",
      "previous_iter_valid_loss : 0.07733512669801712\n",
      "\n",
      "    342000\t  0.079310\t  0.077335\t  0.078055\t\tCURRENT LEARNING RATE: 0.016323537725208434\n",
      "previous_iter_valid_loss : 0.07808753848075867\n",
      "\n",
      "    342200\t  0.079921\t  0.078088\t  0.078048\t\tCURRENT LEARNING RATE: 0.01629092327507963\n",
      "previous_iter_valid_loss : 0.07789228111505508\n",
      "\n",
      "    342400\t  0.079989\t  0.077892\t  0.078049\t\tCURRENT LEARNING RATE: 0.016258373988665645\n",
      "previous_iter_valid_loss : 0.07800570875406265\n",
      "\n",
      "    342600\t  0.080129\t  0.078006\t  0.078027\t\tCURRENT LEARNING RATE: 0.016225889735769296\n",
      "previous_iter_valid_loss : 0.07866831868886948\n",
      "\n",
      "    342800\t  0.080604\t  0.078668\t  0.078025\t\tCURRENT LEARNING RATE: 0.01619347038645352\n",
      "previous_iter_valid_loss : 0.07720178365707397\n",
      "\n",
      "    343000\t  0.079102\t  0.077202\t  0.078027\t\tCURRENT LEARNING RATE: 0.016161115811040884\n",
      "previous_iter_valid_loss : 0.07669852674007416\n",
      "\n",
      "    343200\t  0.078797\t  0.076699\t  0.078017\t\tCURRENT LEARNING RATE: 0.016128825880113037\n",
      "previous_iter_valid_loss : 0.07867278903722763\n",
      "\n",
      "    343400\t  0.080818\t  0.078673\t  0.077998\t\tCURRENT LEARNING RATE: 0.01609660046451022\n",
      "previous_iter_valid_loss : 0.07656316459178925\n",
      "\n",
      "    343600\t  0.078624\t  0.076563\t  0.077972\t\tCURRENT LEARNING RATE: 0.01606443943533072\n",
      "previous_iter_valid_loss : 0.07711657136678696\n",
      "\n",
      "    343800\t  0.079190\t  0.077117\t  0.077963\t\tCURRENT LEARNING RATE: 0.016032342663930384\n",
      "previous_iter_valid_loss : 0.07690387964248657\n",
      "\n",
      "    344000\t  0.079019\t  0.076904\t  0.077936\t\tCURRENT LEARNING RATE: 0.016000310021922075\n",
      "previous_iter_valid_loss : 0.07641493529081345\n",
      "\n",
      "    344200\t  0.078288\t  0.076415\t  0.077934\t\tCURRENT LEARNING RATE: 0.015968341381175196\n",
      "previous_iter_valid_loss : 0.07717426866292953\n",
      "\n",
      "    344400\t  0.079167\t  0.077174\t  0.077935\t\tCURRENT LEARNING RATE: 0.015936436613815122\n",
      "previous_iter_valid_loss : 0.07989707589149475\n",
      "\n",
      "    344600\t  0.081963\t  0.079897\t  0.077937\t\tCURRENT LEARNING RATE: 0.01590459559222276\n",
      "previous_iter_valid_loss : 0.07711951434612274\n",
      "\n",
      "    344800\t  0.079098\t  0.077120\t  0.077927\t\tCURRENT LEARNING RATE: 0.01587281818903397\n",
      "previous_iter_valid_loss : 0.07853789627552032\n",
      "\n",
      "    345000\t  0.080538\t  0.078538\t  0.077933\t\tCURRENT LEARNING RATE: 0.0158411042771391\n",
      "previous_iter_valid_loss : 0.08036946505308151\n",
      "\n",
      "    345200\t  0.082473\t  0.080369\t  0.077953\t\tCURRENT LEARNING RATE: 0.015809453729682458\n",
      "previous_iter_valid_loss : 0.07647824287414551\n",
      "\n",
      "    345400\t  0.078449\t  0.076478\t  0.077944\t\tCURRENT LEARNING RATE: 0.01577786642006182\n",
      "previous_iter_valid_loss : 0.07768779993057251\n",
      "\n",
      "    345600\t  0.079849\t  0.077688\t  0.077931\t\tCURRENT LEARNING RATE: 0.015746342221927893\n",
      "previous_iter_valid_loss : 0.07891259342432022\n",
      "\n",
      "    345800\t  0.081162\t  0.078913\t  0.077917\t\tCURRENT LEARNING RATE: 0.015714881009183855\n",
      "previous_iter_valid_loss : 0.07881839573383331\n",
      "\n",
      "    346000\t  0.080811\t  0.078818\t  0.077908\t\tCURRENT LEARNING RATE: 0.0156834826559848\n",
      "previous_iter_valid_loss : 0.0769570842385292\n",
      "\n",
      "    346200\t  0.078975\t  0.076957\t  0.077903\t\tCURRENT LEARNING RATE: 0.01565214703673729\n",
      "previous_iter_valid_loss : 0.07902224361896515\n",
      "\n",
      "    346400\t  0.081043\t  0.079022\t  0.077905\t\tCURRENT LEARNING RATE: 0.015620874026098783\n",
      "previous_iter_valid_loss : 0.0781998485326767\n",
      "\n",
      "    346600\t  0.080216\t  0.078200\t  0.077900\t\tCURRENT LEARNING RATE: 0.015589663498977219\n",
      "previous_iter_valid_loss : 0.07636614888906479\n",
      "\n",
      "    346800\t  0.078413\t  0.076366\t  0.077873\t\tCURRENT LEARNING RATE: 0.01555851533053043\n",
      "previous_iter_valid_loss : 0.07699775695800781\n",
      "\n",
      "    347000\t  0.079017\t  0.076998\t  0.077860\t\tCURRENT LEARNING RATE: 0.015527429396165715\n",
      "previous_iter_valid_loss : 0.07677359879016876\n",
      "\n",
      "    347200\t  0.078814\t  0.076774\t  0.077857\t\tCURRENT LEARNING RATE: 0.01549640557153928\n",
      "previous_iter_valid_loss : 0.07721615582704544\n",
      "\n",
      "    347400\t  0.079173\t  0.077216\t  0.077857\t\tCURRENT LEARNING RATE: 0.015465443732555801\n",
      "previous_iter_valid_loss : 0.07775919884443283\n",
      "\n",
      "    347600\t  0.079786\t  0.077759\t  0.077860\t\tCURRENT LEARNING RATE: 0.015434543755367866\n",
      "previous_iter_valid_loss : 0.07741864025592804\n",
      "\n",
      "    347800\t  0.079440\t  0.077419\t  0.077827\t\tCURRENT LEARNING RATE: 0.015403705516375538\n",
      "previous_iter_valid_loss : 0.07684159278869629\n",
      "\n",
      "    348000\t  0.078836\t  0.076842\t  0.077803\t\tCURRENT LEARNING RATE: 0.015372928892225808\n",
      "previous_iter_valid_loss : 0.07980716973543167\n",
      "\n",
      "    348200\t  0.081973\t  0.079807\t  0.077789\t\tCURRENT LEARNING RATE: 0.01534221375981215\n",
      "previous_iter_valid_loss : 0.0764225423336029\n",
      "\n",
      "    348400\t  0.078463\t  0.076423\t  0.077782\t\tCURRENT LEARNING RATE: 0.01531155999627398\n",
      "previous_iter_valid_loss : 0.07809843868017197\n",
      "\n",
      "    348600\t  0.080360\t  0.078098\t  0.077783\t\tCURRENT LEARNING RATE: 0.015280967478996219\n",
      "previous_iter_valid_loss : 0.07651454210281372\n",
      "\n",
      "    348800\t  0.078682\t  0.076515\t  0.077768\t\tCURRENT LEARNING RATE: 0.015250436085608741\n",
      "previous_iter_valid_loss : 0.07656840980052948\n",
      "\n",
      "    349000\t  0.078579\t  0.076568\t  0.077766\t\tCURRENT LEARNING RATE: 0.015219965693985945\n",
      "previous_iter_valid_loss : 0.07736954092979431\n",
      "\n",
      "    349200\t  0.079347\t  0.077370\t  0.077767\t\tCURRENT LEARNING RATE: 0.015189556182246215\n",
      "previous_iter_valid_loss : 0.07693792134523392\n",
      "\n",
      "    349400\t  0.079153\t  0.076938\t  0.077766\t\tCURRENT LEARNING RATE: 0.01515920742875147\n",
      "previous_iter_valid_loss : 0.07733277231454849\n",
      "\n",
      "    349600\t  0.079353\t  0.077333\t  0.077758\t\tCURRENT LEARNING RATE: 0.015128919312106647\n",
      "previous_iter_valid_loss : 0.07673055678606033\n",
      "\n",
      "    349800\t  0.078771\t  0.076731\t  0.077756\t\tCURRENT LEARNING RATE: 0.01509869171115925\n",
      "previous_iter_valid_loss : 0.07635415345430374\n",
      "\n",
      "    350000\t  0.078352\t  0.076354\t  0.077749\t\tCURRENT LEARNING RATE: 0.01506852450499883\n",
      "previous_iter_valid_loss : 0.07685425132513046\n",
      "\n",
      "    350200\t  0.078910\t  0.076854\t  0.077736\t\tCURRENT LEARNING RATE: 0.015038417572956516\n",
      "previous_iter_valid_loss : 0.07923131436109543\n",
      "\n",
      "    350400\t  0.081155\t  0.079231\t  0.077746\t\tCURRENT LEARNING RATE: 0.015008370794604549\n",
      "previous_iter_valid_loss : 0.0770459696650505\n",
      "\n",
      "    350600\t  0.079156\t  0.077046\t  0.077745\t\tCURRENT LEARNING RATE: 0.014978384049755766\n",
      "previous_iter_valid_loss : 0.07877695560455322\n",
      "\n",
      "    350800\t  0.080731\t  0.078777\t  0.077752\t\tCURRENT LEARNING RATE: 0.01494845721846316\n",
      "previous_iter_valid_loss : 0.07649176567792892\n",
      "\n",
      "    351000\t  0.078682\t  0.076492\t  0.077745\t\tCURRENT LEARNING RATE: 0.014918590181019353\n",
      "previous_iter_valid_loss : 0.07700849324464798\n",
      "\n",
      "    351200\t  0.079198\t  0.077008\t  0.077739\t\tCURRENT LEARNING RATE: 0.014888782817956168\n",
      "previous_iter_valid_loss : 0.07677162438631058\n",
      "\n",
      "    351400\t  0.078759\t  0.076772\t  0.077732\t\tCURRENT LEARNING RATE: 0.0148590350100441\n",
      "previous_iter_valid_loss : 0.07706121355295181\n",
      "\n",
      "    351600\t  0.079091\t  0.077061\t  0.077727\t\tCURRENT LEARNING RATE: 0.01482934663829189\n",
      "previous_iter_valid_loss : 0.07940222322940826\n",
      "\n",
      "    351800\t  0.081408\t  0.079402\t  0.077674\t\tCURRENT LEARNING RATE: 0.014799717583946\n",
      "previous_iter_valid_loss : 0.07727108150720596\n",
      "\n",
      "    352000\t  0.079045\t  0.077271\t  0.077671\t\tCURRENT LEARNING RATE: 0.014770147728490186\n",
      "previous_iter_valid_loss : 0.07741852849721909\n",
      "\n",
      "    352200\t  0.079305\t  0.077419\t  0.077669\t\tCURRENT LEARNING RATE: 0.01474063695364497\n",
      "previous_iter_valid_loss : 0.07668089866638184\n",
      "\n",
      "    352400\t  0.078636\t  0.076681\t  0.077653\t\tCURRENT LEARNING RATE: 0.014711185141367232\n",
      "previous_iter_valid_loss : 0.07709822058677673\n",
      "\n",
      "    352600\t  0.079013\t  0.077098\t  0.077626\t\tCURRENT LEARNING RATE: 0.014681792173849666\n",
      "previous_iter_valid_loss : 0.07710307836532593\n",
      "\n",
      "    352800\t  0.078919\t  0.077103\t  0.077618\t\tCURRENT LEARNING RATE: 0.01465245793352038\n",
      "previous_iter_valid_loss : 0.0764080137014389\n",
      "\n",
      "    353000\t  0.078234\t  0.076408\t  0.077599\t\tCURRENT LEARNING RATE: 0.014623182303042357\n",
      "previous_iter_valid_loss : 0.07645519822835922\n",
      "\n",
      "    353200\t  0.078301\t  0.076455\t  0.077589\t\tCURRENT LEARNING RATE: 0.01459396516531305\n",
      "previous_iter_valid_loss : 0.07624537497758865\n",
      "\n",
      "    353400\t  0.078234\t  0.076245\t  0.077586\t\tCURRENT LEARNING RATE: 0.014564806403463856\n",
      "previous_iter_valid_loss : 0.07650640606880188\n",
      "\n",
      "    353600\t  0.078443\t  0.076506\t  0.077576\t\tCURRENT LEARNING RATE: 0.014535705900859702\n",
      "previous_iter_valid_loss : 0.0767136663198471\n",
      "\n",
      "    353800\t  0.078706\t  0.076714\t  0.077544\t\tCURRENT LEARNING RATE: 0.014506663541098527\n",
      "previous_iter_valid_loss : 0.07710447162389755\n",
      "\n",
      "    354000\t  0.079106\t  0.077104\t  0.077535\t\tCURRENT LEARNING RATE: 0.014477679208010864\n",
      "previous_iter_valid_loss : 0.07614655047655106\n",
      "\n",
      "    354200\t  0.078106\t  0.076147\t  0.077525\t\tCURRENT LEARNING RATE: 0.014448752785659331\n",
      "previous_iter_valid_loss : 0.0774063915014267\n",
      "\n",
      "    354400\t  0.079103\t  0.077406\t  0.077506\t\tCURRENT LEARNING RATE: 0.014419884158338211\n",
      "previous_iter_valid_loss : 0.08045660704374313\n",
      "\n",
      "    354600\t  0.082296\t  0.080457\t  0.077525\t\tCURRENT LEARNING RATE: 0.014391073210572945\n",
      "previous_iter_valid_loss : 0.07699362188577652\n",
      "\n",
      "    354800\t  0.079100\t  0.076994\t  0.077514\t\tCURRENT LEARNING RATE: 0.014362319827119717\n",
      "previous_iter_valid_loss : 0.0768776386976242\n",
      "\n",
      "    355000\t  0.078982\t  0.076878\t  0.077494\t\tCURRENT LEARNING RATE: 0.01433362389296494\n",
      "previous_iter_valid_loss : 0.0770130455493927\n",
      "\n",
      "    355200\t  0.079223\t  0.077013\t  0.077495\t\tCURRENT LEARNING RATE: 0.014304985293324853\n",
      "previous_iter_valid_loss : 0.07735530287027359\n",
      "\n",
      "    355400\t  0.079434\t  0.077355\t  0.077489\t\tCURRENT LEARNING RATE: 0.014276403913645005\n",
      "previous_iter_valid_loss : 0.07654843479394913\n",
      "\n",
      "    355600\t  0.078535\t  0.076548\t  0.077483\t\tCURRENT LEARNING RATE: 0.014247879639599854\n",
      "previous_iter_valid_loss : 0.07667351514101028\n",
      "\n",
      "    355800\t  0.078598\t  0.076674\t  0.077470\t\tCURRENT LEARNING RATE: 0.014219412357092252\n",
      "previous_iter_valid_loss : 0.07733277231454849\n",
      "\n",
      "    356000\t  0.079472\t  0.077333\t  0.077467\t\tCURRENT LEARNING RATE: 0.014191001952253045\n",
      "previous_iter_valid_loss : 0.07706739753484726\n",
      "\n",
      "    356200\t  0.078924\t  0.077067\t  0.077470\t\tCURRENT LEARNING RATE: 0.01416264831144056\n",
      "previous_iter_valid_loss : 0.07765540480613708\n",
      "\n",
      "    356400\t  0.079708\t  0.077655\t  0.077476\t\tCURRENT LEARNING RATE: 0.014134351321240213\n",
      "previous_iter_valid_loss : 0.07684340327978134\n",
      "\n",
      "    356600\t  0.078877\t  0.076843\t  0.077475\t\tCURRENT LEARNING RATE: 0.01410611086846399\n",
      "previous_iter_valid_loss : 0.07721167802810669\n",
      "\n",
      "    356800\t  0.078969\t  0.077212\t  0.077473\t\tCURRENT LEARNING RATE: 0.014077926840150053\n",
      "previous_iter_valid_loss : 0.07675790041685104\n",
      "\n",
      "    357000\t  0.078716\t  0.076758\t  0.077474\t\tCURRENT LEARNING RATE: 0.014049799123562244\n",
      "previous_iter_valid_loss : 0.0768962949514389\n",
      "\n",
      "    357200\t  0.078829\t  0.076896\t  0.077471\t\tCURRENT LEARNING RATE: 0.014021727606189666\n",
      "previous_iter_valid_loss : 0.07721617072820663\n",
      "\n",
      "    357400\t  0.079177\t  0.077216\t  0.077464\t\tCURRENT LEARNING RATE: 0.013993712175746202\n",
      "previous_iter_valid_loss : 0.077286496758461\n",
      "\n",
      "    357600\t  0.078987\t  0.077286\t  0.077465\t\tCURRENT LEARNING RATE: 0.013965752720170107\n",
      "previous_iter_valid_loss : 0.07733574509620667\n",
      "\n",
      "    357800\t  0.079119\t  0.077336\t  0.077461\t\tCURRENT LEARNING RATE: 0.013937849127623508\n",
      "previous_iter_valid_loss : 0.07701611518859863\n",
      "\n",
      "    358000\t  0.078933\t  0.077016\t  0.077463\t\tCURRENT LEARNING RATE: 0.013910001286492009\n",
      "previous_iter_valid_loss : 0.07633940130472183\n",
      "\n",
      "    358200\t  0.077994\t  0.076339\t  0.077463\t\tCURRENT LEARNING RATE: 0.013882209085384196\n",
      "previous_iter_valid_loss : 0.07884082943201065\n",
      "\n",
      "    358400\t  0.080822\t  0.078841\t  0.077466\t\tCURRENT LEARNING RATE: 0.01385447241313124\n",
      "previous_iter_valid_loss : 0.07971063256263733\n",
      "\n",
      "    358600\t  0.081378\t  0.079711\t  0.077476\t\tCURRENT LEARNING RATE: 0.013826791158786404\n",
      "previous_iter_valid_loss : 0.07714110612869263\n",
      "\n",
      "    358800\t  0.078862\t  0.077141\t  0.077480\t\tCURRENT LEARNING RATE: 0.013799165211624644\n",
      "previous_iter_valid_loss : 0.07651245594024658\n",
      "\n",
      "    359000\t  0.078355\t  0.076512\t  0.077481\t\tCURRENT LEARNING RATE: 0.013771594461142124\n",
      "previous_iter_valid_loss : 0.0780508816242218\n",
      "\n",
      "    359200\t  0.080181\t  0.078051\t  0.077488\t\tCURRENT LEARNING RATE: 0.013744078797055817\n",
      "previous_iter_valid_loss : 0.07701877504587173\n",
      "\n",
      "    359400\t  0.079005\t  0.077019\t  0.077492\t\tCURRENT LEARNING RATE: 0.013716618109303016\n",
      "previous_iter_valid_loss : 0.0766216292977333\n",
      "\n",
      "    359600\t  0.078559\t  0.076622\t  0.077493\t\tCURRENT LEARNING RATE: 0.013689212288040948\n",
      "previous_iter_valid_loss : 0.07710306346416473\n",
      "\n",
      "    359800\t  0.079087\t  0.077103\t  0.077493\t\tCURRENT LEARNING RATE: 0.01366186122364628\n",
      "previous_iter_valid_loss : 0.0768115371465683\n",
      "\n",
      "    360000\t  0.078574\t  0.076812\t  0.077492\t\tCURRENT LEARNING RATE: 0.013634564806714726\n",
      "previous_iter_valid_loss : 0.07709767669439316\n",
      "\n",
      "    360200\t  0.078927\t  0.077098\t  0.077480\t\tCURRENT LEARNING RATE: 0.013607322928060573\n",
      "previous_iter_valid_loss : 0.07650289684534073\n",
      "\n",
      "    360400\t  0.078254\t  0.076503\t  0.077483\t\tCURRENT LEARNING RATE: 0.013580135478716282\n",
      "previous_iter_valid_loss : 0.07672931998968124\n",
      "\n",
      "    360600\t  0.078640\t  0.076729\t  0.077465\t\tCURRENT LEARNING RATE: 0.013553002349932007\n",
      "previous_iter_valid_loss : 0.07751372456550598\n",
      "\n",
      "    360800\t  0.079332\t  0.077514\t  0.077455\t\tCURRENT LEARNING RATE: 0.013525923433175208\n",
      "previous_iter_valid_loss : 0.07659755647182465\n",
      "\n",
      "    361000\t  0.078523\t  0.076598\t  0.077442\t\tCURRENT LEARNING RATE: 0.01349889862013017\n",
      "previous_iter_valid_loss : 0.07834462076425552\n",
      "\n",
      "    361200\t  0.080516\t  0.078345\t  0.077448\t\tCURRENT LEARNING RATE: 0.013471927802697617\n",
      "previous_iter_valid_loss : 0.07674096524715424\n",
      "\n",
      "    361400\t  0.078484\t  0.076741\t  0.077450\t\tCURRENT LEARNING RATE: 0.013445010872994231\n",
      "previous_iter_valid_loss : 0.07677638530731201\n",
      "\n",
      "    361600\t  0.078779\t  0.076776\t  0.077439\t\tCURRENT LEARNING RATE: 0.01341814772335227\n",
      "previous_iter_valid_loss : 0.07644109427928925\n",
      "\n",
      "    361800\t  0.078188\t  0.076441\t  0.077418\t\tCURRENT LEARNING RATE: 0.013391338246319088\n",
      "previous_iter_valid_loss : 0.0771632045507431\n",
      "\n",
      "    362000\t  0.079191\t  0.077163\t  0.077422\t\tCURRENT LEARNING RATE: 0.01336458233465675\n",
      "previous_iter_valid_loss : 0.07660520076751709\n",
      "\n",
      "    362200\t  0.078653\t  0.076605\t  0.077423\t\tCURRENT LEARNING RATE: 0.013337879881341566\n",
      "previous_iter_valid_loss : 0.0783924087882042\n",
      "\n",
      "    362400\t  0.080344\t  0.078392\t  0.077407\t\tCURRENT LEARNING RATE: 0.013311230779563699\n",
      "previous_iter_valid_loss : 0.07670959085226059\n",
      "\n",
      "    362600\t  0.078650\t  0.076710\t  0.077408\t\tCURRENT LEARNING RATE: 0.01328463492272669\n",
      "previous_iter_valid_loss : 0.07678955793380737\n",
      "\n",
      "    362800\t  0.078676\t  0.076790\t  0.077408\t\tCURRENT LEARNING RATE: 0.01325809220444709\n",
      "previous_iter_valid_loss : 0.0770556852221489\n",
      "\n",
      "    363000\t  0.078964\t  0.077056\t  0.077407\t\tCURRENT LEARNING RATE: 0.013231602518553981\n",
      "previous_iter_valid_loss : 0.07727383822202682\n",
      "\n",
      "    363200\t  0.079056\t  0.077274\t  0.077410\t\tCURRENT LEARNING RATE: 0.013205165759088594\n",
      "previous_iter_valid_loss : 0.07959851622581482\n",
      "\n",
      "    363400\t  0.081496\t  0.079599\t  0.077427\t\tCURRENT LEARNING RATE: 0.013178781820303844\n",
      "previous_iter_valid_loss : 0.07716810703277588\n",
      "\n",
      "    363600\t  0.078981\t  0.077168\t  0.077420\t\tCURRENT LEARNING RATE: 0.013152450596663954\n",
      "previous_iter_valid_loss : 0.07734900712966919\n",
      "\n",
      "    363800\t  0.079235\t  0.077349\t  0.077425\t\tCURRENT LEARNING RATE: 0.01312617198284398\n",
      "previous_iter_valid_loss : 0.07669758051633835\n",
      "\n",
      "    364000\t  0.078643\t  0.076698\t  0.077407\t\tCURRENT LEARNING RATE: 0.013099945873729445\n",
      "previous_iter_valid_loss : 0.07662979513406754\n",
      "\n",
      "    364200\t  0.078646\t  0.076630\t  0.077407\t\tCURRENT LEARNING RATE: 0.013073772164415867\n",
      "previous_iter_valid_loss : 0.07652492076158524\n",
      "\n",
      "    364400\t  0.078386\t  0.076525\t  0.077404\t\tCURRENT LEARNING RATE: 0.013047650750208382\n",
      "previous_iter_valid_loss : 0.07643306255340576\n",
      "\n",
      "    364600\t  0.078410\t  0.076433\t  0.077404\t\tCURRENT LEARNING RATE: 0.01302158152662129\n",
      "previous_iter_valid_loss : 0.07628633826971054\n",
      "\n",
      "    364800\t  0.078219\t  0.076286\t  0.077402\t\tCURRENT LEARNING RATE: 0.012995564389377674\n",
      "previous_iter_valid_loss : 0.07853132486343384\n",
      "\n",
      "    365000\t  0.080381\t  0.078531\t  0.077412\t\tCURRENT LEARNING RATE: 0.012969599234408935\n",
      "previous_iter_valid_loss : 0.07633815705776215\n",
      "\n",
      "    365200\t  0.078156\t  0.076338\t  0.077411\t\tCURRENT LEARNING RATE: 0.012943685957854433\n",
      "previous_iter_valid_loss : 0.0759144201874733\n",
      "\n",
      "    365400\t  0.077591\t  0.075914\t  0.077408\t\tCURRENT LEARNING RATE: 0.012917824456061013\n",
      "previous_iter_valid_loss : 0.07813172042369843\n",
      "\n",
      "    365600\t  0.079989\t  0.078132\t  0.077414\t\tCURRENT LEARNING RATE: 0.01289201462558265\n",
      "previous_iter_valid_loss : 0.07629398256540298\n",
      "\n",
      "    365800\t  0.078064\t  0.076294\t  0.077408\t\tCURRENT LEARNING RATE: 0.01286625636317997\n",
      "previous_iter_valid_loss : 0.07671071588993073\n",
      "\n",
      "    366000\t  0.078483\t  0.076711\t  0.077380\t\tCURRENT LEARNING RATE: 0.012840549565819906\n",
      "previous_iter_valid_loss : 0.07678284496068954\n",
      "\n",
      "    366200\t  0.078599\t  0.076783\t  0.077376\t\tCURRENT LEARNING RATE: 0.01281489413067522\n",
      "previous_iter_valid_loss : 0.07675988227128983\n",
      "\n",
      "    366400\t  0.078536\t  0.076760\t  0.077370\t\tCURRENT LEARNING RATE: 0.012789289955124147\n",
      "previous_iter_valid_loss : 0.07677853107452393\n",
      "\n",
      "    366600\t  0.078569\t  0.076779\t  0.077353\t\tCURRENT LEARNING RATE: 0.012763736936749943\n",
      "previous_iter_valid_loss : 0.0776786059141159\n",
      "\n",
      "    366800\t  0.079523\t  0.077679\t  0.077360\t\tCURRENT LEARNING RATE: 0.012738234973340508\n",
      "previous_iter_valid_loss : 0.07608287036418915\n",
      "\n",
      "    367000\t  0.077707\t  0.076083\t  0.077358\t\tCURRENT LEARNING RATE: 0.012712783962887947\n",
      "previous_iter_valid_loss : 0.07666192203760147\n",
      "\n",
      "    367200\t  0.078257\t  0.076662\t  0.077355\t\tCURRENT LEARNING RATE: 0.012687383803588193\n",
      "previous_iter_valid_loss : 0.07703423500061035\n",
      "\n",
      "    367400\t  0.078568\t  0.077034\t  0.077338\t\tCURRENT LEARNING RATE: 0.012662034393840563\n",
      "previous_iter_valid_loss : 0.07755281776189804\n",
      "\n",
      "    367600\t  0.079155\t  0.077553\t  0.077338\t\tCURRENT LEARNING RATE: 0.012636735632247398\n",
      "previous_iter_valid_loss : 0.07638664543628693\n",
      "\n",
      "    367800\t  0.078103\t  0.076387\t  0.077320\t\tCURRENT LEARNING RATE: 0.012611487417613606\n",
      "previous_iter_valid_loss : 0.07621533423662186\n",
      "\n",
      "    368000\t  0.077857\t  0.076215\t  0.077320\t\tCURRENT LEARNING RATE: 0.012586289648946303\n",
      "previous_iter_valid_loss : 0.07595892250537872\n",
      "\n",
      "    368200\t  0.077471\t  0.075959\t  0.077306\t\tCURRENT LEARNING RATE: 0.012561142225454375\n",
      "previous_iter_valid_loss : 0.07583913952112198\n",
      "\n",
      "    368400\t  0.077246\t  0.075839\t  0.077296\t\tCURRENT LEARNING RATE: 0.012536045046548101\n",
      "previous_iter_valid_loss : 0.07705502957105637\n",
      "\n",
      "    368600\t  0.078403\t  0.077055\t  0.077293\t\tCURRENT LEARNING RATE: 0.012510998011838722\n",
      "previous_iter_valid_loss : 0.07665080577135086\n",
      "\n",
      "    368800\t  0.078103\t  0.076651\t  0.077291\t\tCURRENT LEARNING RATE: 0.012486001021138077\n",
      "previous_iter_valid_loss : 0.0770983099937439\n",
      "\n",
      "    369000\t  0.078544\t  0.077098\t  0.077294\t\tCURRENT LEARNING RATE: 0.01246105397445816\n",
      "previous_iter_valid_loss : 0.0764540582895279\n",
      "\n",
      "    369200\t  0.077932\t  0.076454\t  0.077280\t\tCURRENT LEARNING RATE: 0.012436156772010761\n",
      "previous_iter_valid_loss : 0.07663381099700928\n",
      "\n",
      "    369400\t  0.078102\t  0.076634\t  0.077280\t\tCURRENT LEARNING RATE: 0.012411309314207026\n",
      "previous_iter_valid_loss : 0.0762115940451622\n",
      "\n",
      "    369600\t  0.077648\t  0.076212\t  0.077279\t\tCURRENT LEARNING RATE: 0.0123865115016571\n",
      "previous_iter_valid_loss : 0.07785164564847946\n",
      "\n",
      "    369800\t  0.079304\t  0.077852\t  0.077282\t\tCURRENT LEARNING RATE: 0.012361763235169694\n",
      "previous_iter_valid_loss : 0.0770624503493309\n",
      "\n",
      "    370000\t  0.078395\t  0.077062\t  0.077285\t\tCURRENT LEARNING RATE: 0.012337064415751714\n",
      "previous_iter_valid_loss : 0.07652673870325089\n",
      "\n",
      "    370200\t  0.077905\t  0.076527\t  0.077286\t\tCURRENT LEARNING RATE: 0.012312414944607842\n",
      "previous_iter_valid_loss : 0.07786688953638077\n",
      "\n",
      "    370400\t  0.079295\t  0.077867\t  0.077294\t\tCURRENT LEARNING RATE: 0.012287814723140169\n",
      "previous_iter_valid_loss : 0.07680415362119675\n",
      "\n",
      "    370600\t  0.078243\t  0.076804\t  0.077292\t\tCURRENT LEARNING RATE: 0.012263263652947769\n",
      "previous_iter_valid_loss : 0.08064019680023193\n",
      "\n",
      "    370800\t  0.081906\t  0.080640\t  0.077281\t\tCURRENT LEARNING RATE: 0.012238761635826335\n",
      "previous_iter_valid_loss : 0.0820888876914978\n",
      "\n",
      "    371000\t  0.083899\t  0.082089\t  0.077300\t\tCURRENT LEARNING RATE: 0.012214308573767759\n",
      "previous_iter_valid_loss : 0.07695912569761276\n",
      "\n",
      "    371200\t  0.078291\t  0.076959\t  0.077300\t\tCURRENT LEARNING RATE: 0.012189904368959769\n",
      "previous_iter_valid_loss : 0.07885240018367767\n",
      "\n",
      "    371400\t  0.080163\t  0.078852\t  0.077311\t\tCURRENT LEARNING RATE: 0.012165548923785501\n",
      "previous_iter_valid_loss : 0.07903245836496353\n",
      "\n",
      "    371600\t  0.080112\t  0.079032\t  0.077319\t\tCURRENT LEARNING RATE: 0.012141242140823155\n",
      "previous_iter_valid_loss : 0.07672128081321716\n",
      "\n",
      "    371800\t  0.078210\t  0.076721\t  0.077312\t\tCURRENT LEARNING RATE: 0.012116983922845556\n",
      "previous_iter_valid_loss : 0.07707273215055466\n",
      "\n",
      "    372000\t  0.078333\t  0.077073\t  0.077312\t\tCURRENT LEARNING RATE: 0.01209277417281981\n",
      "previous_iter_valid_loss : 0.077224001288414\n",
      "\n",
      "    372200\t  0.078422\t  0.077224\t  0.077317\t\tCURRENT LEARNING RATE: 0.012068612793906874\n",
      "previous_iter_valid_loss : 0.07637494057416916\n",
      "\n",
      "    372400\t  0.077515\t  0.076375\t  0.077308\t\tCURRENT LEARNING RATE: 0.012044499689461209\n",
      "previous_iter_valid_loss : 0.07745370268821716\n",
      "\n",
      "    372600\t  0.078608\t  0.077454\t  0.077309\t\tCURRENT LEARNING RATE: 0.012020434763030356\n",
      "previous_iter_valid_loss : 0.07819666713476181\n",
      "\n",
      "    372800\t  0.079424\t  0.078197\t  0.077307\t\tCURRENT LEARNING RATE: 0.011996417918354587\n",
      "previous_iter_valid_loss : 0.07639866322278976\n",
      "\n",
      "    373000\t  0.077663\t  0.076399\t  0.077302\t\tCURRENT LEARNING RATE: 0.011972449059366484\n",
      "previous_iter_valid_loss : 0.07916120439767838\n",
      "\n",
      "    373200\t  0.080570\t  0.079161\t  0.077316\t\tCURRENT LEARNING RATE: 0.011948528090190584\n",
      "previous_iter_valid_loss : 0.07698658853769302\n",
      "\n",
      "    373400\t  0.078138\t  0.076987\t  0.077305\t\tCURRENT LEARNING RATE: 0.011924654915142973\n",
      "previous_iter_valid_loss : 0.07651007175445557\n",
      "\n",
      "    373600\t  0.077775\t  0.076510\t  0.077307\t\tCURRENT LEARNING RATE: 0.011900829438730927\n",
      "previous_iter_valid_loss : 0.07777901738882065\n",
      "\n",
      "    373800\t  0.079013\t  0.077779\t  0.077314\t\tCURRENT LEARNING RATE: 0.011877051565652498\n",
      "previous_iter_valid_loss : 0.08077263087034225\n",
      "\n",
      "    374000\t  0.082193\t  0.080773\t  0.077335\t\tCURRENT LEARNING RATE: 0.011853321200796173\n",
      "previous_iter_valid_loss : 0.07815223932266235\n",
      "\n",
      "    374200\t  0.079586\t  0.078152\t  0.077346\t\tCURRENT LEARNING RATE: 0.01182963824924045\n",
      "previous_iter_valid_loss : 0.07899069041013718\n",
      "\n",
      "    374400\t  0.080444\t  0.078991\t  0.077360\t\tCURRENT LEARNING RATE: 0.011806002616253503\n",
      "previous_iter_valid_loss : 0.07837140560150146\n",
      "\n",
      "    374600\t  0.079595\t  0.078371\t  0.077358\t\tCURRENT LEARNING RATE: 0.011782414207292756\n",
      "previous_iter_valid_loss : 0.07718580216169357\n",
      "\n",
      "    374800\t  0.078483\t  0.077186\t  0.077363\t\tCURRENT LEARNING RATE: 0.011758872928004553\n",
      "previous_iter_valid_loss : 0.07696011662483215\n",
      "\n",
      "    375000\t  0.078375\t  0.076960\t  0.077363\t\tCURRENT LEARNING RATE: 0.011735378684223743\n",
      "previous_iter_valid_loss : 0.07864397019147873\n",
      "\n",
      "    375200\t  0.080134\t  0.078644\t  0.077373\t\tCURRENT LEARNING RATE: 0.011711931381973309\n",
      "previous_iter_valid_loss : 0.07748638838529587\n",
      "\n",
      "    375400\t  0.078848\t  0.077486\t  0.077379\t\tCURRENT LEARNING RATE: 0.011688530927464027\n",
      "previous_iter_valid_loss : 0.07695481181144714\n",
      "\n",
      "    375600\t  0.078261\t  0.076955\t  0.077360\t\tCURRENT LEARNING RATE: 0.011665177227094032\n",
      "previous_iter_valid_loss : 0.07750435918569565\n",
      "\n",
      "    375800\t  0.079002\t  0.077504\t  0.077367\t\tCURRENT LEARNING RATE: 0.011641870187448505\n",
      "previous_iter_valid_loss : 0.07740677148103714\n",
      "\n",
      "    376000\t  0.078878\t  0.077407\t  0.077372\t\tCURRENT LEARNING RATE: 0.011618609715299244\n",
      "previous_iter_valid_loss : 0.07913707196712494\n",
      "\n",
      "    376200\t  0.080448\t  0.079137\t  0.077385\t\tCURRENT LEARNING RATE: 0.011595395717604342\n",
      "previous_iter_valid_loss : 0.08042363077402115\n",
      "\n",
      "    376400\t  0.081942\t  0.080424\t  0.077406\t\tCURRENT LEARNING RATE: 0.011572228101507766\n",
      "previous_iter_valid_loss : 0.0791897103190422\n",
      "\n",
      "    376600\t  0.080537\t  0.079190\t  0.077420\t\tCURRENT LEARNING RATE: 0.01154910677433903\n",
      "previous_iter_valid_loss : 0.07907158136367798\n",
      "\n",
      "    376800\t  0.080387\t  0.079072\t  0.077433\t\tCURRENT LEARNING RATE: 0.011526031643612785\n",
      "previous_iter_valid_loss : 0.07997789233922958\n",
      "\n",
      "    377000\t  0.081333\t  0.079978\t  0.077451\t\tCURRENT LEARNING RATE: 0.011503002617028487\n",
      "previous_iter_valid_loss : 0.07838600128889084\n",
      "\n",
      "    377200\t  0.079727\t  0.078386\t  0.077443\t\tCURRENT LEARNING RATE: 0.011480019602469992\n",
      "previous_iter_valid_loss : 0.07819154113531113\n",
      "\n",
      "    377400\t  0.079618\t  0.078192\t  0.077443\t\tCURRENT LEARNING RATE: 0.011457082508005216\n",
      "previous_iter_valid_loss : 0.07867752760648727\n",
      "\n",
      "    377600\t  0.080245\t  0.078678\t  0.077448\t\tCURRENT LEARNING RATE: 0.011434191241885744\n",
      "previous_iter_valid_loss : 0.07754750549793243\n",
      "\n",
      "    377800\t  0.079050\t  0.077548\t  0.077452\t\tCURRENT LEARNING RATE: 0.01141134571254649\n",
      "previous_iter_valid_loss : 0.07844675332307816\n",
      "\n",
      "    378000\t  0.079901\t  0.078447\t  0.077450\t\tCURRENT LEARNING RATE: 0.011388545828605297\n",
      "previous_iter_valid_loss : 0.07914549857378006\n",
      "\n",
      "    378200\t  0.080798\t  0.079145\t  0.077460\t\tCURRENT LEARNING RATE: 0.011365791498862608\n",
      "previous_iter_valid_loss : 0.07794052362442017\n",
      "\n",
      "    378400\t  0.079605\t  0.077941\t  0.077468\t\tCURRENT LEARNING RATE: 0.011343082632301063\n",
      "previous_iter_valid_loss : 0.07726390659809113\n",
      "\n",
      "    378600\t  0.078841\t  0.077264\t  0.077471\t\tCURRENT LEARNING RATE: 0.011320419138085177\n",
      "previous_iter_valid_loss : 0.07847824692726135\n",
      "\n",
      "    378800\t  0.079981\t  0.078478\t  0.077467\t\tCURRENT LEARNING RATE: 0.011297800925560932\n",
      "previous_iter_valid_loss : 0.07969048619270325\n",
      "\n",
      "    379000\t  0.081379\t  0.079690\t  0.077481\t\tCURRENT LEARNING RATE: 0.011275227904255457\n",
      "previous_iter_valid_loss : 0.0858745202422142\n",
      "\n",
      "    379200\t  0.087611\t  0.085875\t  0.077523\t\tCURRENT LEARNING RATE: 0.01125269998387663\n",
      "previous_iter_valid_loss : 0.07799787819385529\n",
      "\n",
      "    379400\t  0.079717\t  0.077998\t  0.077531\t\tCURRENT LEARNING RATE: 0.011230217074312746\n",
      "previous_iter_valid_loss : 0.08287616074085236\n",
      "\n",
      "    379600\t  0.084776\t  0.082876\t  0.077525\t\tCURRENT LEARNING RATE: 0.011207779085632127\n",
      "previous_iter_valid_loss : 0.07860346138477325\n",
      "\n",
      "    379800\t  0.080089\t  0.078603\t  0.077519\t\tCURRENT LEARNING RATE: 0.0111853859280828\n",
      "previous_iter_valid_loss : 0.07840824872255325\n",
      "\n",
      "    380000\t  0.080002\t  0.078408\t  0.077527\t\tCURRENT LEARNING RATE: 0.011163037512092093\n",
      "previous_iter_valid_loss : 0.07941290736198425\n",
      "\n",
      "    380200\t  0.080898\t  0.079413\t  0.077539\t\tCURRENT LEARNING RATE: 0.011140733748266326\n",
      "previous_iter_valid_loss : 0.08108209073543549\n",
      "\n",
      "    380400\t  0.082738\t  0.081082\t  0.077561\t\tCURRENT LEARNING RATE: 0.0111184745473904\n",
      "previous_iter_valid_loss : 0.07782264798879623\n",
      "\n",
      "    380600\t  0.079257\t  0.077823\t  0.077565\t\tCURRENT LEARNING RATE: 0.011096259820427492\n",
      "previous_iter_valid_loss : 0.07853478938341141\n",
      "\n",
      "    380800\t  0.080224\t  0.078535\t  0.077562\t\tCURRENT LEARNING RATE: 0.011074089478518657\n",
      "previous_iter_valid_loss : 0.08072081208229065\n",
      "\n",
      "    381000\t  0.082292\t  0.080721\t  0.077580\t\tCURRENT LEARNING RATE: 0.011051963432982507\n",
      "previous_iter_valid_loss : 0.08125617355108261\n",
      "\n",
      "    381200\t  0.082855\t  0.081256\t  0.077603\t\tCURRENT LEARNING RATE: 0.011029881595314818\n",
      "previous_iter_valid_loss : 0.08017680794000626\n",
      "\n",
      "    381400\t  0.081667\t  0.080177\t  0.077619\t\tCURRENT LEARNING RATE: 0.011007843877188225\n",
      "previous_iter_valid_loss : 0.07766926288604736\n",
      "\n",
      "    381600\t  0.079169\t  0.077669\t  0.077620\t\tCURRENT LEARNING RATE: 0.010985850190451809\n",
      "previous_iter_valid_loss : 0.07950197905302048\n",
      "\n",
      "    381800\t  0.080948\t  0.079502\t  0.077634\t\tCURRENT LEARNING RATE: 0.01096390044713081\n",
      "previous_iter_valid_loss : 0.07896736264228821\n",
      "\n",
      "    382000\t  0.080346\t  0.078967\t  0.077642\t\tCURRENT LEARNING RATE: 0.010941994559426212\n",
      "previous_iter_valid_loss : 0.07860593497753143\n",
      "\n",
      "    382200\t  0.079886\t  0.078606\t  0.077645\t\tCURRENT LEARNING RATE: 0.010920132439714448\n",
      "previous_iter_valid_loss : 0.07835125923156738\n",
      "\n",
      "    382400\t  0.079719\t  0.078351\t  0.077647\t\tCURRENT LEARNING RATE: 0.010898314000546996\n",
      "previous_iter_valid_loss : 0.07982537150382996\n",
      "\n",
      "    382600\t  0.081374\t  0.079825\t  0.077656\t\tCURRENT LEARNING RATE: 0.010876539154650082\n",
      "previous_iter_valid_loss : 0.07985270768404007\n",
      "\n",
      "    382800\t  0.081275\t  0.079853\t  0.077662\t\tCURRENT LEARNING RATE: 0.010854807814924285\n",
      "previous_iter_valid_loss : 0.08072260767221451\n",
      "\n",
      "    383000\t  0.082037\t  0.080723\t  0.077680\t\tCURRENT LEARNING RATE: 0.010833119894444226\n",
      "previous_iter_valid_loss : 0.07893472909927368\n",
      "\n",
      "    383200\t  0.080221\t  0.078935\t  0.077691\t\tCURRENT LEARNING RATE: 0.010811475306458183\n",
      "previous_iter_valid_loss : 0.07772441953420639\n",
      "\n",
      "    383400\t  0.079133\t  0.077724\t  0.077686\t\tCURRENT LEARNING RATE: 0.010789873964387787\n",
      "previous_iter_valid_loss : 0.08414940536022186\n",
      "\n",
      "    383600\t  0.085891\t  0.084149\t  0.077724\t\tCURRENT LEARNING RATE: 0.01076831578182763\n",
      "previous_iter_valid_loss : 0.08088558167219162\n",
      "\n",
      "    383800\t  0.082445\t  0.080886\t  0.077743\t\tCURRENT LEARNING RATE: 0.010746800672544961\n",
      "previous_iter_valid_loss : 0.08032240718603134\n",
      "\n",
      "    384000\t  0.081665\t  0.080322\t  0.077760\t\tCURRENT LEARNING RATE: 0.010725328550479307\n",
      "previous_iter_valid_loss : 0.08016557991504669\n",
      "\n",
      "    384200\t  0.081484\t  0.080166\t  0.077779\t\tCURRENT LEARNING RATE: 0.010703899329742162\n",
      "previous_iter_valid_loss : 0.08029471337795258\n",
      "\n",
      "    384400\t  0.081844\t  0.080295\t  0.077794\t\tCURRENT LEARNING RATE: 0.010682512924616602\n",
      "previous_iter_valid_loss : 0.07926661521196365\n",
      "\n",
      "    384600\t  0.080694\t  0.079267\t  0.077791\t\tCURRENT LEARNING RATE: 0.01066116924955699\n",
      "previous_iter_valid_loss : 0.08125099539756775\n",
      "\n",
      "    384800\t  0.082711\t  0.081251\t  0.077812\t\tCURRENT LEARNING RATE: 0.010639868219188584\n",
      "previous_iter_valid_loss : 0.08235231041908264\n",
      "\n",
      "    385000\t  0.084118\t  0.082352\t  0.077831\t\tCURRENT LEARNING RATE: 0.010618609748307247\n",
      "previous_iter_valid_loss : 0.07988487929105759\n",
      "\n",
      "    385200\t  0.081486\t  0.079885\t  0.077829\t\tCURRENT LEARNING RATE: 0.010597393751879056\n",
      "previous_iter_valid_loss : 0.08246493339538574\n",
      "\n",
      "    385400\t  0.084373\t  0.082465\t  0.077858\t\tCURRENT LEARNING RATE: 0.010576220145040009\n",
      "previous_iter_valid_loss : 0.08093588799238205\n",
      "\n",
      "    385600\t  0.082625\t  0.080936\t  0.077875\t\tCURRENT LEARNING RATE: 0.010555088843095637\n",
      "previous_iter_valid_loss : 0.08046533167362213\n",
      "\n",
      "    385800\t  0.082104\t  0.080465\t  0.077882\t\tCURRENT LEARNING RATE: 0.010533999761520717\n",
      "previous_iter_valid_loss : 0.0786115750670433\n",
      "\n",
      "    386000\t  0.080146\t  0.078612\t  0.077881\t\tCURRENT LEARNING RATE: 0.010512952815958883\n",
      "previous_iter_valid_loss : 0.07979045063257217\n",
      "\n",
      "    386200\t  0.081409\t  0.079790\t  0.077896\t\tCURRENT LEARNING RATE: 0.010491947922222335\n",
      "previous_iter_valid_loss : 0.0791616439819336\n",
      "\n",
      "    386400\t  0.080808\t  0.079162\t  0.077896\t\tCURRENT LEARNING RATE: 0.01047098499629146\n",
      "previous_iter_valid_loss : 0.08095131069421768\n",
      "\n",
      "    386600\t  0.082387\t  0.080951\t  0.077910\t\tCURRENT LEARNING RATE: 0.010450063954314536\n",
      "previous_iter_valid_loss : 0.08011318743228912\n",
      "\n",
      "    386800\t  0.081516\t  0.080113\t  0.077929\t\tCURRENT LEARNING RATE: 0.010429184712607358\n",
      "previous_iter_valid_loss : 0.08263865113258362\n",
      "\n",
      "    387000\t  0.084040\t  0.082639\t  0.077957\t\tCURRENT LEARNING RATE: 0.010408347187652942\n",
      "previous_iter_valid_loss : 0.08040661364793777\n",
      "\n",
      "    387200\t  0.081818\t  0.080407\t  0.077975\t\tCURRENT LEARNING RATE: 0.010387551296101149\n",
      "previous_iter_valid_loss : 0.07997524738311768\n",
      "\n",
      "    387400\t  0.081511\t  0.079975\t  0.077989\t\tCURRENT LEARNING RATE: 0.010366796954768396\n",
      "previous_iter_valid_loss : 0.07952757924795151\n",
      "\n",
      "    387600\t  0.080831\t  0.079528\t  0.077998\t\tCURRENT LEARNING RATE: 0.010346084080637278\n",
      "previous_iter_valid_loss : 0.0815708264708519\n",
      "\n",
      "    387800\t  0.083093\t  0.081571\t  0.078019\t\tCURRENT LEARNING RATE: 0.010325412590856283\n",
      "previous_iter_valid_loss : 0.08391210436820984\n",
      "\n",
      "    388000\t  0.085364\t  0.083912\t  0.078054\t\tCURRENT LEARNING RATE: 0.010304782402739413\n",
      "previous_iter_valid_loss : 0.07935831695795059\n",
      "\n",
      "    388200\t  0.080766\t  0.079358\t  0.078052\t\tCURRENT LEARNING RATE: 0.0102841934337659\n",
      "previous_iter_valid_loss : 0.07925951480865479\n",
      "\n",
      "    388400\t  0.080659\t  0.079260\t  0.078066\t\tCURRENT LEARNING RATE: 0.01026364560157983\n",
      "previous_iter_valid_loss : 0.07929857820272446\n",
      "\n",
      "    388600\t  0.080790\t  0.079299\t  0.078072\t\tCURRENT LEARNING RATE: 0.010243138823989853\n",
      "previous_iter_valid_loss : 0.08046720176935196\n",
      "\n",
      "    388800\t  0.081904\t  0.080467\t  0.078092\t\tCURRENT LEARNING RATE: 0.010222673018968826\n",
      "previous_iter_valid_loss : 0.07979205995798111\n",
      "\n",
      "    389000\t  0.081180\t  0.079792\t  0.078108\t\tCURRENT LEARNING RATE: 0.01020224810465351\n",
      "previous_iter_valid_loss : 0.08188638091087341\n",
      "\n",
      "    389200\t  0.083323\t  0.081886\t  0.078130\t\tCURRENT LEARNING RATE: 0.010181863999344213\n",
      "previous_iter_valid_loss : 0.08003916591405869\n",
      "\n",
      "    389400\t  0.081412\t  0.080039\t  0.078146\t\tCURRENT LEARNING RATE: 0.010161520621504492\n",
      "previous_iter_valid_loss : 0.08161085098981857\n",
      "\n",
      "    389600\t  0.083217\t  0.081611\t  0.078167\t\tCURRENT LEARNING RATE: 0.0101412178897608\n",
      "previous_iter_valid_loss : 0.08068809658288956\n",
      "\n",
      "    389800\t  0.082053\t  0.080688\t  0.078187\t\tCURRENT LEARNING RATE: 0.010120955722902196\n",
      "previous_iter_valid_loss : 0.08422339707612991\n",
      "\n",
      "    390000\t  0.085621\t  0.084223\t  0.078226\t\tCURRENT LEARNING RATE: 0.010100734039879971\n",
      "previous_iter_valid_loss : 0.08160330355167389\n",
      "\n",
      "    390200\t  0.083138\t  0.081603\t  0.078250\t\tCURRENT LEARNING RATE: 0.01008055275980738\n",
      "previous_iter_valid_loss : 0.08540606498718262\n",
      "\n",
      "    390400\t  0.086795\t  0.085406\t  0.078281\t\tCURRENT LEARNING RATE: 0.010060411801959263\n",
      "previous_iter_valid_loss : 0.08014486730098724\n",
      "\n",
      "    390600\t  0.081616\t  0.080145\t  0.078296\t\tCURRENT LEARNING RATE: 0.010040311085771771\n",
      "previous_iter_valid_loss : 0.08057187497615814\n",
      "\n",
      "    390800\t  0.082079\t  0.080572\t  0.078305\t\tCURRENT LEARNING RATE: 0.010020250530842007\n",
      "previous_iter_valid_loss : 0.08115087449550629\n",
      "\n",
      "    391000\t  0.082730\t  0.081151\t  0.078329\t\tCURRENT LEARNING RATE: 0.01000023005692773\n",
      "previous_iter_valid_loss : 0.08000563830137253\n",
      "\n",
      "    391200\t  0.081456\t  0.080006\t  0.078344\t\tCURRENT LEARNING RATE: 0.00998024958394701\n",
      "previous_iter_valid_loss : 0.08081632852554321\n",
      "\n",
      "    391400\t  0.082404\t  0.080816\t  0.078364\t\tCURRENT LEARNING RATE: 0.009960309031977938\n",
      "previous_iter_valid_loss : 0.08040539920330048\n",
      "\n",
      "    391600\t  0.081916\t  0.080405\t  0.078381\t\tCURRENT LEARNING RATE: 0.00994040832125827\n",
      "previous_iter_valid_loss : 0.08174282312393188\n",
      "\n",
      "    391800\t  0.083152\t  0.081743\t  0.078392\t\tCURRENT LEARNING RATE: 0.009920547372185144\n",
      "previous_iter_valid_loss : 0.08211209625005722\n",
      "\n",
      "    392000\t  0.083679\t  0.082112\t  0.078417\t\tCURRENT LEARNING RATE: 0.009900726105314731\n",
      "previous_iter_valid_loss : 0.080793596804142\n",
      "\n",
      "    392200\t  0.082262\t  0.080794\t  0.078433\t\tCURRENT LEARNING RATE: 0.009880944441361943\n",
      "previous_iter_valid_loss : 0.08108942210674286\n",
      "\n",
      "    392400\t  0.082655\t  0.081089\t  0.078456\t\tCURRENT LEARNING RATE: 0.009861202301200092\n",
      "previous_iter_valid_loss : 0.085257388651371\n",
      "\n",
      "    392600\t  0.086825\t  0.085257\t  0.078496\t\tCURRENT LEARNING RATE: 0.009841499605860598\n",
      "previous_iter_valid_loss : 0.08005562424659729\n",
      "\n",
      "    392800\t  0.081591\t  0.080056\t  0.078511\t\tCURRENT LEARNING RATE: 0.009821836276532646\n",
      "previous_iter_valid_loss : 0.081595279276371\n",
      "\n",
      "    393000\t  0.083021\t  0.081595\t  0.078537\t\tCURRENT LEARNING RATE: 0.0098022122345629\n",
      "previous_iter_valid_loss : 0.08006267249584198\n",
      "\n",
      "    393200\t  0.081540\t  0.080063\t  0.078555\t\tCURRENT LEARNING RATE: 0.009782627401455156\n",
      "previous_iter_valid_loss : 0.08283745497465134\n",
      "\n",
      "    393400\t  0.084250\t  0.082837\t  0.078588\t\tCURRENT LEARNING RATE: 0.009763081698870068\n",
      "previous_iter_valid_loss : 0.08063416182994843\n",
      "\n",
      "    393600\t  0.081977\t  0.080634\t  0.078609\t\tCURRENT LEARNING RATE: 0.009743575048624786\n",
      "previous_iter_valid_loss : 0.08015810698270798\n",
      "\n",
      "    393800\t  0.081619\t  0.080158\t  0.078626\t\tCURRENT LEARNING RATE: 0.009724107372692695\n",
      "previous_iter_valid_loss : 0.08055076748132706\n",
      "\n",
      "    394000\t  0.081821\t  0.080551\t  0.078643\t\tCURRENT LEARNING RATE: 0.009704678593203057\n",
      "previous_iter_valid_loss : 0.08427666872739792\n",
      "\n",
      "    394200\t  0.085739\t  0.084277\t  0.078684\t\tCURRENT LEARNING RATE: 0.009685288632440735\n",
      "previous_iter_valid_loss : 0.07992760837078094\n",
      "\n",
      "    394400\t  0.081323\t  0.079928\t  0.078696\t\tCURRENT LEARNING RATE: 0.009665937412845852\n",
      "previous_iter_valid_loss : 0.08689001202583313\n",
      "\n",
      "    394600\t  0.088172\t  0.086890\t  0.078728\t\tCURRENT LEARNING RATE: 0.009646624857013513\n",
      "previous_iter_valid_loss : 0.08577938377857208\n",
      "\n",
      "    394800\t  0.087205\t  0.085779\t  0.078772\t\tCURRENT LEARNING RATE: 0.00962735088769346\n",
      "previous_iter_valid_loss : 0.08048128336668015\n",
      "\n",
      "    395000\t  0.081893\t  0.080481\t  0.078790\t\tCURRENT LEARNING RATE: 0.009608115427789799\n",
      "previous_iter_valid_loss : 0.08074235171079636\n",
      "\n",
      "    395200\t  0.082066\t  0.080742\t  0.078809\t\tCURRENT LEARNING RATE: 0.009588918400360654\n",
      "previous_iter_valid_loss : 0.08092077076435089\n",
      "\n",
      "    395400\t  0.082183\t  0.080921\t  0.078827\t\tCURRENT LEARNING RATE: 0.009569759728617903\n",
      "previous_iter_valid_loss : 0.08080679178237915\n",
      "\n",
      "    395600\t  0.082007\t  0.080807\t  0.078848\t\tCURRENT LEARNING RATE: 0.009550639335926819\n",
      "previous_iter_valid_loss : 0.08050259202718735\n",
      "\n",
      "    395800\t  0.081753\t  0.080503\t  0.078867\t\tCURRENT LEARNING RATE: 0.009531557145805818\n",
      "previous_iter_valid_loss : 0.08245866745710373\n",
      "\n",
      "    396000\t  0.083680\t  0.082459\t  0.078893\t\tCURRENT LEARNING RATE: 0.009512513081926105\n",
      "previous_iter_valid_loss : 0.08201668411493301\n",
      "\n",
      "    396200\t  0.083327\t  0.082017\t  0.078918\t\tCURRENT LEARNING RATE: 0.009493507068111407\n",
      "previous_iter_valid_loss : 0.08081725984811783\n",
      "\n",
      "    396400\t  0.082172\t  0.080817\t  0.078934\t\tCURRENT LEARNING RATE: 0.009474539028337635\n",
      "previous_iter_valid_loss : 0.08099082857370377\n",
      "\n",
      "    396600\t  0.082324\t  0.080991\t  0.078954\t\tCURRENT LEARNING RATE: 0.009455608886732613\n",
      "previous_iter_valid_loss : 0.08122722059488297\n",
      "\n",
      "    396800\t  0.082524\t  0.081227\t  0.078974\t\tCURRENT LEARNING RATE: 0.009436716567575743\n",
      "previous_iter_valid_loss : 0.08035797625780106\n",
      "\n",
      "    397000\t  0.081776\t  0.080358\t  0.078992"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4109212/316153099.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0mtraces_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraces_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0mtraces_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraces_window\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0msave_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m )\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Pulled_Github_Repositories/torchQN/utils/utils.py\u001b[0m in \u001b[0;36mwrapper_timer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"timing this arbitrary function\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mrun_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4109212/1472050648.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(target, model, train_x, train_t, valid_x, valid_t, traces, PARAMS, traces_step, traces_window, save_model)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0mtraces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraces_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m         \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraces_window\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m     )\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4109212/1472050648.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(target, model, avloss, getbatch, train_x, train_t, valid_x, valid_t, PARAMS, traces, step, window)\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# no need to compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;31m# wrt. x and t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "target = \"RecoDatapT\"\n",
    "source = FIELDS[target]\n",
    "features = source[\"inputs\"]\n",
    "print(\"Training Features:\\n\", features)\n",
    "print(\"\\nTarget = \", target)\n",
    "\n",
    "print(\"USING NEW DATASET\\n\")\n",
    "######################################\n",
    "USE_BRADEN_SCALING=False\n",
    "#####################################\n",
    "################################### CONFIGURATIONS ###################################\n",
    "\n",
    "JUPYTER = True\n",
    "use_subsample = False\n",
    "# use_subsample = True\n",
    "if use_subsample:\n",
    "    SUBSAMPLE = int(\n",
    "        1e5\n",
    "    )  # subsample use for development - in production use whole dataset\n",
    "else:\n",
    "    SUBSAMPLE = None\n",
    "\n",
    "# Load scaled data\n",
    "# scaled_train_data, scaled_test_data, scaled_valid_data = load_scaled_dataframes()\n",
    "\n",
    "\n",
    "# Get targets and features\n",
    "# if USE_BRADEN_SCALING==True:\n",
    "#     print(f\"spliting data for {target}\")\n",
    "#     train_t, train_x = split_t_x(\n",
    "#         df=scaled_train_data, target=target, input_features=features\n",
    "#     )\n",
    "#     print(\"train_t shape = \", train_t.shape, \"train_x shape = \", train_x.shape)\n",
    "#     print(\"\\n Training features:\\n\")\n",
    "#     print(train_x)\n",
    "#     valid_t, valid_x = split_t_x(\n",
    "#         df=scaled_valid_data, target=target, input_features=features\n",
    "#     )\n",
    "#     print(\"valid_t shape = \", valid_t.shape, \"valid_x shape = \", valid_x.shape)\n",
    "#     test_t, test_x = split_t_x(df=scaled_test_data, target=target, input_features=features)\n",
    "#     print(\"test_t shape = \", test_t.shape, \"test_x shape = \", test_x.shape)\n",
    "\n",
    "# else:\n",
    "#     print(f\"spliting data for {target}\")\n",
    "#     train_t, train_x = normal_split_t_x(\n",
    "#     df=raw_train_data, target=target, input_features=features\n",
    "#     )\n",
    "#     print(\"train_t shape = \", train_t.shape, \"train_x shape = \", train_x.shape)\n",
    "#     print(\"\\n Training features:\\n\")\n",
    "#     print(train_x)\n",
    "#     valid_t, valid_x = normal_split_t_x(\n",
    "#     df=raw_valid_data, target=target, input_features=features\n",
    "#     )\n",
    "#     print(\"valid_t shape = \", valid_t.shape, \"valid_x shape = \", valid_x.shape)\n",
    "#     test_t, test_x = normal_split_t_x(df=raw_test_data, target=target, input_features=features)\n",
    "#     print(\"test_t shape = \", test_t.shape, \"test_x shape = \", test_x.shape)\n",
    "\n",
    "\n",
    "print(f\"spliting data for {target}\")\n",
    "train_t, train_x = normal_split_t_x(\n",
    "df=raw_train_data, target=target, input_features=features\n",
    ")\n",
    "print(\"train_t shape = \", train_t.shape, \"train_x shape = \", train_x.shape)\n",
    "print(\"\\n Training features:\\n\")\n",
    "print(train_x)\n",
    "valid_t, valid_x = normal_split_t_x(\n",
    "df=raw_valid_data, target=target, input_features=features\n",
    ")\n",
    "print(\"valid_t shape = \", valid_t.shape, \"valid_x shape = \", valid_x.shape)\n",
    "test_t, test_x = normal_split_t_x(df=raw_test_data, target=target, input_features=features)\n",
    "print(\"test_t shape = \", test_t.shape, \"test_x shape = \", test_x.shape)\n",
    "\n",
    "\n",
    "print(\"no need to train_test_split since we already have the split dataframes\")\n",
    "print(valid_x.mean(axis=0), valid_x.std(axis=0))\n",
    "print(train_x.mean(axis=0), train_x.std(axis=0))\n",
    "print(valid_t.mean(), valid_t.std())\n",
    "print(train_t.mean(), train_t.std())\n",
    "NFEATURES = train_x.shape[1]\n",
    "######################################################\n",
    "\n",
    "# Apply z scaling to features and targets\n",
    "# to features\n",
    "TRAIN_SCALE_DICT=get_train_scale_dict(USE_BRADEN_SCALING)\n",
    "apply_z_generator = apply_z_to_features(TRAIN_SCALE_DICT, train_x, test_x, valid_x)\n",
    "train_x_z_scaled = next(apply_z_generator)\n",
    "test_x_z_scaled = next(apply_z_generator)\n",
    "valid_x_z_scaled = next(apply_z_generator)\n",
    "print(valid_x_z_scaled.mean(axis=0), valid_x_z_scaled.std(axis=0))\n",
    "print(train_x_z_scaled.mean(axis=0), train_x_z_scaled.std(axis=0))\n",
    "\n",
    "# to targets\n",
    "apply_z_to_targets_generator = apply_z_to_targets(\n",
    "    train_t, test_t, valid_t\n",
    ")\n",
    "train_t_z_scaled = next(apply_z_to_targets_generator)\n",
    "test_t_z_scaled = next(apply_z_to_targets_generator)\n",
    "valid_t_z_scaled = next(apply_z_to_targets_generator)\n",
    "print(valid_t_z_scaled.mean(), valid_t_z_scaled.std())\n",
    "print(train_t_z_scaled.mean(), train_t_z_scaled.std())\n",
    "\n",
    "\n",
    "\n",
    "###########################################################\n",
    "# Decide on parameters for this model and training\n",
    "PARAMS_pT = {\n",
    "\"n_layers\": int(4),\n",
    "\"hidden_size\": int(6),\n",
    "\"dropout_1\": float(0.6),\n",
    "\"dropout_2\": float(0.1),\n",
    "\"activation\": \"LeakyReLU\",\n",
    "    'optimizer_name':'Adam',\n",
    "    'starting_learning_rate':float(0.5),\n",
    "    'momentum':float(0.6),\n",
    "    'batch_size':int(1024),\n",
    "    'n_iterations': int(5e5),\n",
    "}\n",
    "\n",
    "optimizer_name=PARAMS_pT['optimizer_name']\n",
    "print(type(optimizer_name))\n",
    "# optimizer_name = BEST_PARAMS[\"optimizer_name\"].to_string().split()[1]\n",
    "NITERATIONS=PARAMS_pT['n_iterations']\n",
    "BATCHSIZE=PARAMS_pT['batch_size']\n",
    "comment=''\n",
    "\n",
    "\n",
    "\n",
    "# N_epochs X N_train_examples = N_iterations X batch_size\n",
    "N_epochs = (NITERATIONS * BATCHSIZE) / int(train_x.shape[0])\n",
    "print(f\"training for {NITERATIONS} iteration, which is  {N_epochs} epochs\")\n",
    "\n",
    "#train model from scratch\n",
    "filename_model = utils.get_model_filename(target, PARAMS_pT)\n",
    "#or pick up trained model\n",
    "# filename_model = 'Trained_IQNx4_RecoDatapT_10_layer6_hiddenLeakyReLU_activation512_batchsize300_Kiteration.dict'\n",
    "\n",
    "trained_models_dir = \"trained_models\"\n",
    "utils.mkdir(trained_models_dir)\n",
    "# on cluster, Im using another TRAIN directory\n",
    "PATH_model = os.path.join(\n",
    "    IQN_BASE, #the loaction of the repo\n",
    "    \"JupyterBook\", #up tp TRAIN could be combined in a srs dicretory\n",
    "    \"Cluster\", \n",
    "    \"TRAIN\",\n",
    "    trained_models_dir, #/trained_models \n",
    "    filename_model # utils.get_model_filename has the saved file format \n",
    ")\n",
    "\n",
    "#LOAD EITHER TRAINED OR UNTRAINED MODEL\n",
    "# to load untrained model (start training from scratch), uncomment the next line\n",
    "untrained_model = load_untrained_model(PARAMS_pT)\n",
    "# to continune training of model (pickup where the previous training left off), uncomment below\n",
    "# trained_model =load_trained_model(PATH=PATH_model, PARAMS=PARAMS_pT)\n",
    "\n",
    "IQN_trace = ([], [], [], [])\n",
    "traces_step = 200\n",
    "traces_window = traces_step\n",
    "IQN = run(\n",
    "    target=target,\n",
    "    model=untrained_model,\n",
    "    train_x=train_x_z_scaled,\n",
    "    train_t=train_t_z_scaled,\n",
    "    valid_x=test_x_z_scaled,\n",
    "    valid_t=test_t_z_scaled,\n",
    "    traces=IQN_trace,\n",
    "    PARAMS=PARAMS_pT,\n",
    "    traces_step=traces_step,\n",
    "    traces_window=traces_window,\n",
    "    save_model=False,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "SAVE_LAST_MODEL=False\n",
    "if SAVE_LAST_MODEL:\n",
    "    # ## Save last iteration of trained model \n",
    "    #dont save the last model, it might be worse than previous iterations, which were automatically savedby model checkpoints\n",
    "\n",
    "    final_path = utils.get_model_filename(target, PARAMS_pT).split('.dict')[0]+'_FINAL.dict'\n",
    "\n",
    "    trained_models_dir = \"trained_models\"\n",
    "    utils.mkdir(trained_models_dir)\n",
    "    # on cluster, Im using another TRAIN directory\n",
    "    PATH_final_model = os.path.join(\n",
    "    IQN_BASE, \"JupyterBook\", \"Cluster\", \"TRAIN\", trained_models_dir, final_path\n",
    "    )\n",
    "\n",
    "    save_model(IQN, PATH_final_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f98e6c-b1af-4b28-853f-25121451acc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to continune training of model (pickup where the previous training left off), uncomment below\n",
    "trained_model =load_trained_model(PATH=PATH_model, PARAMS=PARAMS_pT)\n",
    "\n",
    "IQN_trace = ([], [], [], [])\n",
    "traces_step = 20\n",
    "traces_window = traces_step\n",
    "IQN = run(\n",
    "    target=target,\n",
    "    model=trained_model,\n",
    "    train_x=train_x_z_scaled,\n",
    "    train_t=train_t_z_scaled,\n",
    "    valid_x=test_x_z_scaled,\n",
    "    valid_t=test_t_z_scaled,\n",
    "    traces=IQN_trace,\n",
    "    PARAMS=PARAMS_pT,\n",
    "    traces_step=traces_step,\n",
    "    traces_window=traces_window,\n",
    "    save_model=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb6e75c-af85-4e41-9c7b-591ae354c773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
